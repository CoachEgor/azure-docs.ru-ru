---
title: Azure Data Lake Storage Gen1 - настройка производительности
description: Описывает, как настроить данные Azure Data Lake Storage Gen1 для производительности.
author: stewu
ms.service: data-lake-store
ms.topic: conceptual
ms.date: 06/30/2017
ms.author: stewu
ms.openlocfilehash: 2521700e0f07691541ee6cbbf085a8be72f08129
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "73904626"
---
# <a name="tune-azure-data-lake-storage-gen1-for-performance"></a>Настройте хранилище Azure Data Lake Data Gen1 для производительности

Data Lake Storage Gen1 поддерживает высокую пропускную емкость интенсивной аналитики и передачи данных. В Data Lake Storage 1-го поколения важно использовать всю доступную пропускную способность (объем данных, которые можно читать или записывать в секунду), чтобы обеспечить высокую производительность. Для этого нужно выполнить как можно больше операций чтения и записи параллельно.

![Производительность Data Lake Storage 1-го поколения](./media/data-lake-store-performance-tuning-guidance/throughput.png)

Data Lake Storage 1-го поколения можно масштабировать, чтобы предоставить необходимую пропускную способность для всех сценариев аналитики. По умолчанию учетная запись Data Lake Storage 1-го поколения автоматически предоставляет достаточную пропускную способность для выполнения различных сценариев использования. В случаях, когда клиенты достигают лимита по умолчанию, учетную запись Data Lake Storage 1-го поколения можно настроить для предоставления большей пропускной способности, связавшись с поддержкой Майкрософт.

## <a name="data-ingestion"></a>Прием данных

При поимке данных из исходной системы в Data Lake Storage Gen1 важно учитывать, что узким местом может быть исходное оборудование, исходное сетевое оборудование и подключение к сети Data Lake Storage Gen1.

![Производительность Data Lake Storage 1-го поколения](./media/data-lake-store-performance-tuning-guidance/bottleneck.png)

Важно обеспечить, чтобы на движение данных не повлияли эти факторы.

### <a name="source-hardware"></a>Исходное оборудование

Независимо от того, используете ли вы в Azure специальные машины или ввовы, следует тщательно выбрать соответствующее оборудование. В качестве исходного дискового оборудования следует использовать SSD, а не жесткие диски, поэтому выбирайте дисковое оборудование с быстро работающими шпинделями. В качестве исходного сетевого оборудования используйте самые быстрые сетевые адаптеры. В Azure мы рекомендуем VMs Azure D14 с соответствующим и сетевым оборудованием.

### <a name="network-connectivity-to-data-lake-storage-gen1"></a>Подключение к сети data Lake Storage Gen1

Сетевое подключение между исходными данными и Data Lake Storage 1-го поколения иногда может быть узким местом. Если исходные данные находятся в локальной среде, рекомендуется использовать выделенный канал с [Azure ExpressRoute](https://azure.microsoft.com/services/expressroute/). Если исходные данные находятся в Azure, вы сможете обеспечить лучшую производительность, если разместить данные в том же регионе Azure, что и учетная запись Data Lake Storage 1-го поколения.

### <a name="configure-data-ingestion-tools-for-maximum-parallelization"></a>Настройка средств приема данных для обеспечения максимальной параллелизации

После того, как вы обратились к исходным средствам и узким местам подключения к сети, вы готовы настроить свои инструменты приема. В следующей таблице перечислены ключевые параметры нескольких популярных средств приема и предоставлены подробные статьи по настройке производительности для них. Дополнительные сведения о выборе подходящего средства для вашего сценария см. в [этой статье](https://docs.microsoft.com/azure/data-lake-store/data-lake-store-data-scenarios).

| Инструмент          | Параметры | Дополнительные сведения                                                                 |
|--------------------|------------------------------------------------------|------------------------------|
| PowerShell       | PerFileThreadCount, ConcurrentFileCount | [Ссылку](https://docs.microsoft.com/azure/data-lake-store/data-lake-store-get-started-powershell) |
| AdlCopy    | Единицы измерения Azure Data Lake Analytics | [Ссылку](https://docs.microsoft.com/azure/data-lake-store/data-lake-store-copy-data-azure-storage-blob#performance-considerations-for-using-adlcopy)         |
| DistCp            | -m (mapper) | [Ссылку](https://docs.microsoft.com/azure/data-lake-store/data-lake-store-copy-data-wasb-distcp#performance-considerations-while-using-distcp)                             |
| Фабрика данных Azure| parallelCopies | [Ссылку](../data-factory/copy-activity-performance.md)                          |
| Sqoop           | fs.azure.block.size, -m (mapper) | [Ссылку](https://blogs.msdn.microsoft.com/bigdatasupport/2015/02/17/sqoop-job-performance-tuning-in-hdinsight-hadoop/)        |

## <a name="structure-your-data-set"></a>Структура набора данных

При хранении данных в Data Lake Storage Gen1 размер файла, количество файлов и структура папок влияют на производительность. В следующем разделе описаны рекомендации в этих областях.

### <a name="file-size"></a>Размер файла

Как правило, у модулей аналитики, таких как HDInsight и Azure Data Lake Analytics, нагрузка зависит от количества файлов. Если вы храните данные в большом количестве небольших файлов, это может отрицательно сказаться на производительности.

Упорядочивайте свои данные в файлы большого размера для лучшей производительности. Как правило, организуйте наборы данных в файлах размером 256 МБ или больше. В некоторых случаях, например относительно изображений и двоичных данных, их параллельная обработка невозможна. В этих случаях рекомендуется хранить отдельные файлы под 2 ГБ.

Иногда конвейеры данных имеют ограниченный контроль над необработанными данными, в которых имеется множество небольших файлов. Рекомендуется использовать процесс подготовки, который создает файлы большего размера для дочерних приложений.

### <a name="organize-time-series-data-in-folders"></a>Организация данных временных рядов в папках

Для рабочих нагрузок Hive и ADLA обрыв каши перегородок данных временных рядов может помочь некоторым запросам прочитать только подмножество данных, что повышает производительность.

Те конвейеры, которые глотают данные временных рядов, часто размещают свои файлы со структурированным именованием файлов и папок. Ниже приводится общий пример, который мы видим для данных, которые структурированы по дате:

    \DataSet\YYYY\MM\DD\datafile_YYYY_MM_DD.tsv

Обратите внимание, что данные времени и даты отображаются и как папки, и в имени файла.

Ниже приведен распространенный шаблон для даты и времени:

    \DataSet\YYYY\MM\DD\HH\mm\datafile_YYYY_MM_DD_HH_mm.tsv

Выбор, который вы делаете с помощью упорядочения папки и файлов, должен быть оптимизирован для больших размеров файлов и разумного количества файлов в каждой папке.

## <a name="optimize-io-intensive-jobs-on-hadoop-and-spark-workloads-on-hdinsight"></a>Оптимизация интенсивных рабочих мест вв.К.Нагисте и Спарк на HDInsight

Задания можно отнести к одной из трех категорий:

* **Интенсивно использующие ЦП.** Эти задания имеют долгое время вычисления с минимальным временем ввода-вывода. Примеры включают машинное обучение и задания обработки естественных языков.
* **Память интенсивная.** Эти задания используют большой объем памяти. Примеры включают PageRank и задания аналитики в реальном времени.
* **С большим количеством операций ввода-вывода.** Эти задания большую часть своего времени выполняют операции ввода-вывода. Распространенным примером является задание копирования, которое выполняет только операции чтения и записи. Другие примеры включают задания по подготовке данных, которые считывают многочисленные данные, выполняют некоторые преобразования данных, а затем заражают данные обратно в хранилище.

Следующее руководство применяется только к заданиям с большим объемом операций ввода-вывода.

### <a name="general-considerations-for-an-hdinsight-cluster"></a>Общие рекомендации, связанные с кластером HDInsight

* **Поддерживаемые версии HDInsight.** Для повышения производительности используйте последний выпуск HDInsight.
* **Регионах.** Разместите учетную запись Data Lake Storage 1-го поколения в том же регионе, что и кластер HDInsight.

Кластер HDInsight An состоит из двух головных узлов и нескольких рабочих узлов. Каждый рабочий узел предоставляет определенное количество ядер и памяти, которые определяют тип виртуальной машины. При выполнении задания YARN выступает в качестве согласователя ресурсов, который выделяет доступную память и ядра для создания контейнеров. Каждый контейнер выполняет задачи, которые необходимы для выполнения задания. Контейнеры выполняются параллельно для быстрой обработки задачи. Таким образом производительность повышается за счет выполнения максимально возможного количества контейнеров параллельно.

В пределах кластера HDInsight имеется три уровня, которые можно настроить, чтобы увеличить число контейнеров и использовать всю доступную пропускную способность.

* **Физический уровень**
* **Слой Ярна**
* **Слой рабочей нагрузки**

### <a name="physical-layer"></a>Физический уровень

**Запустите кластер с большим количеством узлов и/или на виртуальной машине большего размера.** Больший кластер позволит вам выполнять дополнительные контейнеры YARN, как это показано на рисунке ниже.

![Производительность Data Lake Storage 1-го поколения](./media/data-lake-store-performance-tuning-guidance/VM.png)

**Используйте виртуальные машины с большей пропускной способностью сети.** Пропускная способность сети может быть узким местом, если она меньше, чем пропускная способность Data Lake Storage 1-го поколения. У различных виртуальных машин будет разная пропускная способность сети. Выберите тип виртуальной машины с самой большой пропускной способностью сети.

### <a name="yarn-layer"></a>Слой Ярна

**Используйте контейнеры YARN меньшего размера.** Уменьшите размер каждого контейнера YARN, чтобы создать больше контейнеров с тем же объемом ресурсов.

![Производительность Data Lake Storage 1-го поколения](./media/data-lake-store-performance-tuning-guidance/small-containers.png)

В зависимости от рабочей нагрузки минимальный необходимый размер контейнера YARN будет иметься всегда. Если выбрать слишком маленький контейнер, у заданий будут возникать проблемы из-за нехватки памяти. Обычно контейнеры YARN должны быть не меньше 1 ГБ. Это часто можно увидеть 3 ГБ Контейнеров YARN. Для некоторых рабочих нагрузок могут потребоваться контейнеры YARN большего размера.

**Увеличьте количество ядер на контейнер YARN.** Увеличьте количество ядер, выделенных для каждого контейнера, чтобы увеличить число параллельных задач, которые выполняются в каждом контейнере. Это работает для таких приложений, как Spark, которые выполняют несколько задач в контейнере. Для таких приложений, как Hive, которые работают по одному потоку в каждом контейнере, лучше иметь больше контейнеров, а не больше ядер на контейнер.

### <a name="workload-layer"></a>Слой рабочей нагрузки

**Используйте все доступные контейнеры.** Установите количество задач, чтобы быть равным или больше, чем количество доступных контейнеров, так что все ресурсы используются.

![Производительность Data Lake Storage 1-го поколения](./media/data-lake-store-performance-tuning-guidance/use-containers.png)

**Незавершенные задачи ресурсоемки.** Если у каждой задачи есть большой объем данных для обработки, неудачное выполнение задачи приводит к дорогостоящей повторной попытке. Поэтому лучше создавать больше задач, каждая из которых обрабатывает небольшой объем данных.

Помимо общих рекомендаций, приведенных выше, каждое приложение имеет различные параметры, которые можно настроить для каждого конкретного приложения. В следующей таблице перечислены некоторые параметры и ссылки для начала работы с настройкой производительности для каждого приложения.

| Рабочая нагрузка               | Параметры для настройки задач                                                         |
|--------------------|-------------------------------------------------------------------------------------|
| [Spark в HDInsight](data-lake-store-performance-tuning-spark.md)  | <ul><li>Num-executors</li><li>Executor-memory</li><li>Executor-cores</li></ul> |
| [Hive в HDInsight](data-lake-store-performance-tuning-hive.md)    | <ul><li>hive.tez.container.size</li></ul>         |
| [MapReduce в HDInsight](data-lake-store-performance-tuning-mapreduce.md)            | <ul><li>Mapreduce.map.memory</li><li>Mapreduce.job.maps</li><li>Mapreduce.reduce.memory</li><li>Mapreduce.job.reduces</li></ul> |
| [Storm в HDInsight](data-lake-store-performance-tuning-storm.md)| <ul><li>Количество рабочих процессов</li><li>Количество экземпляров исполнителей воронки</li><li>Количество экземпляров исполнителей сита </li><li>Количество задач воронки</li><li>Количество задач сита</li></ul>|

## <a name="see-also"></a>См. также

* [Общие сведения об Azure Data Lake Storage Gen1](data-lake-store-overview.md)
* [Начало работы с аналитикой озера данных Azure](../data-lake-analytics/data-lake-analytics-get-started-portal.md)
