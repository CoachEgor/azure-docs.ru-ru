---
title: Настройка производительности TCP/IP для виртуальных машин Azure | Документация Майкрософт
description: Узнайте, различные распространенные TCP/IP методы настройки производительности, а также их связь с виртуальными машинами Azure.
services: virtual-network
documentationcenter: na
author:
- rimayber
- dgoddard
- stegag
- steveesp
- minale
- btalb
- prachank
manager: paragk
editor: ''
ms.assetid: ''
ms.service: virtual-network
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: infrastructure-services
ms.date: 04/02/2019
ms.author:
- rimayber
- dgoddard
- stegag
- steveesp
- minale
- btalb
- prachank
ms.openlocfilehash: d0124d6656167af3942e0d054b4e1fa7a2b48e8b
ms.sourcegitcommit: 6f043a4da4454d5cb673377bb6c4ddd0ed30672d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/08/2019
ms.locfileid: "65410048"
---
# <a name="tcpip-performance-tuning-for-azure-vms"></a>TCP/IP Настройка производительности для виртуальных машин Azure

В этой статье рассматриваются распространенные методы настройки производительности TCP/IP и некоторые особенности, которые следует учитывать при использовании для виртуальных машин, работающих в Azure. Он предоставляют общий обзор технологии и изучите, как они настроены.

## <a name="common-tcpip-tuning-techniques"></a>Распространенные методы настройки TCP/IP

### <a name="mtu-fragmentation-and-large-send-offload"></a>MTU, фрагментации и Разгрузка большой отправки

#### <a name="mtu"></a>MTU

Данных (MTU) — это самый большой размер фрейм (пакет), указанного в байтах, которые могут быть отправлены через сетевой интерфейс. Значение MTU является значением настраиваемого параметра. MTU по умолчанию, используемый на виртуальных машинах Azure, и значение по умолчанию для большинства устройств сети глобально, – 1500 байтов.

#### <a name="fragmentation"></a>Фрагментация

Фрагментация возникает при отправке пакета, превышает MTU сетевого интерфейса. Стек TCP/IP нарушит пакет на более мелкие части (фрагменты), которые соответствуют MTU интерфейса. Фрагментация происходит на уровне IP и не зависит от базового протокола (например, TCP). При отправке пакета 2000 байтовое через сетевой интерфейс с значение MTU 1500, пакет будет разделить на один пакет 1500 байтов и один пакет 500 байт.

Сетевые устройства в пути между источником и назначением можно либо пакеты перетаскивания, превышающих размер MTU или фрагментацию на более мелкие части.

#### <a name="the-dont-fragment-bit-in-an-ip-packet"></a>Don't Fragment бит в пакет IP

Бит Don't Fragment (DF) — флажок в заголовке протокола IP. Бит DF указывает, что сетевые устройства на пути между отправителем и получателем должна не фрагментацию. Этот бит может быть установлена по многим причинам. (См. в разделе «Обнаружения PMTU» этой статьи для одним из примеров). Сетевое устройство получает пакет с фрагментировать и пакета превышает MTU для интерфейса устройства, стандартное поведение при устройства пакета. Устройство отправляет сообщение проверки связи ICMP с необходимостью фрагментации обратно к исходному источнику пакета.

#### <a name="performance-implications-of-fragmentation"></a>Последствия фрагментации для производительности

Фрагментация может повлиять снижению производительности. Одним из основных причин воздействие на производительность является ЦП и памяти последствия фрагментации и повторную сборку пакетов. Когда сетевого устройства требуется fragment пакет, его необходимо распределить ресурсы ЦП и памяти для выполнения фрагментации.

То же самое происходит, когда собираются пакет. Сетевое устройство имеет для хранения всех фрагментов до их получения, его можно собрать их исходный пакет. Процесс фрагментации и повторной сборки также может привести к задержке.

Другие возможные снижения производительности фрагментации подразумевается, что фрагментированных пакетов могут приходить в неправильном порядке. Если пакеты принимаются в неправильном порядке, некоторые типы сетевых устройств можно удалить их. Когда это происходит, весь пакет должен быть повторно.

Фрагменты обычно удаляются с устройств безопасности, например сетевые брандмауэры или после получения сетевого устройства буферы исчерпаны. При получения сетевого устройства буферы исчерпаны, сетевое устройство пытается воссоздать фрагментированных пакетов, но отсутствуют ресурсы для хранения и reassume пакет.

Фрагментация можно рассматривать как отрицательное операции, но поддержка для фрагментации необходим, если вы подключаетесь различными сетями через Интернет.

#### <a name="benefits-and-consequences-of-modifying-the-mtu"></a>Преимущества и последствия изменения MTU

Вообще говоря можно создать более эффективной сетью, увеличив значение MTU. Каждый пакет, который передается имеет информацию заголовка, которая добавляется в исходный пакет. Когда фрагментации создает дополнительные пакеты, дополнительные заголовок издержки, который делает сети менее эффективным.

Ниже приведен пример. Размер заголовка Ethernet — 14 байт, а также последовательность проверки кадра 4 байтам для обеспечения согласованности кадра. Если один пакет 2000 байтовое отправляется, 18 дополнительных байт для Ethernet добавляется в сети. Если пакет фрагментированы в пакет 1500 байтов и 500-байтовый пакет, каждый пакет будет иметь 18 байт заголовок кадра протокола Ethernet общей сложности состоит из 36 байтов.

Имейте в виду, что при увеличении MTU не требуется создавать более эффективной сетью. Если приложение отправляет пакеты только 500 байт, тем же размером заголовка будет существовать ли значение MTU является 1500 или 9000 байт. Сети становится более эффективным, только в том случае, если он использует больший размер пакетов, которые были затронуты MTU.

#### <a name="azure-and-vm-mtu"></a>Azure и MTU виртуальной Машины

По умолчанию для виртуальных машин Azure составляет 1 500 байт. Стек виртуальной сети Azure будет пытаться fragment пакет до 1400 байт. Но стек виртуальной сети разрешает пакетов до 2,006 байт при черная задается в IP-заголовке.

Обратите внимание, что стек виртуальной сети не является по своей природе неэффективным, так как фрагменты пакетов до 1400 байт, несмотря на то, что виртуальные машины имеют значение MTU 1500. Большое количество сетевых пакетов намного меньше, чем 1400 или 1500 байтов.

#### <a name="azure-and-fragmentation"></a>Azure и фрагментации

Стек виртуальной сети предназначена для удаления «ошибочного фрагмента», то есть фрагментированных пакетов, которые не прибудут в исходном порядке фрагментированного. Эти пакеты удаляются главным образом из-за было объявлено в ноября 2018 года, вызывается FragmentSmack уязвимость сети.

FragmentSmack является дефект в обработке ядро Linux повторную сборку фрагментированных пакетов IPv4 и IPv6. Удаленный злоумышленник может использовать этот недостаток, чтобы триггер дорогостоящие фрагмент сборки операций, которые могут привести к повышенной ЦП и отказ в обслуживании в целевой системе.

#### <a name="tune-the-mtu"></a>Настройка MTU

Значение MTU виртуальной Машины Azure, можно настроить, как и в любых других операционных систем. Не стоит фрагментация, которая происходит в Azure, описанных выше, когда вы настраиваете значение MTU.

Мы не рекомендуем клиентам в повышении MTU виртуальной Машины. Это обсуждение предназначена для описания того, как Azure реализует MTU и выполняет фрагментацию.

> [!IMPORTANT]
>Увеличение MTU не известен для повышения производительности и может иметь отрицательное влияние на производительность приложения.
>
>

#### <a name="large-send-offload"></a>Разгрузка большой отправки

Разгрузка большой отправки (LSO) может повысить производительность сети за счет разгрузки сегментации пакетов Ethernet-адаптеру. При включении LSO стека TCP/IP создает больших пакетов TCP и отправляет его Ethernet-адаптеру для сегментации перед пересылкой. Преимуществом LSO является то, что он может освободить ЦП от сегментирования пакетов в размерах, которые соответствуют MTU и разгрузка обработки для интерфейса Ethernet, где он выполняется в оборудовании. Дополнительные сведения о преимуществах LSO см. в разделе [Разгрузка большой отправки поддержкой](https://docs.microsoft.com/windows-hardware/drivers/network/performance-in-network-adapters#supporting-large-send-offload-lso).

При включении LSO Azure клиенты могут увидеть кадра больших размеров, при выполнении записи пакетов. Эти размеры больших кадров может привести некоторые клиенты предположить, что фрагментации, или, если она не используется большими MTU. С помощью LSO адаптер Ethernet можно объявить больший максимальный размер (MSS) в стек TCP/IP для создания большего размера пакета TCP. Это весь кадр несегментированный пересылаются в адаптер Ethernet и будет видима в записи пакета, выполняемые на виртуальной Машине. Однако пакет будет разбит на многие части адаптер Ethernet, в соответствии с адаптер Ethernet MTU.

### <a name="tcp-mss-window-scaling-and-pmtud"></a>Масштабирование окна TCP MSS и PMTUD

#### <a name="tcp-maximum-segment-size"></a>Максимальный размер TCP

TCP максимальный размер (пакета MSS) — это параметр, который ограничивает размер TCP-сегментов, что избавляет от фрагментации пакетов TCP. Операционные системы, чтобы задать MSS обычно будет используйте следующую формулу:

`MSS = MTU - (IP header size + TCP header size)`

IP-заголовке и в заголовке TCP: 20 байт или всего 40 байт. Поэтому интерфейс со значением MTU 1500 будет иметь MSS 1,460. Но MSS можно изменить.

Этот параметр является согласованные трехстороннее подтверждение TCP при настройке сеанса TCP между источником и назначением. Обе стороны отправлять значение MSS и меньшее из двух используется для подключения TCP.

Имейте в виду, что MTU источника и назначения не только факторов, которые определяют значение MSS. Промежуточных сетевых устройств, таких как VPN-шлюзов, включая VPN-шлюза Azure, можно настроить MTU независимо от источника и назначения, чтобы обеспечить оптимальную производительность.

#### <a name="path-mtu-discovery"></a>Обнаружения PMTU

Согласовывается MSS, но он не может указывать фактические MSS, который может использоваться. Это обусловлено другим сетевым устройствам на пути между источником и назначением может иметь меньшее значение MTU, чем источник и назначение. В этом случае устройство, которого MTU меньше, чем пакет удалит пакет. Устройство отправит обратно сообщение проверки связи ICMP с необходимостью фрагментации (типа 3, 4 кода), которое содержит его MTU. Это сообщение проверки связи ICMP позволяет на исходном узле уменьшить его MTU путь соответствующим образом. Этот процесс называется обнаружения MTU пути (PMTUD).

Процесс PMTUD неэффективен и влияет на производительность сети. При отправке пакетов, превышать сетевой путь MTU, пакеты нужно повторно с нижней MSS. Если отправитель не получает сообщения проверки связи ICMP с необходимостью фрагментации, возможно из-за сетевой брандмауэр в пути (обычно называется *PMTUD blackhole*), отправитель не знает, ему следует уменьшить MSS и будет непрерывно повторной передачи пакета. Вот почему мы не рекомендуем увеличить число MTU виртуальной Машины Azure.

#### <a name="vpn-and-mtu"></a>MTU и VPN

При использовании виртуальных машин, выполняющих инкапсуляция (например, IPsec VPN), существуют некоторые дополнительные соображения относительно размера пакета и MTU. Виртуальные частные сети добавьте дополнительные заголовки пакетов, который увеличивает размер пакета и требует меньшего размера MSS.

Для Azure мы рекомендуем задать фиксация TCP MSS 1350 байт и туннелирования интерфейс MTU 1400. Дополнительные сведения см. в разделе [VPN устройства и страница параметров IPSec/IKE](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-about-vpn-devices).

### <a name="latency-round-trip-time-and-tcp-window-scaling"></a>Задержка, время приема-передачи и масштабирование окна TCP

#### <a name="latency-and-round-trip-time"></a>Время задержки и приема-передачи

Задержки в сети регулируется скорости света по сети оптоволоконные волокон. Пропускная способность сети TCP также эффективно регулируется времени кругового пути (RTT) между двумя сетевыми устройствами.

| | | | |
|-|-|-|-|
|**Route**|**расстояние**|**Одностороннее времени**|**RTT**|
|Нью-Йорка до Сан-Франциско|4,148 км|21 ms|42 ms|
|Нью-Йорк, Лондон|5,585 км|28 ms|56 ms|
|Нью-Йорка для Сидней|15,993 км|80 мс|160 мс|

Эта таблица показывает величину расстояния между двумя расположениями. В сетях расстояние является обычно больше, чем Бразилию расстояние. Ниже приведен простой формулы для вычисления минимальное время приема-Передачи, как это определяется скорости света.

`minimum RTT = 2 * (Distance in kilometers / Speed of propagation)`

Можно использовать 200 для скорости передачи. Это расстояние в метрах, что свет проходит в 1 миллисекунде.

В качестве примера давайте рассмотрим Нью-Йорка до Сан-Франциско. Бразилию расстояние — 4,148 км. Установка этого значения в уравнение, мы получаем следующее:

`Minimum RTT = 2 * (4,148 / 200)`

Выходные данные формулы указывается в миллисекундах.

Если вы хотите обеспечить максимальную производительность сети, логические вариантом является Выбор места назначения с кратчайшее расстояние между ними. Также следует разрабатывать виртуальной сети, чтобы оптимизировать путь трафика и сокращения задержек. Дополнительные сведения см. в разделе «Рекомендации по проектированию сети» этой статьи.

#### <a name="latency-and-round-trip-time-effects-on-tcp"></a>Эффекты времени задержки и круговой путь через TCP-

Время приема-передачи имеет непосредственное влияние на максимальную пропускную способность TCP. В протоколе TCP *размер окна* максимальный объем трафика, которое может быть отправлено через TCP-подключение, прежде чем отправитель должен получать подтверждения от получателя. Если задано значение TCP MSS 1,460 и размер окна TCP имеет значение 65 535, отправитель может отправлять пакеты 45, прежде чем у того получать подтверждения от получателя. Если отправитель не получает подтверждение, оно будет повторную передачу данных. Вот формула:

`TCP window size / TCP MSS = packets sent`

В этом примере 65 535 / 1,460 округляется до 45.

Это состояние «Ожидание подтверждения», механизм, чтобы обеспечить надежную доставку данных, является то, что вызывает времени приема-Передачи повлиять на пропускную способность TCP. Чем дольше выполняется отправитель ожидает подтверждения, чем дольше он должен ожидать перед отправкой данных.

Вот формула для расчета максимальная пропускная способность одного соединения TCP:

`Window size / (RTT latency in milliseconds / 1,000) = maximum bytes/second`

В этой таблице показано максимальное МБ / пропускную способность одного соединения TCP. (Для удобства чтения мегабайтах будет использоваться для единицы измерения).

| | | | |
|-|-|-|-|
|**Размер окна TCP (в байтах)**|**Задержка приема-Передачи (мс)**|**Максимальное мегабайт пропускной способности в секунду**|**Максимальное Мбит/с пропускной способности**|
|65 535|1|65.54|524.29|
|65 535|30|2.18|17.48|
|65 535|60|1,09|8.74|
|65 535|90|.73|5.83|
|65 535|120|.55|4.37|

Если пакеты будут потеряны, хотя отправитель повторно передает данные, которые уже отправлены, будет снижена максимальная пропускная способность TCP-подключения.

#### <a name="tcp-window-scaling"></a>Масштабирование окна TCP

Масштабирование окна TCP — это метод, который динамически увеличивается размер окна TCP больше данных, отправляемых по истечении которого запрашивается подтверждение. В предыдущем примере прежде чем она необходима, подтверждение отправится 45 пакетов. Если вы увеличите число пакетов, которые могут быть отправлены, прежде чем требуется подтверждение, уменьшается количество раз, когда отправитель ожидает подтверждения, что увеличивает максимальную пропускную способность TCP.

В этой таблице показано эти связи:

| | | | |
|-|-|-|-|
|**Размер окна TCP (в байтах)**|**Задержка приема-Передачи (мс)**|**Максимальное мегабайт пропускной способности в секунду**|**Максимальное Мбит/с пропускной способности**|
|65 535|30|2.18|17.48|
|131,070|30|4.37|34.95|
|262,140|30|8.74|69.91|
|524,280|30|17.48|139.81|

Но значение заголовка TCP для размера окна TCP только 2 байта, это означает, что максимальное значение — окно приема составляет 65 535. Чтобы увеличить максимальный размер окна, был введен коэффициент масштабирования окна TCP.

Коэффициент масштабирования также — это параметр, который можно настроить в операционной системе. Вот формула для расчета размера окна TCP с помощью коэффициентов масштабирования.

`TCP window size = TCP window size in bytes \* (2^scale factor)`

Ниже приведен расчета коэффициента масштабирования окна 3 и окну размером 65 535.

`65,535 \* (2^3) = 262,140 bytes`

Коэффициент масштабирования 14 результатов в размер окна TCP из 14 (максимально разрешенное смещение). Размер окна TCP будет 1,073,725,440 байт (8,5 гигабит).

#### <a name="support-for-tcp-window-scaling"></a>Поддержка масштабирование окна TCP

Windows можно задать разные коэффициенты масштабирования для различными типами соединений. (Классы подключений относятся центра обработки данных, Интернет и т. д.) Использовании `Get-NetTCPConnection` команду PowerShell, чтобы просмотреть окно масштабирования тип подключения:

```powershell
Get-NetTCPConnection
```

Можно использовать `Get-NetTCPSetting` команду PowerShell для просмотра значений каждого класса:

```powershell
Get-NetTCPSetting
```

Можно задать начальный размер окна TCP и коэффициент масштабирования TCP в Windows с помощью `Set-NetTCPSetting` команду PowerShell. Дополнительные сведения см. в разделе [NetTCPSetting набора](https://docs.microsoft.com/powershell/module/nettcpip/set-nettcpsetting?view=win10-ps).

```powershell
Set-NetTCPSetting
```

Действующие параметры TCP для `AutoTuningLevel`:

| | | | |
|-|-|-|-|
|**/ Scannow**|**Коэффициент масштабирования**|**Коэффициент масштабирования**|**Для формулы<br/>вычислить максимальный размер окна**|
|Отключено|Нет|Нет|Размер окна|
|С ограниченным доступом|4.|2^4|Размер окна * (2 ^ 4)|
|Ограничен|2|2^2|Размер окна * (2 ^ 2)|
|Нормальный|8|2^8|Размер окна * (2 ^ 8)|
|Экспериментальный|14|2^14|Размер окна * (2 ^ 14)|

Эти параметры используются чаще всего влияют на производительность TCP, но имейте в виду, что множество других факторов, в Интернете, за пределами элемента управления Azure, также могут повлиять на производительность TCP.

#### <a name="increase-mtu-size"></a>Увеличьте размер MTU

Поскольку больших MTU означает больше MSS, может возникнуть вопрос ли увеличение MTU может повысить производительность TCP. Скорее всего, нет. Существуют, преимущества и недостатки размер пакета после только что TCP-трафик. Как обсуждалось ранее, наиболее важные факторы, влияющие на производительность пропускной способности TCP, размер окна TCP, потери пакетов и составляет время кругового пути.

> [!IMPORTANT]
> Не рекомендуется, что клиенты Azure изменить значение MTU по умолчанию на виртуальных машинах.
>
>

### <a name="accelerated-networking-and-receive-side-scaling"></a>Ускорение сети и масштабирование на стороне приема

#### <a name="accelerated-networking"></a>Ускорение работы в сети

Функции сети виртуальных машин традиционно были на гостевой виртуальной Машине и узле низкоуровневой оболочки/интенсивное использование ресурсов ЦП. Процессор компьютера, включая все инкапсуляцию виртуальной сети и декапсуляция всех пакетов, изменится через узел обрабатывается в программном обеспечении. Поэтому большего объема трафика, который проходит через узел, загрузить более высокая загрузка ЦП. И если узловом ЦП занят с другими операциями, который также влияет на пропускную способность сети и задержки. Azure решает эту проблему с повышением производительности сети.

Повышение производительности сети предоставляет согласованный ultralow задержи через собственные программируемых оборудования Azure и технологии, такие как SR-IOV. Повышение производительности сети перемещает большую часть Azure программно определяемого сетевого стека ЦП и в основе FPGA SmartNICs. Благодаря этому изменению приложения для конечных пользователей для освобождения процессорное время, которая помещает меньшей нагрузки на виртуальной Машине, уменьшение дрожания и несогласованности задержки. Другими словами производительность может быть более детерминированным.

Повышение производительности сети повышает производительность, позволяя гостевой виртуальной Машине для обхода узла и установить datapath непосредственно с SmartNIC узла. Ниже приведены некоторые возможности функции ускорения сети.

- **Уменьшить задержку в секунду (pps) выше пакетов в**: Удаление виртуального коммутатора на пути к данным, уменьшает количество времени, затрачиваемое узел для обработки политики для пакетов и увеличивается число пакетов, которые могут быть обработаны на виртуальной машине.

- **Уменьшение дрожания**: Виртуальный коммутатор обработки зависит от того, объем политики, который необходимо применить и рабочей нагрузки ЦП, выполняющего обработку. Принудительное применение политик к оборудованию удаляет устраняется за счет доставки пакетов непосредственно к виртуальной Машине, устраняя взаимодействия узла для виртуальной Машины и всех прерываний работы программного обеспечения и переключений контекста.

- **Уменьшение нагрузки ЦП**: Обход виртуального коммутатора на узле приводит к меньшему использованию ЦП для обработки сетевого трафика.

Чтобы использовать ускоренную сеть, необходимо явно включить его на каждом подходящую виртуальную Машину. См. в разделе [Создание виртуальной машины Linux с ускоренной сетью](https://docs.microsoft.com/azure/virtual-network/create-vm-accelerated-networking-cli) инструкции.

#### <a name="receive-side-scaling"></a>Масштабирование на стороне приема

Принимающая сторона масштабирования (RSS) — это технология драйвера сети, которая распределяет получения сетевого трафика, более эффективно распределяя получать обработки между несколькими ЦПУ в многопроцессорной системе. Проще говоря RSS позволяет обрабатывать более принятого трафика, так как она использует все доступные процессоры вместо одного в системе. Дополнительные технические сведения по RSS, см. в разделе [введение в масштабирование на стороне приема](https://docs.microsoft.com/windows-hardware/drivers/network/introduction-to-receive-side-scaling).

Чтобы обеспечить максимальную производительность при включенной функцией ускорения сети на виртуальной Машине, вам потребуется включить RSS. RSS можно также указать, что преимущества на виртуальных машинах, которые не используют ускорение сети. Общие сведения о том, как определить, включена ли RSS и как ее включить, см. в разделе [оптимизировать пропускную способность сети для виртуальных машин Azure](https://aka.ms/FastVM).

### <a name="tcp-timewait-and-timewait-assassination"></a>TCP TIME_WAIT и TIME_WAIT assassination

TCP TIME_WAIT — другой общий параметр, который влияет на производительность сети и приложений. На загруженные виртуальные машины, которые открывающих и закрывающих много сокетов, как клиенты или серверы (исходный порт IP:Source + IP:Destination порт назначения), во время обычной работы протокола TCP данного сокета могут быть сохранены в состоянии TIME_WAIT, в течение длительного времени. Чтобы разрешить дополнительные данные, которые доставляются на сокете перед его закрытием предназначен состоянии TIME_WAIT. Поэтому стеков TCP/IP обычно предотвратить повторное использование сокета, автоматическое удаление пакетов TCP SYN клиента.

Количество времени, сокет находится в TIME_WAIT настраивается. Он может варьироваться от 30 секунд до 240 секунд. Сокеты представляют собой ограниченный ресурс, а количество сокетов, которые могут использоваться в любой момент времени можно настроить. (Количество доступных сокетов, — обычно около 30 000.) Если доступных сокетов используются или если клиенты и серверы имеют несовпадающие TIME_WAIT параметры виртуальной Машины производится попытка повторного использования сокетов в состоянии TIME_WAIT, новые соединения завершится ошибкой, потому автоматически отбрасываются пакеты SYN TCP.

Значение для диапазона портов для исходящего трафика сокетов обычно настраивается в стеке TCP/IP операционной системы. То же самое справедливо для TCP TIME_WAIT параметры и повторное использование сокета. Изменение этих номеров может потенциально повысить масштабируемость. Но в зависимости от ситуации, эти изменения могут вызвать проблемы совместимости. Вам следует соблюдать осторожность при изменении этих значений.

TIME_WAIT assassination можно использовать для устранения этой масштабирования. TIME_WAIT assassination позволяет повторно использовать в определенных ситуациях, как и когда порядковый номер в виде пакета по IP-адрес нового подключения превышает порядковый номер последнего пакета из предыдущее подключение сокет. В этом случае операционная система позволит установить новое соединение (он будет принимать новые SYN-ACK) и принудительно закройте предыдущее подключение, который был в состоянии TIME_WAIT. Эта возможность поддерживается на виртуальных машинах Windows в Azure. Дополнительные сведения о поддержке в других виртуальных машин, проверьте у поставщика ОС.

Дополнительные сведения о настройке параметров TCP TIME_WAIT и диапазон портов источника, см. в разделе [параметры, которые могут быть изменены для повышения производительности сети](https://docs.microsoft.com/biztalk/technical-guides/settings-that-can-be-modified-to-improve-network-performance).

## <a name="virtual-network-factors-that-can-affect-performance"></a>Виртуальная сеть факторы, которые могут повлиять на производительность

### <a name="vm-maximum-outbound-throughput"></a>Пропускная способность максимальное исходящего трафика виртуальной Машины

Azure предоставляет широкий набор типов и размеров виртуальных Машин, каждый из которых имеет определенное сочетание характеристик производительности. Одна из этих возможностей — сетевой пропускной способности (или пропускной способности), которая измеряется в мегабитах в секунду (Мбит/с). Так, как виртуальные машины размещены на общем оборудовании, емкость сети должна справедливо распределяться между виртуальными машинами, используя то же оборудование. Крупным виртуальным машинам выделяется больше пропускной способности, чем меньше виртуальных машин.

Пропускная способность сети, выделяемая каждой виртуальной машине, определяет скорость передачи данных от виртуальной машины (исходящий трафик). Ограничение распространяется на весь сетевой трафик, покидающий виртуальную машину, независимо от его назначения. Например если виртуальная машина имеет ограничение в 1000 Мбит/с, это ограничение применяется ли исходящий трафик, предназначенный для другой виртуальной машине в той же виртуальной сети или за пределами Azure.

Входящий трафик не измеряется и не ограничивается напрямую. Однако существуют другие факторы, такие как ЦП и размеры хранилища, которые могут повлиять на способность виртуальной машины для обработки входящих данных.

Повышение производительности сети позволяет повысить производительность сети, включая задержку, пропускную способность и использование ЦП. Ускорение работы в сети может повысить пропускную способность виртуальной машины, но это может происходить, только до достижения выделенной пропускной способности виртуальной машины.

Виртуальные машины Azure имеют по крайней мере один сетевой интерфейс, подключенный к ним. Они могут иметь несколько. Пропускная способность, выделенная для виртуальной машины равно сумме весь исходящий трафик через все сетевые интерфейсы, подключенные к компьютеру. Другими словами пропускная способность выделяется на основе виртуальной машины, независимо от того, сколько сетевых интерфейсов подключенных к машине.

Ожидаемая пропускная способность и число сетевых интерфейсов, поддерживаемых каждого размера виртуальной Машины описаны в [Windows для размеров виртуальных машин в Azure](https://docs.microsoft.com/azure/virtual-machines/windows/sizes?toc=%2fazure%2fvirtual-network%2ftoc.json). Чтобы просмотреть максимальную пропускную способность, выберите тип, например **общего назначения**, а затем найдите в разделе о серии на соответствующей странице (например, «серии Dv2»). Для каждого ряда, имеется таблица, которая содержит сетевые спецификации в последнем столбце, который называется «максимальное число сетевых адаптеров / ожидаемая пропускная способность сети (Мбит/с).»

Ограничение пропускной способности применяется ко всей виртуальной машине. Пропускная способность не зависит от следующих факторов:

- **Количество сетевых интерфейсов**: Ограничение пропускной способности применяется к сумме весь исходящий трафик из виртуальной машины.

- **Повышение производительности сети**: Однако эта функция может быть максимально эффективно использовать заявленный предел, ограничение не изменяется.

- **Назначение трафика**: Ограничения на исходящий учитываются все назначения.

- **Протокол**: Весь исходящий трафик по всем протоколам учитывается при подсчете ограничение.

Дополнительные сведения см. в разделе [пропускной способности сети виртуальной машины](https://aka.ms/AzureBandwidth).

### <a name="internet-performance-considerations"></a>Рекомендации по безопасности Интернета

Как описано в этой статье, факторов, в Интернете и за пределами элемента управления Azure может повлиять на производительность сети. Ниже приведены некоторые из этих факторов.

- **Задержка**. Время кругового пути между двумя конечными точками можно повлиять на проблемы в промежуточных сетях, трафик, который не принимает «» расстояние кратчайшего маршрута и не самые оптимальные пути пиринга.

- **Потеря пакетов**: Потеря пакетов может быть вызвана перегрузка сети, физический путь проблем и низкой производительности сетевых устройств.

- **Размер MTU/фрагментации**: Фрагментация вдоль пути может привести к задержкам в поступления данных или в пакеты, поступающие в неправильном порядке, что может повлиять на доставку пакетов.

Трассировка маршрута — это хороший инструмент для измерения характеристик производительности сети (например, потери пакетов и задержки) каждого сетевого пути между устройством исходного и целевого устройства.

### <a name="network-design-considerations"></a>Рекомендации по проектированию сети

А также рекомендации, см. выше в этой статье топологии виртуальной сети может повлиять на производительность сети. Например концентратор и спица разработки, что backhauls глобально трафик к виртуальной сети концентратора одним будут представлены сетевые задержки, которые будет влиять на производительность сети.

Количество сетевых устройств, сетевой трафик проходит через могут также влиять на общую задержку. Например в структуре концентратор и спица, если трафик проходит через виртуальный сетевой модуль периферийной зоны и виртуальное устройство центра перед транзитом к Интернету, сетевых виртуальных модулей может приводить к задержкам.

### <a name="azure-regions-virtual-networks-and-latency"></a>Регионы Azure, виртуальные сети и задержки

Регионы Azure состоят из нескольких центрах обработки данных, которые существуют в общий географический регион. Эти центры обработки данных не может находиться рядом друг с другом. В некоторых случаях они делятся по мере 10 километров. Виртуальная сеть располагается там логических перекрыл сети Azure физического центра обработки данных. Виртуальная сеть не означает любой топологии конкретной сети центра обработки данных.

Например две виртуальные машины, которые находятся в той же виртуальной сети и подсети можно в разных стойках, строк или даже центров обработки данных. Они могут быть разделены метров оптический кабель или километров от оптический кабель. Этот вариант может приводить к задержкам переменной (несколько разницу в миллисекундах) между разными виртуальными машинами.

Географического размещения виртуальных машин и потенциальных результате задержка между двумя виртуальными машинами, могут зависеть от конфигурации группы доступности и зон доступности. Но расстояние между центрами обработки данных в регионе конкретного региона и в основном от по топологии центра обработки данных в регионе.

### <a name="source-nat-port-exhaustion"></a>Нехватка портов NAT источника

Развертывание в Azure могут взаимодействовать с конечными точками за пределами Azure в Интернете и/или в пространстве общедоступных IP-адрес. Когда экземпляр инициирует исходящее подключение, Azure динамически сопоставляет частный IP-адрес общедоступного IP-адреса. После того как Azure создаст это сопоставление, обратный трафик исходящего потока можно также получить доступ к частный IP-адрес которой изначально отправлен поток.

Для каждого исходящего подключения балансировщик нагрузки Azure необходимо поддерживать это сопоставление для некоторого периода времени. Мультитенантный характер Azure обслуживание это сопоставление для каждого исходящего потока для каждой виртуальной Машины может быть много ресурсов. Поэтому существуют ограничения, которые задаются и на основе конфигурации виртуальной сети Azure. Или, чтобы обозначить более точно, виртуальной Машины Azure можно сделать только определенное количество исходящих подключений в определенный момент времени. При достижении этих ограничений, виртуальная машина не сможете выполнить более исходящие подключения.

Но это поведение можно изменить. Дополнительные сведения о SNAT и SNAT порта исчерпанию. см. в разделе [в этой статье](https://docs.microsoft.com/azure/load-balancer/load-balancer-outbound-connections).

## <a name="measure-network-performance-on-azure"></a>Измерение производительности сети в Azure

Ряд максимальные ограничения производительности в этой статье относятся к задержки в сети / приема-передачи времени (RTT) между двумя виртуальными машинами. Этот раздел содержит ряд предложений по проверка задержки или времени приема-Передачи и способы тестирования производительности TCP и производительность сети виртуальной Машины. Можно настроить, и значения TCP/IP и сети, обсуждалось ранее, с помощью методики, описанные в этом разделе описано тестирование производительности. Можно подключить задержки, MTU, MSS и окно значения размера в вычисления, ранее указанный и сравнить теоретического максимума до фактических значений, которые вы заметили во время тестирования.

### <a name="measure-round-trip-time-and-packet-loss"></a>Измерения времени кругового пути и потери пакетов

Производительность TCP основывается на время приема-Передачи и потерю пакетов. Служебную программу PING доступны в Windows и Linux предоставляет удобный способ измерения времени приема-Передачи и потери пакетов. Минимальное/максимальное/среднее задержку между источником и назначением будут показаны результаты из проверки СВЯЗИ. Он также будет показано потери пакетов. Проверка СВЯЗИ по протоколу ICMP по умолчанию. PsPing можно использовать для тестирования TCP времени приема-Передачи. Дополнительные сведения см. в разделе [PsPing](https://docs.microsoft.com/sysinternals/downloads/psping).

### <a name="measure-actual-throughput-of-a-tcp-connection"></a>Мера фактическая пропускная способность TCP-подключения

NTttcp — это средство для тестирования производительности TCP из виртуальной Машины Windows или Linux. Можно изменить различные параметры TCP и затем проверить преимущества с помощью NTttcp. Для получения дополнительных сведений см. следующие ресурсы.

- [Проверка (NTttcp) пропускной способности](https://aka.ms/TestNetworkThroughput)

- [NTttcp Utility](https://gallery.technet.microsoft.com/NTttcp-Version-528-Now-f8b12769)

### <a name="measure-actual-bandwidth-of-a-virtual-machine"></a>Мера фактическую пропускную способность виртуальной машины

Тестирование производительности разных типов виртуальных Машин, ускоренной сети и так далее, используя средство iPerf. iPerf также доступна в Linux и Windows. iPerf можно использовать TCP или UDP для тестирования общую пропускную способность сети. тест пропускной способности TCP iPerf зависят от факторов, описанных в этой статье (такие как задержка и время приема-Передачи). Поэтому UDP может дают лучшие результаты, если вы хотите проверить максимальную пропускную способность.

Дополнительные сведения вы найдете в следующих статьях:

- [Устранение проблем с производительностью сети Expressroute](https://docs.microsoft.com/azure/expressroute/expressroute-troubleshooting-network-performance)

- [Порядок проверки пропускной способности VPN для виртуальной сети](https://docs.microsoft.com/azure/vpn-gateway/vpn-gateway-validate-throughput-to-vnet)

### <a name="detect-inefficient-tcp-behaviors"></a>Обнаружить неэффективным поведения TCP

В записи пакетов Azure клиенты могут увидеть пакеты TCP с флагами TCP (SACK, DUP ACK, повторно ПЕРЕДАВАЕМЫХ и БЫСТРО ПЕРЕДАВАТЬ), которые могут указывать на проблемы с производительностью сети. Эти пакеты отдельно указали неэффективное использование сети, возникающие в результате потери пакетов. Но потери пакетов не обязательно из-за проблем с производительностью в Azure. Проблемы с производительностью может быть результатом ошибки в приложении, проблемы операционной системы или других проблем, не связанных напрямую к платформе Azure.

Кроме того Имейте в виду, что некоторые повторной передачи и повторяющиеся ACK допускаются в сети. Протоколы TCP были созданы надежность. Свидетельство пакетов TCP в записи пакета не обязательно свидетельствует системные сети, получать только чрезмерное.

Тем не менее эти типы пакетов, чтобы узнать, что пропускная способность TCP не даст его максимальную производительность, для причин, рассмотренных в других разделах этой статьи.

## <a name="next-steps"></a>Дальнейшие действия

Теперь, когда вы узнали о TCP/IP, Настройка производительности для виртуальных машин Azure, вы можете прочитать о других вопросах [Планирование виртуальных сетей](https://docs.microsoft.com/azure/virtual-network/virtual-network-vnet-plan-design-arm) или [Дополнительные сведения о подключении и настройке виртуальных сетей ](https://docs.microsoft.com/azure/virtual-network/).
