---
title: Балансовая нагрузка на разделы в нескольких экземплярах - Концентраторы событий Azure Документы Майкрософт
description: Описывает, как сбалансировать нагрузку на разделы в нескольких экземплярах приложения с помощью процессора событий и SDK центров событий Azure.
services: event-hubs
documentationcenter: .net
author: ShubhaVijayasarathy
editor: ''
ms.service: event-hubs
ms.devlang: na
ms.topic: conceptual
ms.tgt_pltfrm: na
ms.workload: na
ms.date: 01/16/2020
ms.author: shvija
ms.openlocfilehash: bf90120157bf64bd62a3b5ec9d8a6b2c6260e024
ms.sourcegitcommit: 632e7ed5449f85ca502ad216be8ec5dd7cd093cb
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/30/2020
ms.locfileid: "80398296"
---
# <a name="balance-partition-load-across-multiple-instances-of-your-application"></a>Баланснагрузка перегородки в нескольких экземплярах приложения
Для масштабирования приложения для обработки событий можно запустить несколько экземпляров приложения и сбалансировать нагрузку между собой. В более старых версиях [EventProcessorHost](event-hubs-event-processor-host.md) позволил сбалансировать нагрузку между несколькими экземплярами программы и событиями контрольно-пропускного пункта при получении. В новых версиях (5.0 далее) **EventProcessorClient** (.NET и Java) или **EventHubConsumerClient** (Python и JavaScript) позволяет сделать то же самое. Модель разработки упрощается с помощью событий. Вы подписываетесь на интересующие вас события, регистрируя обработчика событий.

В этой статье описывается пример сценария использования нескольких экземпляров для чтения событий из концентратора событий, а затем приводится подробная информация об особенностях клиента процессора событий, что позволяет получать события сразу из нескольких разделов и балансировать с другими потребителями, использующими один и тот же концентратор событий и группу потребителей.

> [!NOTE]
> Масштабирование в Центрах событий базируется на идее секционированных потребителей. В отличие от шаблона [конкурирующих потребителей](https://msdn.microsoft.com/library/dn568101.aspx), секционированный потребительский шаблон обеспечивает высокий уровень масштабирования путем удаления конфликтного узкого места и упрощения сквозного параллелизма.

## <a name="example-scenario"></a>Пример сценария

В качестве примера рассмотрим компанию по обеспечению безопасности дома, которая отслеживает 100 000 домов. Каждую минуту он получает данные с различных датчиков, таких как детектор движения, датчик открытого окна двери/окна, детектор разрыва стекла и так далее, установленный в каждом доме. Компания предоставляет веб-сайт для жителей, чтобы наблюдать за деятельностью своего дома почти в реальном времени.

Каждый датчик отправляет данные в концентратор событий. Концентратор событий настроен на 16 секций. В конце потребления необходим механизм, который может читать эти события, консолидировать их (фильтр, агрегат и т.д.) и сбросить агрегат в капля хранилища, который затем проецируется на удобную веб-страницу.

## <a name="write-the-consumer-application"></a>Написание приложения-потребителя

При создании потребителя в распределенной среде сценарий должен удовлетворять следующие требования:

1. **Масштаб.** Создайте несколько потребителей и каждый потребитель возьмет на себя ответственность за чтение нескольких секций Центров событий.
2. **Балансировка нагрузки.** Изменяйте количество потребителей динамически. Например, при добавлении нового типа датчика в каждый дом (например, детектора угарного газа) увеличивается число событий. В этом случае оператор (человек) увеличивает число экземпляров потребителя. Затем пул потребителей может перебалансировать количество секций, которыми они владеют, для распределения нагрузки на вновь добавленных потребителей.
3. **Бесшовное резюме на сбои:** Если потребитель **(потребитель A**) не удается (например, виртуальная машина хостинг аудора потребитель внезапно выходит из строя), то другие потребители могут забрать разделы, принадлежащие **потребителю и** продолжать. Кроме того, точка продолжения, называемая *контрольной точкой* или *смещением*, должна находиться в точке пересечения, в которой произошел сбой **потребителя А**, или немного раньше этого.
4. **Потребляйте события:** В то время как предыдущие три пункта касаются управления потребителем, должен быть код, чтобы потреблять события и делать что-то полезное с ним. Например, агрегировать его и загрузить его в хранилище капли.

## <a name="event-processor-or-consumer-client"></a>Обработчик событий или клиент-потребитель

Вам не нужно создавать свое собственное решение, отвечая этим требованиям. Эту функциональность предоставляют sDK-центры Azure Event Hubs. В SDK .NET или Java используется клиент-процессор событий (EventProcessorClient), а в SDK Python и Java Script вы используете EventHubConsumerClient. В старой версии SDK эти функции поддерживал и хост-процессора событий (EventProcessorHost).

В большинстве сценариев производства мы рекомендуем использовать клиент процессора событий для чтения и обработки событий. Клиент процессора предназначен для обеспечения надежного опыта обработки событий во всех разделах концентратора событий в режиме выполнения и терпимым образом ошибка, обеспечивая при этом средства для checkpoint его прогресса. Клиенты процессора событий также могут работать совместно в контексте группы потребителей для данного концентратора событий. Клиенты будут автоматически управлять распределением и балансировкой работы по мере того, как экземпляры становятся доступными или недоступными для группы.

## <a name="partition-ownership-tracking"></a>Отслеживание владения секциями

Экземпляр процессора событий обычно владеет и обрабатывает события из одного или нескольких разделов. Владение разделами равномерно распределено между всеми активными экземплярами процессора событий, связанными с концентратором событий и комбинацией группы потребителей. 

Каждому процессору события предоставляется уникальный идентификатор и претензии на владение разделами путем добавления или обновления входа в магазине контрольной точки. Все экземпляры процессора событий периодически взаимодействуют с этим магазином, чтобы обновить собственное состояние обработки, а также узнать о других активных экземплярах. Эти данные затем используются для баланса нагрузки между активными процессорами. Новые экземпляры могут присоединиться к пулу обработки для масштабирования. При снижении экземпляров либо из-за сбоев, либо из-за снижения масштабов, владение разделом изящно передается другим активным процессорам.

Записи о собственности на разделы в хранилище контрольной точки отслеживают пространство имен event Hubs, название концентратора событий, группу потребителей, идентификатор процессора событий (также известный как владелец), идентификатор раздела и последнее измененное время.



| пространство имен Центров событий;               | имя концентратора событий; | **Потребительская группа** | Владелец                                | Partition ID | Последнее измененное время  |
| ---------------------------------- | -------------- | :----------------- | :----------------------------------- | :----------- | :------------------ |
| mynamespace.servicebus.windows.net | myeventhub     | myconsumergroup    | 3be3f9d3-9d9e-4c50-9491-85ece8334ff6 | 0            | 2020-01-15T01:22:15 |
| mynamespace.servicebus.windows.net | myeventhub     | myconsumergroup    | f5cc5176-ce96-4bb4-bbaa-a0e3a9054ecf | 1            | 2020-01-15T01:22:17 |
| mynamespace.servicebus.windows.net | myeventhub     | myconsumergroup    | 72b980e9-2efc-4ca7-ab1b-ffd7bece8472 | 2            | 2020-01-15T01:22:10 |
|                                    |                | :                  |                                      |              |                     |
|                                    |                | :                  |                                      |              |                     |
| mynamespace.servicebus.windows.net | myeventhub     | myconsumergroup    | 844bd8fb-1f3a-4580-984d-6324f9e208af | 15           | 2020-01-15T01:22:00 |

Каждый экземпляр процессора события приобретает право собственности на раздел и начинает обработку раздела с последнего известного [контрольно-пропускного пункта.](# Checkpointing) Если процессор выходит из строя (VM выключается), то другие экземпляры обнаруживают это, глядя на последнее измененное время. Другие экземпляры пытаются получить право собственности на разделы, ранее принадлежавшие неактивному экземпляру, и магазин контрольной точки гарантирует, что только один из экземпляров может претендовать на право собственности на раздел. Таким образом, в любой данный момент времени, есть в лучшем случае один процессор, получающий события от раздела.

## <a name="receive-messages"></a>Получение сообщений

При создании процессора событий указаны функции, которые будут обрабатывать события и ошибки. Каждый вызов функции, которая обрабатывает события, обеспечивает одно событие из определенного раздела. Это ваша ответственность, чтобы справиться с этим событием. Если вы хотите убедиться, что потребитель обрабатывает каждое сообщение хотя бы один раз, вам нужно написать свой собственный код с логикой повтора. Но учитывайте при этом возможность получения поврежденных сообщений.

Мы рекомендуем вам делать вещи относительно быстро. То есть, делать как можно меньше обработки, как это возможно. Если вам нужно написать на хранение и сделать некоторые области разгрома, то лучше использовать две группы потребителей и два процессора событий.

## <a name="checkpointing"></a>Контрольные точки

*Checkpointing* — это процесс, по которому процессор события отмечает или фиксирует положение последнего успешно обработанного события в рамках раздела. Маркировка контрольной точки обычно выполняется в рамках функции, которая обрабатывает события и происходит на основе раздела внутри группы потребителей. 

Если процессор событий отключается от раздела, другой экземпляр может возобновить обработку раздела на контрольно-пропускном пункте, ранее зафиксированного последним процессором этой раздела в этой группе потребителей. Когда процессор подключается, он передает смещение в концентратор событий, чтобы указать место, в котором начать чтение. Таким образом, можно использовать контрольные точки как для обозначения событий как "полных" приложениями вниз по течению, так и для обеспечения устойчивости при выходе из системы обработки событий. Вы можете вернуться к предыдущим данным, указав более низкое значение смещения по отношению к этому процессу создания контрольных точек. 

Когда контрольный пункт выполняется для обозначения события как обработанного, вход в хранилище контрольной точки добавляется или обновляется с компенсационным и номером последовательности события. Пользователи должны определить частоту обновления контрольно-пропускного пункта. Обновление после каждого успешно обработанного события может иметь последствия для производительности и затрат, поскольку оно запускает операцию записи в базовый магазин контрольно-пропускного пункта. Кроме того, контрольный пунктинг каждого отдельного события свидетельствует о шаблоне обмена сообщениями в очереди, для которого очередь Service Bus может быть лучшим вариантом, чем концентратор событий. Идея Центров событий заключается в том, что вы получаете доставку по принципу "хотя бы раз" в масштабе. Благодаря тому, что ваши идемпотентные нисходящие системы легко восстанавливаются после сбоев или перезапуска, это приводит к тому, что одни и те же события принимаются несколько раз.

> [!NOTE]
> Если вы используете Хранилище Azure Blob storage в качестве хранилища в среде, поддерживающей другую версию Storage Blob SDK, чем те, которые обычно доступны в Azure, вам нужно будет использовать код для изменения версии API службы хранения на конкретную версию, поддерживаемую этой средой. Например, если вы работаете с [концентраторами событий в версии Azure Stack Hub 2002](https://docs.microsoft.com/azure-stack/user/event-hubs-overview)года, наиболее доступной версией для службы хранения является версия 2017-11-09. В этом случае необходимо использовать код для таргетинга на версию API службы хранения данных на 2017-11-09 годы. Для примера таргетинга на конкретную версию API хранилища см. 
> - [.NET](https://github.com/Azure/azure-sdk-for-net/tree/master/sdk/eventhub/Azure.Messaging.EventHubs.Processor/samples/Sample10_RunningWithDifferentStorageVersion.cs). 
> - [Java](https://github.com/Azure/azure-sdk-for-java/blob/master/sdk/eventhubs/azure-messaging-eventhubs-checkpointstore-blob/src/samples/java/com/azure/messaging/eventhubs/checkpointstore/blob/EventProcessorWithOlderStorageVersion.java)
> - [JavaScript](https://github.com/Azure/azure-sdk-for-js/blob/master/sdk/eventhub/eventhubs-checkpointstore-blob/samples/receiveEventsWithDownleveledStorage.js) или [TypeScript](https://github.com/Azure/azure-sdk-for-js/blob/master/sdk/eventhub/eventhubs-checkpointstore-blob/samples/receiveEventsWithDownleveledStorage.ts)
> - [Python](https://github.com/Azure/azure-sdk-for-python/blob/master/sdk/eventhub/azure-eventhub-checkpointstoreblob-aio/samples/event_processor_blob_storage_example_with_storage_api_version.py)

## <a name="thread-safety-and-processor-instances"></a>Потокобезопасность и экземпляры процессора

По умолчанию процессор событий или потребитель является безопасным потоком и ведет себя синхронно. При появлении событий для раздела вызывается функция, которая обрабатывает события. Последующие сообщения и вызовы этой функции выстраиваются в очередь за кулисами, поскольку насос сообщения продолжает работать в фоновом режиме на других потоках. Потокобезопасность устраняет потребность в потокобезопасной коллекции и значительно повышает производительность.

## <a name="next-steps"></a>Следующие шаги
Смотрите следующие быстрые старты:

- [.NET Core](get-started-dotnet-standard-send-v2.md)
- [Java](event-hubs-java-get-started-send.md)
- [Python](get-started-python-send-v2.md)
- [JavaScript](get-started-node-send-v2.md)
