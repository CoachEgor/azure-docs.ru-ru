---
title: Избегайте чрезмерного подгонки & несбалансированных данных с помощью Аутомл
titleSuffix: Azure Machine Learning
description: Выявление распространенных ловушек моделей ML и управление ими с помощью автоматизированных решений машинного обучения Машинное обучение Azure.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 04/09/2020
ms.openlocfilehash: 76f920ad6aae68defb567a7a6623d1ffd488af5f
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "80874863"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>Предотвращение перегонки и несбалансированных данных с помощью автоматизированного машинного обучения

Избыточные и несбалансированные данные — это распространенные ошибки при создании моделей машинного обучения. По умолчанию автоматизированное машинное обучение Машинное обучение Azure предоставляет диаграммы и метрики, помогающие определить эти риски, и реализует рекомендации по их устранению. 

## <a name="identify-over-fitting"></a>Выявление чрезмерного размера

Чрезмерное размещение в машинном обучении происходит, когда модель рассмотрела обучающие данные слишком хорошо, и в результате невозможность точного предсказания невидимых тестовых данных. Иными словами, модель просто запомнила конкретные закономерности и шум в обучающих данных, но недостаточно гибка для создания прогнозов на реальных данных.

Рассмотрим следующие обученные модели и соответствующие им точности для обучения и тестирования.

| Модель | Точность обучения | Точность теста |
|-------|----------------|---------------|
| Объект | 99,9 % | 95% |
| B | 87% | 87% |
| В | 99,9 % | 45 % |

Учитывая модель **а**, Существует распространенное заблуждение, которое, если точность тестирования невидимых данных ниже, чем точность обучения, модель чрезмерно замещается. Однако точность тестирования всегда должна быть меньше, чем точность обучения, а различие в сравнении с более точным соответствием сводится к *тому, насколько* это менее точно. 

При сравнении моделей **a** и **B**модель **a** является лучшей моделью, так как она имеет более высокую точность тестирования, и несмотря на то, что точность теста немного ниже 95%. Вы не выбираете модель **B** просто потому, что точность обучения и тестирования ближе друг к другу.

Модель **C** представляет собой четкий случай чрезмерного подгонки; точность обучения очень высока, но точность тестирования не близка к высокому. Это различие является субъективным, но поступает из знаний о проблеме и данных, а какие величины ошибок приемлемы.

## <a name="prevent-over-fitting"></a>Запретить перегонка

В наиболее вопиющихной модели предполагается, что сочетания значений компонентов, отображаемые во время обучения, всегда будут иметь одни и те же выходные данные для целевого объекта.

Лучший способ предотвратить избыточное размещение заключается в соблюдении лучших рекомендаций для машинного обучения, в том числе:

* Использование дополнительных обучающих данных и устранение статистических смещений
* Предотвращение утечки целевых объектов
* Использование меньшего числа функций
* **Оптимизация для обычных и параметров**
* **Ограничения сложности модели**
* **Перекрестная проверка**

В контексте автоматизированного ML первые три указанных выше элемента — это **лучшие методики, которые вы реализуете**. Последними тремя полужирными элементами являются **лучшие методики, автоматически реализуемые в ML** по умолчанию для защиты от чрезмерного подгонки. В параметрах, отличных от автоматизированного ML, необходимо выполнить все шесть рекомендаций, чтобы избежать избыточных моделей.

### <a name="best-practices-you-implement"></a>Рекомендации по реализации

Использование **большего объема данных** — это самый простой и лучший способ предотвратить чрезмерное подгонка, и как только дополнительная премия обычно повышает точность. При использовании большего количества данных модель не будет запоминать точные закономерности, и она вынуждена достигнуть решений, более гибких для удовлетворения дополнительных условий. Также важно распознавать **статистический сдвиг**, чтобы убедиться в том, что обучающие данные не включают в себя изолированные шаблоны, которые не существуют в данных с прямым прогнозированием. Этот сценарий может быть трудно решать, так как между наборами обучения и тестирования может не быть чрезмерного размера, но при сравнении с динамическими тестовыми данными может существовать избыточное размещение.

Утечка целевого объекта — это аналогичная ситуация, в которой вы можете не увидеть чрезмерный выбор между наборами обучения и тестирования, но он отображается на этапе прогнозирования. Утечка целевого объекта происходит, когда во время обучения модель "мошенничества" получает доступ к данным, которые обычно не должны быть в стадии прогнозирования. Например, если ваша проблема состоит в том, чтобы предсказать, что цена товара будет в пятницу, но одна из функций случайно включала данные из четверг, это данные, которые модель не будет иметь на этапе прогнозирования, так как она не может увидеть будущее. Утечка целевого объекта — это простая ошибка, которую можно пропустить, но она часто характеризуется некорректной высокой точностью для вашей проблемы. Если вы пытаетесь спрогнозировать цену акций и обучили модель с точностью до 95%, скорее всего, в ваших функциях подоошел утечка целевого объекта.

Удаление компонентов также может помочь при чрезмерном сопоставлении, предотвращая использование моделью слишком большого количества полей для запоминания конкретных шаблонов, что делает ее более гибкой. Это может быть трудно измерять количественно, но если вы можете удалить функции и обеспечить одинаковую точность, вы, вероятно, сделали модель более гибкой и сократили риск чрезмерного изменения.

### <a name="best-practices-automated-ml-implements"></a>Рекомендации по автоматизированному созданию машинного обучения

Регулярная обработка — это процесс минимизации функции затрат для пенализе сложных и чрезмерно зафиксированных моделей. Существуют различные типы функций для работы с регулярными обобщениями, но в целом все они имеют размер, дисперсию и сложность модели пенализе. Автоматизированный ML использует L1 (Лассо), L2 («зубчатый») и Еластикнет (L1 и L2 одновременно) в различных сочетаниях с различными параметрами настройки параметров, которые контролируют перекрестное размещение. В простых терминах автоматизированное создание машинного обучения будет зависеть от того, насколько контролируется модель, и выбрать наилучший результат.

Автоматизированное ML также реализует явные ограничения сложности модели для предотвращения чрезмерного подгонки. В большинстве случаев эта реализация предназначена для алгоритмов дерева принятия решений или леса, где максимальная глубина дерева ограничена, а общее число деревьев, используемых в методах леса или ансамблей, ограничено.

Перекрестная проверка (ОПС) — это процесс создания множества подмножеств полных обучающих данных и обучения модели по каждому подмножеству. Идея состоит в том, что модель может получить «счастливое» и иметь высокую точность с одним подмножеством, но с использованием множества подмножеств, которые модель не достигает такой высокой точности каждый раз. При выполнении ОПС вы предоставляете набор проверочных данных для проверки, указываете, какие подмножества будут обучены (количество подмножеств), а автоматически ML — обучение модели и Настройка параметров для сворачивания ошибок в наборе проверки. Один сгиб может быть чрезмерно подогнать, но при использовании многих из них уменьшается вероятность того, что ваша окончательная модель не умещается. Компромисс заключается в том, что ОПС приводит к увеличению времени обучения и, таким образом, к большей стоимости, так как вместо того, чтобы обучить модель один раз, вы обучили его один раз для каждого *n* подмножества. 

> [!NOTE]
> Перекрестная проверка не включена по умолчанию. его необходимо настроить в параметрах автоматического ML. Однако после настройки перекрестной проверки и предоставленного набора данных проверки процесс выполняется автоматически. См. 

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>Выявление моделей с несбалансированными данными

Несбалансированные данные обычно находятся в данных для сценариев классификации машинного обучения и ссылаются на данные, которые содержат непропорциональное отношение наблюдений в каждом классе. Такое дисбаланс может привести к ложному получению положительного результата точности модели, так как входные данные имеют сдвиг к одному классу, что приводит к тому, что обученная модель имитирует этот сдвиг. 

Так как алгоритмы классификации обычно оцениваются с точностью, проверка оценки точности модели является хорошим способом определения того, влияет ли это на несбалансированные данные. Обладает ли она высокой точностью или действительно низкой точностью для определенных классов?

Кроме того, автоматические запуски ML автоматически создают следующие диаграммы, которые помогут понять правильность классификаций модели и определить модели, потенциально влияющие на несбалансированные данные.

Диаграмма| Описание
---|---
[Матрица путаницы](how-to-understand-automated-ml.md#confusion-matrix)| Оценивает правильно классифицированные метки относительно фактических меток данных. 
[Точность и отзыв](how-to-understand-automated-ml.md#precision-recall-chart)| Оценивает отношение правильных меток относительно соотношения найденных экземпляров меток данных 
[Кривые ROC](how-to-understand-automated-ml.md#roc)| Вычисляет отношение правильных меток к соотношения ложных положительных меток.

## <a name="handle-imbalanced-data"></a>Обработку несбалансированных данных 

В рамках своей цели упрощения рабочего процесса машинного обучения автоматизированный ML имеет встроенные возможности для помощи с несбалансированными данными, такими как, 

- **Весовой столбец**. Автоматический ML поддерживает взвешенный столбец в качестве входных данных, что приводит к сокращению или уменьшению количества строк в данные, что может сделать класс более или менее важным.

- Алгоритмы, используемые автоматизированным ML, могут правильно работать с дисбалансом до 20:1, что означает, что наиболее распространенный класс может содержать в данных в 20 раз больше строк, чем наименее распространенный класс.

Следующие методы являются дополнительными вариантами для управления несбалансированными данными за пределами автоматизированного ML. 

- Перевыборка до неравномерного распределения класса с помощью более мелких классов или выборке более крупных классов. Для обработки и анализа этих методов требуется опыт.

- Используйте метрику производительности, которая лучше работает с несбалансированными данными. Например, показатель F1 — это взвешенное среднее значение точности и отзыва. Точность измеряет точное значение классификатора — низкая точность указывает на большое число ложных положительных результатов--, при отзыве измеряет полноту классификатора--низкий отзыв указывает на большое число ложных отрицательных результатов. 

## <a name="next-steps"></a>Дальнейшие шаги

См. примеры и научитесь создавать модели с помощью автоматизированного машинного обучения.

+ Следуйте указаниям [руководства: автоматическое обучение модели регрессии с машинное обучение Azure](tutorial-auto-train-models.md)

+ Настройте параметры для автоматического обучения.
  + В Машинное обучение Azure Studio [выполните следующие действия](how-to-use-automated-ml-for-ml-models.md).
  + С помощью пакета SDK для Python [выполните следующие действия](how-to-configure-auto-train.md).


