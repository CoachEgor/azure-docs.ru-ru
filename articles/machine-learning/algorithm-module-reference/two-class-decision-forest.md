---
title: 'Двухклассный лес принятия решений: Ссылка на модуль'
titleSuffix: Azure Machine Learning
description: Узнайте, как использовать модуль «Двухклассный лес решений» в Azure Machine Learning для создания модели машинного обучения на основе алгоритма лесов принятия решений.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/22/2020
ms.openlocfilehash: c9388da449e75dee00fd43af9a4e0407c46f597a
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "77916716"
---
# <a name="two-class-decision-forest-module"></a>Двухклассный модуль «Лес принятия решений»

В этой статье описывается модуль в дизайнере машинного обучения Azure (предварительный просмотр).

Используйте этот модуль для создания модели машинного обучения на основе алгоритма лесов принятия решений.  

Решение леса быстро, под наблюдением модели ансамбля. Этот модуль является хорошим выбором, если вы хотите предсказать цель с максимум двумя результатами. 

## <a name="understanding-decision-forests"></a>Понимание решения лесов

Этот алгоритм лесовосстановления решения является методом обучения ансамбля, предназначенным для задач классификации. Методы ансамбля основаны на общем принципе, что вместо того, чтобы полагаться на одну модель, вы можете получить лучшие результаты и более обобщенную модель, создавая несколько связанных моделей и комбинируя их в некотором роде. Вообще говоря, модели совокупности обеспечивают большее покрытие и точность, чем одно дерево принятия решений. 

Есть много способов создать отдельные модели и объединить их в ансамбле. Это конкретное осуществление решения лесных работ путем создания нескольких деревьев решений, а затем **голосование** по наиболее популярным классом вывода. Голосование является одним из наиболее известных методов для получения результатов в ансамбле модели. 

+ Создается много отдельных деревьев классификации, используя весь набор данных, но различные (обычно рандомизированные) отправные точки. Это отличается от случайного подхода к лесу, при котором деревья отдельных решений могут использовать только рандомизированную часть данных или объектов.
+ Каждое дерево в решении лесного дерева выводит ненормализованную частоту гистограммы этикеток. 
+ Процесс агрегации суммирует эти гистограммы и нормализует результат, чтобы получить «вероятности» для каждой метки. 
+ Деревья, которые имеют высокую уверенность прогноза будет иметь больший вес в окончательном решении ансамбля.

Деревья решений в целом имеют много преимуществ для классификационных задач:
  
- Они могут фиксировать нелинейные границы решений.
- Вы можете обучать и предсказывать на большом количестве данных, так как они эффективны в вычислениях и использовании памяти.
- Выбор функций интегрирован в процессы обучения и классификации.  
- Деревья могут вместить шумные данные и множество функций.  
- Они являются непараметрическими моделями, что означает, что они могут обрабатывать данные с различными дистрибутивами. 

Тем не менее, простые деревья решений могут переопрошаться на данные, и менее обобщаемы, чем дерево ансамблей.

Для получения дополнительной информации, [см.](https://go.microsoft.com/fwlink/?LinkId=403677)  

## <a name="how-to-configure"></a>Порядок настройки
  
1.  Добавьте **модуль «Двухклассный лес решений»** в конвейер в Azure Machine Learning и откройте панель **«Свойства»** модуля. 

    Вы можете найти модуль под **машинного обучения**. Расширить **инициализацию,** а затем **классификацию.**  
  
2.  Для **метода перевыборки**выберите метод, используемый для создания отдельных деревьев.  Вы можете выбрать один из **Bagging** или **Replicate**.  
  
    -   **Bagging**: Bagging также называется *загрузка агрегации*. В этом методе каждое дерево выращивается на новом образце, созданном путем случайной выборки исходного набора данных с заменой до тех пор, пока у вас не будет набора данных размер оригинала.  
  
         Выходы моделей комбинируются *путем голосования,* что является формой агрегации. Каждое дерево в классификационном решении леса выводит ненормализованную частотную гистограмму этикеток. Агрегация заключается в сумме этих гистограмм и нормализовать, чтобы получить "вероятности" для каждого лейбла. Таким образом, деревья, которые имеют высокую уверенность прогноза будет иметь больший вес в окончательном решении ансамбля.  
  
         Для получения дополнительной информации смотрите запись Википедии для агрегирования Bootstrap.  
  
    -   **Репликация**: В репликации каждое дерево обучается на тех же данных ввода. Определение того, какой разделенный предикат используется для каждого узла дерева, остается случайным, и деревья будут разнообразными.   
  
3.  Укажите, как нужно обучить модель, установив опцию **«Создать тренер».**  
  
    -   **Единый параметр**: Если вы знаете, как настроить модель, вы можете предоставить определенный набор значений в качестве аргументов.

    -   **Диапазон параметров**: Если вы не уверены в лучших параметрах, вы можете найти оптимальные параметры с помощью модуля [Tune Model Hyperparameters.](tune-model-hyperparameters.md) Вы предоставляете некоторый диапазон значений, и тренер итерирует несколько комбинаций параметров, чтобы определить комбинацию значений, которая дает наилучший результат.
  
4.  Для **количества деревьев решений,** введите максимальное количество деревьев решений, которые могут быть созданы в ансамбле. Создавая больше деревьев решений, вы потенциально можете получить лучшее покрытие, но время обучения увеличивается.  
  
    > [!NOTE]
    >  Это значение также контролирует количество деревьев, отображаемых при визуализации обученной модели. Если вы хотите увидеть или распечатать одно дерево, можно установить значение до 1. Однако может быть получено только одно дерево (дерево с первоначальным набором параметров) и никаких дальнейших итераций не выполняется.
  
5.  Для **максимальной глубины деревьев решения,** введите номер, чтобы ограничить максимальную глубину любого дерева решения. Увеличение глубины дерева может повысить точность, однако при этом могут возникать лжевзаимосвязи и увеличиваться время обучения.
  
6.  Для **количества случайных сплитов на узла**введите количество сплитов, которые можно использовать при построении каждого узла дерева. Разделение *split* означает, что объекты на каждом уровне дерева (узла) делятся случайным образом.
  
7.  Для **минимального количества образцов на узла листа**укажите минимальное количество случаев, необходимых для создания любого терминального узла (листа) в дереве.
  
     Увеличив это значение, вы увеличиваете пороговое значение для создания новых правил. Например, при использовании значения по умолчанию 1, даже один случай может привести к созданию нового правила. Если увеличить его до 5, для создания правила обучающие данные должны будут содержать не менее пяти вариантов.  
  
8.  Выберите **неизвестные значения Разрешить для опции категориальных объектов** для создания группы для неизвестных значений в наборах обучения или проверки. Модель может быть менее точной для известных значений, но она может обеспечить лучшие прогнозы для новых (неизвестных) значений. 

     При этом выборе этой опции модель может принимать только те значения, которые содержатся в обучаемых данных.
  
9. Прикрепите набор данных с маркировкой и один из [обучающие модулей:](module-reference.md)  
  
    -   При установке **режима создания тренажера** на **единый параметр**используйте модуль [Модели поезда.](./train-model.md)  
    
## <a name="results"></a>Результаты

После завершения обучения:

+ Чтобы сохранить моментальный снимок обученной модели, выберите вкладку **Выводы** в правой панели **модуля модели Train.** Выберите значок **набора данных Регистра,** чтобы сохранить модель в качестве многоразового модуля.

+ Чтобы использовать модель для скоринга, добавьте модуль **Модели оценки** в конвейер.

## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с [набором модулей, доступных](module-reference.md) для машинного обучения Azure. 