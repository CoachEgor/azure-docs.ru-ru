---
title: 'Вычисление модели: ссылка на модуль'
titleSuffix: Azure Machine Learning service
description: Узнайте, как использовать модуль оценки модели в службе Машинное обучение Azure для измерения точности обученной модели.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: xiaoharper
ms.author: zhanxia
ms.date: 05/06/2019
ms.openlocfilehash: 0ad4ceedf9c1d65339c9e4aabebc0a47475ed568
ms.sourcegitcommit: e0e6663a2d6672a9d916d64d14d63633934d2952
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/21/2019
ms.locfileid: "72693804"
---
# <a name="evaluate-model-module"></a>Вычисление модуля модели

В этой статье описывается модуль визуального интерфейса (Предварительная версия) для службы Машинное обучение Azure.

Используйте этот модуль для измерения точности обученной модели. Вы предоставляете набор данных, содержащий оценки, сформированные из модели, а модуль « **Анализ модели** » вычисляет набор метрик оценки, стандартных для отрасли.
  
 Метрики, возвращаемые функцией " **вычислить модель** ", зависят от типа модели, которую вы оцениваете:  
  
-   **Модели классификации**    
-   **Модели регрессии**    



> [!TIP]
> Если вы не знакомы с оценкой модели, мы рекомендуем использовать серию видео Dr. Стивен Elston) в рамках [курса машинного обучения](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/) из EdX. 


Существует три способа использования модуля « **Анализ модели** »:

+ Создание оценок для обучающих данных и оценка модели на основе этих оценок
+ Создание оценок для модели, но сравнение этих оценок с показателями в зарезервированном проверочном наборе
+ Сравнение оценок для двух различных, но связанных моделей с использованием одного набора данных

## <a name="use-the-training-data"></a>Использование обучающих данных

Чтобы оценить модель, необходимо подключить набор данных, содержащий набор входных столбцов и оценок.  Если другие данные недоступны, можно использовать исходный набор данных.

1. Соедините выходные данные оцененной [модели](./score-model.md) оценки с входными **данными для** **вычисления модели**. 
2. Щелкните **оценить модуль модели** и запустите конвейер, чтобы создать оценки оценки.

## <a name="use-testing-data"></a>Использование данных тестирования

Распространенный сценарий в машинном обучении заключается в разделении исходного набора данных на обучающие и проверочные наборы, с помощью модуля [Split](./split-data.md) или модуля [Partition и Sample](./partition-and-sample.md) . 

1. Соедините выходные данные оцененной [модели](score-model.md) оценки с входными **данными для** **вычисления модели**. 
2. Соедините выходные данные модуля Split Data (разделение данных), содержащего проверочные данные, с верным входом **оценки модели**.
2. Щелкните пункт **вычислить модуль модели** и выберите **Выполнить выбранное** , чтобы создать оценки.

## <a name="compare-scores-from-two-models"></a>Сравнение оценок из двух моделей

Можно также подключить второй набор оценок для **оценки модели**.  Оценки могут быть общим набором вычислений, которые имеют известные результаты, или набором результатов из другой модели для одних и тех же данных.

Эта функция полезна, поскольку вы можете легко сравнивать результаты из двух разных моделей на одних и тех же данных. Также можно сравнить результаты двух разных запусков по одному и тому же данным с разными параметрами.

1. Соедините выходные данные оцененной [модели](score-model.md) оценки с входными **данными для** **вычисления модели**. 
2. Соедините выход модуля оценки модели для второй модели с верным входом **оценки модели**.
3. Щелкните правой кнопкой мыши пункт **Вычисление модели**и выберите команду **выполнить** , чтобы создать оценки.

## <a name="results"></a>Результаты

После выполнения **оценки модели**щелкните правой кнопкой мыши модуль и выберите **результаты оценки** , чтобы просмотреть результаты. Вы сможете:

+ Сохранение результатов в виде набора данных для упрощения анализа с помощью других средств
+ Создание визуализации в интерфейсе

Если вы подключаете наборы данных к обоим входам для **вычисления модели**, результаты будут содержать метрики для обоих наборов или обеих моделей.
Модель или данные, присоединенные к левому порту, сначала отображаются в отчете, за которыми следуют метрики набора данных или модель, присоединенная к нужному порту.  

Например, на следующем рисунке представлено сравнение результатов из двух моделей кластеризации, созданных на основе одних и тех же данных, но с разными параметрами.  

![AML&#95;Comparing2Models](media/module/aml-comparing2models.png "AML_Comparing2Models")  

Поскольку это модель кластеризации, результаты оценки отличаются от результатов при сравнении показателей двух моделей регрессии или сравнении двух моделей классификации. Однако общая презентация одинакова. 

## <a name="metrics"></a>Метрики

В этом разделе описываются метрики, возвращаемые для конкретных типов моделей, поддерживаемых для использования с **моделью Evaluate**.

+ [модели классификации](#bkmk_classification)
+ [модели регрессии](#bkmk_regression)

###  <a name="bkmk_classification"></a>Метрики для моделей классификации

При оценке моделей классификации выводятся следующие метрики. При сравнении моделей они будут ранжированы по метрике, выбранному для оценки.  
  
-   **Точность** измеряет значение эффективности модели классификации, как пропорции истинных результатов для общего числа вариантов.  
  
-   **Точность** — это пропорция истинных результатов по всем положительным результатам.  
  
-   **Отзыв** — это часть всех правильных результатов, возвращаемых моделью.  
  
-   **F-Оценка** вычисляется как взвешенное среднее значение точности и может быть получено между 0 и 1, где идеальным значением F-Score является 1.  
  
-   **AUC** измеряет область под кривой, построенную на истинных положительных значениях по оси y, и ложные срабатывания по оси x. Эта метрика полезна, так как она предоставляет одно число, которое позволяет сравнивать модели различных типов.  
  
- **Средняя вероятность потери журнала** — это единственная оценка, используемая для выведения штрафа за неверные результаты. Он вычисляется как разница между двумя распределениями вероятностей — значением true и значением в модели.  
  
- **Курс обучения** — это единственная оценка, которая представляет преимущества классификатора по случайному прогнозу. Потери журнала измеряют неопределенность модели, сравнивая вероятности, которые она выводит к известным значениям (Земля-правда) в метках. Необходимо максимально сокращать потери журнала для модели в целом.

##  <a name="bkmk_regression"></a>Метрики для моделей регрессии
 
Метрики, возвращаемые для моделей регрессии, обычно предназначены для оценки объема ошибок.  Модель считается подгонку для данных, если разница между наблюдаемыми и прогнозируемыми значениями невелика. Однако при просмотре шаблона остатков (разница между любой прогнозируемой точкой и соответствующим фактическим значением) может сообщить о потенциальном смещении в модели.  
  
 Для вычисления моделей регрессии выводятся следующие метрики. При сравнении моделей они ранжированы по метрике, выбранному для оценки.  
  
- **Средняя абсолютная ошибка (MAE)** измеряет, насколько близки прогнозы к фактическим результатам; Таким же показателем является более низкий показатель.  
  
- **Средняя квадратная ошибка (Корень среднеквадратичной погрешности)** создает одно значение, которое суммирует ошибку в модели. Изменяя разницу, метрика не учитывает разницу между чрезмерным прогнозированием и прогнозированием.  
  
- **Относительная абсолютная ошибка (рае)** — это относительная абсолютная разница между ожидаемыми и фактическими значениями; относительный, поскольку средняя разница делится на арифметическое среднее значение.  
  
- **Относительная квадратная ошибка (РСЕ)** аналогично нормализует общую квадратную ошибку прогнозируемых значений путем деления на общую квадратную ошибку фактических значений.  
  
- **Равна нулю одна ошибка (мзое)** указывает, был ли прогноз правильным.  Другими словами: `ZeroOneLoss(x,y) = 1` при `x!=y`; в противном случае `0`.
  
- **Коэффициент определения**, часто называемый R<sup>2</sup>, представляет прогнозируемую мощность модели в виде значения от 0 до 1. Ноль означает, что модель является случайной (ничего не объясняет); 1 означает, что вполне подходит. Однако следует соблюдать осторожность при интерпретации значений R<sup>2</sup> , так как низкие значения могут быть полностью нормальны, а высокие значения могут быть подозрительными.
  

## <a name="next-steps"></a>Дальнейшие действия

См. [набор модулей, доступных](module-reference.md) машинное обучение Azure службе. 