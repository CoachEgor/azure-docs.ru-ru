---
title: 'Оценка модели: Модуль Ссылка'
titleSuffix: Azure Machine Learning
description: Узнайте, как использовать модуль «Оценка модели» в Azure Machine Learning для измерения точности обученной модели.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 02/24/2020
ms.openlocfilehash: c1bcbb6a368c9c80f968c48c1a6e0bc6c95133d6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79456410"
---
# <a name="evaluate-model-module"></a>Оценить модуль модели

В этой статье описывается модуль в дизайнере машинного обучения Azure (предварительный просмотр).

Используйте этот модуль для измерения точности обученной модели. Вы предоставляете набор данных, содержащий баллы, генерируемые из модели, и модуль **Evaluate Model** вычисляет набор стандартных метрик оценки.
  
 Метрики, возвращенные **моделью оценки,** зависят от типа модели, которую вы оцениваете:  
  
-   **Модели классификации**    
-   **Модели регрессии**  
-   **Модели кластеризации**  


> [!TIP]
> Если вы новичок в оценке модели, мы рекомендуем серию видео д-р Стивен Элстон, как часть [курса машинного обучения](https://blogs.technet.microsoft.com/machinelearning/2015/09/08/new-edx-course-data-science-machine-learning-essentials/) от EdX. 


Существует три способа использования модуля **Модели оценки:**

+ Создание баллов по учебным данным и оценка модели на основе этих показателей
+ Создание баллов по модели, но сравнить эти баллы на баллы на зарезервированном наборе тестирования
+ Сравните баллы для двух разных, но связанных моделей, используя один и тот же набор данных

## <a name="use-the-training-data"></a>Использование обучающие данные

Для оценки модели необходимо подключить набор данных, который содержит набор входных столбцов и оценки.  Если другие данные отсутствуют, можно использовать исходный набор данных.

1. Подключите выход **набора данных** оценки [модели к](./score-model.md) вхустройству **модели оценки.** 
2. Нажмите **«Оценить модель»** и запустите конвейер для генерации оценок.

## <a name="use-testing-data"></a>Использование данных тестирования

Распространенным сценарием в машинном обучении является разделение исходного набора данных на наборы данных для обучения и тестирования с помощью модуля [Split](./split-data.md) или модуля [Раздела и образца.](./partition-and-sample.md) 

1. Подключите выход **набора данных** оценки [модели к](score-model.md) вхустройству **модели оценки.** 
2. Подключите выход модуля Split Data, содержащего данные тестирования, к правому вхустройству **модели Оценки.**
2. Нажмите **«Оценить модель модуля»** и выберите **выбранный Run** для генерации оценок.

## <a name="compare-scores-from-two-models"></a>Сравните оценки двух моделей

Вы также можете подключить второй набор баллов для **оценки модели.**  Оценки могут быть общим набором оценок, который знает результаты, или набором результатов из другой модели для одних и тех же данных.

Эта функция полезна, так как вы можете легко сравнить результаты двух различных моделей по одним и тем же данным. Или вы можете сравнить результаты двух различных выполнений по аналогичным данным с разными параметрами.

1. Подключите выход **набора данных** оценки [модели к](score-model.md) вхустройству **модели оценки.** 
2. Подключите выход модуля модели оценки для второй модели к правому вправе **модели Оценки.**
3. Отправить конвейер.

## <a name="results"></a>Результаты

После запуска **модели оценки,** нажмите правой кнопкой мыши модуль и выберите **Визуализировать результаты оценки,** чтобы увидеть результаты.

При подключении наборов данных к обоим входным данным **модели Оценки**результаты будут содержать метрики для обоих наборов данных или обеих моделей.
Модель или данные, прикрепленные к левому порту, представлены сначала в отчете, а затем метрики для набора данных или модели, прикрепленной к правому порту.  

Например, следующее изображение представляет собой сравнение результатов двух моделей кластеризации, которые были построены на одних и тех же данных, но с различными параметрами.  

![Сравнение2Модели](media/module/evaluate-2-models.png)  

Поскольку это модель кластеризации, результаты оценки отличаются от результатов оценки, если сравнивать оценки из двух моделей регрессии или сравнивать две модели классификации. Тем не менее, общая презентация та же. 

## <a name="metrics"></a>Метрики

В этом разделе описаны метрики, возвращенные для конкретных типов моделей, поддерживаемых для использования с **помощью Модели оценки:**

+ [модели классификации](#metrics-for-classification-models)
+ [регрессионные модели](#metrics-for-regression-models)
+ [модели кластеризации](#metrics-for-clustering-models)

### <a name="metrics-for-classification-models"></a>Метрики для классификационных моделей

При оценке классификационных моделей сообщается о следующих метриках.
  
-   **Точность** измеряет доброту модели классификации как пропорцию истинных результатов к общему объему случаев.  
  
-   **Точность** – это доля истинных результатов по всем положительным результатам.  
  
-   **Напомним,** это доля всех правильных результатов, возвращенных моделью.  
  
-   **F-оценка** вычисляется как средневзвешенное значение точности и отзыва между 0 и 1, где идеальное значение F-оценки составляет 1.  
  
-   **AUC** измеряет область под кривой, построенной с истинными срабатываниями на оси y и ложными срабатываниями на оси x. Эта метрика полезна, поскольку она предоставляет единое число, которое позволяет сравнивать модели различных типов.  
  
- **Средняя потеря журнала** — это один балл, используемый для выражения штрафа за неправильные результаты. Он рассчитывается как разница между двумя вероятностными распределениями - истинным и верным в модели.  
  
- **Потеря журнала обучения** — это один балл, который представляет собой преимущество классификатора над случайным прогнозом. Потеря журнала измеряет неопределенность модели, сравнивая вероятности, которые она выводит, с известными значениями (земляная истина) на этикетках. Необходимо свести к минимуму потерю журнала для модели в целом.

### <a name="metrics-for-regression-models"></a>Метрики для моделей регрессии
 
Метрики, возвращенные для моделей регрессии, предназначены для оценки количества ошибок.  Считается, что модель хорошо соответствует данным, если разница между наблюдаемыми и прогнозируемыми значениями мала. Однако, глядя на шаблон остатков (разница между какой-либо одной прогнозируемой точки и ее соответствующей фактической стоимости) может многое рассказать о потенциальной предвзятости в модели.  
  
 Приведены следующие метрики для оценки моделей регрессии.
  
- **Средняя абсолютная ошибка (MAE)** измеряет, насколько близки прогнозы к фактическим результатам; таким образом, более низкий балл лучше.  
  
- **Ошибка исходного квадрата (RMSE)** создает единое значение, которое обобщает ошибку в модели. По квадратные разница, метрика игнорирует разницу между чрезмерного прогнозирования и недопрогнозирования.  
  
- **Относительная абсолютная погрешность (RAE)** представляет собой относительную абсолютную разницу между ожидаемыми и фактическими значениями; относительная, потому что средняя разница делится на арифметическое среднее.  
  
- **Относительная ошибка квадратного квадрата (RSE)** также нормализует общую квадратную ошибку прогнозируемых значений путем деления общей квадратной ошибки фактических значений.  
  

  
- **Коэффициент определения,** часто называемый R<sup>2,</sup>представляет собой прогностический эффект модели как значение между 0 и 1. Ноль означает, что модель является случайной (ничего не объясняет); 1 означает, что есть идеально подходят. Однако при интерпретации значений R<sup>2</sup> следует соблюдать осторожность, поскольку низкие значения могут быть полностью нормальными, а высокие значения могут быть подозрительными.

###  <a name="metrics-for-clustering-models"></a>Метрики для моделей кластеризации

Поскольку модели кластеризации во многих отношениях существенно отличаются от классификационных и регрессионных моделей, [Оценка модели](evaluate-model.md) также возвращает другой набор статистических данных для моделей кластеризации.  
  
 В статистике, возвращенной для модели кластеризации, описывается количество точек данных, назначенных каждому кластеру, количество разделения между кластерами и то, насколько плотно точки данных сгруппированы в каждом кластере.  
  
 Статистические данные по модели кластеризации усредняются по всему набору данных, при этом дополнительные строки содержат статистические данные по кластеру.  
  
Приведены следующие метрики для оценки моделей кластеризации.
    
-   Оценки в столбце, **Среднее расстояние до другого центра**, представляют, как близко, в среднем, каждая точка в кластере к центроидам всех других кластеров.   

-   Оценки в столбце, **Среднее расстояние до кластерного центра**, представляют близость всех точек в кластере к центроиду этого кластера.  
  
-   В столбце **«Количество очков»** показано количество точек данных, назначенных каждому кластеру, а также общее общее количество точек данных в любом кластере.  
  
     Если количество точек данных, назначенных кластерам, меньше общего числа доступных точек данных, это означает, что точки данных не могут быть назначены кластеру.  
  
-   Оценки в столбце, **Максимальное расстояние до кластерного центра**, представляют сумму расстояний между каждой точкой и центроидом кластера этой точки.  
  
     Если это число высокое, это может означать, что кластер широко рассредоточен. Эту статистику следует просмотреть вместе со **средним расстоянием до кластерного центра,** чтобы определить спред кластера.   

-   Комбинированная оценка **оценки** в нижней части каждого раздела результатов перечисляет усредненные баллы для кластеров, созданных в этой конкретной модели.  
  

## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с [набором модулей, доступных](module-reference.md) для машинного обучения Azure. 