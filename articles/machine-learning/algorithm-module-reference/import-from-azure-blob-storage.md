---
title: 'Импорт из хранилища BLOB-объектов Azure: Ссылка на модуль'
titleSuffix: Azure Machine Learning service
description: Узнайте, что в этом разделе описывается использование импорта из модуля в хранилище BLOB-объектов в службе машинного обучения Azure для чтения данных из хранилища BLOB-объектов Azure, таким образом, чтобы данные можно использовать в эксперимента машинного обучения.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: xiaoharper
ms.author: zhanxia
ms.date: 05/02/2019
ROBOTS: NOINDEX
ms.openlocfilehash: 4ac98516c1a326e1ede09bbb9660113ffd0642a0
ms.sourcegitcommit: d4dfbc34a1f03488e1b7bc5e711a11b72c717ada
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "65029690"
---
# <a name="import-from-azure-blob-storage-module"></a>Импортировать из хранилища больших двоичных объектов модуля

В этой статье описывается модуль визуального интерфейса (Предварительная версия) для службы машинного обучения Azure.

Этот модуль используется для чтения данных из хранилища BLOB-объектов Azure, таким образом, чтобы данные можно использовать в эксперимента машинного обучения.  

Служба BLOB-объектов Azure — для хранения больших объемов данных, включая двоичные данные. Большие двоичные объекты Azure может осуществляться из любого места и с помощью HTTP или HTTPS. Проверка подлинности может потребоваться в зависимости от типа хранилища BLOB-объектов. 

- Общедоступный BLOB-объектов может осуществляться любым пользователем, или пользователи, имеющие URL-адрес SAS.
- Личные BLOB-объекты требуется вход в систему и учетные данные.

Импорт из хранилища BLOB-объектов требуется сохранять данные в большие двоичные объекты, использующие **блочный BLOB-объект** формат. Файлы, хранящиеся в большой двоичный объект необходимо использовать с разделителями запятыми (CSV) или разделителями табуляции (TSV) форматы. При чтении файла записи и все применимые заголовки атрибутов загружаются как строки в память как набор данных.


Мы настоятельно рекомендуем профилировать данные перед импортом, чтобы убедиться в том, что схема является должным образом. Процесс импорта сканирует некоторое количество головной строк для определения схемы, но более поздней версии строк могут содержать дополнительные столбцы или данных, привести к ошибкам.



## <a name="manually-set-properties-in-the-import-data-module"></a>Вручную задать свойства в модуле импорта данных

Следующие шаги описывают, как вручную настроить источника импорта.

1. Добавить **импорта данных** эксперимент модуль. Этот модуль в интерфейсе, можно найти в **ввод и вывод данных**

2. Для **источника данных**выберите **хранилище BLOB-объектов**.

3. Для **тип проверки подлинности**, выберите **Public (URL-адрес SAS)** Если вы знаете, что данные предоставлено как источник общих данных. URL-адрес SAS — это URL-адрес привязанный ко времени для общего доступа, которые можно создавать с помощью служебной программы службы хранилища Azure.

    В противном случае выберите **учетной записи**.

4. Если данные находятся в **открытый** BLOB-объектов, который может осуществляться с помощью URL-адрес SAS, дополнительные учетные данные не требуются, так как строка URL-адрес содержит все сведения, необходимые для загрузки и проверки подлинности.

    В **URI** введите или вставьте полный URI, определяющий учетной записи и общедоступный большой двоичный объект.



5. Если данные находятся в **частного** учетной записи, необходимо ввести учетные данные, включая имя учетной записи и ключ.

    - Для **имя учетной записи**введите или вставьте имя учетной записи, которая содержит BLOB-объектов, необходимо получить доступ.

        Например, если полный URL-адрес учетной записи хранения `http://myshared.blob.core.windows.net`, следует ввести `myshared`.

    - Для **ключ учетной записи**, вставьте ключ доступа к хранилищу, которая связана с учетной записью.

        Если вы не знаете ключ доступа, см. в разделе, «Управление учетными записями хранения Azure» этой статьи: [Об учетных записях хранения Azure](https://docs.microsoft.com/azure/storage/storage-create-storage-account).

6. Для **путь к контейнеру, каталогу или BLOB-объектов**, введите имя определенного большого двоичного объекта, которые необходимо получить.

    Например, если вы отправили файл с именем **data01.csv** в контейнер **trainingdata** в учетной записи с именем **mymldata**, было бы полный URL-адрес для файла: `http://mymldata.blob.core.windows.net/trainingdata/data01.txt` .

    Таким образом, в поле **путь к контейнеру, каталогу или BLOB-объектов**, введите: `trainingdata/data01.csv`

    Чтобы импортировать несколько файлов, можно использовать подстановочные знаки `*` (звездочка) или `?` (вопросительный знак).

    Например, при условии, что контейнер `trainingdata` содержит несколько файлов совместимый формат, можно использовать следующие спецификации для чтения всех файлов, начиная с `data`и объединить их в один набор данных:

    `trainingdata/data*.csv`

    Нельзя использовать подстановочные знаки в именах контейнеров. Если вам нужно импортировать файлы из нескольких контейнеров, используйте отдельный экземпляр **импорта данных** модуля для каждого контейнера, а затем объединить его с помощью [Добавление строк](./add-rows.md) модуля.

    > [!NOTE]
    > Если вы выбрали параметр **использовать кэшированные результаты**, любые изменения, внесенные в файлы в контейнере не запускают обновление данных в эксперименте.

7. Для **формат файла большого двоичного объекта**, выберите параметр, указывающий формат данных, которые хранятся в BLOB-объектов, так что машинного обучения Azure может обработать данные соответствующим образом. Поддерживаются следующие форматы:

    - **CSV-ФАЙЛ**: Значения с разделителями запятыми (CSV) являются формат хранения по умолчанию для экспорта и импорта файлов в машинном обучении Azure. Если данные уже содержат строку заголовка, не забудьте выбрать параметр, **файл содержит строку заголовков**, или заголовок будет рассматриваться как строки данных.

       

    - **TSV**: Значения, разделенные табуляцией (TSV) имеют формат, используемый в многие средства машинного обучения. Если данные уже содержат строку заголовка, не забудьте выбрать параметр, **файл содержит строку заголовков**, или заголовок будет рассматриваться как строки данных.

       

    - **ARFF**: Этот формат поддерживает импорт файлов в формат, используемый в наборе инструментов Weka. 

   

8. Запустите эксперимент.


## <a name="next-steps"></a>Дальнейшие действия

См. в разделе [набор модулей, доступных](module-reference.md) для службы машинного обучения Azure. 