---
title: Латентный Распределение Дирихлет
titleSuffix: Azure Machine Learning
description: Узнайте, как использовать модуль latent Dirichlet Allocation для группы неклассифицированного текста в несколько категорий.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 03/11/2020
ms.openlocfilehash: 1384491489c175ffc338f80a99aa8d5050f835d5
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "80109229"
---
# <a name="latent-dirichlet-allocation"></a>Латентный Распределение Дирихлет

В этой статье описывается, как использовать модуль **latent Dirichlet Allocation** в конструкторе машинного обучения Azure Machine Learning (предварительный просмотр) для группы неклассифицированного текста в несколько категорий. 

Латентное распределение Dirichlet (LDA) часто используется в обработке естественного языка (NLP) для поиска схожих текстов. Другим распространенным термином является *тема моделирования*.

Этот модуль берет столбец текста и генерирует следующие выводы:

+ Исходный текст, вместе с баллом для каждой категории

+ Матрица функций, содержащая извлеченные термины и коэффициенты для каждой категории

+ Преобразование, которое можно сохранить и повторно применить к новому тексту, используемому в качестве ввода

Этот модуль использует scikit-учиться библиотеке. Для получения более подробной информации о scikit-узнать, см.

### <a name="more-about-latent-dirichlet-allocation-lda"></a>Подробнее о латентном распределении Дирихлета (LDA)

Вообще говоря, LDA не является методом классификации как таковой, но использует генеративный подход. Это означает, что вам не нужно предоставлять известные метки класса, а затем сделать вывод о шаблонах.  Вместо этого алгоритм генерирует вероятностную модель, которая используется для определения групп тем. Можно использовать вероятностную модель для классификации либо существующих обучаемых случаев, либо новых случаев, которые вы предоставляете модели в качестве входных ввода.

Генеративная модель может быть предпочтительнее, поскольку она позволяет избежать каких-либо сильных предположений о взаимосвязи между текстом и категориями, и использует только распределение слов для математически модели ровесной темы.

+ Теория обсуждается в этом документе, доступныкак в качестве загрузки PDF: [Латент Dirichlet Распределение: Blei, Ng, и Иордании](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf)

+ Реализация этого модуля основана на [scikit-библиотеке для](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py) LDA.

Для получения дополнительной информации смотрите раздел [Технические примечания.](#technical-notes)

## <a name="how-to-configure-latent-dirichlet-allocation"></a>Как настроить латентный распределение дирихлета

Этот модуль требует набора данных, который содержит столбец текста, как сырой, так и предварительно обработанный.

1. Добавьте модуль **latent Dirichlet Allocation** в конвейер.

2. В качестве ввода для модуля предоставьте набор данных, содержащий одну или несколько текстовых столбцов.

3. Для **целевых столбцов**выберите один или несколько столбцов, содержащих текст для анализа.

    Вы можете выбрать несколько столбцов, но они должны быть типа строки данных.

    Как правило, поскольку LDA создает из текста большую матрицу функций, обычно анализируешь один текстовый столбец.

4. Для **количества тем для моделирования**введите целый ряд между 1 и 1000, который указывает, сколько категорий или тем, которые вы хотите получить из входного текста.

    По умолчанию создаются 5 тем.

5. Для **N-граммов**укажите максимальную длину N-граммов, генерируемых во время хэширования.

    По умолчанию 2, что означает, что и биграммы и unigrams генерируются.

6. Выберите **опцию нормализации** для преобразования значений вывода в вероятности. Таким образом, вместо того, чтобы представлять преобразованные значения в качестве целых чибар, значения в наборе данных вывода и функции будут трансформироваться следующим образом:

    + Значения в наборе данных будут представлены `P(topic|document)`как вероятность, где .

    + Значения в матрице темы функции будут `P(word|topic)`представлены как вероятность, где .

    > [!NOTE] 
    > В Azure Machine Learning designer (предварительный просмотр), потому что библиотека, которую мы основывали, scikit-learn, больше не поддерживает ненормализованную *doc_topic_distr* выход из версии 0.19, поэтому в этом модуле параметр **нормализации** может быть применен только к выходу **матрицы тема тикации,** вывод **трансформированного набора данных** всегда нормализуется.

7. Выберите опцию, **показать все параметры,** а затем установить его на правду, если вы хотите просмотреть, а затем установить дополнительные расширенные параметры.

    Эти параметры специфичны для реализации LDA для scikit-learn. Есть несколько хороших учебников о LDA в scikit-учиться, а также официальный [scikit-узнать документ](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html).

    + **Rho параметр**. Предоставьте предварительную вероятность снисхоти дистрибутивов тем. Соответствует параметру `topic_word_prior` sklearn. Вы будете использовать значение 1, если вы ожидаете, что распределение слов является плоским; т.е. все слова считаются равновесными. Если вы думаете, что большинство слов появляются редко, вы можете установить его на гораздо более низкое значение.

    + **Альфа-параметр**. Укажите предварительную вероятность снижания весов темы для одного документа.  Соответствует параметру `doc_topic_prior` sklearn.

    + **Ориентировочное количество документов**. Введите число, которое представляет вашу лучшую оценку количества документов (строк), которые будут обработаны. Это позволяет модулю выделить хэш-таблицу достаточного размера.  Соответствует параметру `total_samples` в scikit-учите.

    + **Размер партии**. Введите число, которое указывает, сколько строк для включения в каждую партию текста, отправленного в модель LDA. Соответствует параметру `batch_size` в scikit-учите.

    + **Начальное значение итерации, используемое в расписании обновления обучения.** Укажите начальное значение, которое снизило скорость обучения для ранних итераций в онлайн-обучении. Соответствует параметру `learning_offset` в scikit-учите.

    + **Мощность, применяемая к итерации во время обновлений.** Укажите уровень мощности, применяемой к колу итерации, чтобы контролировать скорость обучения во время онлайн-обновлений. Соответствует параметру `learning_decay` в scikit-учите.

    + **Количество проходов по данным.** Укажите максимальное количество раз, когда алгоритм будет циклически работать над данными. Соответствует параметру `max_iter` в scikit-учите.

8. Выберите опцию, **построить словарь ngrams** или **построить словарь ngrams до LDA**, если вы хотите создать n-грамм список в первоначальный проход, прежде чем классифицировать текст.

    Если вы создаете первоначальный словарь заранее, вы можете использовать словарь при просмотре модели. Возможность отображения результатов в тексте, а не на численных индексах, как правило, легче для интерпретации. Тем не менее, сохранение словаря займет больше времени и использовать дополнительное хранилище.

9. Для **максимального размера словаря ngram**введите общее количество строк, которые могут быть созданы в словаре n-gram.

    Этот параметр полезен для управления размером словаря. Однако, если количество ngrams в входе превышает этот размер, могут произойти столкновения.

10. Отправить конвейер. Модуль LDA использует теорему Байеса для определения того, какие темы могут быть связаны с отдельными словами. Слова не связаны исключительно с какими-либо темами или группами; вместо этого, каждый n-грамм имеет ученую вероятность быть связанным с любым из обнаруженных классов.

## <a name="results"></a>Результаты

Модуль имеет два выхода:

+ **Преобразованный набор данных**: Содержит текст ввода и определенное количество обнаруженных категорий, а также оценки для каждого примера текста для каждой категории.

+ **Матрица темы функции**: The leftmost колонка содержит извлеченную функцию текста, и есть столбец для каждой категории, содержащий балл для этой функции в этой категории.


### <a name="lda-transformation"></a>Преобразование LDA

Этот модуль также выводит *преобразование LDA,* которое применяетLD к набору данных.

Это преобразование можно сохранить, зарегистрировав набор данных под вкладкой **Выпусков журналов** в правом стеле модуля и повторно использовать его для других наборов данных. Это может быть полезно, если вы прошли обучение на большом корпусе и хотите повторно использовать коэффициенты или категории.

### <a name="refining-an-lda-model-or-results"></a>Уточнение модели или результатов LDA

Обычно невозможно создать единую модель LDA, которая будет отвечать всем потребностям, и даже модель, предназначенная для одной задачи, может потребовать много итераций для повышения точности. Мы рекомендуем вам попробовать все эти методы для улучшения модели:

+ Изменение параметров модели
+ Использование визуализации для понимания результатов
+ Получение обратной связи экспертов по предметам, чтобы выяснить, являются ли сгенерированные темы полезными.

Квалификационные меры также могут быть полезны для оценки результатов. Для оценки результатов моделирования тем рассмотрите:

+ Точность - Есть похожие элементы действительно похожи?
+ Разнообразие - Может ли модель различать аналогичные элементы, когда это необходимо для решения бизнес-проблем?
+ Масштабируемость - Работает ли она на широком диапазоне категорий текста или только на узком целевом домене?

Точность моделей, основанных на LDA, часто может быть улучшена с помощью обработки естественного языка для очистки, обобщения и упрощения текста. Например, следующие методы, поддерживаемые в Azure Machine Learning, могут повысить точность классификации:

+ Удаление стоп-слов

+ Нормализация дела

+ Лемматизация или стебель

+ Распознавание именованных сущностей

Для получения дополнительной информации, [см.](preprocess-text.md)

В конструкторе также можно использовать библиотеки R или Python для обработки текста: [Execute R Script,](execute-r-script.md) [Execute Python Script](execute-python-script.md)



## <a name="technical-notes"></a>Технические примечания

Этот раздел содержит детали реализации, советы и ответы на часто задаваемые вопросы.

### <a name="implementation-details"></a>Сведения о реализации

По умолчанию распределение выходов для преобразованного набора данных и матрицы тематики нормализуется как вероятности.

+ Преобразованный набор данных нормализуется как условная вероятность тем, данных документу. В этом случае сумма каждой строки равна 1.

+ Матрица тематики нормализуется как условная вероятность слов данной темы. В этом случае сумма каждого столбца равна 1.

> [!TIP]
> Иногда модуль может вернуть пустую тему, которая чаще всего вызвана псевдослучайной инициализацией алгоритма.  Если это произойдет, можно попробовать изменить связанные параметры, такие как максимальный размер словаря N-грамма или количество битов, которые можно использовать для хэширования функций.

### <a name="lda-and-topic-modeling"></a>LDA и тема моделирования

Латентное распределение Dirichlet (LDA) часто используется для *моделирования тем на основе контента,* что в основном означает изучение категорий из неклассифицированного текста. В моделировании темы на основе контента темой темой является распределение слов.

Например, предположим, что вы предоставили корпус отзывов клиентов, который включает в себя много, много продуктов. Текст обзоров, которые были представлены многими клиентами с течением времени будет содержать много терминов, некоторые из которых используются в нескольких темах.

**Тема,** которая определена в процессе LDA, может представлять обзоры для отдельного продукта А, или она может представлять группу обзоров продуктов. Для LDA сама тема является лишь распределением вероятности с течением времени для набора слов.

Условия редко являются исключительными для какого-либо одного продукта, но могут относиться к другим продуктам, или быть общими терминами, которые применяются ко всему ("великий", "ужасный"). Другие термины могут быть шум слова.  Тем не менее, важно понимать, что метод LDA не претендует на захват всех слов во Вселенной, или понять, как слова связаны, кроме вероятности совместного возникновения. Он может только группировать слова, которые были использованы в целевом домене.

После вычисления термина индексы сравниваются с отдельными строками текста с помощью меры сходства на расстоянии, чтобы определить, похожи ли две части текста друг на друга.  Например, вы можете обнаружить, что продукт имеет несколько имен, которые сильно коррелируют. Или, вы можете обнаружить, что сильно негативные термины, как правило, связаны с конкретным продуктом. Вы можете использовать меру сходства как для определения связанных терминов, так и для создания рекомендаций.

###  <a name="module-parameters"></a>Параметры модуля

|name|Тип|Диапазон|Необязательный|Значение по умолчанию|Описание|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|Целевые столбцы|Выполните действия на странице Выбор столбцов.||Обязательно|StringFeature|Имя целевого столбца или индекс|  
|Количество тем для моделирования|Целое число|[1;1000]|Обязательно|5|Моделирование распределения документов по темам N|  
|N-граммы|Целое число|[1;10]|Обязательно|2|Орден N-граммов, генерируемый во время хэширования|  
|Нормализации|Логическое|Значение true или false|Обязательно|Да|Нормализация вывода вероятностей.  Преобразованный набор данных будет P (тема&#124;документ) и матрица темы характеристики будет P (слово&#124;теме)|  
|Показать все варианты|Логическое|Значение true или false|Обязательно|False|Представляет дополнительные параметры, характерные для scikit-учиться онлайн LDA|  
|Ро параметр|Float|[0.00001;1.0]|Применяется при выборе флажка **все параметры**|0,01|Тема слова предварительного распределения|  
|Альфа-параметр|Float|[0.00001;1.0]|Применяется при выборе флажка **все параметры**|0,01|Тема документа предварительного распространения|  
|Ориентировочное количество документов|Целое число|[1;int.MaxValue]|Применяется при выборе флажка **все параметры**|1000|Ориентировочное количество документов (соответствует total_samples параметру)|  
|Размер партии|Целое число|[1;1024]|Применяется при выборе флажка **все параметры**|32|Размер партии|  
|Начальное значение итерации, используемое в графике обновления скорости обучения|Целое число|0;int. MaxValue|Применяется при выборе флажка **все параметры**|0|Начальное значение, что downweights скорость обучения для ранних итераций. Соответствует параметру learning_offset|  
|Мощность, применяемая к итерации во время обновления|Float|[0.0;1.0]|Применяется при выборе флажка **все параметры**|0,5|Мощность применяется к итерации рассчитывать для того, чтобы контролировать скорость обучения. Соответствует параметру learning_decay |  
|Число итераций обучения|Целое число|[1;1024]|Применяется при выборе флажка **все параметры**|25|Число итераций обучения|  
|Построить словарь ngrams|Логическое|Значение true или false|Применяется, когда **Показать все варианты** флажок *не* выбран|True|Создает словарь ngrams до вычисления LDA. Полезно для проверки и интерпретации моделей|  
|Максимальный размер словаря ngram|Целое число|[1;int.MaxValue]|Применяется, когда **опция Построить словарь ngrams** является правдой|20 000|Максимальный размер словаря ngrams. Если количество токенов в вхотобье превышает этот размер, могут возникнуть коллимузии|  
|Количество битов, которые можно использовать для хэширования функций|Целое число|[1;31]|Применяется, когда **Показать все варианты** флажок *не* выбран и **построить словарь ngrams** является ложным|12|Количество битов, которые можно использовать для хэширования функций| 
|Построить словарь ngrams до LDA|Логическое|Значение true или false|Применяется при выборе флажка **все параметры**|True|Создает словарь ngrams до LDA. Полезно для проверки и интерпретации моделей|  
|Максимальное количество ngrams в словаре|Целое число|[1;int.MaxValue]|Применяется, когда **Показать все варианты** флажок выбран и вариант **Build словарь ngrams** является правдой|20 000|Максимальный размер словаря. Если количество токенов в вхотобье превышает этот размер, могут возникнуть коллимузии|  
|Количество битов хэша|Целое число|[1;31]|Применяется при выборе флажка **все варианты** и **вариант Build dictionary ngrams** является ложным|12|Количество битов, которые можно использовать во время хэширования функций|   


## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с [набором модулей, доступных](module-reference.md) для машинного обучения Azure.   
Список ошибок, характерных для модулей, [см.](designer-error-codes.md)
