---
title: Латентное распределение Дирихле (LDA)
titleSuffix: Azure Machine Learning
description: Узнайте, как использовать модуль выделения скрытых Дирихле метода для группирования неклассифицированного текста в несколько категорий.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 03/11/2020
ms.openlocfilehash: 1384491489c175ffc338f80a99aa8d5050f835d5
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "80109229"
---
# <a name="latent-dirichlet-allocation"></a>Латентное распределение Дирихле (LDA)

В этой статье описывается использование модуля « **скрытое выделение Дирихле метода** » в конструкторе машинное обучение Azure (Предварительная версия) для группирования неклассифицированного текста в несколько категорий. 

Скрытое выделение Дирихле метода (LDA) часто используется в обработке естественного языка (NLP) для поиска похожих текстов. Другим распространенным термином является *моделирование разделов*.

Этот модуль принимает столбец текста и создает следующие выходные данные:

+ Исходный текст вместе с показателем для каждой категории

+ Матрица функций, содержащая извлеченные термины и коэффициенты для каждой категории

+ Преобразование, которое можно сохранить и применить повторно к новому тексту, используемому в качестве входных данных

В этом модуле используется библиотека scikit-учиться. Дополнительные сведения о scikit-сведениях см. в [репозитории GitHub, который содержит учебники и описание алгоритма.

### <a name="more-about-latent-dirichlet-allocation-lda"></a>Дополнительные сведения о скрытом выделении Дирихле метода (LDA)

Вообще говоря, LDA не является методом классификации на SE, но использует регенеративный подход. Это означает, что вам не нужно указывать известные метки классов, а затем определять закономерности.  Вместо этого алгоритм создает модель вероятностная, которая используется для выделения групп разделов. Модель вероятностная можно использовать для классификации существующих обучающих вариантов или новых вариантов, предоставляемых модели в качестве входных данных.

Регенеративная модель может быть предпочтительнее, поскольку она позволяет избежать принятия каких-либо строгих допущений относительно связи между текстом и категориями и использует только распределение слов для подразделов с математическими моделями.

+ Теория обсуждается в этой статье, которая доступна как загрузка в формате PDF: [скрытые Дирихле метода выделения: блеи, NG и Иордания.](https://ai.stanford.edu/~ang/papers/nips01-lda.pdf)

+ Реализация в этом модуле основана на [библиотеке scikit-учиться](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/decomposition/_lda.py) для Lda.

Дополнительные сведения см. в разделе [Технические примечания](#technical-notes) .

## <a name="how-to-configure-latent-dirichlet-allocation"></a>Настройка выделения скрытых Дирихле метода

Для этого модуля требуется набор данных, содержащий столбец текста, либо необработанный, либо предварительно обработанный.

1. Добавьте в конвейер модуль **выделения скрытых Дирихле метода** .

2. В качестве входных данных для модуля укажите набор данных, содержащий один или несколько текстовых столбцов.

3. Для поля **целевые столбцы**выберите один или несколько столбцов, содержащих текст для анализа.

    Можно выбрать несколько столбцов, но они должны иметь строковый тип данных.

    Как правило, так как LDA создает крупную матрицу функций из текста, обычно анализируется один текстовый столбец.

4. Для параметра **число разделов для модели**введите целое число от 1 до 1000, которое указывает, сколько категорий или разделов нужно наследовать от входного текста.

    По умолчанию создаются 5 разделов.

5. Для **n-грамм**укажите максимальную длину n-грамм, созданную во время хэширования.

    Значение по умолчанию — 2, то есть создаются и биграмм, и униграмм.

6. Выберите параметр **нормализация** для преобразования выходных значений в вероятности. Таким образом, вместо того, чтобы представлять преобразованные значения как целые числа, значения в наборе данных вывода и функции будут преобразованы следующим образом:

    + Значения в наборе данных будут представлены как вероятность, где `P(topic|document)`.

    + Значения в матрице раздела функции будут представлены как вероятность, где `P(word|topic)`.

    > [!NOTE] 
    > В конструкторе Машинное обучение Azure (Предварительная версия), так как библиотека, на которую мы основан, scikit-учиться, больше не поддерживает ненормализованные *doc_topic_distr* выходные данные версии 0,19, поэтому в этом модуле параметр **нормализации** можно применять только к выходным данным в **матрице** , **преобразованные** выходные данные всегда нормализованы.

7. Выберите параметр, **Показать все параметры**и задайте для него значение true, если требуется просмотреть и затем задать дополнительные дополнительные параметры.

    Эти параметры относятся к реализации scikit-учиться LDA. Есть несколько хороших руководств по LDA в scikit-учиться, а также официальный [документ scikit-учиться](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html).

    + **Параметр Ро**. Укажите более раннюю вероятность для распределения разделов. Соответствует `topic_word_prior` параметру sklearn. Значение 1 следует использовать, если предполагается, что распределение слов является плоским; Например, все слова считаются екуипробабле. Если вы считаете, что большинство слов имеют разреженный вид, можно задать для него более низкое значение.

    + **Альфа-параметр**. Укажите более раннюю вероятность для веса разделов в документе.  Соответствует `doc_topic_prior` параметру sklearn.

    + **Предполагаемое количество документов**. Введите число, представляющее наиболее подходящую оценку количества документов (строк), которые будут обработаны. Это позволяет модулю выделить хэш-таблицу достаточного размера.  Соответствует `total_samples` параметру в scikit — сведения.

    + **Размер пакета**. Введите число, которое указывает, сколько строк следует включить в каждый пакет текста, отправляемый в модель LDA. Соответствует `batch_size` параметру в scikit — сведения.

    + **Начальное значение итерации, используемое в расписании обновлений для образовательных**заработок. Укажите начальное значение, довнвеигхтс обучающий темп для ранних итераций в интерактивном обучении. Соответствует `learning_offset` параметру в scikit — сведения.

    + **Питание, применяемое к итерации во время обновлений**. Указывает уровень мощности, применяемый к количеству итераций, для управления частотой обучения во время обновлений в сети. Соответствует `learning_decay` параметру в scikit — сведения.

    + **Количество проходов по данным**. Укажите максимальное число циклов, по которым алгоритм будет циклически проходить по данным. Соответствует `max_iter` параметру в scikit — сведения.

8. Выберите параметр, **построить словарь n-граммы** или **словарь сборки n-граммы до Lda**, если хотите создать список n-грамм на начальном этапе перед классификацией текста.

    Если исходный словарь создан заранее, можно использовать словарь при просмотре модели. Возможность сопоставлять результаты с текстом, а не с числовыми индексами, как правило, проще для интерпретации. Однако сохранение словаря займет больше времени и использует дополнительное хранилище.

9. Для параметра **максимальный размер словаря ngram**введите общее число строк, которые могут быть созданы в словаре n-грамм.

    Этот параметр полезен для управления размером словаря. Однако если число n-граммы во входных данных превышает этот размер, могут возникать конфликты.

10. Отправьте конвейер. Модуль LDA использует алгоритм Байеса теорема, чтобы определить, какие темы могут быть связаны с отдельными словами. Слова не связаны только с какими либо разделами или группами. Вместо этого каждая n-грамма имеет определенную вероятность, связанную с любым из обнаруженных классов.

## <a name="results"></a>Результаты

Модуль имеет два выхода:

+ **Преобразованный набор данных**: содержит входной текст и указанное число обнаруженных категорий вместе с показателями для каждого текстового примера для каждой категории.

+ **Матрица раздела компонентов**: крайний левый столбец содержит функцию извлеченного текста, а для каждой категории, содержащей оценку для этой функции в этой категории, существует столбец.


### <a name="lda-transformation"></a>Преобразование LDA

Этот модуль также выводит *Преобразование Lda* , которое применяет Lda к набору данных.

Это преобразование можно сохранить, заменив набор данных на вкладке **выходные данные и журналы** в правой области модуля и повторно используя его для других наборов данных. Это может быть полезно, если вы обучились по большому совокупности и хотите повторно использовать коэффициенты или категории.

### <a name="refining-an-lda-model-or-results"></a>Уточнение модели LDA или результатов

Обычно нельзя создать отдельную модель LDA, которая будет соответствовать всем потребностям, и даже модель, предназначенная для одной задачи, может потребовать много итераций для повышения точности. Мы рекомендуем использовать все эти методы для улучшения модели:

+ Изменение параметров модели
+ Использование визуализации для понимания результатов
+ Получите отзывы экспертов, чтобы узнать, полезны ли созданные разделы.

Качественные меры также могут быть полезны для оценки результатов. Чтобы оценить результаты моделирования разделов, учитывайте следующее.

+ Точность — аналогичные элементы похожи?
+ Разнообразие — может ли модель отличать похожие элементы, когда это требуется для бизнес-задачи?
+ Масштабируемость. работает ли она для широкого спектра текстовых категорий или только для узких целевых доменов?

Точность моделей, основанных на LDA, часто можно улучшить, используя обработку на естественном языке для очистки, суммирования и упрощения или категоризации текста. Например, следующие методы, поддерживаемые в Машинное обучение Azure, могут улучшить точность классификации:

+ Удаление стоп-слов

+ Нормализация вариантов

+ Лемматизация или извлечение корней

+ Распознавание именованных сущностей

Дополнительные сведения см. в разделе [Предварительная обработка текста](preprocess-text.md).

В конструкторе можно также использовать библиотеки R или Python для обработки текста: [выполнение скрипта r](execute-r-script.md), [выполнение скрипта Python](execute-python-script.md)



## <a name="technical-notes"></a>Технические примечания

В этом разделе содержатся сведения о реализации, советы и ответы на часто задаваемые вопросы.

### <a name="implementation-details"></a>Сведения о реализации

По умолчанию распределения выходов для преобразованного набора данных и матрицы компонентов-разделов нормализованы как вероятности.

+ Преобразованный набор данных нормализуется как условная вероятность разделов, заданных документом. В этом случае сумма каждой строки равна 1.

+ Матрица функций-разделов нормализована как условная вероятность слов, заданных в разделе. В этом случае сумма каждого столбца равна 1.

> [!TIP]
> Иногда модуль может вернуть пустой раздел, который чаще всего вызывается при инициализации алгоритма псевдо-Random.  В этом случае можно попробовать изменить связанные параметры, например максимальный размер словаря N-грамм или число битов, которое будет использоваться для хэширования компонентов.

### <a name="lda-and-topic-modeling"></a>Моделирование LDA и разделов

Выделение скрытых Дирихле метода (LDA) часто используется для *моделирования разделов на основе содержимого*, что по сути означает категории обучения из неклассифицированного текста. В разделе моделирование разделов на основе содержимого раздел представляет собой распределение по словам.

Например, предположим, что вы предоставили совокупности проверок клиентов, включающих множество и многие продукты. Текст проверок, отправленных многими клиентами со временем, будет содержать много терминов, некоторые из которых используются в нескольких разделах.

**Раздел** , идентифицированный процессом Lda, может представлять рецензии для отдельного продукта а или представлять группу проверок продукта. Для LDA сам раздел является просто распределением вероятности по времени для набора слов.

Термины редко исключаются для одного продукта, но могут ссылаться на другие продукты или представлять собой общие термины, применимые ко всем («отлично», «ужасные»). Другие термины могут быть неучитываемыми словами.  Однако важно понимать, что метод LDA не предназначен для захвата всех слов в вселенной или для понимания того, как слова связаны, помимо вероятностей сосуществования. Он может группировать только те слова, которые использовались в конечном домене.

После расчета индексов терминов отдельные строки текста сравниваются с помощью меры подобия на основе расстояния, чтобы определить, являются ли два фрагмента текста похожими.  Например, может оказаться, что у продукта есть несколько имен, которые имеют строгую корреляцию. Или вы можете обнаружить, что строго отрицательные термины обычно связаны с определенным продуктом. Для определения связанных терминов и создания рекомендаций можно использовать меру подобия.

###  <a name="module-parameters"></a>Параметры модуля

|Имя|Type|Диапазон|Необязательный|По умолчанию|Описание|  
|----------|----------|-----------|--------------|-------------|-----------------|  
|Целевые столбцы|Выполните действия на странице Выбор столбцов.||Обязательный|StringFeature|Имя или индекс целевого столбца|  
|Число разделов для модели|Целое число|[1; 1000]|Обязательный|5|Моделирование распределения документов по N темам|  
|N-граммы|Целое число|[1; 10]|Обязательный|2|Порядок N-датаграмм, созданных во время хэширования|  
|Нормализовать|Логическое значение|Значение true или false|Обязательный|Да|Нормализовать выходные данные в вероятности.  Преобразованный набор данных будет иметь вид P (раздел&#124;документ), а матрица с тем или другими компонентами будет иметь вид P (Word&#124;раздел).|  
|Отображение всех параметров|Логическое значение|Значение true или false|Обязательный|False|Предоставляет дополнительные параметры, относящиеся к scikit-учиться Интернету LDA|  
|Параметр Ро|Float|[намерено; 1,0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,01|Предварительное распространение слова в разделе|  
|Альфа-параметр|Float|[намерено; 1,0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,01|Документ о предыдущем распространении раздела|  
|Предполагаемое число документов|Целое число|[1;int.MaxValue]|Применяется, если установлен флажок " **Показывать все параметры** "|1000|Предполагаемое число документов (соответствует параметру total_samples)|  
|Размер пакета|Целое число|[1; 1024]|Применяется, если установлен флажок " **Показывать все параметры** "|32|Размер пакета|  
|Начальное значение итерации, используемое в расписании обновления темпов обучения|Целое число|[0; int. MaxValue|Применяется, если установлен флажок " **Показывать все параметры** "|0|Начальное значение, довнвеигхтс обучающий темп для ранних итераций. Соответствует параметру learning_offset|  
|Питание, применяемое к итерации во время обновлений|Float|[0.0; 1.0]|Применяется, если установлен флажок " **Показывать все параметры** "|0,5|Питание, применяемое к количеству итераций для контроля скорости обучения. Соответствует параметру learning_decay |  
|Число итераций обучения|Целое число|[1; 1024]|Применяется, если установлен флажок " **Показывать все параметры** "|25|Число итераций обучения|  
|Сборка словаря n-граммы|Логическое значение|Значение true или false|Применяется, если флажок " **Показывать все параметры** " *не* установлен|True|Создает словарь n-граммы до вычисления LDA. Полезно для проверки и интерпретации модели|  
|Максимальный размер словаря ngram|Целое число|[1;int.MaxValue]|Применяется, когда параметр **Build Dictionary объекта n-граммы** имеет значение true|20 000|Максимальный размер словаря n-граммы. Если количество токенов во входных данных превышает этот размер, могут возникать конфликты|  
|Число битов, используемых для хэширования компонентов|Целое число|[1; 31]|Применяется, если флажок **Показывать все параметры** *не* установлен и **словарь сборки n-граммы** имеет значение false.|12|Число битов, используемых для хэширования компонентов| 
|Сборка словаря n-граммы до LDA|Логическое значение|Значение true или false|Применяется, если установлен флажок " **Показывать все параметры** "|True|Создает словарь n-граммы до LDA. Полезно для проверки и интерпретации модели|  
|Максимальное число n-граммы в словаре|Целое число|[1;int.MaxValue]|Применяется, если установлен флажок **Показывать все параметры** и параметр **построить словарь N-граммы** имеет значение true.|20 000|Максимальный размер словаря. Если количество токенов во входных данных превышает этот размер, могут возникать конфликты|  
|Число хэш-битов|Целое число|[1; 31]|Применяется, если установлен флажок **Показывать все параметры** и параметр **построить словарь N-граммы** имеет значение false.|12|Число битов, используемых при хэшировании компонентов|   


## <a name="next-steps"></a>Дальнейшие шаги

См. [набор модулей, доступных](module-reference.md) для машинное обучение Azure.   
Список ошибок, характерных для модулей, см. [в разделе исключения и коды ошибок для конструктора](designer-error-codes.md).
