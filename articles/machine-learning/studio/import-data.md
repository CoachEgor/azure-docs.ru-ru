---
title: Импорт данных для обучения
titleSuffix: ML Studio (classic) - Azure
description: Как импортировать данные в студию машинного обучения Azure (классический) из различных источников данных. Узнайте, какие типы данных и форматы данных поддерживаются.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio
ms.topic: conceptual
author: likebupt
ms.author: keli19
ms.custom: previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 02/01/2019
ms.openlocfilehash: cee49124a7547399889e425008a8580b9b25945a
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79217980"
---
# <a name="import-your-training-data-into-azure-machine-learning-studio-classic-from-various-data-sources"></a>Импортируйте свои обучающие данные в студию машинного обучения Azure (классический) из различных источников данных

[!INCLUDE [Notebook deprecation notice](../../../includes/aml-studio-notebook-notice.md)]

Чтобы использовать собственные данные в Machine Learning Studio (классический) для разработки и обучения прогностической аналитики решения, вы можете использовать данные из: 

* **локальный файл**, заранее отправляйте данные из жесткого диска, чтобы создать модуль набора данных в рабочей области;
* **источники данных в Интернете**, чтобы получать данные в ходе эксперимента с помощью модуля [Импорт данных][import-data];
* **Студия машинного обучения (классический) эксперимент** - Использование данных, которые были сохранены в качестве набора данных в машинном обучении Studio (классический)
* [**локальная база данных SQL Server**](use-data-from-an-on-premises-sql-server.md), чтобы использовать данные из локальной базы данных SQL Server без необходимости вручную копировать данные.

> [!NOTE]
> В Студии машинного обучения (классический) имеется ряд выборочных наборов данных, которые можно использовать для обучения данных. Для получения информации о них [см.](use-sample-datasets.md)

## <a name="prepare-data"></a>Подготовка данных

Студия машинного обучения (классическая) предназначена для работы с прямоугольными или табулярными данными, такими как текстовые данные, которые разграничивают или структурированы, из базы данных, хотя в некоторых случаях могут использоваться непрямоугольные данные.

Лучше всего, если ваши данные относительно чистые, прежде чем импортировать его в Studio (классический). Например, обратите внимание на строки без кавычек.

Тем не менее, есть модули, доступные в Studio (классический), которые позволяют некоторые манипуляции данных в рамках эксперимента после импорта данных. В зависимости от алгоритмов машинного обучения, которые вы будете использовать, необходимо решить, как будут обрабатываться структурные трудности в данных, например отсутствующие значения и разреженные данные, и существуют ли модули, которые могут здесь помочь. В разделе **Преобразование данных** палитры модулей найдите модули, которые выполняют такие функции.

В любой точке вашего эксперимента можно просмотреть или скачать данные, созданные модулем, щелкнув правой кнопкой мыши порт вывода. В зависимости от модуля, могут быть различные варианты загрузки доступны, или вы можете быть в состоянии визуализировать данные в вашем веб-браузере в Studio (классический).

## <a name="supported-data-formats-and-data-types"></a>Поддерживаемые форматы и типы данных

В свой эксперимент можно импортировать значительное количество типов данных, в зависимости от того, какая система используется для импорта данных и каков источник этих данных:

* Обычный текст (TXT)
* Текст с разделителями-запятыми с заголовком (CSV) или без заголовка (NH.CSV)
* Текст с разделителями-табуляциями с заголовком (TSV) или без заголовка (NH.TSV)
* Файл Excel
* Таблица Azure
* Таблица Hive
* Таблицы базы данных SQL
* Значения OData
* данные SVMLight (SVMLIGHT) (подробнее о формате см. в [определении SVMLight](http://svmlight.joachims.org/));
* данные в формате ARFF (подробнее о формате см. в [определении ARFF](https://weka.wikispaces.com/ARFF));
* ZIP-файл (ZIP)
* Файл объекта или рабочей области R (RData)

Если вы импортируете данные в таком формате, как ARFF, который включает метаданные, Studio (классический) использует эти метаданные для определения заголовка и типа данных каждого столбца.

Если вы импортируете такие данные, как формат TSV или CSV, который не включает эти метаданные, Studio (классический) делает вывод о типе данных для каждого столбца, пробучивая данные. Если данные также не имеют заголовков столбцов, Studio (классический) предоставляет имена по умолчанию.

Вы можете явно указать или изменить заголовки и типы данных для столбцов с помощью модуля [Изменить метаданные][edit-metadata].

Следующие типы данных распознаются Studio (классический):

* Строка
* Целое число
* Double
* Логическое
* Дата и время
* TimeSpan

Для передачи данных между модулями Студия использует внутренний тип данных, который называется ***Таблица данных***. Можно явно преобразовать данные в формат таблицы данных с помощью модуля [Convert to Dataset.][convert-to-dataset]

Любой модуль, который принимает форматы, отличные от таблицы данных, перед передачей данных в следующий модуль преобразует данные в формат таблицы данных без вмешательства пользователя.

При необходимости можете преобразовать формат таблицы данных обратно в формат CSV, TSV, ARFF или SVMLight, используя другие модули преобразования.
Узнать о модулях, которые выполняют эти функции, можно узнать в разделе **Преобразование форматов данных** палитры модулей.

## <a name="data-capacities"></a>Емкости данных

Модули в машинном обучении Studio (классические) поддерживают наборы данных до 10 ГБ плотных численных данных для обычных случаев использования. Если модуль принимает несколько видов входных данных, то их общий объем должен составлять 10 ГБ. Вы можете создать выборку больших наборов данных с помощью запросов Hive или Базы данных SQL Azure или предварительной обработки модуля "Обучение на основе счетчиков" перед импортом данных.  

Следующие типы данных можно развернуть в большие наборы данных при нормализации признаков. Максимальный объем этих данных — менее 10 ГБ:

* разреженные;
* категориальные;
* Строки
* Двоичные данные

В следующих модулях можно использовать наборы данных объемом менее 10 ГБ:

* модули системы рекомендаций;
* модуль метода увеличения числа примеров миноритарного класса с помощью синтетических объектов (SMOTE);
* модули написания сценариев: R, Python, SQL;
* модули, в которых объем выходных данных может превышать объем входных данных, такие как "Слияние" или "Хэширование признаков";
* "Перекрестная проверка", "Гиперпараметры модели настройки", "Порядковая регрессия" и "Многоклассовая классификация «один — все»", когда число итераций очень велико.

Для наборов данных объемом больше, чем несколько гигабайт, требуется передать данные в службу хранилища Azure или Базу данных SQL Azure либо использовать HDInsight, а не отправлять данные прямо из локального файла.

Вы можете найти сведения о данных изображений в ссылке на модуль [Импорт образов](https://docs.microsoft.com/azure/machine-learning/studio-module-reference/import-images#bkmk_Notes).

## <a name="import-from-a-local-file"></a>Импорт из локального файла

Вы можете загрузить файл данных с жесткого диска для использования в качестве обучающие данные в Studio (классический). При импорте файла данных, можете создать модуль набора данных, который готов для использования в экспериментах рабочей области.

Чтобы импортировать данные из локального жесткого диска, выполните следующие действия:

1. Нажмите **кнопку «New»** в нижней части окна Студии (классический).
2. Выберите **Набор данных** и **From local file** (Из локального файла).
3. В **журнале Upload— новом** диалоге набора данных просматривайте файл, который вы хотите загрузить.
4. Введите имя, укажите тип данных и, при необходимости, введите описание. Рекомендуем ввести описание — оно позволяет записать все характеристики данных, которые необходимо помнить при использовании данных в будущем.
5. Флажок **Это новая версия существующего набора данных** позволяет обновить существующий набор данных новыми данными. Чтобы выполнить это, установите флажок, а затем введите имя существующего набора данных.

![Передача нового набора данных](./media/import-data/upload-dataset-from-local-file.png)

Время передачи зависит от объема данных и скорости подключения к службе. Если вы знаете, файл займет много времени, вы можете сделать другие вещи внутри Studio (классический), пока вы ждете. Тем не менее закрытие браузера до завершения загрузки данных приведет к ошибке передачи данных.

После загрузки данные сохраняются в модуле набора данных и доступны для любого эксперимента в рабочей области.

При редактировании эксперимента вы можете найти ранее отправленные наборы данных в списке **My Datasets** (Мои наборы данных), который входит в список **Saved Datasets** (Сохраненные наборы данных), в палитре модулей. Перетащите набор данных на холст эксперимента, где нужно использовать эти данные для последующего анализа и машинного обучения.

## <a name="import-from-online-data-sources"></a>Импорт из сетевых источников данных

Используя модуль [Импорт данных][import-data], ваш эксперимент может импортировать данные из различных подключенных источников данных во время проведения эксперимента.

> [!NOTE]
> Эта статья содержит общие сведения о модуле [Импорт данных][import-data]. Дополнительные сведения о типах данных, к которым можно получить доступ, форматах, параметрах, а также ответы на часто задаваемые вопросы см. в разделе справки по модулю [Импорт данных][import-data].

Вы можете получить доступ к данным из одного из нескольких подключенных источников данных во время запуска эксперимента с помощью модуля [Импорт данных][import-data].

* URL-адрес с использованием HTTP;
* Hadoop с использованием HiveQL
* хранилище BLOB-объектов Azure.
* Таблица Azure
* базу данных SQL Azure или сервер SQL Server на виртуальной машине Azure;
* локальная база данных SQL Server;
* поставщик веб-канала данных (в настоящее время OData).
* Azure Cosmos DB

Так как доступ к этим данным для обучения осуществляется во время эксперимента, они доступны только в рамках этого эксперимента. Для сравнения: данные, хранящиеся в модуле набора данных, доступны для любого эксперимента в рабочей области.

Чтобы получить доступ к онлайн-источникам данных в эксперименте Studio (классический), добавьте модуль [импортных данных][import-data] в свой эксперимент. Затем выберите **Запустить мастер импорта данных** в разделе **Свойства**, чтобы получить пошаговые инструкции по выбору и настройке источника данных. Кроме того, вы можете вручную выбрать **Источник данных** в разделе **Свойства** и указать параметры, необходимые для доступа к данным.

Поддерживаемые сетевые источники данных описаны в таблице ниже. Кроме того, в этой таблице перечислены поддерживаемые форматы файлов и параметры, используемые для доступа к данным.

> [!IMPORTANT]
> В настоящее время модули [Импорт данных][import-data] и [Экспорт данных][export-data] могут читать и записывать только данные в службе хранилища Azure, созданной с помощью классической модели развертывания. Другими словами, новый тип учетной записи хранилища BLOB-объектов Azure, предоставляющий "горячий" или "холодный" уровень доступа к хранилищу, не еще поддерживается.
>
> Как правило, это не повлияет на учетные записи хранения Azure, созданные до появления данного уровня служб.
> Если необходимо создать учетную запись, выберите **классическую** модель развертывания или используйте Resource Manager и в качестве **типа учетной записи** выберите **Общее назначение**, а не **Хранилище BLOB-объектов**.
>
> Дополнительные сведения см. в разделе [Хранилище BLOB-объектов Azure: "горячий" и "холодный" уровни хранилища](../../storage/blobs/storage-blob-storage-tiers.md).

### <a name="supported-online-data-sources"></a>Поддерживаемые сетевые источники данных
Модуль Машинного обучения Azure Machine Learning Studio (классический) модуль **импортных данных** поддерживает следующие источники данных:

| Источник данных | Описание | Параметры |
| --- | --- | --- |
| URL-адрес с использованием протокола HTTP |Считывает данные в файлах с разделителями-запятыми (CSV), файлах с разделителями-табуляциями (TSV), а также в файлах в формате ARFF и SVM-light из любого URL-адреса, использующего протокол HTTP. |<b>URL-адрес</b>. Задает полное имя файла, включая URL-адрес сайта и имя файла с любым расширением. <br/><br/><b>Формат данных</b>. Задает один из поддерживаемых форматов данных: CSV, TSV, ARFF или SVM-light. Если данные содержат строку заголовков, она используется для назначения имен столбцов. |
| Hadoop/HDFS |Считывает данные из распределенного хранилища в Hadoop. Необходимые вам данные можно указать с помощью HiveQL, языка запросов на основе SQL. Кроме того, Hive'L может использоваться для агрегирования данных и обработки данных перед добавлением данных в Studio (классический). |<b>Hive database query</b> (Запрос к базе данных Hive). Указывает запрос Hive, используемый для создания данных.<br/><br/><b>HCatalog server URI</b> (URI сервера HCatalog). Задает имя кластера в формате *&lt;имя_кластера&gt;.azurehdinsight.net*.<br/><br/><b>Hadoop user account name</b> (Имя учетной записи пользователя Hadoop). Задает имя учетной записи пользователя Hadoop для подготовки кластера.<br/><br/><b>Hadoop user account password</b> (Пароль учетной записи пользователя Hadoop). Задает учетные данные, используемые при подготовке кластера. Дополнительные сведения см. в статье [Создание кластеров Hadoop в HDInsight](/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters).<br/><br/><b>Location of output data</b> (Расположение выходных данных). Указывает, где хранятся данные: в распределенной файловой системе Hadoop (HDFS) или в Azure. <br/><ul>Если выходные данные хранятся в HDFS, укажите универсальный код ресурса (URI) сервера HDFS. (не забудьте указать имя кластера HDInsight без префикса HTTPS://). <br/><br/>Если выходные данные хранятся в Azure, необходимо указать имя учетной записи хранения Azure, ключ доступа к хранилищу и имя контейнера хранилища.</ul> |
| База данных SQL |Считывает данные, хранящиеся в базе данных SQL Azure или в базе данных SQL Server, запущенной на виртуальной машине Azure. |<b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><ul>Если используется база данных SQL Azure, введите создаваемое имя сервера. Обычно он имеет форму * &lt;generated_identifier&gt;.database.windows.net.* <br/><br/>В случае, если сервер S'L, размещенный на Azure Виртуальный компьютер введите *tcp:&lt;Виртуальная машина&gt;DNS Имя , 1433*</ul><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Server user account password</b> (Пароль учетной записи пользователя сервера). Задает пароль для учетной записи указанного пользователя.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| Локальная база данных SQL |Считывает данные, хранящиеся в локальной базе данных SQL. |<b>Шлюз данных</b>. Задает имя шлюза управления данными, установленного на компьютере, имеющем доступ к базе данных SQL Server. Для получения информации о настройке шлюза см. [Perform Advanced Analytics с Azure Machine Learning Studio (классический) с использованием данных с внутреннего сервера S'L.](use-data-from-an-on-premises-sql-server.md)<br/><br/><b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Имя пользователя и пароль</b>. Чтобы ввести учетные данные базы данных, щелкните <b>Введите значения</b>. Можно использовать встроенную аутентификацию Windows или аутентификацию SQL Server, в зависимости от настроек локального сервера SQL Server.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| таблице Azure |Считывает данные из службы таблиц в хранилище Azure.<br/><br/>Если вам нечасто требуется считывание больших объемов данных, используйте службу таблиц Azure. Это недорогое и гибкое нереляционное (NoSQL) решение хранилища с высокой степенью масштабируемости и доступности. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account. Каждое из этих значений имеет собственный набор параметров. <br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Table URI</b> (URI таблицы). Задает общедоступный или подписанный URL-адрес (SAS) таблицы.<br/><br/><b>Specifies the rows to scan for property names</b> (Указывает строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице. <br/><br/>Если данные однородные и прогнозируемые, рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы с использованием наборов свойств, которые различаются в зависимости от глубины и положения таблицы, выберите параметр *ScanAll* для сканирования всех строк. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей таблицу, выбранную для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Имя таблицы</b>. Указывает имя таблицы, содержащей данные для чтения.<br/><br/><b>Rows to scan for property names</b> (Строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице.<br/><br/>Если данные однородные и прогнозируемые, то рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы с использованием наборов свойств, которые различаются в зависимости от глубины и положения таблицы, выберите параметр *ScanAll* для сканирования всех строк. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/> |
| хранилище BLOB-объектов Azure |Считывает данные, хранящиеся в службе больших двоичных объектов в хранилище Azure, включая изображения, неструктурированные текстовые данные и двоичные данные.<br/><br/>Службу BLOB-объектов можно использовать для предоставления общего доступа к данным или для закрытого хранения данных приложения. Доступ к данным можно получить из любого места, подключившись через протокол HTTP или HTTPS. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account.<br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Универсальный код ресурса (URI)</b>. Задает общедоступный или подписанный URL-адрес (SAS) большого двоичного объекта службы хранилища.<br/><br/><b>Формат файла</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы: CSV, TSV и ARFF.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей большой двоичный объект, выбранный для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Path to container, directory, or blob</b> (Путь к контейнеру, каталогу или большому двоичному объекту). Задает имя большого двоичного объекта, содержащего данные для чтения.<br/><br/><b>Формат файла BLOB-объекта</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы данных: CSV, TSV, ARFF, CSV с заданной кодировкой и Excel. <br/><br/><ul>Если используется формат CSV или TSV, обязательно укажите, содержит ли файл строку заголовка.<br/><br/>Для чтения данных из книги Excel можно использовать параметр Excel. Для параметра <i>Формат данных Excel</i> укажите расположение данных: в диапазоне листа Excel или в таблице Excel. В параметре <i>Excel sheet or embedded table</i> (Лист или внедренная таблица Excel) укажите имя листа или таблицы для считывания данных.</ul><br/> |
| Поставщик веб-канала данных |Считывает данные, получаемые от поддерживаемого поставщика веб-канала. В настоящее время поддерживается только формат Open Data Protocol (OData). |<b>Data content type</b> (Тип содержимого данных). Задает формат OData.<br/><br/><b>Исходный URL-адрес</b>. Указывает полный URL-адрес веб-канала данных. <br/>Например, этот URL-адрес позволяет считывать данные из примера базы данных Northwind: https://services.odata.org/northwind/northwind.svc/. |

## <a name="import-from-another-experiment"></a>Импорт из другого эксперимента

Иногда понадобится получить в эксперименте промежуточный результат, который будет использоваться в другом эксперименте. Для этого сохраните модуль как набор данных, выполнив указанные ниже действия.

1. Щелкните выходные данные модуля, которые требуется сохранить в виде набора данных.
2. Щелкните **Сохранить как набор данных**.
3. При появлении запроса введите имя и описание, которое позволит легко идентифицировать набор данных.
4. Установите флажок **ОК** .

После завершения сохранения набор данных будет доступен для использования в любом эксперименте в рабочей области. Его можно найти в списке **Сохраненные наборы данных** в палитре модулей.

## <a name="next-steps"></a>Дальнейшие действия

[Развертывание веб-сервисов Azure Machine Learning Studio, которые используют модули импорта данных и экспорта данных](web-services-that-use-import-export-modules.md)


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[export-data]: https://msdn.microsoft.com/library/azure/7A391181-B6A7-4AD4-B82D-E419C0D6522C/


<!-- Module References -->
[convert-to-dataset]: https://msdn.microsoft.com/library/azure/72bf58e0-fc87-4bb1-9704-f1805003b975/
[edit-metadata]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
