---
title: Импорт обучающих данных из разных источников данных
titleSuffix: Azure Machine Learning Studio (classic)
description: Импорт данных в Машинное обучение Azure Studio (классическая модель) из различных источников данных. Узнайте, какие типы данных и форматы данных поддерживаются.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio
ms.topic: conceptual
author: xiaoharper
ms.author: amlstudiodocs
ms.custom: previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 02/01/2019
ms.openlocfilehash: 6e84f5c8cab6323234b81126ad3e8b1299e10171
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2019
ms.locfileid: "73492890"
---
# <a name="import-your-training-data-into-azure-machine-learning-studio-classic-from-various-data-sources"></a>Импорт обучающих данных в Машинное обучение Azure Studio (классическая модель) из различных источников данных

Чтобы использовать собственные данные в Машинное обучение Studio (классическая модель) для разработки и обучения решения для прогнозной аналитики, можно использовать следующие данные: 

* **локальный файл**, заранее отправляйте данные из жесткого диска, чтобы создать модуль набора данных в рабочей области;
* **Источники данных в сети** — используйте модуль [Импорт данных][import-data] для доступа к данным из одного из нескольких источников в сети во время работы эксперимента.
* **Эксперименты машинное обучение Studio (классическая модель)** — использование данных, сохраненных в виде набора данных, в классической версии машинное обучение Studio
* [**локальная база данных SQL Server**](use-data-from-an-on-premises-sql-server.md), чтобы использовать данные из локальной базы данных SQL Server без необходимости вручную копировать данные.

> [!NOTE]
> В классической версии Машинное обучение Studio доступно несколько примеров наборов данных, которые можно использовать для обучения. Дополнительные сведения см. в разделе [Использование образцов наборов данных в машинное обучение Azure Studio (классическая модель)](use-sample-datasets.md).

## <a name="prepare-data"></a>Подготовка данных

Классическая версия Машинное обучение Studio предназначена для работы с прямоугольными или табличными данными, такими как текстовые данные с разделителями или структурированными данными из базы данных, хотя в некоторых обстоятельствах могут использоваться непрямоугольные данные.

Рекомендуется, чтобы данные были относительно очищены перед импортом в классической версии Studio. Например, обратите внимание на строки без кавычек.

Однако в классической версии Studio есть модули, которые позволяют выполнить некоторую обработку данных в эксперименте после импорта данных. В зависимости от алгоритмов машинного обучения, которые вы будете использовать, необходимо решить, как будут обрабатываться структурные трудности в данных, например отсутствующие значения и разреженные данные, и существуют ли модули, которые могут здесь помочь. В разделе **Преобразование данных** палитры модулей найдите модули, которые выполняют такие функции.

В любой точке вашего эксперимента можно просмотреть или скачать данные, созданные модулем, щелкнув правой кнопкой мыши порт вывода. В зависимости от модуля могут быть доступны различные варианты загрузки, или вы можете визуализировать данные в веб-браузере в классической версии Studio.

## <a name="supported-data-formats-and-data-types"></a>Поддерживаемые форматы и типы данных

В свой эксперимент можно импортировать значительное количество типов данных, в зависимости от того, какая система используется для импорта данных и каков источник этих данных:

* Обычный текст (TXT)
* Текст с разделителями-запятыми с заголовком (CSV) или без заголовка (NH.CSV)
* Текст с разделителями-табуляциями с заголовком (TSV) или без заголовка (NH.TSV)
* Файл Excel
* таблицу Azure;
* Таблица Hive
* Таблицы базы данных SQL
* Значения OData
* данные SVMLight (SVMLIGHT) (подробнее о формате см. в [определении SVMLight](http://svmlight.joachims.org/));
* данные в формате ARFF (подробнее о формате см. в [определении ARFF](https://weka.wikispaces.com/ARFF));
* ZIP-файл (ZIP)
* Файл объекта или рабочей области R (RData)

При импорте данных в таком формате, как ARFF, который содержит метаданные, классическая версия Studio использует эти метаданные для определения заголовка и типа данных каждого столбца.

Если импортируются данные, такие как формат TSV или CSV, не включающий эти метаданные, классическая версия Studio выводит тип данных для каждого столбца, выполнив выборку данных. Если в данных также нет заголовков столбцов, классическая версия Studio предоставляет имена по умолчанию.

Можно явно указать или изменить заголовки и типы данных для столбцов с помощью модуля [изменение метаданных][edit-metadata] .

Классическая версия Studio распознает следующие типы данных:

* string
* Целое число
* Double
* Логический
* DateTime
* TimeSpan

Для передачи данных между модулями Студия использует внутренний тип данных, который называется ***Таблица данных***. Вы можете явно преобразовать данные в формат таблицы данных с помощью модуля [преобразовать в набор данных][convert-to-dataset] .

Любой модуль, который принимает форматы, отличные от таблицы данных, перед передачей данных в следующий модуль преобразует данные в формат таблицы данных без вмешательства пользователя.

При необходимости можете преобразовать формат таблицы данных обратно в формат CSV, TSV, ARFF или SVMLight, используя другие модули преобразования.
Узнать о модулях, которые выполняют эти функции, можно узнать в разделе **Преобразование форматов данных** палитры модулей.

## <a name="data-capacities"></a>Емкости данных

Модули в классической версии Машинное обучение Studio поддерживают наборы данных размером до 10 ГБ, которые используются для распространенных вариантов использования. Если модуль принимает несколько видов входных данных, то их общий объем должен составлять 10 ГБ. Вы можете создать выборку больших наборов данных с помощью запросов Hive или Базы данных SQL Azure или предварительной обработки модуля "Обучение на основе счетчиков" перед импортом данных.  

Следующие типы данных можно развернуть в большие наборы данных при нормализации признаков. Максимальный объем этих данных — менее 10 ГБ:

* разреженные;
* категориальные;
* строк
* Двоичные данные

В следующих модулях можно использовать наборы данных объемом менее 10 ГБ:

* модули системы рекомендаций;
* модуль метода увеличения числа примеров миноритарного класса с помощью синтетических объектов (SMOTE);
* модули написания сценариев: R, Python, SQL;
* модули, в которых объем выходных данных может превышать объем входных данных, такие как "Слияние" или "Хэширование признаков";
* "Перекрестная проверка", "Гиперпараметры модели настройки", "Порядковая регрессия" и "Многоклассовая классификация «один — все»", когда число итераций очень велико.

Для наборов данных объемом больше, чем несколько гигабайт, требуется передать данные в службу хранилища Azure или Базу данных SQL Azure либо использовать HDInsight, а не отправлять данные прямо из локального файла.

Вы можете найти сведения о данных изображений в ссылке на модуль [Импорт образов](https://docs.microsoft.com/azure/machine-learning/studio-module-reference/import-images#bkmk_Notes).

## <a name="import-from-a-local-file"></a>Импорт из локального файла

Вы можете передать файл данных с жесткого диска, чтобы использовать его в качестве обучающих данных в классической версии Studio. При импорте файла данных, можете создать модуль набора данных, который готов для использования в экспериментах рабочей области.

Чтобы импортировать данные из локального жесткого диска, выполните следующие действия:

1. В нижней части окна Studio (классическая модель) щелкните **+ создать** .
2. Выберите **Набор данных** и **From local file** (Из локального файла).
3. В диалоговом окне **Upload a new dataset**  (Отправить новый набор данных) перейдите к файлу, который необходимо отправить.
4. Введите имя, укажите тип данных и, при необходимости, введите описание. Рекомендуем ввести описание — оно позволяет записать все характеристики данных, которые необходимо помнить при использовании данных в будущем.
5. Флажок **Это новая версия существующего набора данных** позволяет обновить существующий набор данных новыми данными. Чтобы выполнить это, установите флажок, а затем введите имя существующего набора данных.

![Передача нового набора данных](./media/import-data/upload-dataset-from-local-file.png)

Время передачи зависит от объема данных и скорости подключения к службе. Если известно, что файл займет много времени, можно выполнить другие действия в классической версии Studio, пока вы ждете. Тем не менее закрытие браузера до завершения загрузки данных приведет к ошибке передачи данных.

После загрузки данные сохраняются в модуле набора данных и доступны для любого эксперимента в рабочей области.

При редактировании эксперимента вы можете найти ранее отправленные наборы данных в списке **My Datasets** (Мои наборы данных), который входит в список **Saved Datasets** (Сохраненные наборы данных), в палитре модулей. Перетащите набор данных на холст эксперимента, где нужно использовать эти данные для последующего анализа и машинного обучения.

## <a name="import-from-online-data-sources"></a>Импорт из сетевых источников данных

С помощью модуля [Импорт данных][import-data] ваш эксперимент может импортировать данные из различных источников данных в сети во время выполнения эксперимента.

> [!NOTE]
> В этой статье содержатся общие сведения о модуле [импорта данных][import-data] . Более подробные сведения о типах данных, к которым можно получить доступ, форматах, параметрах и ответы на часто задаваемые вопросы, см. в разделе Справочник по модулям для модуля [Импорт данных][import-data] .

С помощью модуля [Импорт данных][import-data] можно получить доступ к данным из одного из нескольких источников данных в сети во время выполнения эксперимента:

* URL-адрес с использованием HTTP;
* Hadoop с использованием HiveQL
* Хранилище blob-объектов Azure
* таблицу Azure;
* базу данных SQL Azure или сервер SQL Server на виртуальной машине Azure;
* локальная база данных SQL Server;
* поставщик веб-канала данных (в настоящее время OData).
* Azure Cosmos DB

Так как доступ к этим данным для обучения осуществляется во время эксперимента, они доступны только в рамках этого эксперимента. Для сравнения: данные, хранящиеся в модуле набора данных, доступны для любого эксперимента в рабочей области.

Чтобы получить доступ к сетевым источникам данных в эксперименте Studio (классическая модель), добавьте модуль [Импорт данных][import-data] в эксперимент. Затем выберите **Запустить мастер импорта данных** в разделе **Свойства**, чтобы получить пошаговые инструкции по выбору и настройке источника данных. Кроме того, вы можете вручную выбрать **Источник данных** в разделе **Свойства** и указать параметры, необходимые для доступа к данным.

Поддерживаемые сетевые источники данных описаны в таблице ниже. Кроме того, в этой таблице перечислены поддерживаемые форматы файлов и параметры, используемые для доступа к данным.

> [!IMPORTANT]
> В настоящее время модули [импорта данных][import-data] и [экспорта данных][export-data] могут считывать и записывать данные только из службы хранилища Azure, созданной с помощью классической модели развертывания. Другими словами, новый тип учетной записи хранилища BLOB-объектов Azure, предоставляющий "горячий" или "холодный" уровень доступа к хранилищу, не еще поддерживается.
>
> Как правило, это не повлияет на учетные записи хранения Azure, созданные до появления данного уровня служб.
> Если необходимо создать учетную запись, выберите **классическую** модель развертывания или используйте Resource Manager и в качестве **типа учетной записи** выберите **Общее назначение**, а не **Хранилище BLOB-объектов**.
>
> Дополнительные сведения см. в разделе [Хранилище BLOB-объектов Azure: "горячий" и "холодный" уровни хранилища](../../storage/blobs/storage-blob-storage-tiers.md).

### <a name="supported-online-data-sources"></a>Поддерживаемые сетевые источники данных
Классическая версия модуля **импорта данных** машинное обучение Azure Studio поддерживает следующие источники данных:

| Источник данных | Description (Описание) | Параметры |
| --- | --- | --- |
| URL-адрес с использованием протокола HTTP |Считывает данные в файлах с разделителями-запятыми (CSV), файлах с разделителями-табуляциями (TSV), а также в файлах в формате ARFF и SVM-light из любого URL-адреса, использующего протокол HTTP. |<b>URL-адрес</b>. Задает полное имя файла, включая URL-адрес сайта и имя файла с любым расширением. <br/><br/><b>Формат данных</b>. Задает один из поддерживаемых форматов данных: CSV, TSV, ARFF или SVM-light. Если данные содержат строку заголовков, она используется для назначения имен столбцов. |
| Hadoop/HDFS |Считывает данные из распределенного хранилища в Hadoop. Необходимые вам данные можно указать с помощью HiveQL, языка запросов на основе SQL. HiveQL также можно использовать для агрегирования данных и выполнения фильтрации данных перед добавлением данных в классическую версию Studio. |<b>Hive database query</b> (Запрос к базе данных Hive). Указывает запрос Hive, используемый для создания данных.<br/><br/><b>HCatalog server URI</b> (URI сервера HCatalog). Задает имя кластера в формате *&lt;имя_кластера&gt;.azurehdinsight.net*.<br/><br/><b>Hadoop user account name</b> (Имя учетной записи пользователя Hadoop). Задает имя учетной записи пользователя Hadoop для подготовки кластера.<br/><br/><b>Hadoop user account password</b> (Пароль учетной записи пользователя Hadoop). Задает учетные данные, используемые при подготовке кластера. Дополнительные сведения см. в статье [Создание кластеров Hadoop в HDInsight](/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters).<br/><br/><b>Location of output data</b> (Расположение выходных данных). Указывает, где хранятся данные: в распределенной файловой системе Hadoop (HDFS) или в Azure. <br/><ul>Если выходные данные хранятся в HDFS, укажите универсальный код ресурса (URI) сервера HDFS. (не забудьте указать имя кластера HDInsight без префикса HTTPS://). <br/><br/>Если выходные данные хранятся в Azure, необходимо указать имя учетной записи хранения Azure, ключ доступа к хранилищу и имя контейнера хранилища.</ul> |
| База данных SQL |Считывает данные, хранящиеся в базе данных SQL Azure или в базе данных SQL Server, запущенной на виртуальной машине Azure. |<b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><ul>Если используется база данных SQL Azure, введите создаваемое имя сервера. Обычно оно указывается в таком формате: *&lt;созданный_идентификатор&gt;.database.windows.net*. <br/><br/>В случае с SQL Server, размещенным на виртуальной машине Azure *, введите TCP:&lt;DNS-имя виртуальной машины&gt;, 1433*</ul><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Server user account password</b> (Пароль учетной записи пользователя сервера). Задает пароль для учетной записи указанного пользователя.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| Локальная база данных SQL |Считывает данные, хранящиеся в локальной базе данных SQL. |<b>Шлюз данных</b>. Задает имя шлюза управления данными, установленного на компьютере, имеющем доступ к базе данных SQL Server. Сведения о настройке шлюза см. в статье [Выполнение расширенной аналитики с классической версией машинное обучение Azure Studio с использованием данных из локального сервера SQL](use-data-from-an-on-premises-sql-server.md)Server.<br/><br/><b>Имя сервера базы данных</b>. Указывает имя сервера, на котором запущена база данных.<br/><br/><b>Имя базы данных</b>. Задает имя базы данных на сервере. <br/><br/><b>Server user account name</b> (Имя учетной записи пользователя сервера). Задает имя пользователя учетной записи с разрешением на доступ к базе данных. <br/><br/><b>Имя пользователя и пароль</b>. Чтобы ввести учетные данные базы данных, щелкните <b>Введите значения</b>. Можно использовать встроенную аутентификацию Windows или аутентификацию SQL Server, в зависимости от настроек локального сервера SQL Server.<br/><br/><b>Запрос к базе данных</b>. Введите инструкцию SQL, описывающую данные, которые необходимо получить. |
| таблице Azure |Считывает данные из службы таблиц в хранилище Azure.<br/><br/>Если вам нечасто требуется считывание больших объемов данных, используйте службу таблиц Azure. Это недорогое и гибкое нереляционное (NoSQL) решение хранилища с высокой степенью масштабируемости и доступности. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account. Каждое из этих значений имеет собственный набор параметров. <br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Table URI</b> (URI таблицы). Задает общедоступный или подписанный URL-адрес (SAS) таблицы.<br/><br/><b>Specifies the rows to scan for property names</b> (Указывает строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице. <br/><br/>Если данные однородные и прогнозируемые, рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы и имеют наборы свойств, которые различаются в зависимости от вложенности и положения таблицы, выберите значение *ScanAll*, чтобы проверить все строки. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей таблицу, выбранную для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Имя таблицы</b>. Указывает имя таблицы, содержащей данные для чтения.<br/><br/><b>Rows to scan for property names</b> (Строки для поиска имен свойств). Значение <i>TopN</i> позволяет проверить указанное число строк, а значение <i>ScanAll</i> — получить все строки в таблице.<br/><br/>Если данные однородные и прогнозируемые, то рекомендуется выбрать *TopN* и ввести значение N. Для больших таблиц это может сократить время чтения.<br/><br/>Если данные структурированы и имеют наборы свойств, которые различаются в зависимости от вложенности и положения таблицы, выберите значение *ScanAll*, чтобы проверить все строки. Это гарантирует целостность полученного свойства и преобразования метаданных.<br/><br/> |
| Хранилище больших двоичных объектов Azure |Считывает данные, хранящиеся в службе больших двоичных объектов в хранилище Azure, включая изображения, неструктурированные текстовые данные и двоичные данные.<br/><br/>Службу BLOB-объектов можно использовать для предоставления общего доступа к данным или для закрытого хранения данных приложения. Доступ к данным можно получить из любого места, подключившись через протокол HTTP или HTTPS. |Изменение параметров в модуле **Импорт данных** зависит от того, обращаетесь ли вы к общедоступной информации или к частной учетной записи хранения, для входа в которую нужны учетные данные. Это определяется параметром <b>Тип проверки подлинности</b>, который может иметь значение PublicOrSAS или Account.<br/><br/><b>Public or Shared Access Signature (SAS) URI</b> (URI общедоступного или подписанного URL-адреса (SAS)). Используются следующие параметры.<br/><br/><ul><b>Универсальный код ресурса (URI)</b>. Задает общедоступный или подписанный URL-адрес (SAS) большого двоичного объекта службы хранилища.<br/><br/><b>Формат файла</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы: CSV, TSV и ARFF.<br/><br/></ul><b>Private Storage Account</b> (Частная учетная запись хранения). Параметры: <br/><br/><ul><b>Имя учетной записи</b>. Указывает имя учетной записи, содержащей большой двоичный объект, выбранный для чтения.<br/><br/><b>Ключ учетной записи</b>. Указывает ключ к хранилищу данных, связанный с этой учетной записью.<br/><br/><b>Path to container, directory, or blob</b> (Путь к контейнеру, каталогу или большому двоичному объекту). Задает имя большого двоичного объекта, содержащего данные для чтения.<br/><br/><b>Формат файла BLOB-объекта</b>. Задает формат данных в службе BLOB-объектов. Поддерживаемые форматы данных: CSV, TSV, ARFF, CSV с заданной кодировкой и Excel. <br/><br/><ul>Если используется формат CSV или TSV, обязательно укажите, содержит ли файл строку заголовка.<br/><br/>Для чтения данных из книги Excel можно использовать параметр Excel. В параметре <i>Формат данных Excel</i> укажите, где находятся данные: в диапазоне листа Excel или в таблице Excel. В параметре <i>Excel sheet or embedded table</i> (Лист или внедренная таблица Excel) укажите имя листа или таблицы для считывания данных.</ul><br/> |
| Поставщик веб-канала данных |Считывает данные, получаемые от поддерживаемого поставщика веб-канала. В настоящее время поддерживается только формат Open Data Protocol (OData). |<b>Data content type</b> (Тип содержимого данных). Задает формат OData.<br/><br/><b>Исходный URL-адрес</b>. Указывает полный URL-адрес веб-канала данных. <br/>Например, этот URL-адрес позволяет считывать данные из примера базы данных Northwind: https://services.odata.org/northwind/northwind.svc/. |

## <a name="import-from-another-experiment"></a>Импорт из другого эксперимента

Иногда понадобится получить в эксперименте промежуточный результат, который будет использоваться в другом эксперименте. Для этого сохраните модуль как набор данных, выполнив указанные ниже действия.

1. Щелкните выходные данные модуля, которые требуется сохранить в виде набора данных.
2. Щелкните **Сохранить как набор данных**.
3. При появлении запроса введите имя и описание, которое позволит легко идентифицировать набор данных.
4. Установите флажок **ОК** .

После завершения сохранения набор данных будет доступен для использования в любом эксперименте в рабочей области. Его можно найти в списке **Сохраненные наборы данных** в палитре модулей.

## <a name="next-steps"></a>Дальнейшие действия

[Развертывание веб-служб Машинное обучение Azure Studio, использующих модули импорта и экспорта данных](web-services-that-use-import-export-modules.md)


<!-- Module References -->
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[export-data]: https://msdn.microsoft.com/library/azure/7A391181-B6A7-4AD4-B82D-E419C0D6522C/


<!-- Module References -->
[convert-to-dataset]: https://msdn.microsoft.com/library/azure/72bf58e0-fc87-4bb1-9704-f1805003b975/
[edit-metadata]: https://msdn.microsoft.com/library/azure/370b6676-c11c-486f-bf73-35349f842a66/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
