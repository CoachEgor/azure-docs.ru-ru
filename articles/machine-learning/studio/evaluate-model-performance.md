---
title: Оценка работы модели.
titleSuffix: ML Studio (classic) - Azure
description: Узнайте, как оценить производительность модели в Студии машинного обучения Azure (классический) и о метриках, доступных для этой задачи.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio
ms.topic: conceptual
author: likebupt
ms.author: keli19
ms.custom: seodec18, previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 03/20/2017
ms.openlocfilehash: 3c041834b9ad191817cdf1380b0a75efc7639bd0
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79218154"
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning-studio-classic"></a>Как оценить эффективность модели в Студии машинного обучения Azure (классическая версия)

[!INCLUDE [Notebook deprecation notice](../../../includes/aml-studio-notebook-notice.md)]

В этой статье показано, как оценить производительность модели в Azure Machine Learning Studio (классический) и кратко ещё объяснение метрик, доступных для этой задачи. Доступны три стандартных сценария управляемого обучения: 

* регрессия
* двоичная классификация; 
* классификация по нескольким классам.



Оценка эффективности модели является одним из основных этапов процесса обработки и анализа данных. Она показывает, насколько успешно обученная модель обрабатывает (прогнозирует) набор данных. 

Студия машинного обучения Azure (классическая) поддерживает оценку модели с помощью двух своих основных модулей машинного обучения: [Evaluate Model][evaluate-model] и [Cross-Validate Model.][cross-validate-model] Эти модули позволяют видеть эффективность модели в пересчете на различные показатели, обычно используемые в машинном обучении и статистике.

## <a name="evaluation-vs-cross-validation"></a>Сравнение оценки и перекрестной проверки
Оценка и перекрестная проверка — это стандартные способы для измерения эффективности модели. Оба модуля генерируют показатели оценки, которые вы можете проверить или сравнить с показателями других моделей.

[Evaluate Model][evaluate-model] ожидает набранный набор данных в качестве ввода (или два в случае, если вы хотите сравнить производительность двух различных моделей). Поэтому необходимо обучить модель с помощью модуля [Train Model][train-model] и сделать прогнозы на некоторых наборах данных с помощью модуля [Score Model,][score-model] прежде чем вы сможете оценить результаты. Оценка основывается на подсчитанных метках или вероятностях и на истинных метках. Все эти значения предоставляет модуль [Score Model][score-model] (Оценка модели).

Кроме того, вы можете использовать перекрестную проверку, чтобы автоматически выполнить ряд операций "обучить-подсчитать-оценить" (10 сборок) для различных подмножеств входных данных. Входные данные делятся на 10 частей: одна резервируется для тестирования, а остальные 9 — для обучения. Этот процесс повторяется 10 раз, затем из показателей оценки выводится средняя величина. Эта процедура позволяет определить, насколько хорошо модель будет обобщаться на новых наборах данных. Модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) берет необученную модель и несколько группированных наборов данных, а затем в дополнение к усредненным результатам выводит результаты оценки каждой из 10 сборок.

В следующих разделах мы создадим простые модели регрессии и классификации и оценим их эффективность, используя модули [Evaluate Model][evaluate-model] (Анализ модели) и [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели).

## <a name="evaluating-a-regression-model"></a>Оценка модели регрессии
Предположим, мы хотим предсказать цену автомобиля, используя такие функции, как габариты, лошадиные силы, спецификации двигателя и так далее. Это типичная задача регрессии, где целевой переменной *price* (Цена) присвоено непрерывное числовое значение. Мы можем поместить линейную модель регрессии, которая, учитывая значения характеристик определенного автомобиля, может предсказать цену этого автомобиля. Эту модель регрессии можно использовать для подсчета того же набора данных, который использовался для обучения. После того, как мы прогнозируем цены на автомобили, мы можем оценить производительность модели, глядя на то, насколько прогнозы отклоняются от фактических цен в среднем. Чтобы проиллюстрировать это, мы используем *набор данных о ценах на автомобили (Raw),* доступный в разделе **Сохраненные наборы данных** в студии машинного обучения (классический).

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочее пространство в студии машинного обучения Azure (классический):

* данные о ценах на автомобили (необработанные);
* [Линейная регрессия][linear-regression]
* [Модель поезда][train-model]
* [Оценка модели][score-model]
* [Анализ модели][evaluate-model]

Соедините порты, как показано на рисунке 1 ниже, и установите для столбца "Метка" модуля [Обучение модели][train-model] значение *цена*.

![Оценка модели регрессии](./media/evaluate-model-performance/1.png)

Рис. 1. Оценка модели регрессии.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После проведения эксперимента щелкните порт вывода модуля [Evaluate Model][evaluate-model] (Анализ модели) и выберите *Визуализировать*, чтобы отобразить результаты оценки. Для моделей регрессии доступны такие метрики оценки: *Mean Absolute Error* (Средняя абсолютная погрешность), *Root Mean Absolute Error* (Среднеквадратическая абсолютная погрешность), *Relative Absolute Error* (Относительная абсолютная погрешность), *Relative Squared Error* (Относительная среднеквадратическая погрешность) и *Coefficient of Determination* (Коэффициент детерминации).

Термин "ошибка" здесь означает разницу между прогнозируемым значением и истинным значением. Абсолютное значение или квадрат этой разницы обычно вычисляется, чтобы зафиксировать абсолютную величину ошибки во всех экземплярах, так как разница между прогнозируемым и истинным значением иногда может быть отрицательным числом. Показатели ошибки измеряют прогнозируемую эффективность модели регрессии с точки зрения среднего отклонения ее прогнозов от истинных значений. Чем ниже значения ошибок, тем более точно модель прогнозирует. Общий показатель ошибок 0 означает, что модель идеально подбирает данные.

Для определения способности модели подбирать данные также часто используется коэффициент детерминации, который также известен как R-квадрат. Его можно интерпретировать как пропорцию отклонений, которые объясняются моделью. В этом случае чем выше пропорция, тем лучше. Значение 1 означает идеальное совпадение.

![Показатели оценки линейной регрессии](./media/evaluate-model-performance/2.png)

Рис. 2. Показатели оценки линейной регрессии.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как уже упоминалось ранее, с помощью модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) можно автоматически выполнять повторное обучение, оценку и анализ. Для этого вам потребуются набор данных, необученная модель и модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (см. рисунок ниже). Необходимо установить столбец метки в *цене* в свойствах модуля [Cross-Validate Model.][cross-validate-model]

![Перекрестная проверка модели регрессии](./media/evaluate-model-performance/3.png)

Рис. 3. Перекрестная проверка модели регрессии.

После проведения эксперимента вы можете проверить результаты оценки. Для этого щелкните правый порт вывода модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели). Вы увидите подробное представление показателей для каждой итерации (сборки) и усредненные результаты каждого из показателей (рис. 4).

![Результаты перекрестной проверки модели регрессии](./media/evaluate-model-performance/4.png)

Рис. 4 Результаты перекрестной проверки модели регрессии.

## <a name="evaluating-a-binary-classification-model"></a>Оценка модели двоичной классификации
При использовании двоичной классификации целевая переменная имеет только два возможных результата (например, {0, 1} или {ложь, истина}, {отрицательный, положительный}). Предположим, вам дают набор данных взрослых сотрудников с некоторыми демографическими и занятости переменных, и что вам предлагается предсказать уровень дохода, двоичная переменная со значениями "<50 K", ">50 K". Иными словами, отрицательный класс представляет работников, которые зарабатывают меньше 50 000 в год, а положительный класс представляет всех остальных работников. Как и в сценарии с регрессией, мы должны обучить модель, посчитать некоторые данные и оценивать результаты. Основным отличием здесь является выбор метрик Azure Machine Learning Studio (классические) вычислений и выходов. Чтобы проиллюстрировать сценарий прогнозирования уровня дохода, мы будем использовать набор данных [Adult](https://archive.ics.uci.edu/ml/datasets/Adult) для создания студийного (классического) эксперимента и оценки производительности двухклассной логистической модели регрессии, обычно используемого двоичного классификатора.

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочее пространство в студии машинного обучения Azure (классический):

* набор данных Adult Census Income Binary Classification;
* [Двухклассовая регрессионная логистическая модель][two-class-logistic-regression]
* [Модель поезда][train-model]
* [Оценка модели][score-model]
* [Анализ модели][evaluate-model]

Соедините порты, как показано на рисунке 5 ниже, и установите для столбца "Метка" модуля [Обучение модели][train-model] значение *доход*.

![Оценка модели двоичной классификации](./media/evaluate-model-performance/5.png)

Рис. 5. Оценка модели двоичной классификации.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После проведения эксперимента щелкните порт вывода модуля [Evaluate Model][evaluate-model] (Анализ модели) и выберите *Визуализировать*, чтобы увидеть результаты оценки (рис. 7). Для моделей двоичной классификации доступны такие метрики оценки: *Accuracy* (Правильность), *Precision* (Точность), *Recall* (Полнота), *F1 Score* (Оценка F1) и *AUC*. Кроме того, модуль выводит матрицы неточностей, которые отображают число истинно положительных, ложноотрицательных, ложноположительных и истинно отрицательных результатов, а также кривые *ROC*, *Precision/Recall* (Точность и полнота) и *Lift* (Точность прогноза).

Правильность выражается пропорцией правильно классифицированных экземпляров. Это, как правило, первый показатель, который вы видите во время оценки классификатора. Однако, когда тестовые данные несбалансированы (где большинство экземпляров относятся к одному из классов), или вы больше заинтересованы в производительности на одном из классов, точность на самом деле не отражает эффективность классификатора. Предположим, вы тестируете в сценарии классификации уровня дохода, данные, в которых 99 % экземпляров представляют людей, которые зарабатывают меньше или ровно 50 000 $ в год. Точность можно достичь 0,99, предсказав класс "<50K" для всех экземпляров. Кажется, что классификатор в целом хорошо справляется с заданием, но в действительности он не смог правильно классифицировать ни одно из лиц с высоким уровнем дохода (1 %).

Поэтому будет целесообразно вычислить дополнительные показатели, которые фиксируют более конкретные аспекты оценки. Прежде чем углубляться в подробности таких показателей, важно понять матрицу неточностей оценки двоичной классификации. Метки класса в наборе обучения могут принимать только два возможных значения, которые мы обычно называем положительными или отрицательными. Положительные и отрицательные экземпляры, которые классификатор прогнозирует правильно, называются истинно положительными (ИП) и истинно отрицательными (ИО) результатами соответственно. Точно так же неправильно классифицированные экземпляры называются ложно положительными (ЛП) и ложно отрицательными результатами (ЛО). Матрица путаницы — это просто таблица, показывающая количество экземпляров, подпадающих под каждую из этих четырех категорий. Студия машинного обучения Azure (классическая) автоматически решает, какой из двух классов в наборе данных является положительным классом. Если метки класса являются Boolean или integers, то "истинные" или "1" помечены экземпляры назначаются положительный класс. Если метки являются строками, например, с набором данных о доходах, метки сортируются в алфавитном порядке, а первый уровень выбирается как отрицательный класс, а второй уровень — положительный класс.

![Матрица неточностей двоичной классификации](./media/evaluate-model-performance/6a.png)

Рис. 6. Матрица неточностей двоичной классификации.

Возвращаясь к проблеме классификации доходов, нужно задать несколько оценочных вопросов, которые помогут определить эффективность используемого классификатора. Естественный вопрос: "Из людей, которых модель предсказала зарабатывать >50 K (ТПЗП), сколько были классифицированы правильно (TP)? На этот вопрос можно ответить, взглянув на показатель **точности** модели, который представляет долю правильно классифицированных положительных результатов: ИП / (ИП + ЛП). Другой распространенный вопрос: "Из всех высокооплачиваемых работников с доходом >50тыс (ТПЗ-ФН), сколько классификатор классифицировать правильно (TP)". Это значение представлено показателем **полноты** или процента истинно положительных результатов классификатора: ИП / (ИП + ЛП). Вы могли заметить, что существует очевидный компромисс между точностью и полнотой. Например, обрабатывая относительно сбалансированный набор данных, классификатор, который прогнозирует в основном положительные экземпляры, будет иметь высокий уровень полноты, но довольно низкий уровень точности, так как многие отрицательные экземпляры будут неправильно классифицированы из-за большого количества ложно позитивных результатов. Чтобы увидеть график изменения этих двух показателей, щелкните кривую **ТОЧНОСТЬ/ПОЛНОТА** на странице вывода результатов оценки (верхняя левая часть рисунка 7).

![Результаты оценки двоичной классификации](./media/evaluate-model-performance/7.png)

Рис. 7. Результаты оценки двоичной классификации.

Не менее часто используется показатель **оценки F1**, который учитывает и точность, и полноту. Это гармоничное среднее из этих двух метрик и вычисляется как таковой: F1 No 2 (точность х напомнить) / (точность и отзыв). Оценка F1 является хорошим способом обобщить оценку в одном номере, но это всегда хорошая практика, чтобы посмотреть на точность и вспомнить вместе, чтобы лучше понять, как классификатор ведет себя.

Кроме того, вы можете сравнить доли истинно положительных результатов и ложноположительных результатов, представленных кривой **рабочей характеристики приемника (ROC)** и соответствующим значением **площади под ROC-кривой (AUC)**. Чем ближе эта кривая к верхнему левому углу, тем лучше производительность классификатора (то есть максимизация истинной положительной скорости при минимизации ложноположительной скорости). Кривые, близкие к диагонали графика, получаются из классификаторов, которые, как правило, делают прогнозы, близкие к случайному угадыванию.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как и в примере регрессии, мы можем выполнять перекрестную проверку для повторного обучения, оценки и оценки различных подмножества данных автоматически. Подобным образом мы можем использовать модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели), необученную регрессионную логистическую модель и набор данных. Столбец метки должен быть настроен на *доход* в свойствах модуля [Cross-Validate Model.][cross-validate-model] Если по завершении эксперимента щелкнуть правый порт вывода в модуле [Cross-Validate Model][cross-validate-model] (Модель перекрестной проверки), отобразятся значения метрик двоичной классификации для каждой свертки, а также среднее значение и стандартное отклонение каждого из них. 

![Перекрестная проверка модели двоичной классификации](./media/evaluate-model-performance/8.png)

Рис. 8. Перекрестная проверка модели двоичной классификации.

![Результаты перекрестной проверки модели двоичной классификации](./media/evaluate-model-performance/9.png)

Рис. 9. Результаты перекрестной проверки модели двоичной классификации.

## <a name="evaluating-a-multiclass-classification-model"></a>Оценка модели классификации по нескольким классам
В этом эксперименте мы будем использовать популярный набор данных [Iris,](https://archive.ics.uci.edu/ml/datasets/Iris "Iris") который содержит экземпляры трех различных типов (классов) растения радужной оболочки глаза. Для каждого экземпляра имеется четыре значения функций (длина/ширина и длина лепестка/ширина). В предыдущих экспериментах мы обучали и тестировали модели с использованием одних и тех же наборов данных. Здесь мы будем использовать модуль [Split Data][split] для создания двух подмножеств данных, подготовки на первом, а также оценка и оценка на втором. Набор данных Iris находится в открытом доступе в [репозитории машинного обучения UCI](https://archive.ics.uci.edu/ml/index.html). Его можно скачать с помощью модуля [импорта данных][import-data].

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочее пространство в студии машинного обучения Azure (классический):

* [Данные по импорту][import-data]
* [Лес решений с несколькими классами][multiclass-decision-forest]
* [Разделение данных][split]
* [Модель поезда][train-model]
* [Оценка модели][score-model]
* [Анализ модели][evaluate-model]

Соедините порты, как показано на рисунке 10.

Установите значение 5 для индекса столбца "Метка" в модуле [Обучение модели][train-model]. У этого набора данных нет строки заголовка, но мы знаем, что этикетки находятся в пятом столбце.

Щелкните модуль [импорта данных][import-data] и задайте для свойства *Источник данных* значение *Web URL via HTTP* (URL-адрес с использованием протокола HTTP), а для свойства *URL-адреса* — http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.

Укажите дробное число экземпляров, которые будут использоваться для обучения модуля [разделения данных][split] (например, 0,7).

![Оценка классификатора с несколькими классами](./media/evaluate-model-performance/10.png)

Рис. Оценка классификатора с несколькими классами

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
Запустите эксперимент и щелкните порт вывода в модуле [Evaluate Model][evaluate-model] (Анализ модели). В этом случае результаты оценки представлены в виде матрицы неточностей. Матрица показывает фактические и прогнозируемые экземпляры для всех трех классов.

![Результаты оценки классификации по нескольким классам](./media/evaluate-model-performance/11.png)

Рис. 11. Результаты оценки классификации по нескольким классам.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как уже упоминалось ранее, с помощью модуля [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) можно автоматически выполнять повторное обучение, оценку и анализ. Вам потребуется набор данных, необученная модель и модуль [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (см. рисунок ниже). Снова нужно установить значение для столбца "Метка" в модуле [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели) (в данном случае индекс столбца — 5). Если по завершении эксперимента щелкнуть правый порт вывода в модуле [Cross-Validate Model][cross-validate-model] (Перекрестная проверка модели), вы увидите значения показателей для каждой свертки, а также среднее значение и стандартное отклонение. Отображаемые здесь показатели похожи на показатели, о которых шла речь в разделе, посвященном двоичной классификации. Однако в многоклассовой классификации вычисление истинных срабатываний/негативов и ложных срабатываний/отрицательных результатов осуществляется путем расчета на основе одного класса, так как нет общего положительного или отрицательного класса. Например, при вычислении точности или отзыва класса «Iris-setosa» предполагается, что это положительный класс, а все остальные – как отрицательные.

![Перекрестная проверка модели классификации по нескольким классам](./media/evaluate-model-performance/12.png)

Рис. 12. Перекрестная проверка модели классификации по нескольким классам.

![Результаты перекрестной проверки модели классификации по нескольким классам](./media/evaluate-model-performance/13.png)

Рис. 13. Результаты перекрестной проверки модели классификации по нескольким классам.

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/
