---
title: Оценка работы модели.
titleSuffix: Azure Machine Learning Studio (classic)
description: В этой статье показано, как оценить производительность модели в Машинное обучение Azure Studio (классическая модель) и приводится краткое описание метрик, доступных для этой задачи.
services: machine-learning
ms.service: machine-learning
ms.subservice: studio
ms.topic: conceptual
author: xiaoharper
ms.author: amlstudiodocs
ms.custom: seodec18, previous-author=heatherbshapiro, previous-ms.author=hshapiro
ms.date: 03/20/2017
ms.openlocfilehash: 7947c1be552e72cea9fb0b9214e82a1ecc481fb1
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2019
ms.locfileid: "73493080"
---
# <a name="how-to-evaluate-model-performance-in-azure-machine-learning-studio-classic"></a>Оценка производительности модели в Машинное обучение Azure Studio (классическая модель)

В этой статье показано, как оценить производительность модели в Машинное обучение Azure Studio (классическая модель) и приводится краткое описание метрик, доступных для этой задачи. Доступны три стандартных сценария управляемого обучения: 

* регрессия;
* двоичная классификация; 
* классификация по нескольким классам.



Оценка эффективности модели является одним из основных этапов процесса обработки и анализа данных. Она показывает, насколько успешно обученная модель обрабатывает (прогнозирует) набор данных. 

Машинное обучение Azure Studio (классическая модель) поддерживает оценку модели двумя основными модулями машинного обучения: [Оценка][evaluate-model] модели и [Перекрестная проверка модели][cross-validate-model]. Эти модули позволяют видеть эффективность модели в пересчете на различные показатели, обычно используемые в машинном обучении и статистике.

## <a name="evaluation-vs-cross-validation"></a>Сравнение оценки и перекрестной проверки
Оценка и перекрестная проверка — это стандартные способы для измерения эффективности модели. Оба модуля генерируют показатели оценки, которые вы можете проверить или сравнить с показателями других моделей.

Функция "Оценка модели" предполагает, что в качестве входных данных используется [оцененный][evaluate-model] DataSet (или 2, если вы хотите сравнить производительность двух разных моделей). Это означает, что необходимо обучить модель с помощью модуля [обучение модели][train-model] и создать прогнозы для некоторого набора данных с помощью модуля [Оценка модели][score-model] , прежде чем можно будет оценить результаты. Оценка основана на оцененных метках и вероятностях, а также на истинных метках, все из которых выводятся модулем [оценки модели][score-model] .

Кроме того, вы можете использовать перекрестную проверку, чтобы автоматически выполнить ряд операций "обучить-подсчитать-оценить" (10 сборок) для различных подмножеств входных данных. Входные данные делятся на 10 частей: одна резервируется для тестирования, а остальные 9 — для обучения. Этот процесс повторяется 10 раз, затем из показателей оценки выводится средняя величина. Эта процедура позволяет определить, насколько хорошо модель будет обобщаться на новых наборах данных. Модуль [перекрестной проверки модели][cross-validate-model] принимает обученную модель и некоторый помеченный набор данных и выводит результаты оценки каждого из 10 сверток в дополнение к усредненным результатам.

В следующих разделах мы создадим простые модели регрессии и классификации и вычисляем их производительность, используя модули [оценки][evaluate-model] и [перекрестной проверки модели][cross-validate-model] .

## <a name="evaluating-a-regression-model"></a>Оценка модели регрессии
Предположим, мы хотим предсказать цену автомобиля, используя такие параметры, как размеры, мощность, характеристики двигателя и т. д. Это типичная задача регрессии, где целевой переменной *price* (Цена) присвоено непрерывное числовое значение. Мы можем подобрать простую модель линейной регрессии, которая сможет прогнозировать цену автомобиля, учитывая значения параметров этого автомобиля. Эту модель регрессии можно использовать для подсчета того же набора данных, который использовался для обучения. После того как мы получим прогнозируемые цены на все автомобили, мы сможем оценить эффективность модели. Для этого мы сравним, насколько прогнозы отличаются от фактических цен в среднем. Чтобы проиллюстрировать это, мы используем набор данных « *данные о ценах автомобилей (RAW)* », доступный в разделе « **сохраненные наборы** данных» классической версии машинное обучение Azure Studio.

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область в классической версии Машинное обучение Azure Studio:

* данные о ценах на автомобили (необработанные);
* [Линейная регрессия][linear-regression]
* [Обучение модели][train-model]
* [Модель оценки][score-model]
* [Вычисление модели][evaluate-model]

Подключите порты, как показано ниже, на рис. 1 и задайте для столбца метки модуля [обучение модели][train-model] значение *Цена*.

![Оценка модели регрессии](./media/evaluate-model-performance/1.png)

Рисунок 1. Оценка модели регрессии.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После выполнения эксперимента можно щелкнуть порт вывода модуля [Анализ модели][evaluate-model] и выбрать *визуализировать* , чтобы просмотреть результаты оценки. Для моделей регрессии доступны такие метрики оценки: *Mean Absolute Error* (Средняя абсолютная погрешность), *Root Mean Absolute Error* (Среднеквадратическая абсолютная погрешность), *Relative Absolute Error* (Относительная абсолютная погрешность), *Relative Squared Error* (Относительная среднеквадратическая погрешность) и *Coefficient of Determination* (Коэффициент детерминации).

Термин "ошибка" здесь означает разницу между прогнозируемым значением и истинным значением. Абсолютное значение или квадрат этой разницы обычно вычисляется, чтобы зафиксировать абсолютную величину ошибки во всех экземплярах, так как разница между прогнозируемым и истинным значением иногда может быть отрицательным числом. Показатели ошибки измеряют прогнозируемую эффективность модели регрессии с точки зрения среднего отклонения ее прогнозов от истинных значений. Чем ниже значения ошибок, тем более точно модель прогнозирует. Общий показатель ошибок 0 означает, что модель идеально подбирает данные.

Для определения способности модели подбирать данные также часто используется коэффициент детерминации, который также известен как R-квадрат. Его можно интерпретировать как пропорцию отклонений, которые объясняются моделью. В этом случае чем выше пропорция, тем лучше. Значение 1 означает идеальное совпадение.

![Показатели оценки линейной регрессии](./media/evaluate-model-performance/2.png)

Рис. 2. Показатели оценки линейной регрессии.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как упоминалось ранее, вы можете выполнять многократное обучение, оценку и вычисления автоматически с помощью модуля [кросс-Validate Model (перекрестная проверка модели][cross-validate-model] ). В этом случае вам потребуется набор данных, обученная модель и модуль [перекрестной проверки модели][cross-validate-model] (см. рисунок ниже). Необходимо задать для столбца метка значение *Цена* в свойствах модуля [Перекрестная проверка модели][cross-validate-model] .

![Перекрестная проверка модели регрессии](./media/evaluate-model-performance/3.png)

Рис. 3. Перекрестная проверка модели регрессии.

После выполнения эксперимента можно просмотреть результаты оценки, щелкнув правый порт вывода модуля [Перекрестная проверка модели][cross-validate-model] . Вы увидите подробное представление показателей для каждой итерации (сборки) и усредненные результаты каждого из показателей (рис. 4).

![Результаты перекрестной проверки модели регрессии](./media/evaluate-model-performance/4.png)

Рис. 4 Результаты перекрестной проверки модели регрессии.

## <a name="evaluating-a-binary-classification-model"></a>Оценка модели двоичной классификации
При использовании двоичной классификации целевая переменная имеет только два возможных результата (например, {0, 1} или {ложь, истина}, {отрицательный, положительный}). Предположим, вы получили набор данных о работниках с некоторыми демографическими переменными и переменными их занятости. Вас просят предсказать уровень их доходов. Результат нужно выразить в виде бинарной переменной со значениями {"<=50 000", ">50 000"}. Иными словами, отрицательный класс представляет работников, которые зарабатывают меньше 50 000 в год, а положительный класс представляет всех остальных работников. Как и в сценарии с регрессией, мы должны обучить модель, посчитать некоторые данные и оценивать результаты. Основное отличие заключается в выборе классической Машинное обучение Azure версии метрикссе Studio и выводится в классическом виде. Чтобы проиллюстрировать ситуацию прогноза на уровне дохода, мы будем использовать набор данных для [взрослых](https://archive.ics.uci.edu/ml/datasets/Adult) для создания эксперимента Studio (классический) и оценки производительности модели логистической регрессии из двух классов — широко используемого двоичного классификатора.

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область в классической версии Машинное обучение Azure Studio:

* набор данных Adult Census Income Binary Classification;
* [Логистическая регрессия двух классов][two-class-logistic-regression]
* [Обучение модели][train-model]
* [Модель оценки][score-model]
* [Вычисление модели][evaluate-model]

Подключите порты, как показано ниже на рис. 5, и задайте для столбца метки модуля [обучение модели][train-model] значение *доход*.

![Оценка модели двоичной классификации](./media/evaluate-model-performance/5.png)

Рис. 5. Оценка модели двоичной классификации.

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
После выполнения эксперимента можно щелкнуть порт вывода модуля [Анализ модели][evaluate-model] и выбрать *визуализировать* , чтобы просмотреть результаты оценки (рис. 7). Для моделей двоичной классификации доступны такие метрики оценки: *Accuracy* (Правильность), *Precision* (Точность), *Recall* (Полнота), *F1 Score* (Оценка F1) и *AUC*. Кроме того, модуль выводит матрицы неточностей, которые отображают число истинно положительных, ложноотрицательных, ложноположительных и истинно отрицательных результатов, а также кривые *ROC*, *Precision/Recall* (Точность и полнота) и *Lift* (Точность прогноза).

Правильность выражается пропорцией правильно классифицированных экземпляров. Это, как правило, первый показатель, который вы видите во время оценки классификатора. Но если тестовые данные не сбалансированы (большинство экземпляров относятся к одному из классов) или вас больше интересует эффективность на одном из классов, правильность не будет отражать фактическую эффективность классификатора. Предположим, вы тестируете в сценарии классификации уровня дохода, данные, в которых 99 % экземпляров представляют людей, которые зарабатывают меньше или ровно 50 000 $ в год. Можно достичь уровня точности 0,99 путем прогнозирования класса «<=50K» для всех экземпляров. Кажется, что классификатор в целом хорошо справляется с заданием, но в действительности он не смог правильно классифицировать ни одно из лиц с высоким уровнем дохода (1 %).

Поэтому будет целесообразно вычислить дополнительные показатели, которые фиксируют более конкретные аспекты оценки. Прежде чем углубляться в подробности таких показателей, важно понять матрицу неточностей оценки двоичной классификации. Класс меток в обучающем множестве может принимать только 2 возможных значения, которые обычно называются положительным или отрицательным. Положительные и отрицательные экземпляры, которые классификатор прогнозирует правильно, называются истинно положительными (ИП) и истинно отрицательными (ИО) результатами соответственно. Точно так же неправильно классифицированные экземпляры называются ложно положительными (ЛП) и ложно отрицательными результатами (ЛО). Матрица путаницы — это просто таблица, показывающая количество экземпляров, которые попадают под каждую из этих 4 категорий. Классическая версия Машинное обучение Azure Studio автоматически определяет, какой из двух классов в наборе данных является положительным классом. Если метки класса являются логическими операторами или целыми числами, то экземпляры с метками «истина» или «1» присваиваются положительному классу. Если метки являются строками, как в случае с набором данных о доходах, метки сортируются в алфавитном порядке. Первый уровень присваивается отрицательному классу, а второй уровень — положительному классу.

![Матрица неточностей двоичной классификации](./media/evaluate-model-performance/6a.png)

Рис. 6. Матрица неточностей двоичной классификации.

Возвращаясь к проблеме классификации доходов, нужно задать несколько оценочных вопросов, которые помогут определить эффективность используемого классификатора. Вполне естественный вопрос: «Сколько лиц, которые по прогнозам модели зарабатывают > 50 000 (ИП + ЛП), классифицированы правильно (ИП)?» На этот вопрос можно ответить, взглянув на показатель **точности** модели, который представляет долю правильно классифицированных положительных результатов: ИП / (ИП + ЛП). Другой распространенный вопрос: «Из всех высокооплачиваемых специалистов с доходом > 50 000 $ (ИП + ЛП) скольких классификатор классифицировал правильно (ИП)?» Это значение представлено показателем **полноты** или процента истинно положительных результатов классификатора: ИП / (ИП + ЛП). Вы могли заметить, что существует очевидный компромисс между точностью и полнотой. Например, обрабатывая относительно сбалансированный набор данных, классификатор, который прогнозирует в основном положительные экземпляры, будет иметь высокий уровень полноты, но довольно низкий уровень точности, так как многие отрицательные экземпляры будут неправильно классифицированы из-за большого количества ложно позитивных результатов. Чтобы увидеть график изменения этих двух показателей, щелкните кривую **ТОЧНОСТЬ/ПОЛНОТА** на странице вывода результатов оценки (верхняя левая часть рисунка 7).

![Результаты оценки двоичной классификации](./media/evaluate-model-performance/7.png)

Рис. 7. Результаты оценки двоичной классификации.

Не менее часто используется показатель **оценки F1**, который учитывает и точность, и полноту. Это среднее гармоническое этих 2 показателей, которое вычисляется так: F1 = 2 (точность x полнота) / (точность + полнота). Показатель F1 — это удобный способ обобщения оценки в одно число. Но все-таки рекомендуется смотреть на точность и полноту вместе, чтобы лучше понять поведение классификатора.

Кроме того, вы можете сравнить доли истинно положительных результатов и ложноположительных результатов, представленных кривой **рабочей характеристики приемника (ROC)** и соответствующим значением **площади под ROC-кривой (AUC)** . Чем ближе эта кривая к верхнему левому углу, тем выше эффективность классификатора. То есть речь идет о максимальном проценте истинно положительных результатов и минимальном проценте ложно положительных результатов. Кривые, близкие к диагонали графика, получаются из классификаторов, которые, как правило, делают прогнозы, близкие к случайному угадыванию.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как и в примере регрессии, мы можем выполнить перекрестную проверку, чтобы многократно обучить, посчитать и оценить разные подмножества данных автоматически. Аналогичным образом можно использовать модуль [перекрестной проверки модели][cross-validate-model] , обученную модель логистической регрессии и набор данных. Столбец меток должен иметь значение " *доход* " в свойствах модуля [перекрестной проверки модели][cross-validate-model] . После выполнения эксперимента и щелчка правого порта в модуле [перекрестной проверки модели][cross-validate-model] можно увидеть значения метрик двоичной классификации для каждого сгиба, а также среднее и стандартное отклонение каждого из них. 

![Перекрестная проверка модели двоичной классификации](./media/evaluate-model-performance/8.png)

Рис. 8. Перекрестная проверка модели двоичной классификации.

![Результаты перекрестной проверки модели двоичной классификации](./media/evaluate-model-performance/9.png)

Рис. 9. Результаты перекрестной проверки модели двоичной классификации.

## <a name="evaluating-a-multiclass-classification-model"></a>Оценка модели классификации по нескольким классам
В этом эксперименте мы будем использовать популярный набор данных [диафрагмы](https://archive.ics.uci.edu/ml/datasets/Iris "IRI") , который содержит экземпляры трех различных типов (классов) растения. Для каждого экземпляра существует 4 значения признаков: длина и ширина чашелистика и длина и ширина лепестка. В предыдущих экспериментах мы обучали и тестировали модели, используя те же наборы данных. Здесь мы будем использовать модуль [Split Data (разделение данных][split] ), чтобы создать 2 подмножества данных, обучить первый, а также оценку и оценку во втором. Набор данных IRI общедоступен в [машинное обучение репозитории UCI](https://archive.ics.uci.edu/ml/index.html), и его можно загрузить с помощью модуля [Импорт данных][import-data] .

### <a name="creating-the-experiment"></a>Создание эксперимента
Добавьте следующие модули в рабочую область в классической версии Машинное обучение Azure Studio:

* [Импорт данных][import-data]
* [Лес решений в многоклассовых решениях][multiclass-decision-forest]
* [Разделение данных][split]
* [Обучение модели][train-model]
* [Модель оценки][score-model]
* [Вычисление модели][evaluate-model]

Соедините порты, как показано на рисунке 10.

Задайте для индекса столбца метки в модуле [обучение модели][train-model] значение 5. У этого набора данных нет строки заголовка, но мы знаем, что этикетки находятся в пятом столбце.

Щелкните модуль [Импорт данных][import-data] и задайте для свойства *источник данных* значение веб- *URL через HTTP*, а для параметра *URL-адрес* — значение http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data.

Задайте доли экземпляров, которые будут использоваться для обучения в модуле [Split Data][split] (например, 0,7).

![Оценка классификатора с несколькими классами](./media/evaluate-model-performance/10.png)

Рис. Оценка классификатора с несколькими классами

### <a name="inspecting-the-evaluation-results"></a>Проверка результатов оценки
Запустите эксперимент и щелкните порт вывода [вычислить модель][evaluate-model]. В этом случае результаты оценки представлены в виде матрицы неточностей. Матрица показывает фактические экземпляры по сравнению с прогнозируемыми для всех 3 классов.

![Результаты оценки классификации по нескольким классам](./media/evaluate-model-performance/11.png)

Рис. 11. Результаты оценки классификации по нескольким классам.

### <a name="using-cross-validation"></a>Использование перекрестной проверки
Как упоминалось ранее, вы можете выполнять многократное обучение, оценку и вычисления автоматически с помощью модуля [кросс-Validate Model (перекрестная проверка модели][cross-validate-model] ). Вам потребуется набор данных, обученная модель и модуль [перекрестной проверки модели][cross-validate-model] (см. рисунок ниже). Опять же, необходимо задать столбец метки модуля [перекрестной проверки модели][cross-validate-model] (в данном случае — индекс столбца 5). После выполнения эксперимента и щелчка правого порта вывода [модели перекрестной проверки][cross-validate-model]можно просмотреть значения метрик для каждого из сверток, а также среднее и стандартное отклонение. Отображаемые здесь показатели похожи на показатели, о которых шла речь в разделе, посвященном двоичной классификации. Но обратите внимание, что в классификации по нескольким классам истинно положительные/отрицательные результаты и ложно положительные/отрицательные результаты вычисляются путем подсчета на основе каждого класса, так как не существует общего положительного или отрицательного класса. Например, при расчете точности или полноты класса «Ирис щетинистый» предполагается, что это положительный класс, а все остальные являются отрицательными.

![Перекрестная проверка модели классификации по нескольким классам](./media/evaluate-model-performance/12.png)

Рис. 12. Перекрестная проверка модели классификации по нескольким классам.

![Результаты перекрестной проверки модели классификации по нескольким классам](./media/evaluate-model-performance/13.png)

Рис. 13. Результаты перекрестной проверки модели классификации по нескольким классам.

<!-- Module References -->
[cross-validate-model]: https://msdn.microsoft.com/library/azure/75fb875d-6b86-4d46-8bcc-74261ade5826/
[evaluate-model]: https://msdn.microsoft.com/library/azure/927d65ac-3b50-4694-9903-20f6c1672089/
[linear-regression]: https://msdn.microsoft.com/library/azure/31960a6f-789b-4cf7-88d6-2e1152c0bd1a/
[multiclass-decision-forest]: https://msdn.microsoft.com/library/azure/5e70108d-2e44-45d9-86e8-94f37c68fe86/
[import-data]: https://msdn.microsoft.com/library/azure/4e1b0fe6-aded-4b3f-a36f-39b8862b9004/
[score-model]: https://msdn.microsoft.com/library/azure/401b4f92-e724-4d5a-be81-d5b0ff9bdb33/
[split]: https://msdn.microsoft.com/library/azure/70530644-c97a-4ab6-85f7-88bf30a8be5f/
[train-model]: https://msdn.microsoft.com/library/azure/5cc7053e-aa30-450d-96c0-dae4be720977/
[two-class-logistic-regression]: https://msdn.microsoft.com/library/azure/b0fd7660-eeed-43c5-9487-20d9cc79ed5d/

