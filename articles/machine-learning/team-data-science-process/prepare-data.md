---
title: Подготовка данных для ML Studio (классический) - Процесс подготовки данных команды
description: Предварительная обработка и очистка данных для подготовки к эффективному использованию в машинном обучении.
services: machine-learning
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: caedcf313ab809e9607907545f26ca1b62bbeca7
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "76720050"
---
# <a name="tasks-to-prepare-data-for-enhanced-machine-learning"></a>Задачи по подготовке данных для расширенного машинного обучения
Предварительная обработка и очистка данных являются важными задачами, которые должны быть выполнены, прежде чем набор данных может быть использован для обучения модели. Необработанные данные зачастую искажены и ненадежны, и в них могут быть пропущены значения. Использование таких данных при моделировании может приводить к неверным результатам. Эти задачи являются частью процесса обработки и анализа данных группы и обычно подразумевают первоначальное изучение набора данных, используемого для определения и планирования необходимой предварительной обработки. Более подробные инструкции по процессу TDSP см. в процедуре, описанной в статье [Процесс обработки и анализа данных группы](overview.md).

Задачи предварительной обработки и очистки, такие как задача по разведке данных, могут выполняться в самых различных средах, таких как S'L или Hive или Azure Machine Learning Studio (классический), а также с помощью различных инструментов и языков, таких как R или Python, в зависимости от того, где ваши данные хранится и как она отформатирована. Так как по своей природе процесс TDSP является итеративным, эти задачи могут выполняться на различных этапах рабочего процесса.

В этой статье представлены различные концепции обработки данных и задачи, которые могут быть выполнены до или после поступления данных в Azure Machine Learning Studio (классический).

Например, исследование данных и предварительная обработка, выполненная в [Pre-processing data](https://azure.microsoft.com/documentation/videos/preprocessing-data-in-azure-ml-studio/) студии машинного обучения Azure (классика), см.

## <a name="why-pre-process-and-clean-data"></a>Зачем нужна предварительная обработка и очистка данных?
Реальные данные собираются для последующей обработки из разных источников и процессов. Они могут содержать ошибки и повреждения, негативно влияющие на качество набора данных. Вот какими могут быть типичные проблемы с качеством данных:

* **Неполнота**: данные не содержат атрибутов, или в них пропущены значения.
* **Шум**: данные содержат ошибочные записи или выбросы.
* **Несогласованность**: данные содержат конфликтующие между собой записи или расхождения.

Качественные данные — это необходимое условие для создания качественных моделей прогнозирования. Чтобы избежать появления ситуации «мусор на входе, мусор на выходе» и повысить качество данных и, как следствие, эффективность модели, необходимо провести мониторинг работоспособности данных, как можно раньше обнаружить проблемы и решить, какие действия по предварительной обработке и очистке данных необходимы.

## <a name="what-are-some-typical-data-health-screens-that-are-employed"></a>Какие есть стандартные методы мониторинга работоспособности данных
Вот что нужно оценить, чтобы проверить качество данных:

* Количество **записей**.
* Количество **атрибутов** (или **функций).**
* **Типы данных** атрибутов (номинальные, ординаторные или непрерывные).
* Количество **недостающих значений.**
* **Хорошо сформировавшиеся** данные.
  * Если данные имеют формат TSV или CSV, проверьте правильность разделения столбцов и строк соответствующими разделителями.
  * Если данные имеют формат HTML или XML, убедитесь, что формат данных соответствует надлежащим стандартам.
  * Для извлечения структурированной информации из частично структурированных или неструктурированных данных также может потребоваться синтаксический анализ.
* **Несовместимые записи данных**. Проверьте допустимость диапазона значений. Например, если данные содержат gpA студента (средний балл), проверьте, находится ли GPA в указанном диапазоне, например, от 0 до 4.

При поиске проблем с данными необходимы **этапы обработки,** которые часто включают очистку недостающих значений, нормализацию данных, дискретизацию, обработку текста для удаления и/или замены встроенных символов, которые могут повлиять на выравнивание данных, смешанные типы данных в общих полях и другие.

**Azure Machine Learning потребляет хорошо сформировавшиеся табликовые данные.**  Если данные уже в табличная форма, предварительная обработка данных может быть выполнена непосредственно в Azure Machine Learning Studio (классический) в машинном обучении.  Если данные находятся не в табличной форме, а, например, в формате XML, для их преобразования в табличную форму может потребоваться синтаксический анализ.  

## <a name="what-are-some-of-the-major-tasks-in-data-pre-processing"></a>Каковы главные задачи предварительной обработки данных
* **Очистка данных:** Заполняйте недостающие значения, обнаруживайте и удаляйте шумные данные и выбросы.
* **Преобразование данных**: Нормализация данных для уменьшения размеров и шума.
* **Уплотнение данных** — создание выборки данных или атрибутов для упрощения обработки данных.
* **Дискретизация данных** — преобразование непрерывных атрибутов в категориальные, чтобы проще было использовать некоторые методы машинного обучения.
* **Очистка текста:** удалите встроенные символы, которые могут привести к несогласованности данных, например, встроенные вкладки в файл данных, разделенные вкладками, встроенные новые строки, которые могут побить записи, например.

В следующем разделе описаны некоторые шаги предварительной обработки данных.

## <a name="how-to-deal-with-missing-values"></a>Как обрабатывать пропущенные значения
При работе с пропущенными значениями лучше сначала определить причину их появления в данных, что поможет решить проблему. Вот какие бывает методы обработки пропущенных значений:

* **Удаление**: удаление записей с пропущенными значениями.
* **Фиктивная подстановка** — замена пропущенных значений фиктивными, например подстановка значения *unknown* (неизвестно) вместо категориальных или значения 0 вместо чисел.
* **Подстановка среднего значения**: пропущенные числовые данные можно заменить средним значением.
* **Подстановка часто используемого элемента**: пропущенные категориальные значения можно заменить наиболее часто используемым элементом.
* **Подстановка по регрессии**: использование регрессионного метода для замены пропущенных значений регрессионными.  

## <a name="how-to-normalize-data"></a>Как нормализовать данные
Нормализация данных перемасштабирует числовые значения в заданный диапазон. Ниже представлены распространенные методы нормализации данных.

* **Нормализация по методу минимакса**: линейное преобразование данных в диапазоне, например, от 0 до 1, где минимальное и максимальное масштабируемые значения соответствуют 0 и 1 соответственно.
* **Нормализация по Z-показателю**: масштабирование данных на основе среднего значения и стандартного отклонения: деление разницы между данными и средним значением на стандартное отклонение.
* **Десятичное масштабирование**: масштабирование данных путем удаления десятичного разделителя значения атрибута.  

## <a name="how-to-discretize-data"></a>Как дискретизировать данные
Данные можно дискретизировать, преобразовав непрерывные значения в номинальные атрибуты или интервалы. Это можно сделать несколькими способами.

* **Группирование равной ширины**: разделение диапазона всех возможных значений атрибута в группы (N) одинакового размера с последующим присвоением значений, относящихся к ячейке с соответствующим номером.
* **Группирование равной высоты**: разделение всех возможных значений атрибута в группы (N), содержащие одинаковое количество экземпляров, с последующим присвоением значений, относящихся к ячейке с соответствующим номером.  

## <a name="how-to-reduce-data"></a>Как сократить объем данных
Существуют различные методы, с помощью которых вы можете уменьшить размер данных для упрощения обработки данных. В зависимости от размера данных и домена вы можете применить такие методы:

* **Выборка записей**: создание выборки записей данных и выбор репрезентативного подмножества из общего набора данных.
* **Выборка атрибутов**: выбор в данных набора важнейших атрибутов.  
* **Агрегирование**: разделение данных на группы и хранение числовых значений для каждой группы. Например, для уменьшения размера данных вы можете агрегировать числа, обозначающие ежедневный доход сети ресторанов за последние 20 лет, так, чтобы указывался ежемесячный доход.  

## <a name="how-to-clean-text-data"></a>Как очистить данные
**Текстовые поля в табличных данных** могут включать символы, влияющие на выравнивание столбцов и/или записи границ. Например, встроенные вкладки в разделенный файлом причиной выравнивания столбца, а встроенные новые символы линий нарушают линии записи. Неправильная обработка текстовых кодов при написании или чтении текста приводит к потере информации, непреднамеренному введению нечитаемых символов (например, nulls), а также может повлиять на разбор текста. Чтобы очистить текстовые поля, исправить выравнивание и извлечь структурированные текстовые данные из неструктурированных или полу-структурированных, могут потребоваться тщательные разбор и редактирование текста.

**Функция просмотра данных** позволяет ознакомиться с данными заблаговременно. Это поможет вам выявить те или иные проблемы с данными и применить соответствующие методы для решения этих проблем.  Важно понимать, что породило проблемы, как они могли появиться. Этот процесс также поможет вам определиться с этапами обработки данных, которые необходимо предпринять для их устранения. Определение конечных случаев использования и персон также может быть использовано для определения приоритетов усилий по обработке данных.

## <a name="references"></a>Ссылки
> *Интеллектуальный анализ данных: концепции и методы.* Издание третье, Morgan Kaufmann Publishers, 2011. Цзявей Хань (Jiawei Han), Мишлин Кэмбер (Micheline Kamber) и Цзянь Пей (Jian Pei)
> 
> 

