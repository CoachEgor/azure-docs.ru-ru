---
title: Выполнение задач обработки и анализа данных — Процесс обработки и анализа данных группы
description: Вы узнаете, как выполнять проекты по обработке и анализу данных с отслеживанием, контролем версий и поддержкой совместной работы.
author: marktab
manager: marktab
editor: marktab
ms.service: machine-learning
ms.subservice: team-data-science-process
ms.topic: article
ms.date: 01/10/2020
ms.author: tdsp
ms.custom: seodec18, previous-author=deguhath, previous-ms.author=deguhath
ms.openlocfilehash: 984b03288b8dae644fc04a2cd78fb03a2e027f62
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/24/2020
ms.locfileid: "76722209"
---
# <a name="execute-data-science-tasks-exploration-modeling-and-deployment"></a>Выполнение задач обработки и анализа данных: изучение, моделирование и развертывание

В типичным задачам обработки и анализа данных относятся изучение, моделирование и развертывание. В этой статье показано, как использовать служебные программы для **интерактивного изучения данных, анализа данных и создания отчетов (IDEAR)** и **автоматического моделирования и создания отчетов (АМАР)** для выполнения типичных задач обработки и анализа данных, в том числе интерактивного изучения данных, анализа данных, создания отчетов и создания моделей. Варианты развертывания модели в рабочей среде могут включать:

- [Машинное обучение Azure](../index.yml)
- [SQL Server со службами машинного обучения](https://docs.microsoft.com/sql/advanced-analytics/r/r-services)
- [Microsoft Machine Learning Server](https://docs.microsoft.com/machine-learning-server/what-is-machine-learning-server)


## 1. <a name='DataQualityReportUtility-1'></a> исследование 

Специалист по обработке и анализу данных может выполнять изучение данных и создание отчетов различными способами: с помощью библиотек и пакетов, доступных для Python (например, matplotlib), или с помощью R (например, ggplot или lattice). Специалисты по обработке и анализу данных могут настроить такой код в соответствии с потребностями изучения данных для конкретных сценариев. Требования к работе со структурированными и неструктурированными данными (например, текстом и изображениями) отличаются. 

Такие продукты, как Машинное обучение Azure, также обеспечивают [расширенную подготовку данных](../how-to-create-register-datasets.md) для структурирование и исследования данных, включая создание компонентов. Пользователь должен выбрать инструменты, библиотеки и пакеты, которые лучше всего подходят для выполнения его задач. 

Конечный результат этого этапа — это отчет об изучении данных. Он должен дать достаточно полное представление о данных, используемых для моделирования, и предоставить оценку пригодности данных для перехода к шагу моделирования. Служебные программы для командного процесса обработки и анализа данных (TDSP), рассматриваемые в следующих разделах и предназначенные для полуавтоматического изучения, моделирования и создания отчетов, также позволяют получить стандартизированные отчеты об изучении данных и моделировании. 

### <a name="interactive-data-exploration-analysis-and-reporting-using-the-idear-utility"></a>Служебная программа IDEAR для интерактивного изучения данных, анализа данных и создания отчетов

Эта служебная программа на основе R Markdown или Notebook Python является гибким и интерактивным инструментом для оценки и изучения наборов данных. Пользователи могут быстро создавать отчеты по набору данных без сложных процессов программирования. Достаточно нажать пару кнопок, чтобы экспортировать результаты исследования из интерактивного средства в окончательный отчет. Затем он передается клиентам или используется для принятия решений о том, какие переменные следует использовать на следующем этапе моделирования.

В настоящее время средство работает только с блоками данных в памяти. Для настройки параметров изучаемого набора данных используется YAML-файл. Дополнительные сведения см. [на странице IDEAR](https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/DataReport-Utils) в разделе служебных программ TDSP для обработки и анализа данных.


## 2. <a name='ModelingUtility-2'></a> моделирование

Существуют многочисленные наборы средств и пакеты для обучения моделей на разных языках. Специалисты по обработке и анализу данных могут свободно использовать их на свой выбор, пока соблюдаются рекомендации по производительности в отношении точности и задержки для соответствующих коммерческих вариантов использования и рабочих сценариев.

В следующем разделе показано использование служебной программы TDSP на основе R для полуавтоматического моделирования. Эту служебную программу АМАР можно использовать для быстрого создания базовых моделей и параметров, которые должны быть настроены для повышения эффективности модели.
В следующем разделе об управлении моделями показано, как использовать систему для регистрации нескольких моделей и управления ими.


### <a name="model-training-modeling-and-reporting-using-the-amar-utility"></a>Обучение модели: моделирование и создание отчетов с помощью служебной программы АМАР

[Служебная программа для автоматического моделирования и создания отчетов (АМАР)](https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling) — это настраиваемый полуавтоматический инструмент для создания моделей со сканированием гиперпараметров и сравнения точности этих моделей. 

Служебная программа для создания моделей — это файл R Markdown, при выполнении которого создается автономный HTML-документ с оглавлением для удобной навигации по разделам. При запуске файла разметки выполняются три алгоритма: метод регуляризованной регрессии с использованием пакета glmnet, метод случайного леса с использованием пакета randomForest и метод увеличивающихся деревьев с использованием пакета xgboost. При помощи каждого из этих алгоритмов создается обученная модель. После этого сравнивается точность полученных моделей и возвращаются графики относительный важности компонентов. В настоящее время есть две программы: для задач двоичной классификации и для задач регрессии. Основные различия между ними заключаются в том, как определяются параметры управления и метрики точности. 

В YAML-файле указываются следующие данные:

- источник входных данных (хранилище SQL или файл данных R); 
- какая часть данных используется для обучения и для тестирования;
- какие алгоритмы будут выполняться; 
- параметры управления для оптимизации модели:
    - перекрестная проверка; 
    - начальная загрузка;
    - свертывания перекрестной проверки.
- набор гиперпараметров для каждого алгоритма. 

Также в YAML-файле можно быстро изменить число алгоритмов и свертываний для оптимизации, гиперпараметры, а также число их наборов для сканирования, что позволяет оперативно запускать модели. Например, можно выполнить модель с меньшим числом свертываний перекрестной проверки или с меньшим числом наборов параметров. Также можно повысить точность оценки, увеличив количество свертываний перекрестной проверки или количество наборов параметров, если их можно предоставить.

Дополнительные сведения см. на [странице служебной программы для автоматизированного моделирования и создания отчетов](https://github.com/Azure/Azure-TDSP-Utilities/tree/master/DataScienceUtilities/Modeling) в разделе служебных программ TDSP для обработки и анализа данных.

### <a name="model-management"></a>Управление моделями
После создания нескольких моделей обычно требуется система для регистрации моделей и управления ими. Обычно требуется сочетание сценариев или интерфейсов API и серверной базы данных или системы управления версиями. Ниже приведено несколько инструментов, которые можно рассмотреть для выполнения этих задач управления:

1. [Служба "Машинное обучение Azure" — служба управления моделями](../index.yml)
2. [ModelDB из MIT](https://mitdbg.github.io/modeldb/) 
3. [SQL Server как система управления моделями](https://blogs.technet.microsoft.com/dataplatforminsider/2016/10/17/sql-server-as-a-machine-learning-model-management-system/)
4. [Microsoft Machine Learning Server](https://docs.microsoft.com/sql/advanced-analytics/r/r-server-standalone)

## 3. <a name='Deployment-3'></a> развертывание

Развертывание в рабочей среде позволяет использовать модель как важный элемент в работе организации. Прогнозы, полученные от развернутой модели можно использовать для принятия бизнес-решений.

### <a name="production-platforms"></a>Рабочие платформы
Поместить модели в рабочую среду можно с использованием разных подходов и платформ. Вот некоторые из них:


- [Развертывание модели в службе "Машинное обучение Azure"](../how-to-deploy-and-where.md)
- [Развертывание модели на сервере SQL Server](https://docs.microsoft.com/sql/advanced-analytics/tutorials/sqldev-py6-operationalize-the-model)
- [Microsoft Machine Learning Server](https://docs.microsoft.com/sql/advanced-analytics/r/r-server-standalone)

> [!NOTE]
> Перед развертыванием необходимо убедиться, что показатели задержки модели достаточно малы для использования в рабочей среде.
>
>

В пошаговых руководствах доступны дополнительные примеры, которые демонстрируют все этапы процесса для **конкретных сценариев**. Эти этапы с иллюстрациями и краткими описаниями перечислены в статье [Пошаговые руководства по процессу обработки и анализа данных группы](walkthroughs.md). В них показано, как объединить облачные и локальные средства и службы в единый рабочий процесс или конвейер, чтобы создать интеллектуальное приложение.

> [!NOTE]
> Разработка с помощью Студии машинного обучения Azure описывается в разделе [Развертывание веб-службы машинного обучения Azure](../studio/deploy-a-machine-learning-web-service.md).
>
>

### <a name="ab-testing"></a>A/B-тестирование
Если в рабочей среде используется несколько моделей, удобно выполнять [A/B-тестирование](https://en.wikipedia.org/wiki/A/B_testing), чтобы сравнить их эффективность. 

 
## <a name="next-steps"></a>Дальнейшие действия

В разделе [Ход выполнения проектов обработки и анализа данных](track-progress.md) показано, как специалист по обработке и анализу данных может отслеживать ход выполнения проекта обработки и анализа данных.

[Модель операции и CI/CD](ci-cd-flask.md) показывает, как CI/CD могут быть выполнены при помощи разработанных моделей.


