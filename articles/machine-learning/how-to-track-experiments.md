---
title: Эксперименты журнала ML & метрики
titleSuffix: Azure Machine Learning
description: Мониторинг экспериментов Azure ML и мониторинг метрик выполнения для улучшения процесса создания модели. Добавьте журнал в свой обучаемый скрипт и просмотрите зарегистрированные результаты выполнения.  Используйте run.log, Run.start_logging или ScriptRunConfig.
services: machine-learning
author: sdgilley
ms.author: sgilley
ms.reviewer: sgilley
ms.service: machine-learning
ms.subservice: core
ms.workload: data-services
ms.topic: conceptual
ms.date: 03/12/2020
ms.custom: seodec18
ms.openlocfilehash: 0c77e9d0aa4f44f33b1345a6021fc0378459ee85
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79296971"
---
# <a name="monitor-azure-ml-experiment-runs-and-metrics"></a>Monitor Azure ML эксперимент работает и метрики
[!INCLUDE [applies-to-skus](../../includes/aml-applies-to-basic-enterprise-sku.md)]

Увеличьте процесс создания модели, отслеживая ваши эксперименты и отслеживая метрики выполнения. В этой статье узнайте, как добавить код журнала в свой обучаемый скрипт, отправить запуск эксперимента, контролировать запуск и проверить результаты в Azure Machine Learning.

> [!NOTE]
> Машинное обучение Azure может также регистрировать информацию из других источников во время обучения, таких как автоматизированные запуски машинного обучения или контейнер Docker, который выполняет учебную работу. Эти журналы не документированы. Если вы столкнулись с проблемами и обратились в службу поддержки майкрософт, они смогут использовать эти журналы во время устранения неполадок.

> [!TIP]
> Информация в этом документе в первую очередь предназначена для ученых и разработчиков данных, которые хотят контролировать процесс обучения модели. Если вы являетесь администратором, заинтересованным в мониторинге использования ресурсов и событий из машинного обучения [Monitoring Azure Machine Learning](monitor-azure-machine-learning.md)Azure, таких как квоты, завершенные обучающие заезды или завершенные развертывания моделей, см.

## <a name="available-metrics-to-track"></a>Доступные метрики для отслеживания

Следующие метрики можно добавить к выполнению во время обучения эксперимента. Чтобы просмотреть подробный список того, что можно отслеживать при выполнении, ознакомьтесь со [справочной документацией по классу Run](https://docs.microsoft.com/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py).

|Тип| Функция Python | Примечания|
|----|:----|:----|
|Скалярные значения |Функция:<br>`run.log(name, value, description='')`<br><br>Пример<br>run.log("accuracy", 0.95) |Запишите числовое или строковое значение в выполнение с заданным именем. Запись метрики в выполнение приводит к тому, что метрика будет сохранена в записи о выполнении в эксперименте.  Одну и ту же метрику можно несколько раз записать в рамках выполнения. Результат будет считаться вектором этой метрики.|
|Списки|Функция:<br>`run.log_list(name, value, description='')`<br><br>Пример<br>run.log_list("accuracies", [0.6, 0.7, 0.87]) | Запишите список значений в выполнение с заданным именем.|
|Строка|Функция:<br>`run.log_row(name, description=None, **kwargs)`<br>Пример<br>run.log_row("Y over X", x=1, y=0.4) | С помощью *log_row* создается метрика с несколькими столбцами, как описано в kwargs. Каждый именованный параметр создает столбец с указанным значением.  *log_row* можно вызвать один раз, чтобы записать произвольный кортеж, или несколько раз в цикле, чтобы создать полную таблицу.|
|Таблица|Функция:<br>`run.log_table(name, value, description='')`<br><br>Пример<br>run.log_table("Y over X", {"x":[1, 2, 3], "y":[0.6, 0.7, 0.89]}) | Запишите объект словаря в выполнение с заданным именем. |
|Образы|Функция:<br>`run.log_image(name, path=None, plot=None)`<br><br>Пример<br>`run.log_image("ROC", plot=plt)` | Запишите изображение в запись о выполнении. Используйте log_image, чтобы записать файл изображения или график matplotlib в выполнение.  Эти изображения будут видимы, и их можно сравнить в записи о выполнении.|
|Добавление тега к выполнению|Функция:<br>`run.tag(key, value=None)`<br><br>Пример<br>run.tag("selected", "yes") | Добавление тега к выполнению с использованием строкового ключа и дополнительного значения строки.|
|Отправка файла или каталога|Функция:<br>`run.upload_file(name, path_or_stream)`<br> <br> Пример<br>run.upload_file("best_model.pkl", "./model.pkl") | Отправка файла в запись о выполнении. Выполняет автоматическую запись файла в указанном каталоге вывода, который по умолчанию имеет значение "./outputs" для большинства типов выполнения.  Используйте upload_file только в том случае, если необходимо отправить дополнительные файлы или не указан выходной каталог. Мы советуем добавлять `outputs` к имени для того, чтобы файл отправлялся в выходной каталог. Вы можете перечислить все файлы, связанные с этой записью о выполнении, вызвав `run.get_file_names()`.|

> [!NOTE]
> Метрики для скалярных значений, списков, строк и таблиц могут быть типа: число с плавающей точкой, целое число или строка.

## <a name="choose-a-logging-option"></a>Выберите вариант регистрации

Если вы хотите отслеживать свой эксперимент, необходимо добавить код, чтобы запустить ведение журнала при отправке выполнения. Ниже приведены способы активации отправки выполнений:
* __Run.start_logging__ добавляет функции регистрации в сценарий обучения и запускает интерактивный сеанс регистрации в определенном эксперименте. **start_logging** создает интерактивное выполнение для использования в таких сценариях, как записные книжки. Все метрики, записанные во время сеанса, добавляются в запись о выполнении эксперимента.
* __ScriptRunConfig__ добавляет функции ведения журнала в сценарий обучения и загружает всю папку сценария с выполнением.  **ScriptRunConfig** является классом для настройки конфигурации выполнений в сценарии. С использованием этого параметра можно добавить код мониторинга, чтобы получать уведомления о завершении или получить визуальное мини-приложение для мониторинга.

## <a name="set-up-the-workspace"></a>Настройка рабочей области
Перед тем, как включать ведение журнала и отправлять эксперимент, необходимо настроить рабочую область.

1. Загрузите рабочую область. Чтобы узнать больше о настройке [workspace configuration file](how-to-configure-environment.md#workspace)конфигурации рабочего пространства, см.

«!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-within-notebook/train-within-notebook.ipynb?name-load_ws))


## <a name="option-1-use-start_logging"></a>Вариант 1. Использование start_logging

**start_logging** создает интерактивное выполнение для использования в таких сценариях, как записные книжки. Все метрики, записанные во время сеанса, добавляются в запись о выполнении эксперимента.

В следующем примере простая модель sklearn Ridge обучается локально в локальной записной книжке Jupyter. Чтобы узнать больше о представлении экспериментов в различных средах, [см.](https://docs.microsoft.com/azure/machine-learning/how-to-set-up-training-targets)

### <a name="load-the-data"></a>Загрузка данных

В этом примере используется набор данных о диабете, хорошо известный небольшой набор данных, который поставляется с scikit-учиться. Эта ячейка загружает набор данных и разделяет его на случайные наборы обучения и тестирования.

«!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-within-notebook/train-within-notebook.ipynb?name-load_data))

### <a name="add-tracking"></a>Добавление отслеживания
Добавьте отслеживание экспериментов с помощью SDK Azure Machine Learning и загрузите упорную модель в запись запуска эксперимента. Следующий код добавляет теги, журналы и отправляет файл модели в выполнение эксперимента.

«!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-within-notebook/train-within-notebook.ipynb?name-create_experiment)

Сценарий оканчивается на ```run.complete()```, что помечает выполнение как завершенное.  Обычно эта функция используется в сценариях интерактивной записной книжки.

## <a name="option-2-use-scriptrunconfig"></a>Вариант 2. Использование ScriptRunConfig

[**ScriptRunConfig**](https://docs.microsoft.com/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py) — это класс для настройки конфигураций для выполнения сценариев. С использованием этого параметра можно добавить код мониторинга, чтобы получать уведомления о завершении или получить визуальное мини-приложение для мониторинга.

В этом примере расширяется указанная выше базовая модель sklearn Ridge. В нем выполняется простая замена параметров по альфа-значениям модели для записи метрик и обученных моделей в выполнениях в рамках эксперимента. Пример запускается локально в управляемой пользователем среде. 

1. Создайте сценарий обучения `train.py`.

   «!код-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-on-local/train.py)

2. Сценарий `train.py` ссылается на `mylib.py`, который позволяет получить список альфа-значений для использования в модели ridge.

   «!код-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-on-local/mylib.py) 

3. Настройте управляемую пользователем локальную среду.

   «!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-on-local/train-on-local.ipynb?name-user_managed_env))


4. Отправьте сценарий ```train.py``` для выполнения в среде, управляемой пользователем. Вся папка сценария отправляется для обучения, в том числе файл ```mylib.py```.

   «!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-on-local/train-on-local.ipynb?name'src)) «!ноутбук-питон» (я/машинное обучениеNotebookы/как-к-использованию-azureml/training/train-on-local/train-on-local.ipynb?name-run))




## <a name="manage-a-run"></a>Управление пробегом

В статье [«Старт, мониторинг и отмена обучающих запусков»](how-to-manage-runs.md) освещаются конкретные рабочие процессы по изучению машин Azure для управления экспериментами.

## <a name="view-run-details"></a>Просмотр сведений о выполнении

### <a name="view-activequeued-runs-from-the-browser"></a>Просмотр активных/очередных запусков из браузера

Вычислительные цели, используемые для обучения моделей, являются общим ресурсом. Таким образом, они могут иметь несколько запусков в очереди или активны в данный момент времени. Чтобы увидеть запуски для определенной вычислительной цели из вашего браузера, используйте следующие шаги:

1. В [студии машинного обучения Azure](https://ml.azure.com/)выберите рабочее пространство, а затем выберите __вычисления__ с левой стороны страницы.

1. Выберите __обучающие кластеры__ для отображения списка вычислительных целей, используемых для обучения. Затем выберите кластер.

    ![Выберите обучаемый кластер](./media/how-to-track-experiments/select-training-compute.png)

1. Выберите __запуски__. Отображается список запусков, которые используют этот кластер. Для просмотра деталей для определенного запуска используйте ссылку в столбце __Run.__ Для просмотра деталей эксперимента используйте ссылку в столбце __Эксперимента.__

    ![Выберите трассы для тренировочного кластера](./media/how-to-track-experiments/show-runs-for-compute.png)
    
    > [!TIP]
    > Запуск может содержать запуски детей, поэтому одна учебная работа может привести к нескольким записям.

После завершения выполнения он больше не отображается на этой странице. Чтобы просмотреть информацию о завершенных запусках, посетите раздел __Эксперименты__ студии и выберите эксперимент и запуск. Для получения дополнительной информации смотрите раздел [метрик выполнения запросов.](#queryrunmetrics)

### <a name="monitor-run-with-jupyter-notebook-widget"></a>Монитор работает с виджетом ноутбука Jupyter
При использовании метода **ScriptRunConfig** для отправки трасс можно наблюдать за ходом выполнения с помощью [виджета Jupyter.](https://docs.microsoft.com/python/api/azureml-widgets/azureml.widgets?view=azure-ml-py) Подобно представлению запуска, мини-приложение является асинхронным и предоставляет обновления в реальном времени каждые 10–15 секунд до завершения задания.

1. Просмотрите мини-приложения Jupyter во время ожидания завершения выполнения.

   ```python
   from azureml.widgets import RunDetails
   RunDetails(run).show()
   ```

   ![Снимок экрана. Мини-приложение записной книжки Jupyter](./media/how-to-track-experiments/run-details-widget.png)

   Вы также можете получить ссылку на тот же дисплей в рабочем пространстве.

   ```python
   print(run.get_portal_url())
   ```

2. **[Для автоматических запусков машинного обучения]** Доступ к диаграммам из предыдущего выполнения. Заменить `<<experiment_name>>` соответствующее название эксперимента:

   ``` 
   from azureml.widgets import RunDetails
   from azureml.core.run import Run

   experiment = Experiment (workspace, <<experiment_name>>)
   run_id = 'autoML_my_runID' #replace with run_ID
   run = Run(experiment, run_id)
   RunDetails(run).show()
   ```

   ![Мини-приложение записной книжки Jupyter для автоматического машинного обучения](./media/how-to-track-experiments/azure-machine-learning-auto-ml-widget.png)


Чтобы просмотреть более подробную информацию о конвейере, нажмите на конвейер, который вы хотели бы изучить в таблице, и диаграммы будут отображаться во всплывающем окне из студии машинного обучения Azure.

### <a name="get-log-results-upon-completion"></a>Получение результатов записи по завершении

Обучение модели и мониторинг происходят в фоновом режиме, так что вы можете выполнять другие задачи во время ожидания. Также перед выполнением кода можно подождать, пока модель закончит обучение. При использовании **ScriptRunConfig** можно указать ```run.wait_for_completion(show_output = True)```, чтобы узнать, когда обучение модели будет завершено. Флаг ```show_output``` предоставляет подробные выходные данные. 

<a id="queryrunmetrics"></a>

### <a name="query-run-metrics"></a>Запрос метрик выполнения

Метрики обученной модели можно просмотреть с помощью ```run.get_metrics()```. Теперь можно получить все метрики, которые были зарегистрированы в примере выше, чтобы определить оптимальную модель.

<a name="view-the-experiment-in-the-web-portal"></a>
## <a name="view-the-experiment-in-your-workspace-in-azure-machine-learning-studio"></a>Просмотр эксперимента в рабочей области в [студии машинного обучения Azure](https://ml.azure.com)

После завершения эксперимента можно просмотреть записи о выполнении в эксперименте. Вы можете получить доступ к истории из [студии машинного обучения Azure.](https://ml.azure.com)

Перейдите на вкладку «Эксперименты» и выберите эксперимент. Вы приведены к панели мониторинга запуска эксперимента, где можно увидеть отслеживаемые метрики и диаграммы, которые регистрируются для каждого запуска. В этом случае мы регистрируем MSE и альфа-значения.

  ![Проработание деталей в студии машинного обучения Azure](./media/how-to-track-experiments/experiment-dashboard.png)

Вы можете просверлить до определенного запуска, чтобы просмотреть его выходы или журналы, или загрузить снимок эксперимента, который вы представили, чтобы вы могли поделиться папкой эксперимента с другими.

### <a name="viewing-charts-in-run-details"></a>Просмотр диаграмм в сведениях о выполнении

Существуют различные способы использования разных типов метрик во время выполнения и просмотра их в виде диаграмм в студии Машинного обучения Azure.

|Значение в журнале|Пример кода| Представление на портале|
|----|----|----|
|Массив числовых значений| `run.log_list(name='Fibonacci', value=[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89])`|График для одной переменной|
|Одно повторяющееся числовое значение с тем же именем метрики (например, в цикле for)| `for i in tqdm(range(-10, 10)):    run.log(name='Sigmoid', value=1 / (1 + np.exp(-i))) angle = i / 2.0`| График для одной переменной|
|Повторяющиеся строки с двумя числовыми столбцами|`run.log_row(name='Cosine Wave', angle=angle, cos=np.cos(angle))   sines['angle'].append(angle)      sines['sine'].append(np.sin(angle))`|Графики для двух переменных|
|Таблица с двумя числовыми столбцами|`run.log_table(name='Sine Wave', value=sines)`|Графики для двух переменных|


## <a name="example-notebooks"></a>Примеры записных книжек
Основные понятия, описанные в этой статье, демонстрируют следующие записные книжки:
* [how-to-use-azureml/training/train-within-notebook](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/train-within-notebook)
* [how-to-use-azureml/training/train-on-local](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training/train-on-local)
* [как-к-использованию-azureml/трек-и-монитор-эксперименты/лесозаготовки-апи](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/track-and-monitor-experiments/logging-api)

[!INCLUDE [aml-clone-in-azure-notebook](../../includes/aml-clone-for-examples.md)]

## <a name="next-steps"></a>Дальнейшие действия

Попробуйте следующие шаги, чтобы узнать, как использовать пакет SDK службы "Машинное обучение Azure" для Python:

* Пример регистрации оптимальных моделей и их развертывания см. в руководстве [Руководство № 1. Обучение модели классификации изображений с помощью Машинного обучения Azure](tutorial-train-models-with-aml.md).

* Дополнительные сведения о том, как обучать модели PyTorch с помощью службы "Машинное обучение Azure", см. в [этой статье](how-to-train-pytorch.md).
