---
title: Оценка результатов экспериментов Аутомл
titleSuffix: Azure Machine Learning
description: Узнайте, как просматривать и оценивать диаграммы и метрики для каждого из автоматических запусков экспериментов машинного обучения.
services: machine-learning
author: aniththa
ms.author: anumamah
ms.reviewer: nibaccam
ms.service: machine-learning
ms.subservice: core
ms.date: 10/09/2020
ms.topic: conceptual
ms.custom: how-to, contperfq2, automl
ms.openlocfilehash: fcbe0fc5049f6e892f80f048a885c75420bc636e
ms.sourcegitcommit: 6a902230296a78da21fbc68c365698709c579093
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/05/2020
ms.locfileid: "93359091"
---
# <a name="evaluate-automated-machine-learning-experiment-results"></a>Оценка результатов автоматического эксперимента машинного обучения

В этой статье вы узнаете, как просматривать и оценивать результаты автоматизированного машинного обучения, автоматизированного ML и экспериментов. Эти эксперименты состоят из нескольких запусков, где каждый запуск создает модель. Чтобы помочь вам оценить каждую модель, автоматический ML автоматически создает метрики производительности и диаграммы, относящиеся к типу эксперимента. 

Например, автоматизированный ML предоставляет различные диаграммы для моделей классификации и регрессии. 

|Классификация|Регрессия
|---|---|
|<li> [Матрица неточностей](#confusion-matrix) <li>[Диаграмма точности-отзывов](#precision-recall-chart) <li> [ROC-кривые](#roc); <li> [кривая точности прогнозов](#lift-curve);<li> [кривая прироста](#gains-curve);<li> [график калибровки](#calibration-plot). | <li> [Предсказанные и значения true](#pvt) <li> [Гистограмма остатков](#histo)|

## <a name="prerequisites"></a>Обязательные условия

* Подписка Azure. Если у вас еще нет подписки Azure, создайте бесплатную учетную запись, прежде чем начинать работу. Опробуйте [бесплатную или платную версию Машинного обучения Azure](https://aka.ms/AMLFree) уже сегодня.

* Создайте эксперимент для автоматического запуска машинного обучения с помощью пакета SDK или в Машинное обучение Azure Studio.

    * Использование пакета SDK для построения [модели классификации](how-to-auto-train-remote.md) или [модели регрессии](tutorial-auto-train-models.md)
    * Используйте [машинное обучение Azure Studio](how-to-use-automated-ml-for-ml-models.md) для создания модели классификации или регрессии путем передачи соответствующих данных.

## <a name="view-run-results"></a>Просмотреть результаты выполнения

После завершения автоматического эксперимента машинного обучения журнал запусков можно найти в рабочей области машинного обучения с помощью [машинное обучение Azure Studio](overview-what-is-machine-learning-studio.md). 

Для экспериментов с пакетом SDK эти же результаты можно просмотреть во время выполнения при использовании `RunDetails` [мини](/python/api/azureml-widgets/azureml.widgets?preserve-view=true&view=azure-ml-py)-приложения Jupyter.

В следующих шагах и анимации показано, как просматривать журнал выполнения и метрики производительности и диаграммы определенной модели в студии.

![Действия по просмотру журнала выполнения и метрик производительности модели и диаграмм](./media/how-to-understand-automated-ml/view-run-metrics-ui.gif)

Для просмотра журнала выполнения и метрик производительности модели и диаграмм в студии: 

1. [Войдите в студию студии](https://ml.azure.com/) и перейдите к рабочей области.
1. На левой панели рабочей области выберите **запуски**.
1. В списке экспериментов выберите ту, которую хотите просмотреть.
1. В нижней таблице выберите **Запуск**.
1. На вкладке **модели** выберите **имя алгоритма** для модели, которую необходимо просмотреть.
1. На вкладке **метрики** выберите метрики и диаграммы, которые необходимо оценить для этой модели. 


<a name="classification"></a> 

## <a name="classification-performance-metrics"></a>Метрики производительности классификации

В следующей таблице перечислены метрики производительности модели, которые автоматизированное средство ML вычисляет для каждой модели классификации, создаваемой для вашего эксперимента. 

Метрика|Описание|Вычисление|Дополнительные параметры
--|--|--|--
AUC_macro| AUC представляет собой область под кривой рабочих характеристик приемника (ROC). Макрозначение — это среднее арифметическое значение AUC для каждого класса.  | [Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) | average="macro"|
AUC_micro| AUC представляет собой область под кривой рабочих характеристик приемника (ROC). Micro вычисляются глобально путем объединения истинных положительных и ложных срабатываний от каждого класса.| [Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) | average="micro"|
AUC_weighted  | AUC представляет собой область под кривой рабочих характеристик приемника (ROC). Взвешенное значение — это среднее арифметическое для оценки каждого класса, взвешенное по количеству истинных экземпляров в каждом классе.| [Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)|average="weighted"
accuracy|Точность — это процент прогнозируемых меток, которые точно соответствуют истинным меткам. |[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) |None|
average_precision_score_macro|Для вычисления средней точности используется кривая точности и полноты в качестве взвешенного среднего значения точности, полученного для каждого порогового значения, с увеличением полноты за счет предыдущего порогового значения, используемого в качестве весового коэффициента. Макрос — это среднее арифметическое среднее значение точности каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)|average="macro"|
average_precision_score_micro|Для вычисления средней точности используется кривая точности и полноты в качестве взвешенного среднего значения точности, полученного для каждого порогового значения, с увеличением полноты за счет предыдущего порогового значения, используемого в качестве весового коэффициента. Micro вычисляются глобально путем объединения истинных положительных и ложных срабатываний при каждой отсечки.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)|average="micro"|
average_precision_score_weighted|Для вычисления средней точности используется кривая точности и полноты в качестве взвешенного среднего значения точности, полученного для каждого порогового значения, с увеличением полноты за счет предыдущего порогового значения, используемого в качестве весового коэффициента. Взвешенное среднее среднее арифметическое значение точности для каждого класса, взвешенное по количеству истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)|average="weighted"|
balanced_accuracy|Сбалансированная точность — это среднее арифметическое значение полноты для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|average="macro"|
f1_score_macro|Оценка F1 — это среднее гармоническое значение точности и полноты. Макрос — это арифметическое среднее значение оценки F1 для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)|average="macro"|
f1_score_micro|Оценка F1 — это среднее гармоническое значение точности и полноты. Micro вычисляется глобально путем подсчета общих истинных положительных результатов, ложных отрицательных значений и ложных срабатываний.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)|average="micro"|
f1_score_weighted|Оценка F1 — это среднее гармоническое значение точности и полноты. Взвешенное среднее значение по частоте класса оценки F1 для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)|average="weighted"|
log_loss|Это функция потери данных, используемая в логистической регрессии (мультиноминальное) и расширениях ИТ-сетей, таких как нейронные сети, которая определяется как отрицательная вероятность журнала для истинных меток на основе прогнозов классификатора вероятностная. Для одного образца с истинной меткой YT в {0,1} и предполагаемая вероятность ИП, YT = 1, потери журнала — журнал P (yt&#124;ИП) =-(YT log (ИП) + (1 — YT) log (1-ИП)).|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)|None|
norm_macro_recall|Нормализованная полнота макрозначений — это полнота макрозначений, нормализованная таким образом, чтобы случайному выполнению соответствовала оценка 0, а идеальному выполнению — оценка 1. Это достигается за счет norm_macro_recall: = (recall_score_macro-R)/(1-R), где R — ожидаемое значение recall_score_macro для случайных прогнозов (т. е. R = 0,5 для двоичной классификации и R = (1/C) для проблем классификации C-Class).|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|Average = "макрос" |
precision_score_macro|Точность — это процент положительных прогнозируемых элементов, которые правильно помечены. Макрос — это среднее арифметическое значение точности для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)|average="macro"|
precision_score_micro|Точность — это процент положительных прогнозируемых элементов, которые правильно помечены. Micro вычисляется глобально путем подсчета итоговых истинных положительных результатов и ложных положительных результатов.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)|average="micro"|
precision_score_weighted|Точность — это процент положительных прогнозируемых элементов, которые правильно помечены. Взвешенное значение — это среднее арифметическое для каждого класса, взвешенное по числу истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)|average="weighted"|
recall_score_macro|Отзыв — это процент правильно помеченных элементов определенного класса. Макрос — это среднее арифметическое при отзыве для каждого класса.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|average="macro"|
recall_score_micro|Отзыв — это процент правильно помеченных элементов определенного класса. Micro вычисляется глобально путем подсчета итоговых истинных положительных результатов, ложных отрицательных результатов и ложных срабатываний.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|average="micro"|
recall_score_weighted|Отзыв — это процент правильно помеченных элементов определенного класса. Взвешенный — это среднее арифметическое значение для каждого класса, взвешенное по числу истинных экземпляров в каждом классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)|average="weighted"|
weighted_accuracy|Взвешенная точность является точностью, где весовой коэффициент, заданный для каждого примера, равен пропорции истинных экземпляров в этом примере на истинном классе.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)|Значение sample_weight представляет собой вектор, равный доле этого класса для каждого элемента в целевом элементе.|

### <a name="binary-vs-multiclass-metrics"></a>Сравнение двоичных и многоклассовых метрик

Автоматизированное МАШИНное обучение не различает метрики двоичного и многоклассного языка. Одни и те же метрики проверки сообщают, имеет ли набор данных два класса или более двух. Однако некоторые метрики предназначены для многоклассовой классификации. При применении к двоичному набору данных эти метрики не будут рассматривать класс как `true` класс, как можно ожидать. К метрикам, которые явно предназначены для многоклассового класса, добавляется суффикс `micro` , `macro` или `weighted` . Примеры:,,, `average_precision_score` `f1_score` `precision_score` `recall_score` и `AUC` .

Например, вместо того, чтобы вычислить отзыв как, среднее арифметическое вычисление `tp / (tp + fn)` в нескольких классах ( `micro` , `macro` или `weighted` ) для обоих классов набора данных двоичной классификации. Это эквивалентно вычислению отзыва для `true` класса и `false` класса отдельно, а затем получение среднего значения этих двух значений.

## <a name="confusion-matrix"></a>Матрица неточностей

Матрица путаницы описывает производительность модели классификации. В каждой строке отображаются экземпляры истинного или фактического класса в наборе данных, а каждый столбец представляет экземпляры класса, прогнозируемого моделью. 

Для каждой матрицы путаницы автоматический ML показывает частоту каждой прогнозируемой метки (столбца), сравниваемой с истинной меткой (строкой). Чем темнее цвет, тем выше число в этой конкретной части матрицы. 

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?

Матрица путаницы сравнивает фактическое значение набора данных с прогнозируемыми значениями, предоставленными моделью. По этой причине модели машинного обучения имеют более высокую точность, если в модели содержится большая часть ее значений по диагонали, то есть модель прогнозирует правильное значение. Если модель имеет несбалансированный класс, то матрица путаницы помогает обнаружить смещенную модель.

#### <a name="example-1-a-classification-model-with-poor-accuracy"></a>Пример 1. модель классификации с низкой точностью
![Модель классификации с низкой точностью](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-confusion-matrix1.png)

#### <a name="example-2-a-classification-model-with-high-accuracy"></a>Пример 2. модель классификации с высокой точностью 
![Модель классификации с высокой точностью](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-confusion-matrix2.png)

##### <a name="example-3-a-classification-model-with-high-accuracy-and-high-bias-in-model-predictions"></a>Пример 3. модель классификации с высокой точностью и высоким уровнем смещения в прогнозах модели
![Модель классификации с высокой точностью и высоким уровнем смещения в прогнозах модели](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-biased-model.png)

<a name="precision-recall-chart"></a>

## <a name="precision-recall-chart"></a>Диаграмма соотношения полноты и точности

Кривая точности и отзыва показывает связь между точностью и подотзывом из модели. Термин точность представляет способность модели помечать все экземпляры правильно. Термин "полнота" обозначает способность классификатора найти все экземпляры для определенной метки.

С помощью этой диаграммы вы можете сравнить кривые полноты и точности для каждой модели, чтобы определить модель с допустимым соотношением этих параметров для поставленной бизнес-задачи. На этой схеме отображается среднее соотношение полноты и точности на макро-уровне, микро-уровне, а также для всех классов модели. 

При **среднем использовании макроса** метрика вычисляется независимо от каждого класса, а затем получается среднее значение, в котором все классы поровны. Однако в **микросредном** числе вклады всех классов для вычисления среднего значения. Если в наборе данных имеется несбалансированный класс, предпочтительнее использовать Micro-Average.

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?
В зависимости от цели бизнес-задачи, идеальная кривая с точностью отзыва может отличаться. 

##### <a name="example-1-a-classification-model-with-low-precision-and-low-recall"></a>Пример 1. модель классификации с низкой точностью и низким отзывом
![Модель классификации с низкой точностью и низким отзывом](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-precision-recall1.png)

##### <a name="example-2-a-classification-model-with-100-precision-and-100-recall"></a>Пример 2. модель классификации с ~ 100% Precision и ~ 100% отзыв 
![Высокая точность и отзыв модели классификации](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-precision-recall2.png)

<a name="roc"></a>

## <a name="roc-chart"></a>Диаграмма ROC

Операционная характеристика приемника (или ROC) представляет собой график правильно классифицированных меток и неправильно классифицированные метки для конкретной модели. Кривая ROC может быть менее информативной при обучении моделей на наборах данных с высоким дисбалансом классов, так как класс большинства может Drown вклад из классов миноритария.

Вы можете визуализировать область под диаграммой ROC как долю правильно классифицированных образцов. Опытный пользователь диаграммы ROC может выглядеть за пределами области кривой и получить интуиция для истинных положительных и ложных положительных ставок в качестве функции порога классификации или границы принятия решений.

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?
ROCная кривая, которая подходит для левого верхнего угла с 100% истинной ставкой и 0% ложного положительного значения, будет лучшей моделью. Случайная модель отображается в виде плоской линии слева направо верхнего левого угла. Хуже, чем случайный, он получит DIP под линией y = x.

#### <a name="example-1-a-classification-model-with-low-true-labels-and-high-false-labels"></a>Пример 1. модель классификации с низкими истинными метками и высокими ложными метками
![Модель классификации с низкими истинными метками и большими ложными метками](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-roc-1.png)

#### <a name="example-2-a-classification-model-with-high-true-labels-and-low-false-labels"></a>Пример 2. модель классификации с высокими истинными метками и низкими ложными метками

![модель классификации с высокими истинными метками и младшими ложными метками](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-roc-2.png)


<a name="lift-curve"></a>

## <a name="lift-chart"></a>Диаграмма точности прогнозов

Диаграммы точности прогнозов оценивают производительность моделей классификации. На диаграмме точности прогнозов показано, сколько раз оптимизация модели выполняется по сравнению с случайной моделью. Это дает относительную производительность, которая учитывает тот факт, что классификация усложняется по мере увеличения числа классов. Случайная модель неправильно прогнозирует большую долю выборок из набора данных с десятью классами по сравнению с набором данных с двумя классами.

Можно сравнить Прогноз модели, созданной автоматически с Машинное обучение Azure базовой модели (случайная модель), чтобы просмотреть значение этой конкретной модели.

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?

Более производительная модель будет иметь кривую точности прогнозов, которая больше на диаграмме и дальше от базового плана. 

#### <a name="example-1-a-classification-model-that-performs-poorly-compared-to-a-random-selection-model"></a>Пример 1. модель классификации, которая работает плохо по сравнению с моделью произвольного выбора
![Модель классификации, которая хуже модели случайного выбора](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-lift-curve1.png)

#### <a name="example-2-a-classification-model-that-performs-better-than-a-random-selection-model"></a>Пример 2. модель классификации, которая работает лучше модели случайного выбора
![Модель классификации, которая работает лучше](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-lift-curve2.png)

<a name="gains-curve"></a>

## <a name="cumulative-gains-chart"></a>Диаграмма совокупных выигрышей

Диаграмма совокупных выигрышей оценивает производительность модели классификации по каждой части данных. Для каждого процентиля набора данных на диаграмме показано, сколько других выборок было точно классифицировано по сравнению с моделью, которая всегда неверна. Здесь представлена та же информация, что и на диаграмме точности прогнозов, но в другом режиме отображения.

Диаграмма совокупных выигрышей позволяет выбрать отсечение классификации с использованием процента, соответствующего требуемой прибыли от модели. Диаграмму совокупных выигрышей можно сравнить с базовой (неправильной моделью), чтобы увидеть процент выборок, которые были правильно классифицированы на каждом уровне достоверности.

#### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?

Как и в случае с диаграммой точности прогнозов, чем выше базовая кривая с ростом, тем лучше выполняется модель. Кроме того, чем ближе кривая совокупная прибыль к верхнему левому углу графа, тем выше степень параллелизма модели в сравнении с базовыми показателями. 

##### <a name="example-1-a-classification-model-with-minimal-gain"></a>Пример 1. модель классификации с минимальным выигрышем
![модель классификации с минимальным ростом](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-gains-curve2.png)

##### <a name="example-2-a-classification-model-with-significant-gain"></a>Пример 2. модель классификации с значительным выигрышем
![Модель классификации с значительным выигрышем](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-gains-curve1.png)

<a name="calibration-plot"></a>

## <a name="calibration-chart"></a>Диаграмма калибровки

На графике калибровки отображается достоверность прогнозной модели. Это достигается путем отображения связи между прогнозируемой вероятностью и фактической вероятностью, где "вероятность" представляет вероятность того, что конкретный экземпляр принадлежит некоторой метке.

Для всех задач классификации вы можете просмотреть строку калибровки с макро-усреднением, микро-усреднением и для каждого класса в выбранной прогнозной модели.

Классическое **Среднее** вычисляет метрику независимо от каждого класса, а затем принимает среднее значение, одновременно рассматривая все классы. Однако в **микросредном** числе вклады всех классов для вычисления среднего значения. 

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?
Хорошо откалиброванная модель соответствует линии y = x, где она правильно прогнозирует вероятность того, что выборки относятся к каждому классу. Чрезмерно уверенная модель будет превышена до нуля, а другая — неопределенному классу каждого примера.

#### <a name="example-1-a-well-calibrated-model"></a>Пример 1. хорошо откалиброванная модель
![ более хорошо откалиброванная модель](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-calib-curve1.png)

#### <a name="example-2-an-over-confident-model"></a>Пример 2. модель чрезмерной уверенности
![Модель чрезмерной уверенности](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-calib-curve2.png)


<a name="regression"></a> 

## <a name="regression-performance-metrics"></a>Метрики производительности регрессии

В следующей таблице перечислены метрики производительности модели, которые автоматизированное средство ML вычисляет для каждой модели регрессии или прогнозирования, создаваемой для вашего эксперимента. 

|Метрика|Описание|Вычисление|Дополнительные параметры
--|--|--|--|
explained_variance|Объяснимая дисперсия — это доля, учитываемая математической моделью при вычислении дисперсии заданного набора данных. Это процент уменьшения дисперсии исходных данных по отношению к дисперсии ошибок. Если среднее значение ошибки равно 0, то оно равно коэффициенту определения (см. r2_score ниже).|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.explained_variance_score.html)|None|
r2_score;|R ^ 2 является коэффициентом определения или процентным уменьшением в квадратных ошибках по сравнению с базовой моделью, выводит среднее значение. |[Вычисление](https://scikit-learn.org/0.16/modules/generated/sklearn.metrics.r2_score.html)|None|
spearman_correlation;|Корреляция Спирмена — это непараметрическая мера монотонности связи между двумя наборами данных. В отличие от корреляции Пирсона, для корреляции Спирмена не предполагается, что оба набора данных используют нормальное распределение. Как и другие коэффициенты корреляции, этот коэффициент принимает значения от –1 до + 1. Значение 0 означает отсутствие корреляции. Значения корреляции –1 и + 1 означают точную монотонную связь. Положительные значения корреляции означают, что при увеличении значения x также увеличивается значение y. Отрицательные значения корреляции означают, что при увеличении значения x значение y уменьшается.|[Вычисление](https://docs.scipy.org/doc/scipy-0.16.1/reference/generated/scipy.stats.spearmanr.html)|None|
mean_absolute_error|Средняя абсолютная погрешность — это оценочная величина абсолютного значения отклонения между целевым и прогнозируемым значениями.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)|None|
normalized_mean_absolute_error;|Нормализованная средняя абсолютная погрешность равна средней абсолютной погрешности, деленной на диапазон данных.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)|Деление на диапазон данных|
median_absolute_error|Медиана абсолютной погрешности — это медиана всех абсолютных отклонений между целевым и прогнозируемым значениями. Такая потеря устойчива к выбросам.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html)|None|
normalized_median_absolute_error|Нормализованная медиана абсолютной погрешности равна медиане абсолютной погрешности, деленной на диапазон данных.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.median_absolute_error.html)|Деление на диапазон данных|
root_mean_squared_error|Среднеквадратическая погрешность — это среднеквадратическое значение ожидаемого квадратичного отклонения между целевым и прогнозируемыми значениями.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)|None|
normalized_root_mean_squared_error;|Нормализованная среднеквадратическая погрешность равна среднеквадратической погрешности, деленной на диапазон данных.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)|Деление на диапазон данных|
root_mean_squared_log_error|Среднеквадратическая логарифмическая погрешность — это среднеквадратическое значение ожидаемой квадратичной логарифмической погрешности.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html)|None|
normalized_root_mean_squared_log_error;|Нормализованная среднеквадратическая логарифмическая погрешность равна среднеквадратической логарифмической погрешности, деленной на диапазон данных.|[Вычисление](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html)|Деление на диапазон данных|

<a name="pvt"></a>

## <a name="predicted-vs-true-chart"></a>Диаграмма предсказанных и истинных диаграмм

В сравнении с прогнозом и true отображается отношение между прогнозируемым значением и соответствующим значением true для задачи регрессии. 

После каждого запуска для каждой модели регрессии отображается диаграмма прогнозируемых и истинных значений. Для обеспечения конфиденциальности данных значения группируются по ячейкам, размер каждой из которых отображается в виде линейчатой диаграммы в нижней части области диаграммы. Вы можете сравнить результаты прогнозной модели с более светлой областью, которая отображает идеальные значения, требуемые для этой модели, с учетом допусков.

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?
Этот граф можно использовать для измерения производительности модели, чем ближе к линии y = x прогнозируемые значения — чем выше производительность прогнозной модели.

#### <a name="example-1-a-regression-model-with-low-performance"></a>Пример 1. регрессионная модель с низкой производительностью
![Регрессионная модель с низкой точностью прогнозов](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-regression1.png)

#### <a name="example-2-a-regression-model-with-high-performance"></a>Пример 2. регрессионная модель с высокой производительностью
![Регрессионная модель с высокой точностью прогнозов](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-regression2.png)

<a name="histo"></a> 

## <a name="histogram-of-residuals-chart"></a>Гистограмма диаграммы остатков

Автоматический ML автоматически предоставляет диаграмму остатков для отображения распределения ошибок в прогнозах модели регрессии. Остаток — это разница между прогнозом и фактическим значением ( `y_pred - y_true` ). 

### <a name="what-does-a-good-model-look-like"></a>Как выглядит хорошая модель?
Чтобы отобразить поле ошибки с низким смещением, гистограмма остатков должна располагаться в виде колоколообразной кривой, в центре вокруг нуля.

#### <a name="example-1-a-regression-model-with-bias-in-its-errors"></a>Пример 1. модель регрессии с сдвигом в ошибках
![Модель регрессии SA с сдвигом в ошибках](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-regression3.png)

#### <a name="example-2-a-regression-model-with-a-more-even-distribution-of-errors"></a>Пример 2. регрессионная модель с более равномерным распределением ошибок
![Модель регрессии с более равномерным распределением ошибок](./media/how-to-understand-automated-ml/azure-machine-learning-auto-ml-regression4.png)

<a name="explain-model"></a>

## <a name="model-interpretability-and-feature-importance"></a>Интерпретируемость модели и важность функции
Автоматизированный ML предоставляет панель мониторинга для интерпретации машинного обучения для выполнения.

Дополнительные сведения о включении функций интерпретации см. [в разделе интерпретируемость — пояснения к модели в автоматизированном машинном обучении](how-to-machine-learning-interpretability-automl.md).

> [!NOTE]
> Модель Форекастткн в настоящее время не поддерживается клиентом пояснения. Эта модель не возвращает панель мониторинга с объяснением, если она возвращается в качестве лучшей модели и не поддерживает выполнение объяснения по требованию.

## <a name="next-steps"></a>Дальнейшие действия

+ Дополнительные сведения об [автоматизированном машинном обучении](concept-automated-ml.md) в Машинном обучении Azure.
+ Попробуйте пример автоматизированной учебной записной книжки с [описанием модели машинного обучения](https://github.com/Azure/MachineLearningNotebooks/tree/master/how-to-use-azureml/explain-model) .