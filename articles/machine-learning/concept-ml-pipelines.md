---
title: Что такое мл трубопроводы
titleSuffix: Azure Machine Learning
description: В этой статье узнайте о преимуществах конвейеров машинного обучения (ML), которые можно построить с помощью SDK Для Python. Конвейеры машинного обучения используются учеными по обработке данных для создания, оптимизации и управления рабочими процессами машинного обучения.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
ms.author: laobri
author: lobrien
ms.date: 04/01/2020
ms.openlocfilehash: 0cefa78b6f52cc67df8817f68a9b793ab86b2a7f
ms.sourcegitcommit: 2d7910337e66bbf4bd8ad47390c625f13551510b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/08/2020
ms.locfileid: "80878584"
---
# <a name="what-are-azure-machine-learning-pipelines"></a>Что такое конвейеры машинного обучения Azure?

Конвейеры машинного обучения Azure позволяют создавать рабочие процессы в проектах машинного обучения. Эти рабочие процессы имеют ряд преимуществ: 

+ Простота
+ Speed
+ Повторяемость
+ Гибкость
+ Версия и отслеживание
+ Модульность 
+ Контроль качества
+ Контроль затрат

Эти преимущества становятся значительными, как только ваш проект машинного обучения выходит за рамки чистого исследования и переходит к итерации. Даже простые одноступенчатые трубопроводы могут быть ценными. Проекты машинного обучения часто находятся в сложном состоянии, и это может быть облегчением, чтобы сделать точное выполнение одного рабочего процесса тривиальным процессом.

Узнайте, как [создать свой первый конвейер.](how-to-create-your-first-pipeline.md)

![Конвейеры машинного обучения в Azure Machine Learning](./media/concept-ml-pipelines/pipeline-flow.png)

<a name="compare"></a>
### <a name="which-azure-pipeline-technology-should-i-use"></a>Какую технологию конвейера Azure следует использовать?

Облако Azure предоставляет несколько других конвейеров, каждый из которых имеет различное назначение. В следующей таблице перечислены различные конвейеры и то, для чего они используются:

| Сценарий | Первичная персона | Предложение Azure | Предложение OSS | Каноническая труба | Преимущества | 
| -------- | --------------- | -------------- | ------------ | -------------- | --------- | 
| Оркестрирование моделей (машинное обучение) | специалист по анализу и обработке данных; | Конвейеры Машинного обучение Azure | Труба трубопроводы Кубепоток | Дата - > модель | Распределение, кэширование, код-первых, повторное использование | 
| Оркестровка данных (подготовитек данных) | Инженер данных | [Конвейеры Фабрики данных Azure](https://docs.microsoft.com/azure/data-factory/concepts-pipelines-activities) | Apache Airflow | Данные - > данные | Сильно набранодвижение. Деятельность, ориентированная на данные. |
| Оркестрация приложения & кода (CI/CD) | Разработчик приложений / Ops | [Трубопроводы Azure DevOps](https://azure.microsoft.com/services/devops/pipelines/) | Jenkins | Код - Модель - > App/Service | Наиболее открытая и гибкая поддержка деятельности, очереди утверждения, фазы с gating | 


## <a name="what-can-azure-ml-pipelines-do"></a>Что могут сделать провода Azure ML?

Конвейер машинного обучения Azure — это независимо выполняемый рабочий процесс полной задачи машинного обучения. Подзадачи инкапсулируются в последовательность шагов в конвейере. Конвейер машинного обучения Azure может быть таким же простым, как и вызов ы вызова скрипта Python, поэтому _может_ сделать что угодно. Трубопроводы _должны_ быть сосредоточены на задачах машинного обучения, таких как:

+ подготовка данных, включая импорт, проверку, очистку, изменение, преобразование, нормализацию и промежуточное хранение;
+ настройка обучения, включая параметризацию аргументов, путей, а также конфигураций ведения журналов и отчетности;
+ Обучение и проверка эффективно и неоднократно. Эффективность может быть получена за счет указания конкретных подмножеств данных, различных ресурсов аппаратных вычислений, распределенной обработки и мониторинга прогресса
+ развертывание, включая управление версиями, масштабирование, подготовку и управление доступом; 

Независимые шаги позволяют нескольким ученым в области данных работать на одном конвейере одновременно без чрезмерного налогообложения вычислительных ресурсов. Отдельные шаги также упрощают использование различных типов вычислений/размеров для каждого шага.

После создания конвейера часто нужно выполнить более тонкую настройку его цикла обучения. При повторном запуске запуск переходит к шагам, которые необходимо перезапустить, например обновленного сценария обучения. Шаги, которые не нужно перезапускать, пропущены. Тот же анализ применяется к неизменным скриптам, используемым для выполнения шага. Эта функция повторного использования помогает избежать выполнения дорогостоящих и трудоемких шагов, таких как проглатка данных и преобразование, если базовые данные не изменились.

С помощью Машинного обучения Azure вы можете использовать различные наборы инструментов и фреймворков, такие как PyTorch или TensorFlow, для каждого шага в конвейере. Azure координирует различные [вычислительные цели,](concept-azure-machine-learning-architecture.md) которые вы используете, так что ваши промежуточные данные могут быть переданы с целями вычислений ниже по течению.

Вы можете [отслеживать метрики для своих экспериментов конвейера](https://docs.microsoft.com/azure/machine-learning/how-to-track-experiments) непосредственно на портале Azure или [на целевой странице рабочего пространства (предварительный просмотр).](https://ml.azure.com) После публикации конвейера можно настроить конечную точку REST, которая позволяет повторно запустить конвейер с любой платформы или стека.

Короче говоря, все сложные задачи жизненного цикла машинного обучения могут быть помогли с конвейерами. Другие технологии конвейера Azure имеют свои сильные стороны. [Конвейеры Azure Data Factory](https://docs.microsoft.com/azure/data-factory/concepts-pipelines-activities) преуспевают в работе с данными, а [azure Pipelines](https://azure.microsoft.com/services/devops/pipelines/) является подходящим инструментом для непрерывной интеграции и развертывания. Но если основное внимание уделяется машинному обучению, конвейеры Azure Machine Learning, скорее всего, будут лучшим выбором для ваших потребностей в рабочем процессе. 

## <a name="what-are-azure-ml-pipelines"></a>Что такое провода Azure ML?

Конвейер Azure ML выполняет полный логический рабочий процесс с упорядоченной последовательностью шагов. Каждый шаг представляет собой дискретное действие обработки. Трубопроводы работают в контексте [эксперимента](https://docs.microsoft.com/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)по обучению машин Azure.

На ранних стадиях проекта ML хорошо иметь один блокнот Jupyter или скрипт Python, который выполняет всю работу рабочего пространства Azure и конфигурацию ресурсов, подготовку данных, конфигурацию запуска, обучение и проверку. Но так же, как функции и классы быстро становятся предпочтительнее одного императивного блока кода, рабочие процессы ML быстро становятся предпочтительнее монолитного ноутбука или скрипта. 

Модульизируя задачи ML, конвейеры поддерживают императив информатики о том, что компонент должен «делать (только одну вещь хорошо». Модульность, безусловно, имеет жизненно важное значение для успеха проекта при программировании в командах, но даже при работе в одиночку, даже небольшой проект ML включает в себя отдельные задачи, каждый с хорошим количеством сложности. Задачи включают в себя: конфигурацию рабочего пространства и доступ к данным, подготовку данных, определение модели и конфигурацию, а также развертывание. В то время как выходы одной или нескольких задач формируют входы в другую, точные детали реализации какой-либо одной задачи, в лучшем случае, не имеют значения, отвлекаясь в следующем. В худшем случае вычислительное состояние одной задачи может привести к ошибке в другой. 

### <a name="analyzing-dependencies"></a>Анализ зависимостей

Многие экосистемы программирования имеют инструменты, которые организовывают зависимости ресурсов, библиотеки или компиляции. Как правило, эти инструменты используют временные метки файлов для расчета зависимостей. При изменении файла обновляется (загружен, перекомпилирован или упакован файл) только он и его иждивенцев. Конвейеры Azure ML значительно расширяют эту концепцию. Как и традиционные инструменты сборки, конвейеры вычисляют зависимости между шагами и выполняют только необходимые перерасчеты. 

Однако анализ зависимостей в проводах Azure ML является более сложным, чем простые метки времени. Каждый шаг может работать в другой аппаратной и программной среде. Подготовка данных может быть трудоемким процессом, но не требуется работать на оборудовании с мощными графическими процессорами, некоторые шаги могут потребовать ОС-специфического программного обеспечения, вы можете использовать распределенное обучение, и так далее. Хотя экономия средств для оптимизации ресурсов может быть значительной, может быть подавляющим, чтобы вручную жонглировать всеми различными вариациями аппаратных и программных ресурсов. Это еще труднее сделать все, что, даже не делая ошибку в данных, которые вы передаете между шагами. 

Трубопроводы решают эту проблему. Azure Machine Learning автоматически организует все зависимости между этапами конвейера. Эта оркестровка может включать в себя спиннинг вверх и вниз Докер изображения, присоединение и отсоединение вычислительных ресурсов, и перемещение данных между шагами в последовательной и автоматической основе.

### <a name="reusing-results"></a>Результаты повторного использования

Кроме того, выход шага может, если вы выберете, быть повторно использован. Если вы указали повторное использование как возможность и нет зависимых вышеуказанных зависимостей, запускающих перерасчет, служба конвейера будет использовать кэшированную версию результатов шага. Такое повторное использование может значительно сократить время разработки. Если у вас есть сложная задача подготовки данных, вы, вероятно, перезапустить его чаще, чем это строго необходимо. Трубопроводы избавят вас от этого беспокойства: в случае необходимости шаг будет работать, если нет, то не будет.

Весь этот анализ зависимости, оркестровка и активация обрабатываются Azure Machine Learning, когда вы `Experiment`мгновенно выполняете объект [Pipeline,](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline(class)?view=azure-ml-py) передаете его на вызов и вызываете. `submit()` 

### <a name="coordinating-the-steps-involved"></a>Координация соответствующих шагов

При создании и `Pipeline` запуске объекта возникают следующие шаги высокого уровня:

+ Для каждого шага служба рассчитывает требования к:
    + Ресурсы аппаратных вычислений
    + Ресурсы ОС (изображение Докера(ы))
    + Программные ресурсы (Conda / virtualenv зависимости)
    + Вводданные данные 
+ Служба определяет зависимости между шагами, в результате чего динамический график выполнения
+ При запуске каждого узла в графике выполнения:
    + Служба настраивает необходимую аппаратно-программную среду (возможно, повторное использование существующих ресурсов)
    + Шаг выполняется, предоставляя информацию `Experiment` о регистрации и мониторинге содержащегося в его объекте
    + Когда шаг завершается, его выходы готовятся в качестве входов на следующий шаг и/или записываются в хранилище
    + Ресурсы, которые больше не нужны, дорабатываются и отсоединяются

![Шаги трубопровода](./media/concept-ml-pipelines/run_an_experiment_as_a_pipeline.png)

## <a name="building-pipelines-with-the-python-sdk"></a>Строительство трубопроводов с помощью Python SDK

В [SDK Azure Machine Learning Python](https://docs.microsoft.com/python/api/overview/azure/ml/install?view=azure-ml-py)конвейер — это `azureml.pipeline.core` объект Python, определенный в модуле. Объект [Pipeline](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline%28class%29?view=azure-ml-py) содержит упорядоченную последовательность одного или нескольких объектов [PipelineStep.](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.builder.pipelinestep?view=azure-ml-py) Класс `PipelineStep` является абстрактным и фактические шаги будут подклассов, таких как [EstimatorStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimatorstep?view=azure-ml-py), [PythonScriptStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.pythonscriptstep?view=azure-ml-py), или [DataTransferStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.datatransferstep?view=azure-ml-py). Класс [ModuleStep](https://docs.microsoft.com/python/api/azureml-pipeline-steps/azureml.pipeline.steps.modulestep?view=azure-ml-py) содержит многоразовую последовательность шагов, которые могут быть общими между конвейерами. Пробег `Pipeline` как часть `Experiment`.

Конвейер Azure ML связан с рабочим пространством Azure Machine Learning, а шаг конвейера связан с вычислительной целью, доступной в этом рабочем пространстве. Для получения дополнительной информации смотрите [создание и управление рабочими областями машинного обучения Azure на портале Azure](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace) или [Каковы вычислительные цели в Azure Machine Learning?.](https://docs.microsoft.com/azure/machine-learning/concept-compute-target)

В Azure Machine Learning цель вычислений — это среда, в которой происходит фаза ML. Средой программного обеспечения могут быть удаленный VM, Azure Machine Learning Compute, Azure Databricks, Azure Batch и так далее. Аппаратная среда также может сильно варьироваться в зависимости от поддержки графического процессора, памяти, хранения и т.д. Вы можете указать цель вычислений для каждого шага, которая дает вам мелкозернистый контроль над затратами. Вы можете использовать более или менее мощные ресурсы для конкретных действий, объема данных и потребностей в производительности проекта. 

## <a name="building-pipelines-with-the-designer"></a>Строительство трубопроводов с конструктором

Разработчики, предпочитающие поверхность визуального дизайна, могут использовать конструктор Azure Machine Learning для создания конвейеров. Вы можете получить доступ к этому инструменту из выбора **конструктора** на главной странице рабочего пространства.  Дизайнер позволяет перетаскивать и опускать шаги на поверхность дизайна. Для быстрого развития можно использовать существующие модули по всему спектру задач ML; существующие модули охватывают все: от преобразования данных до выбора алгоритмов и обучения и развертывания. Или можно создать полностью пользовательский конвейер, объединив собственные шаги, определенные в сценариях Python.

При визуальном проектировании конвейеров вводы и выходы шага отображаются наглядно. Можно перетаскить и уронить соединения данных, что позволит быстро понять и изменить поток данных конвейера.
 
![Пример конструктора Машинного обучения Azure](./media/concept-designer/designer-drag-and-drop.gif)

### <a name="understanding-the-execution-graph"></a>Понимание графика выполнения

Шаги в конвейере могут иметь зависимость от других шагов. Служба конвейеров Azure ML выполняет работу по анализу и организации этих зависимостей. Узлы в полученном "графике выполнения" являются этапами обработки. Каждый шаг может включать создание или повторное использование определенной комбинации аппаратного и программного обеспечения, повторное использование кэшированных результатов и так далее. Оркестровка и оптимизация этого графика выполнения может значительно ускорить фазу ML и сократить затраты. 

Поскольку шаги запускаются независимо, объекты для хранения входных и выходных данных, которые текут между шагами, должны быть определены извне. Это роль [DataSet](https://docs.microsoft.com/python/api/azureml-core/azureml.data.data_reference.datareference?view=azure-ml-py)и [PipelineData](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.pipelinedata?view=azure-ml-py), объектов. Эти объекты данных связаны с объектом [Datastore,](https://docs.microsoft.com/python/api/azureml-core/azureml.core.datastore%28class%29?view=azure-ml-py) который инкапсулирует их конфигурацию хранения. Базовый `PipelineStep` класс всегда создается со строкой, `name` списком `outputs` `inputs`и списком . Как правило, он также `arguments` имеет список и `resource_inputs`часто он будет иметь список . Подклассы, как правило, также имеют `PythonScriptStep` дополнительные аргументы (например, требуется имя файла и путь запуска скрипта). 

График выполнения является ацикличным, но конвейеры могут работать по постоянному графику и могут запускать скрипты Python, которые могут записывать информацию о состоянии в файловую систему, что позволяет создавать сложные профили. При проектировании конвейера так, чтобы определенные шаги запускали параллельно или асинхронно, Azure Machine Learning прозрачно обрабатывает анализ зависимости и координацию фан-аутов и фан-ви. Как правило, вам не нужно беспокоиться о деталях графика выполнения, но он доступен через атрибут [Pipeline.graph.](https://docs.microsoft.com/python/api/azureml-pipeline-core/azureml.pipeline.core.pipeline.pipeline?view=azure-ml-py#attributes) 


### <a name="a-simple-python-pipeline"></a>Простой питон трубопровода

На этом фрагменте показаны объекты и вызовы, необходимые для создания и запуска базового: `Pipeline`

```python
ws = Workspace.from_config() 
blob_store = Datastore(ws, "workspaceblobstore")
compute_target = ws.compute_targets["STANDARD_NC6"]
experiment = Experiment(ws, 'MyExperiment') 

input_data = Dataset.File.from_files(
    DataPath(datastore, '20newsgroups/20news.pkl'))

output_data = PipelineData("output_data", datastore=blob_store)

input_named = input_data.as_named_input('input')

steps = [ PythonScriptStep(
    script_name="train.py",
    arguments=["--input", input_named.as_download(), "--output", output_data],
    inputs=[input_data],
    outputs=[output_data],
    compute_target=compute_target,
    source_directory="myfolder"
) ]

pipeline = Pipeline(workspace=ws, steps=steps)

pipeline_run = experiment.submit(pipeline)
pipeline_run.wait_for_completion()
```

Фрагмент начинается с общих объектов машинного `Datastore`обучения Azure, a `Experiment` `Workspace`, , [ComputeTarget](https://docs.microsoft.com/python/api/azureml-core/azureml.core.computetarget?view=azure-ml-py)и . Затем код создает объекты `input_data` для `output_data`удержания и . Массив `steps` содержит один элемент, `PythonScriptStep` который будет использовать объекты `compute_target`данных и работать на . Затем код мгновенно мгновьясь за сам `Pipeline` объект, проходя в рабочем пространстве и массиве шагов. Вызов для `experiment.submit(pipeline)` запуска конвейера Azure ML. Вызов `wait_for_completion()` блоков до завершения конвейера. 

Чтобы узнать больше о подключении конвейера к данным, смотрите [статьи доступ к данным в Azure Machine Learning](concept-data.md) и [Перемещение данных в и между этапами конвейера ML (Python)](how-to-move-data-in-out-of-pipelines.md). 

## <a name="best-practices-when-using-pipelines"></a>Рекомендации при использовании трубопроводов

Как вы можете видеть, создание конвейера Azure ML немного сложнее, чем запуск скрипта. Трубопроводы требуют настройки и создания нескольких объектов Python. 

Некоторые ситуации, которые предлагают использовать конвейер:

* В командной среде: разделите задачи ML на несколько независимых шагов, чтобы разработчики могли работать и развивать свои программы самостоятельно. 

* При развертывании или вблизи: пригоняйте конфигурацию и используйте запланированные и управляемые событиями операции, чтобы оставаться на вершине изменяющихся данных.

* На ранних стадиях проекта ML или работы в одиночку: используйте трубопроводы для автоматизации сборки. Если вы начали беспокоиться о воссоздании конфигурации и вычислительного состояния перед реализацией новой идеи, это сигнал, который можно использовать для автоматизации рабочего процесса. 

Легко с энтузиазмом относиться к повторному использованию кэшированных результатов, мелкозернистый контроль над затратами на вычисления и изоляцию процессов, но трубопроводы имеют затраты. Некоторые антишаблоны включают в себя:

* Использование трубопроводов в качестве единственного средства для разделения проблем. Встроенные функции, объекты и модули Python в далеком смысле могут избежать запутанного программного состояния! Шаг конвейера намного дороже, чем вызов функции.

* Тяжелое соединение между шагами конвейера. Если рефакторинг зависимого шага часто требует изменения выходных данных предыдущего шага, вполне вероятно, что отдельные шаги в настоящее время являются большей стоимостью, чем выгодой. Еще одна подсказка о том, что шаги слишком связаны, это аргументы к шагу, который не является данными, а флагами для управления обработкой. 

* Преждевременная оптимизация вычислительных ресурсов. Например, часто существует несколько этапов подготовки данных, и часто можно увидеть: `MpiStep` "О, вот место, где я мог `PythonScriptStep` бы использовать для параллельного программирования, но вот место, где я мог бы использовать с менее мощной вычислительной мишенью", и так далее. И, возможно, в долгосрочной перспективе создание таких мелкозернистых шагов может оказаться целесообразным, особенно если есть возможность использовать кэшированные результаты, а не всегда пересчитывать. Но трубопроводы не предназначены для замены `multiprocessing` родного модуля Python. 

До тех пор, пока проект не получит большое или близкое развертывание, ваши конвейеры должны быть грубыми, а не мелкозернистыми. Если вы считаете свой проект ML вовлечением _этапов_ и конвейера как обеспечивающий полный рабочий процесс для перемещения вас через определенный этап, вы находитесь на правильном пути. 

## <a name="key-advantages"></a>Ключевые преимущества

Ключевыми преимуществами использования конвейеров для рабочих процессов машинного обучения являются:

|Ключевое преимущество|Описание|
|:-------:|-----------|
|**Автоматические&nbsp;выполнения**|Расписание шагов для параллельного или последовательного выполнения в надежной и без присмотра образом. Подготовка и моделирование данных могут длиться несколько дней или недель, а конвейеры позволяют сосредоточиться на других задачах во время выполнения процесса. |
|**Гетерогенивые вычисления**|Используйте несколько конвейеров, которые надежно координируются между неоднородными и масштабируемыми вычислительными ресурсами и местами хранения. Эффективно использовать доступные вычислительные ресурсы, запуская отдельные этапы конвейера на различных вычислительных объектах, таких как HDInsight, GPU Data Science VMs и Databricks.|
|**Повторное использование**|Создавайте шаблоны конвейера для определенных сценариев, таких как переподготовка и пакетный подсчет. Trigger опубликовал конвейеры из внешних систем с помощью простых вызовов REST.|
|**Отслеживание и управление версиями**|Вместо отслеживания данных и папок результатов вручную при выполнении итераций используйте пакет SDK для конвейеров, чтобы присваивать имена и определять версии источников данных, входных и выходных данных. Вы можете также отдельно управлять сценариями и данными для повышения эффективности.|
| **Модульность** | Разделение областей проблем и изолирующие изменения позволяет программному обеспечению развиваться более быстрыми темпами с более высоким качеством. | 
|**Совместная работа**|Трубопроводы позволяют ученым по обработке данных сотрудничать во всех областях процесса проектирования машинного обучения, одновременно работая над этапами конвейера.|

### <a name="choosing-the-proper-pipelinestep-subclass"></a>Выбор правильного подкласса PipelineStep

Является `PythonScriptStep` наиболее гибким подклассом абстрактных `PipelineStep`. Другие подклассы, такие как `EstimatorStep` подклассы, могут `DataTransferStep` выполнять определенные задачи с меньшим количеством кода. Например, `EstimatorStep` можно создать, просто перейдя в имя `Estimator`для шага, и вычислительной цели. Или можно переопределить входы и выходы, параметры конвейера и аргументы. Для получения дополнительной информации [см. модели поездов с помощью машинного обучения Azure с помощью оценщика](how-to-train-ml-models.md). 

Это `DataTransferStep` упрощает перемещение данных между источниками данных и поглотителями. Код для ручной передачи прост, но повторяющийся. Вместо этого можно просто `DataTransferStep` создать имя, ссылки на источник данных и раковину данных, а также цель вычислений. Ноутбук [Azure Machine Learning Pipeline с DataTransferStep](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-data-transfer.ipynb) демонстрирует эту гибкость.

## <a name="modules"></a>Модули

Хотя шаги конвейера позволяют повторно использовать результаты предыдущего запуска, во многих случаях построение шага предполагает, что требуемые скрипты и зависимые файлы должны быть локально доступны. Если специалист по обработке данных хочет опираться на существующий код, скрипты и зависимости часто должны быть клонированы из отдельного репозитория.

Модули по своему использованию аналогичны шагам конвейера, но обеспечивают версию, облегчаемую через рабочее пространство, что позволяет совместноиспользовать и многоразовую работу в масштабе. Модули предназначены для повторного использования в нескольких конвейерах и могут эволюционировать, чтобы адаптировать конкретные вычисления к различным случаям использования. Пользователи могут выполнять следующие задачи в рабочей области, не используя внешние репозитории:

* Создание новых модулей и публикация новых версий существующих модулей
* Осквернение существующих версий
* Отметьте версии, чтобы предотвратить использование потребителями этой версии
* Назначить версии по умолчанию
* Извлечение модулей по версиям из рабочего пространства, чтобы убедиться, что команды используют один и тот же код

Ознакомьтесь с [записным блокнотом](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-how-to-use-modulestep.ipynb) для примеров кода о том, как создавать, подключать и использовать модули в конвейерах Машинного обучения Azure.

## <a name="next-steps"></a>Дальнейшие действия

Конвейеры Azure ML являются мощным объектом, который начинает приравливать к созданию на ранних стадиях разработки. Значение увеличивается по мере роста команды и проекта. В этой статье объясняется, как конвейеры определяются с помощью SDK Azure Machine Learning Python и организованы на Azure. Вы видели некоторые основные исходные коды и `PipelineStep` были введены в несколько классов, которые доступны. Вы должны иметь представление о том, когда использовать провода Azure ML и как Azure управляет ими. 


+ Узнайте, как [создать свой первый конвейер.](how-to-create-your-first-pipeline.md)

+ Узнайте, как [запускать прогнозы пакетов на больших данных.](tutorial-pipeline-batch-scoring-classification.md )

+ Ознакомьтесь с справочниками SDK для [ступеней ядра и](https://docs.microsoft.com/python/api/azureml-pipeline-core/?view=azure-ml-py) [трубопровода.](https://docs.microsoft.com/python/api/azureml-pipeline-steps/?view=azure-ml-py)

+ Попробуйте пример ноутбуков Jupyter, демонстрирующих [конвейеры машинного обучения Azure.](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/machine-learning-pipelines) Узнайте, как [запускать ноутбуки, чтобы исследовать эту службу.](samples-notebooks.md)
