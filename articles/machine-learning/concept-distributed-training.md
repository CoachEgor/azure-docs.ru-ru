---
title: Что такое распределенное обучение?
titleSuffix: Azure Machine Learning
description: Узнайте о распределенном обучении и о том, как Azure Machine Learning поддерживает его.
services: machine-learning
ms.service: machine-learning
author: nibaccam
ms.author: nibaccam
ms.subservice: core
ms.topic: conceptual
ms.date: 03/27/2020
ms.openlocfilehash: a0d5bf795e4759a105b9a235770f37aa10bd6751
ms.sourcegitcommit: e040ab443f10e975954d41def759b1e9d96cdade
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/29/2020
ms.locfileid: "80385549"
---
# <a name="distributed-training-with-azure-machine-learning"></a>Распределенное обучение с помощью машинного обучения Azure

В этой статье вы узнаете о распределенном обучении и о том, как Azure Machine Learning поддерживает его для моделей глубокого обучения. 

При распределенной подготовке рабочая нагрузка для обучения модели делится и распределяется между несколькими мини-процессорами, называемыми рабочими узлами. Эти рабочие узлы работают параллельно с ускорением обучения модели. Распределенное обучение может быть использовано для традиционных моделей ML, но лучше подходит для вычислений и трудоемких задач, таких как [глубокое обучение](concept-deep-learning-vs-machine-learning.md) для обучения глубоким нейронным сетям.

## <a name="deep-learning-and-distributed-training"></a>Глубокое обучение и распределенное обучение 

Существует два основных типа распределенного обучения: [параллелизм данных](#data-parallelism) и [модельный параллелизм.](#model-parallelism) Для распределенного обучения по моделям глубокого [обучения, Azure Machine Learning SDK в Python](https://docs.microsoft.com/python/api/overview/azure/ml/intro?view=azure-ml-py) поддерживает интеграцию с популярными платформами, PyTorch и TensorFlow. Обе платформы используют параллелизм данных для распределенного обучения и могут использовать [horovod](https://horovod.readthedocs.io/en/latest/summary_include.html) для оптимизации вычислительных скоростей. 

* [Распределенное обучение с PyTorch](how-to-train-pytorch.md#distributed-training)

* [Распределенное обучение с Помощью TensorFlow](how-to-train-tensorflow.md#distributed-training)

Для моделей ML, которые не требуют распределенного обучения, см. [модели поездов с Azure Machine Learning](concept-train-machine-learning-model.md#python-sdk) для различных способов обучения моделей с использованием Python SDK.

## <a name="data-parallelism"></a>Параллелизм данных

Параллелизм данных является самым простым в реализации двух распределенных подходов к обучению и достаточен для большинства случаев использования.

При этом подходе данные делятся на разделы, где количество разделов равно общему количеству доступных узлов в вычислительном кластере. Модель копируется в каждом из этих рабочих узлов, и каждый работник работает на своем подмножестве данных. Имейте в виду, что каждый узло должно иметь возможность поддерживать модель, которая проходит обучение, то есть модель должна полностью вписаться в каждый узлы.

Каждый узла независимо вычисляет ошибки между его прогнозами для своих учебных образцов и помеченными выходами. В свою очередь, каждый узлы обновляет свою модель на основе ошибок и должны сообщать все свои изменения другим узлам для обновления соответствующих моделей. Это означает, что узлы рабочего донаработчика должны синхронизировать параметры модели или градиенты в конце пакетных вычислений, чтобы гарантировать, что они обучают последовательную модель. 

## <a name="model-parallelism"></a>Модель параллелизма

В модели параллелизм, также известный как сетевой параллелизм, модель сегментируется на различные части, которые могут работать одновременно в разных узлах, и каждая из них будет работать на одних и тех же данных. Масштабируемость этого метода зависит от степени параллельной задачи алгоритма, и его сложнее реализовать, чем параллелизм данных. 

В параллели модели рабочие узлы должны только синхронизировать общие параметры, обычно один раз для каждого шага вперед или обратного распространения. Кроме того, более крупные модели не являются проблемой, так как каждый узла работает на подразделе модели на тех же обучаемых данных.

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как [настроить учебные среды](how-to-set-up-training-targets.md) с помощью Python SDK.
* В техническом примере см. [сценарий эталонной архитектуры.](https://docs.microsoft.com/azure/architecture/reference-architectures/ai/training-deep-learning)
* [Поезд ML модели с TensorFlow](how-to-train-tensorflow.md).
* [Поезд ML модели с PyTorch](how-to-train-pytorch.md). 