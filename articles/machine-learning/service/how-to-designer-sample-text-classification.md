---
title: Анализ&#58; классификации книги в конструкторе
titleSuffix: Azure Machine Learning
description: Создание модели машинного обучения классификация проверок книг в различные категории.
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: conceptual
author: xiaoharper
ms.author: zhanxia
ms.reviewer: peterlu
ms.date: 11/04/2019
ms.openlocfilehash: 949ddc847a6011d460f2a3685008d12e64868767
ms.sourcegitcommit: 359930a9387dd3d15d39abd97ad2b8cb69b8c18b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/06/2019
ms.locfileid: "73647123"
---
# <a name="sample-7---text-classification-predict-company-category"></a>Пример 7. Классификация текста: прогнозирование категории компании 

В этом примере показано, как использовать модули текстовой аналитики для создания конвейера классификации текста в Машинное обучение Azure конструктора (Предварительная версия).

Цель классификации текста состоит в том, чтобы назначить некоторый фрагмент текста одному или нескольким предопределенным классам или категориям. Фрагментом текста может быть документ, статья новостей, поисковый запрос, электронная почта, твит, запросы в службу поддержки, Отзывы пользователей, проверка продукта и т. д. Приложения классификации текста включают в себя категоризацию газетных статей и новостей по каналам, упорядочение веб-страниц в иерархические категории, фильтрацию нежелательной почты, анализ тональностиности, прогнозирование намерений пользователя из поисковых запросов, маршрутизация билеты на поддержку и анализ отзывов клиентов. 

Этот конвейер обучает **классификатор логистической регрессии с многоклассовой классификацией** для прогнозирования категории компании с набором данных википедии SP 500, производным от Википедии.  

Фундаментальные этапы обучения модели машинного обучения с текстовыми данными:

1. Получение данных

1. Предварительная обработка текстовых данных

1. Проектирование признаков

   Преобразование текста в числовую функцию с помощью модуля извлечения компонентов, например, хэширования признаков, извлечение функции n-грамм из текстовых данных.

1. Обучение модели

1. Набор данных оценки

1. Анализ модели

Вот окончательный завершенный граф конвейера, над которым мы будем работать. Мы предоставим основание для всех модулей, чтобы вы могли принимать аналогичные решения самостоятельно.

[![граф конвейера](./media/how-to-ui-sample-text-classification/nlp-modules-overall.png)](./media/how-to-ui-sample-text-classification/nlp-modules-overall.png#lightbox)

## <a name="data"></a>Данные

В этом конвейере мы используем набор данных **Википедии SP 500** . Набор данных является производным от Википедии (https://www.wikipedia.org/) на основе статей каждой компании S & P 500. Перед отправкой в конструктор Машинное обучение Azure, набор данных был обработан следующим образом:

- Был извлечен текст по каждой конкретной компании
- Удалено форматирование Википедии
- Удалены символы, не являющиеся буквами или цифрами
- Весь текст преобразован в нижний регистр
- Были добавлены известные категории компаний

Не удалось найти статьи для некоторых компаний, поэтому число записей меньше 500.

## <a name="pre-process-the-text-data"></a>Предварительная обработка текстовых данных

Мы используем модуль **предварительной обработки текста** для предварительной обработки текстовых данных, включая определение предложений, маркировку предложений и т. д. Вы нашли все поддерживаемые параметры в статье [**Предварительная обработка текста**](../algorithm-module-reference/preprocess-text.md) . После предварительной обработки да данных мы используем модуль **Split Data (разделение данных** ), чтобы случайным образом разделить входные данные таким образом, чтобы набор данных для обучения содержал 50% исходных данных, а проверочный набор данных содержит 50% от исходных.

## <a name="feature-engineering"></a>Проектирование признаков
В этом примере мы будем использовать два метода, выполняющих проектирование характеристик.

### <a name="feature-hashing"></a>Хэширование признаков
Мы использовали модуль [**хэширования функций**](../algorithm-module-reference/feature-hashing.md) для преобразования обычного текста статей в целые числа и использовали целочисленные значения в качестве входных функций для модели. 

Модуль **хэширования функций** можно использовать для преобразования текстовых документов переменной длины в векторы числовых признаков одинаковой длины с использованием 32-разрядного метода хэширования мурмурхаш v3, предоставляемого библиотекой Wabbit Vowpal. Цель использования хэширования признаков — уменьшение размерности; Кроме того, хэширование признаков делает поиск весовых коэффициентов функций быстрее во время классификации, так как использует сравнение хэш-значений вместо сравнения строк.

В примере конвейера мы устанавливаем число битов хэширования равным 14 и устанавливаем число n-грамм равным 2. С помощью этих параметров хэш-таблица может содержать 2 ^ 14 записей, в которых каждая функция хэширования представляет одну или несколько функций n-грамм, а ее значение — частоту вхождений этого n-грамм в экземпляре текста. Для многих проблем хэш-таблица этого размера больше, чем достаточно, но в некоторых случаях может потребоваться дополнительное пространство, чтобы избежать конфликтов. Оцените производительность решения машинного обучения, используя разное количество битов. 

### <a name="extract-n-gram-feature-from-text"></a>Извлечение функции N-грамм из текста

N-грамма — это непрерывная последовательность из n терминов из заданной последовательности текста. N-грамма размера 1 называется униграм; n-грамма размера 2 — это биграм; n-грамма размера 3 — это триграмм. N-граммы большего размера иногда называются значением n, например, "четыре-граммами", "пять-граммами" и т. д.

Мы использовали [**функцию извлечения N-грамм из текстового**](../algorithm-module-reference/extract-n-gram-features-from-text.md)модуля в качестве другого решения для проектирования характеристик. Этот модуль сначала извлекает набор n-датаграмм, в дополнение к n-датаграммам, число документов, в которых каждый n-грамм отображается в тексте, подсчитывается (DF). В этом примере для вычисления значений компонентов используется метрика TF-IDF. Затем он преобразует неструктурированные текстовые данные в векторы числовых признаков одинаковой длины, где каждая функция представляет TF-IDF n-грамм в экземпляре Text.

После преобразования текстовых данных в векторы числовых характеристик для удаления текстовых данных из набора данных используется модуль **выбора столбца** . 

## <a name="train-the-model"></a>Обучение модели

Выбор алгоритма часто зависит от требований варианта использования. Поскольку целью этого конвейера является прогнозирование категории компании, хорошим выбором является модель классификатора с несколькими классами. Учитывая, что количество функций велико и эти функции являются разреженными, мы используем **многоклассовую модель логистической регрессии** для этого конвейера.

## <a name="test-evaluate-and-compare"></a>Тестирование, оценка и сравнение

 Мы разбиваем набор данных и используем различные наборы данных для обучения и тестирования модели, чтобы сделать оценку модели более целевой.

После обучения модели мы будем использовать **модель оценки** и **вычислить модули модели** для создания прогнозируемых результатов и оценки моделей. Тем не менее, прежде чем использовать модуль **оценки модели** , необходимо выполнить проектирование характеристик, как это было сделано во время обучения. 

Для модуля **хэширования** признаков очень просто выполнить инженера по оценке потока в качестве потока обучения. Используйте модуль **хэширования компонентов** непосредственно для обработки входных текстовых данных.

Чтобы **извлечь N-граммную функцию из текстового** модуля, мы будем подключать **выходные данные результирующего словаря** из обучающего потока **данных к входному словарю** в потоке вычислений и присвоить параметру **режима словаря** значение **ReadOnly.** .
[![график с показателями n-грамм](./media/how-to-ui-sample-text-classification/n-gram.png)](./media/how-to-ui-sample-text-classification/n-gram.png)

После завершения этапа проектирования **модель оценки** можно использовать для создания прогнозов для тестового набора данных с помощью обученной модели. Чтобы проверить результат, выберите порт вывода **модели оценки** и нажмите кнопку **визуализировать**.

Затем мы передаем оценки модулю **Evaluate Model** для создания метрик оценки. Функция " **оценить модель** " имеет два входных порта, поэтому мы можем вычислить и сравнить оцененные наборы данных, созданные с помощью различных методов. В этом примере сравнивается производительность результата, созданного с помощью метода хэширования компонентов и метода n-грамм.
Чтобы проверить результат, выберите порт вывода для **модели вычисления** и щелкните **визуализировать**.

## <a name="clean-up-resources"></a>Очистка ресурсов

[!INCLUDE [aml-ui-cleanup](../../../includes/aml-ui-cleanup.md)]

## <a name="next-steps"></a>Дальнейшие действия

Изучите другие примеры, доступные для конструктора:
- [Пример 1. регрессия: прогнозирование цены автомобиля](how-to-designer-sample-regression-automobile-price-basic.md)
- [Пример 2. регрессия. алгоритмы сравнения для прогнозирования цен автомобилей](how-to-designer-sample-regression-automobile-price-compare-algorithms.md)
- [Пример 3. Классификация с выбором компонентов: прогноз дохода](how-to-designer-sample-classification-predict-income.md)
- [Пример 4. Классификация: прогнозируемый кредитный риск (с учетом стоимости)](how-to-designer-sample-classification-credit-risk-cost-sensitive.md)
- [Пример 5. Классификация: обработка прогнозов](how-to-designer-sample-classification-churn.md)
- [Пример 6. Классификация: прогнозы задержек полета](how-to-designer-sample-classification-flight-delay.md)
