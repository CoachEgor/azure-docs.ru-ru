---
title: Создание пакетов ELT вместо ETL для хранилища данных SQL в Azure | Документация Майкрософт
description: Для загрузки данных в хранилище данных SQL Azure вместо пакетов ETL создавайте процессы извлечения, загрузки и преобразования данных (ELT).
services: sql-data-warehouse
author: kevinvngo
manager: craigg
ms.service: sql-data-warehouse
ms.topic: conceptual
ms.subservice: load data
ms.date: 05/10/2019
ms.author: kevin
ms.reviewer: igorstan
ms.openlocfilehash: 076a9c2cee5a976d1424a6c101822e374c20e83b
ms.sourcegitcommit: 16cb78a0766f9b3efbaf12426519ddab2774b815
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/17/2019
ms.locfileid: "65850551"
---
# <a name="designing-a-polybase-data-loading-strategy-for-azure-sql-data-warehouse"></a>Проектирование стратегии загрузки данных PolyBase для Хранилища данных SQL Azure

Традиционные хранилища данных SMP используют процесс извлечения, преобразования и загрузки (ETL) для загрузки данных. Хранилище данных SQL Azure — это архитектура массовой параллельной обработки (MPP), принимающая преимущество масштабируемости и гибкости ресурсов вычислений и хранения. Применяя процесс извлечения, загрузки и преобразования (ELT), можно воспользоваться преимуществами MPP и исключить ресурсы, необходимые для преобразования данных перед загрузкой. Хотя Хранилище данных SQL поддерживает множество методов загрузки, включая отличные от Polybase варианты, такие как BCP и SQL BulkCopy API, загрузка через PolyBase является самым быстрым и масштабируемым способом загрузки даты.  PolyBase — это технология, которая обращается к внешним данным, хранящимся в хранилище BLOB-объектов Azure или Azure Data Lake Storage, с помощью языка T-SQL.

> [!VIDEO https://www.youtube.com/embed/l9-wP7OdhDk]


## <a name="what-is-elt"></a>Что такое ELT?

Извлечение, загрузка и преобразование (ELT) — это процесс, с помощью которого данные извлекаются из исходной системы, загружаются в хранилище данных, а затем преобразовываются. 

Ниже приведены основные шаги по реализации процесса ELT PolyBase для Хранилища данных SQL:

1. Извлеките исходные данные в текстовые файлы.
2. Поместите данные в хранилище BLOB-объектов Azure или Azure Data Lake Store.
3. Подготовьте данные для загрузки.
4. Загрузите данные в промежуточные таблицы Хранилища данных SQL с помощью PolyBase. 
5. Преобразуйте данные.
6. Вставьте данные в рабочие таблицы.


Инструкции по загрузке см. в руководстве [Загрузка данных из хранилища BLOB-объектов Azure в хранилище данных SQL Azure с помощью PolyBase](load-data-from-azure-blob-storage-using-polybase.md).

Дополнительные сведения см. в записи блога о [стратегиях и шаблонах загрузки в хранилище данных SQL Azure](https://blogs.msdn.microsoft.com/sqlcat/20../../azure-sql-data-warehouse-loading-patterns-and-strategies/). 


## <a name="1-extract-the-source-data-into-text-files"></a>1. Извлечение исходных данных в текстовые файлы

Получение данных за пределами исходной системы зависит от расположения хранилища.  Основной целью является перемещение данных в текстовые файлы с разделителями, поддерживаемыми PolyBase. 

### <a name="polybase-external-file-formats"></a>Форматы внешних файлов PolyBase

PolyBase загружает данные из текстовых файлов с разделителями в кодировке UTF-8 и UTF-16. Кроме текстовых файлов с разделителями данные также загружаются из форматов файлов Hadoop: RC, ORC и PARQUET. PolyBase также может загрузить данные из сжатых файлов Gzip и Snappy. PolyBase в настоящее время не поддерживает расширенную кодировку ASCII, форматы с фиксированной шириной и вложенные форматы, такие как WinZip, JSON и XML. Если вы выполняете экспорт из SQL Server, можно воспользоваться [программой командной строки bcp](/sql/tools/bcp-utility) для экспорта данных в текстовые файлы с разделителями. Parquet с сопоставлением типов данных в хранилище данных SQL выглядит следующим образом:

| **Тип данных parquet** |                      **Тип данных SQL**                       |
| :-------------------: | :----------------------------------------------------------: |
|        tinyint        |                           tinyint                            |
|       smallint        |                           smallint                           |
|          int          |                             int                              |
|        bigint         |                            bigint                            |
|        Логическое        |                             bit                              |
|        Double         |                            float;                             |
|         float;         |                             real                             |
|        Double         |                            money                             |
|        Double         |                          smallmoney                          |
|        string         |                            nchar                             |
|        string         |                           nvarchar                           |
|        string         |                             char                             |
|        string         |                           varchar                            |
|        binary         |                            binary                            |
|        binary         |                          varbinary                           |
|        timestamp       |                             date                             |
|        timestamp       |                        smalldatetime                         |
|        timestamp       |                          datetime2                           |
|        timestamp       |                           Datetime                           |
|        timestamp       |                             time                             |
|       date        | (1) загрузки как int и привести к дате </br> (2) [использовать соединитель хранилища данных SQL Azure Databricks](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse#load-data-into-azure-sql-data-warehouse) с </br> spark.conf.set( "spark.sql.parquet.writeLegacyFormat", "true" ) </br> (**обновления, ожидается в ближайшее время**) |
|        decimal        | [Использование соединителя хранилища данных SQL Azure Databricks](https://docs.microsoft.com/azure/azure-databricks/databricks-extract-load-sql-data-warehouse#load-data-into-azure-sql-data-warehouse) с </br> spark.conf.set( "spark.sql.parquet.writeLegacyFormat", "true" ) </br> (**обновления, ожидается в ближайшее время**) |

## <a name="2-land-the-data-into-azure-blob-storage-or-azure-data-lake-store"></a>2. Помещение данных в хранилище BLOB-объектов Azure или Azure Data Lake Storage

Чтобы поместить данные в службу хранилища Azure, их можно переместить в [хранилище BLOB-объектов Azure](../storage/blobs/storage-blobs-introduction.md) или [Azure Data Lake Store](../data-lake-store/data-lake-store-overview.md). В любом расположении данные должны храниться в текстовых файлах. PolyBase может загрузить их из любого расположения.

Ниже приведены средства и службы, которые можно использовать для перемещения данных в службу хранилища Azure.

- Служба [Azure ExpressRoute](../expressroute/expressroute-introduction.md) повышает пропускную способность сети, производительность, а также предсказуемое поведение. ExpressRoute — это служба, которая направляет данные с помощью выделенного частного подключения в Azure. Подключения ExpressRoute не направляют данные через общедоступный Интернет. Они отличаются повышенной надежностью, более высокой скоростью, меньшей задержкой и дополнительной безопасностью по сравнению с обычными подключениями через общедоступный Интернет.
- [Служебная программа AZCopy](../storage/common/storage-moving-data.md) перемещает данные в службу хранилища Azure через общедоступный Интернет. Этот способ оптимален, если размер данных не превышает 10 ТБ. Для выполнения загрузок на регулярной основе с помощью AZCopy проверьте скорость сети, чтобы просмотреть, подходит ли она. 
- [Фабрика данных Azure (ADF)](../data-factory/introduction.md) включает шлюз, который можно установить на локальном сервере. Затем можно создать конвейер для перемещения данных из локального сервера в службу хранилища Azure. Использование фабрики данных с хранилищем данных SQL описывается в разделе [Загрузка данных в службу "Хранилище данных SQL Azure" с помощью службы "Фабрика данных Azure"](/azure/data-factory/load-azure-sql-data-warehouse).


## <a name="3-prepare-the-data-for-loading"></a>3. Подготовка данных для загрузки

Может потребоваться подготовка и очистка данных в учетной записи хранения перед их загрузкой в хранилище данных SQL. Подготовить данные можно, пока они хранятся в источнике, при экспорте данных в текстовые файлы или после того, как данные окажутся в службе хранилища Azure.  Лучше всего как можно раньше начать работу с данными.  

### <a name="define-external-tables"></a>Определение внешних таблиц

Перед загрузкой данных необходимо определить внешние таблицы в хранилище данных. PolyBase использует внешние таблицы для определения данных и доступа к ним в службе хранилища Azure. Внешняя таблица аналогична представлению базы данных. Внешняя таблица содержит схему таблицы и указывает на данные, хранящиеся за пределами хранилища данных. 

Определение внешних таблиц включает указание источника данных, формата текстовых файлов и определений таблицы. Ниже приведены разделы синтаксиса T-SQL, которые вам понадобятся:
- [CREATE EXTERNAL DATA SOURCE](/sql/t-sql/statements/create-external-data-source-transact-sql)
- [CREATE EXTERNAL FILE FORMAT](/sql/t-sql/statements/create-external-file-format-transact-sql)
- [CREATE EXTERNAL TABLE](/sql/t-sql/statements/create-external-table-transact-sql)

Пример создания внешних объектов см. в разделе [Создание внешних таблиц для примеров данных](load-data-from-azure-blob-storage-using-polybase.md#create-external-tables-for-the-sample-data) в руководстве по загрузке.

### <a name="format-text-files"></a>Форматирование текстовых файлов

После определения внешних объектов необходимо выровнять строки текстовых файлов с внешней таблицей и определением формата файла. Данные в каждой строке текстового файла должны совпадать с определением таблицы.
Для форматирования текстовых файлов сделайте следующее:

- Если данные поступают из нереляционного источника, необходимо преобразовать их в строки и столбцы. Независимо от того, поступают ли данные из реляционного или нереляционного источника, их необходимо преобразовать для соответствия определениям столбцов таблицы, в которую вы планируете загрузить данные. 
- Форматируйте данные в текстовом файле для соответствия определениям столбцов и типам данных в целевой таблице хранилища данных SQL. Неполное соответствие между типами данных во внешних текстовых файлах и таблице хранилища данных вызовет отклонение строк во время загрузки.
- Отделите поля в текстовом файле символом завершения.  Обязательно используйте уникальный символ или последовательность символов. Используйте указанный символ завершения для [создания формата внешнего файла](/sql/t-sql/statements/create-external-file-format-transact-sql).


## <a name="4-load-the-data-into-sql-data-warehouse-staging-tables-using-polybase"></a>4. Загрузка данных в промежуточные таблицы Хранилища данных SQL с помощью PolyBase

Этот метод рекомендуется для загрузки данных в промежуточную таблицу. Промежуточные таблицы позволяют обрабатывать ошибки без оказания влияния на рабочие таблицы. Промежуточная таблица также предоставляет возможность использовать архитектуру MPP в Хранилище данных SQL для преобразования данных перед вставкой в рабочие таблицы.

### <a name="options-for-loading-with-polybase"></a>Варианты загрузки данных с помощью PolyBase

Чтобы загрузить данные с помощью PolyBase, можно использовать любые из приведенных ниже вариантов загрузки.

- [PolyBase с использованием T-SQL](load-data-from-azure-blob-storage-using-polybase.md) хорошо работает, когда данные хранятся в хранилище BLOB-объектов Azure или Azure Data Lake Store. Этот вариант предоставляет наибольший контроль над процессом загрузки, но также требует определения объектов внешних данных. Другие методы определяют эти объекты в фоновом режиме, когда вы сопоставляете исходные таблицы с целевыми.  Для оркестрации загрузок T-SQL можно использовать фабрику данных Azure, службы SSIS или функции Azure. 
- [PolyBase со службами SSIS](/sql/integration-services/load-data-to-sql-data-warehouse) является оптимальным выбором, когда исходные данные хранятся в SQL Server — локально или в облаке. Службы SSIS определяют сопоставления исходной и целевой таблиц, а также управляют загрузкой. При наличии пакетов служб SSIS можно изменить пакеты для работы с новым назначением хранилища данных. 
- [PolyBase с фабрикой данных Azure (ADF)](sql-data-warehouse-load-with-data-factory.md) представляет собой другое средство оркестрации.  Оно определяет конвейер и планирует расписания заданий. 
- [PolyBase с использованием Azure DataBricks](../azure-databricks/databricks-extract-load-sql-data-warehouse.md) передает данные из таблицы хранилища данных SQL в кадр данных Databricks и (или) записывает данные из кадра данных Databricks в таблицу хранилища данных SQL, с помощью PolyBase.

### <a name="non-polybase-loading-options"></a>Варианты загрузки, отличные от PolyBase

Если данные несовместимы с PolyBase, можно использовать программу [bcp](/sql/tools/bcp-utility) или [API-интерфейс SQLBulkCopy](https://msdn.microsoft.com/library/system.data.sqlclient.sqlbulkcopy.aspx). bcp загружает данные напрямую в хранилище данных SQL, минуя хранилище BLOB-объектов Azure и предназначается только для небольших загрузок. Обратите внимание, что производительность загрузки этих вариантов значительно ниже, чем у PolyBase. 


## <a name="5-transform-the-data"></a>5. Преобразование данных

Пока данные находятся в промежуточной таблице, выполните преобразования, необходимые для рабочей нагрузки. Затем переместите данные в рабочую таблицу.


## <a name="6-insert-the-data-into-production-tables"></a>6. Вставка данных в рабочие таблицы

С помощью инструкции INSERT INTO... SELECT данные перемещаются из промежуточной таблицы в постоянную. 

При разработке процесса ETL попробуйте запустить его для небольшого тестового примера. Попробуйте извлечь 1000 строк из таблицы в файл, переместить его в Azure, а затем загрузить в промежуточную таблицу. 


## <a name="partner-loading-solutions"></a>Партнерские решения для загрузки

Многие из наших партнеров предлагают решения для загрузки. Дополнительные сведения см. в статье [Партнеры по бизнес-аналитике хранилища данных SQL](sql-data-warehouse-partner-business-intelligence.md). 


## <a name="next-steps"></a>Дальнейшие действия

Инструкции по загрузке см. [здесь](guidance-for-loading-data.md).


