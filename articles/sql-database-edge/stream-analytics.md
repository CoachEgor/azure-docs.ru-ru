---
title: Использование пакета DAC для базы данных SQL и заданий Stream Analytics с помощью приложения "база данных SQL Azure" | Документация Майкрософт
description: Сведения об использовании заданий Stream Analytics в границе базы данных SQL
keywords: Пограничная база данных SQL, Stream Analytics, SqlPackage
services: sql-database-edge
ms.service: sql-database-edge
ms.topic: conceptual
author: SQLSourabh
ms.author: sourabha
ms.reviewer: sstein
ms.date: 11/04/2019
ms.openlocfilehash: c3ed84e06f693925ed8b484070616e223929e401
ms.sourcegitcommit: 598c5a280a002036b1a76aa6712f79d30110b98d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/15/2019
ms.locfileid: "74108741"
---
# <a name="using-sql-database-dac-package-and-stream-analytics-job-with-sql-database-edge"></a>Использование пакета DAC базы данных SQL и задания Stream Analytics с помощью границы базы данных SQL

Предварительная версия базы данных SQL Azure — это оптимизированное реляционное ядро СУБД, предназначенное для развертывания IoT и пограничных развертываний. Он основан на последних версиях Microsoft SQL Server ядро СУБД, которые обеспечивают ведущие в отрасли функции повышения производительности, безопасности и обработки запросов. Наряду с ведущими в отрасли возможностями управления реляционными базами данных SQL Server, служба "база данных SQL Azure" предоставляет встроенную потоковую возможность для аналитики в реальном времени и сложной обработки событий.

Служба "база данных SQL Azure" также предоставляет собственную реализацию SQLPackage. exe, которая позволяет пользователям развертывать пакет [DAC базы данных SQL](https://docs.microsoft.com/sql/relational-databases/data-tier-applications/data-tier-applications) во время развертывания пограничных баз данных SQL.

Граница базы данных SQL Azure предоставляет два необязательных параметра с помощью параметра *двойника модуля, требуемого* для модуля IOT Edge.

```json
{
    "properties.desired":
    {
        "SqlPackage": "<Optional_DACPAC_ZIP_SAS_URL>",
        "ASAJobInfo": "<Optional_ASA_Job_ZIP_SAS_URL>"
    }
}
```

|Поле | ОПИСАНИЕ |
|------|-------------|
| SqlPackage | Универсальный код ресурса (URI) хранилища BLOB-объектов Azure для файла *. zip, содержащего пакет DAC базы данных SQL.
| асажобинфо | Универсальный код ресурса (URI) хранилища BLOB-объектов Azure для задания ASA ребра. Дополнительные сведения о публикации задания ASA ребра см. в статье [Публикация задания с ребром ASA для базы данных SQL](/azure/sql-database-edge/stream-analytics#using-streaming-jobs-with-sql-database-edge).

## <a name="using-sql-database-dac-packages-with-sql-database-edge"></a>Использование пакетов DAC базы данных SQL с границей базы данных SQL

Чтобы использовать пакет DAC базы данных SQL (*. dacpac) с границей базы данных SQL, выполните приведенные ниже действия.

1. Создание или извлечение пакета DAC для базы данных SQL. Для создания пакета DacPac для существующей базы данных SQL можно использовать основные понятия, упомянутые при [извлечении DAC из существующей базы данных](/sql/relational-databases/data-tier-applications/extract-a-dac-from-a-database/) .

2. Заархивировать файл * *. dacpac* и отправить его в учетную запись хранилища BLOB-объектов Azure. Дополнительные сведения о загрузке файлов в хранилище BLOB-объектов Azure см. [в разделе Отправка, скачивание и вывод списка больших двоичных объектов с помощью портал Azure](../storage/blobs/storage-quickstart-blobs-portal.md).

3. Создайте подпись SAS для ZIP-файла с помощью портал Azure. Дополнительные сведения см. в статье [Делегирование доступа с помощью подписанных URL-адресов (SAS)](../storage/common/storage-sas-overview.md).

4. Обновите конфигурацию модуля ребра базы данных SQL, включив в нее URI SAS для пакета DAC. Обновление модуля ребра базы данных SQL

    1. На портал Azure перейдите к развертыванию центра Интернета вещей.

    2. В левой области щелкните **IOT Edge**.

    3. На странице **IOT Edge** найдите и щелкните IOT EDGE, где развернут модуль ребра базы данных SQL.

    4. На странице устройства *IOT Edge устройство* щелкните **задать модуль**. 

    5. На странице **Установка модулей** щелкните *настроить* для модуля "база данных SQL". 

    6. На панели **IOT Edge пользовательские модули** выберите *необходимые свойства набора модулей* , а затем обновите требуемые свойства, чтобы включить универсальный код ресурса (URI) для параметра SqlPackage, как показано в примере ниже. 

        > [!NOTE]
        > URI SAS ниже предназначен только для иллюстрации. Замените URI фактическим кодом URI из развертывания.

        ```json
            {
                "properties.desired":
                {
                    "SqlPackage": "https://StorageAccountName.blob.core.windows.net/SQLpackageFiles/MeasurementsDB.zip?sp=r&st=2019-09-01T00:00:00Z&se=2019-09-30T00:00:00Z&spr=https&sv=2019-02-02&sr=b&sig=Uh8X0E50qzlxkiKVBJKU3ccVQYwF235qTz7AXp4R3gI%3D",
                }
            }
        ```

    7. Выберите команду **Сохранить**.

    8. На странице **Установка модулей** нажмите кнопку *Далее*.

    9. На странице **Установка модулей** нажмите кнопку *Далее* , а затем — **Отправить**.

5. После отправки обновления модуля DACPAC-файл скачивается, распаковывается и развертывается для экземпляра SQL Server с пограничным экземпляром.

## <a name="using-streaming-jobs-with-sql-database-edge"></a>Использование заданий потоковой передачи с границей базы данных SQL

В базе данных SQL Azure имеется собственная реализация среды выполнения Stream Analytics. Это позволяет пользователям создавать задания Azure Stream Analytics ребра и развертывать это задание как задание пограничной потоковой передачи базы данных SQL. Чтобы создать задание пограничной Stream Analytics, выполните следующие действия.

1. Перейдите к портал Azure с помощью [URL-адреса](https://portal.azure.com/?microsoft_azure_streamanalytics_edgeadapterspreview=true)для просмотра. Этот URL-адрес предварительной версии позволяет пользователям настраивать выходные данные базы данных SQL для задания ребра Stream Analytics.

2. Создайте новое **Azure Stream Analytics на IOT Edge** задание и выберите среду размещения, нацеливание на **границу**.

3. Определите *входные* и *выходные данные* для задания Azure Stream Analytics. Каждый выходной файл SQL (настроенный ниже) привязан к одной таблице в базе данных. При необходимости потоковой передачи данных в несколько таблиц необходимо создать несколько выходов базы данных SQL. Выходные данные SQL можно настроить так, чтобы они указывали на разные базы данных.

    *Входные данные — выберите EdgeHub в качестве входных данных для задания ребра и заполните сведения о ресурсе.*

    *Выходные данные. Выберите базу данных SQL в качестве выходного параметра, введите параметры базы данных SQL вручную и укажите сведения о конфигурации для базы данных и таблицы.*

    |Поле      | ОПИСАНИЕ |
    |---------------|-------------|
    |Псевдоним выходных данных | Имя выходного псевдонима.|
    |База данных | Имя базы данных SQL. Это должно быть допустимое имя базы данных, которое существует на пограничном экземпляре базы данных SQL.|
    |Имя сервера | Имя (или IP-адрес) и сведения об номере порта для экземпляра SQL. Для развертывания с пограничным развертыванием базы данных SQL в качестве имени сервера можно использовать **TCP:., 1433** .|
    |Имя пользователя | Учетная запись входа SQL, которая имеет доступ к базе данных, указанной выше, с помощью модуля чтения данных и модуля записи данных.|
    |Пароль | Пароль для учетной записи входа SQL, упомянутой выше.|
    |таблица | Имя таблицы, которая будет выводиться для задания потоковой передачи.|
    |Наследование секционирования| Этот параметр конфигурации SQL output позволяет наследовать схему секционирования предыдущего шага запроса или входных данных. Если этот параметр включен, запись в таблицу на диске и наличие полной параллельной топологии для вашего задания, предположительно, позволяют повысить пропускную способность.|
    |Размер пакета| Размер пакета — это максимальное число записей, отправляемых при каждой транзакции с массовыми вставками.|

    Пример конфигурации ввода-вывода ниже:

    ```txt
        Input:
            Input from EdgeHub
            Input alias: input
            Event serialization format: JSON
            Encoding: UTF-8
            Event compression type: None

        Output :
            Output alias: output
            Database:  MeasurementsDB
            Server name: tcp:.,1433
            Username: sa
            Password: <Password>
            Table: TemperatureMeasurements
            Inherit Partitioning: Merge all input partitions into a single writer
            Max batch count: 10000
    ```

    > [!NOTE]
    > Дополнительные сведения о выходном адаптере SQL для Azure Stream Analytics см. в разделе [Azure Stream Analytics Output to SQL Azure Database](../stream-analytics/stream-analytics-sql-output-perf.md).

4. Определите запрос задания ASA для задания ребра. Этот запрос должен использовать определенные псевдонимы ввода-вывода в качестве входных и выходных имен в запросе. Дополнительные сведения см. в разделе [Справочник по языку запросов Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference).

5. Задайте параметры учетной записи хранения для задания ребра. Учетная запись хранения используется в качестве целевого объекта публикации для задания ребра.

6. В разделе Настройка выберите Опубликовать и нажмите кнопку Опубликовать. Сохраните URL-адрес SAS для использования с модулем SQL Database ребра.

### <a name="deploy-the-stream-analytics-edge-job-to-the-sql-database-edge"></a>Развертывание задания пограничной Stream Analytics на границе базы данных SQL

Чтобы развернуть задание потоковой передачи в модуле базы данных SQL, обновите конфигурацию модуля ребра базы данных SQL, включив в нее URI SAS для задания потоковой передачи из предыдущего шага. Обновление модуля ребра базы данных SQL

1. На портал Azure перейдите к развертыванию центра Интернета вещей.

2. В левой области щелкните **IOT Edge**.

3. На странице **IOT Edge** найдите и щелкните IOT EDGE, где развернут модуль ребра базы данных SQL.

4. На странице устройства *IOT Edge устройство* щелкните **задать модуль**. 

5. На странице **Установка модулей** щелкните *настроить* для модуля "база данных SQL". 

6. На панели **IOT Edge пользовательские модули** выберите *необходимые свойства набора модулей* , а затем обновите требуемые свойства, чтобы включить универсальный код ресурса (URI) для параметра асажобинфо, как показано в примере ниже. 

    > [!NOTE]
    > URI SAS ниже предназначен только для иллюстрации. Замените URI фактическим кодом URI из развертывания.

    ```json
        {
            "properties.desired":
            {
                "ASAJobInfo": "https://storageAccountName.blob.core.windows.net/asajobs/ASAEdgeJobs/5a9b34db-7a5c-4606-adae-4c8609eaa1c7/d85b5aa6-4d38-4703-bb34-af7f0bd7916d/ASAEdgeJobDefinition.zip?sv=2018-03-28&sr=b&sig=HH%2BFMsEy378RaTxIy2Xo6rM6wDaqoBaZ5zFDBqdZiS0%3D&st=2019-09-01T22%3A24%3A34Z&se=2019-09-30T22%3A34%3A34Z&sp=r"   
            }
        }
    ```

7. Выберите команду **Сохранить**.

8. На странице **Установка модулей** нажмите кнопку *Далее*.

9. На странице **Установка модулей** нажмите кнопку *Далее* , а затем — **Отправить**.

10. После отправки обновления модуля файл задания Stream Analytics загружается, расzip и развертывается для экземпляра SQL Server с пограничным экземпляром.

## <a name="next-steps"></a>Дополнительная информация

- Сведения о ценах и доступности см. на странице с [пограничными базами данных SQL Azure](https://azure.microsoft.com/services/sql-database-edge/).
- Запрос на включение границы базы данных SQL Azure для вашей подписки.
- Чтобы приступить к работе, см. следующие сведения.
  - [Развертывание пограничных баз данных SQL с помощью портал Azure](deploy-portal.md)
