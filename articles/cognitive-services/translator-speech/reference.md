---
title: Справочник по API перевода речи
titleSuffix: Azure Cognitive Services
description: Справочная документация по API перевода речи.
services: cognitive-services
author: Jann-Skotdal
manager: nitinme
ms.service: cognitive-services
ms.subservice: translator-speech
ms.topic: reference
ms.date: 05/18/2018
ms.author: v-jansko
ROBOTS: NOINDEX,NOFOLLOW
ms.openlocfilehash: 3493f6d25461836d8f6e48ce4213b0f5b78b6372
ms.sourcegitcommit: 3102f886aa962842303c8753fe8fa5324a52834a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/23/2019
ms.locfileid: "60539185"
---
# <a name="translator-speech-api"></a>API перевода речи

[!INCLUDE [Deprecation note](../../../includes/cognitive-services-translator-speech-deprecation-note.md)]

Эта служба предоставляет API потоковой передачи для транскрипции разговорной речи с одного языка в текст на другом языке. API также сочетает в себе возможности преобразования текста в речь для обратного перевода переведенного текста. API перевода речи поддерживает такие сценарии, как перевод разговоров в режиме реального времени, как в Skype Translator.

С помощью API перевода речи клиентские приложения выполняют потоковую передачу звука речи в службу и получают поток текстовых результатов, которые включают в себя распознанный текст на исходном языке, а также его перевод на целевой язык. Текстовые результаты создаются путем применения автоматического распознавания речи (ASR) на базе глубоких нейронных сетей к входящему звуковому потоку. Необработанные выходные данные ASR в дальнейшем усовершенствуются с помощью новой техники, называемой TrueText, для того чтобы более точно отражать намерение пользователя. Например, TrueText удаляет слова-паразиты (хмыканье и покашливания) и восстанавливает правильную пунктуацию и регистр букв. Кроме того, включена возможность замаскировать или исключить ненормативную лексику. Модули распознавания и перевода специально обучены для обработки разговорной речи. Служба "Перевод речи" использует обнаружение тишины для определения конца высказывания. После паузы в голосовой активности служба вернет окончательный результат для завершенной фразы. Служба также может возвращать частичные результаты, которые дают промежуточные распознавания и переводы для текущей фразы. Для конечных результатов служба предоставляет возможность синтезировать речь (преобразование текста в речь) из произносимого текста на целевых языках. Звуковой файл перевода текста в речь создается в формате, указанном клиентом. Доступны форматы WAV и MP3.

API перевода речи использует протокол WebSocket для создания полнодуплексного коммуникационного канала между клиентом и сервером. Приложению потребуется выполнить следующие действия для использования службы:

## <a name="1-getting-started"></a>1. Приступая к работе
Для доступа к API перевода текстов нужно [зарегистрироваться в Microsoft Azure](translator-speech-how-to-signup.md).

## <a name="2-authentication"></a>2. Authentication

Используйте ключ подписки для проверки подлинности. API перевода речи поддерживает два режима аутентификации:

* **Использование маркера доступа.** В приложении необходимо получить маркер доступа от службы токенов. Используйте ключ подписки API перевода речи для получения маркера доступа из службы проверки подлинности Azure Cognitive Services. Маркер доступа действителен 10 минут. Получайте новый маркер доступа каждые 10 минут и продолжайте использовать тот же маркер доступа для повторных запросов в течение следующих 10 минут.

* **Использование непосредственно ключа подписки.** В приложении передайте свой ключ подписки в качестве значения `Ocp-Apim-Subscription-Key` в заголовке.

Рассматривайте ключ подписки и маркер доступа как секретные данные, которые должны быть скрыты.

## <a name="3-query-languages"></a>3. Языки запросов
**Запросите ресурс "Языки" для текущего набора поддерживаемых языков.** [Языковые ресурсы](languages-reference.md) предоставляют набор языков и голосов, доступных для распознавания речи, преобразования текста и преобразования текста в речь. Каждому языку или голосу предоставляется идентификатор, который использует API перевода речи для идентификации того же языка или голоса.

## <a name="4-stream-audio"></a>4. Звуковой поток
**Откройте подключение и начните выполнять потоковую передачу звука в службу.** URL-адрес службы — `wss://dev.microsofttranslator.com/speech/translate`. Параметры и форматы звука, ожидаемые службой, описаны ниже в операции `/speech/translate`. Один из параметров используется для передачи маркера доступа из шага 2 выше.

## <a name="5-process-the-results"></a>5. Обработка результатов
**Обработайте результаты, передаваемые потоком обратно из службы.** Формат частичных результатов, конечных результатов и звуковых сегментов преобразования текста в речь описан ниже в документации об операции `/speech/translate`.

Примеры кода, демонстрирующие использование API перевода речи, доступны на [сайте GitHub Microsoft Translator](https://github.com/MicrosoftTranslator).

## <a name="implementation-notes"></a>Примечания по реализации

GET /speech/translate устанавливает сеанс для перевода речи.

### <a name="connecting"></a>Подключение
Перед подключением к службе просмотрите список параметров, приведенных далее в этом разделе. Пример запроса:

`GET wss://dev.microsofttranslator.com/speech/translate?from=en-US&to=it-IT&features=texttospeech&voice=it-IT-Elsa&api-version=1.0`
`Ocp-Apim-Subscription-Key: {subscription key}`
`X-ClientTraceId: {GUID}`

В запросе указывается, что разговорный английский будет передан в службу и переведен на итальянский язык. Каждый результат окончательного распознавания будет создавать аудиоответ с преобразованием текста в речь и с использованием женского голоса, который называется Elsa. Обратите внимание, что запрос включает учетные данные в `Ocp-Apim-Subscription-Key header`. Запрос также следует рекомендациям, устанавливая глобально уникальный идентификатор в заголовке `X-ClientTraceId`. Клиентское приложение должно регистрировать идентификатор трассировки, чтобы его можно было использовать для устранения неполадок при их возникновении.

### <a name="sending-audio"></a>Отправка звука
После установки подключения клиент начинает передавать звук в службу. Клиент отправляет звук блоками. Каждый фрагмент передается с использованием сообщения Websocket типа Binary.

Звуковые входные данные имеют формат звукового файла Waveform (WAVE или более известный как WAV-файл из-за его расширения имени файла). Клиентское приложение должно передавать один канал, подписанный как 16-битный PCM с частотой дискретизации в 16 кГц. Первый набор байтов, передаваемых клиентом, будет включать в себя заголовок WAV. 44-байтовый заголовок для одноканального 16-битного потока PCM с частотой дискретизации 16 кГц:

|Offset|Value|
|:---|:---|
|0–3|"RIFF"|
|4–7|0|
|8–11|"WAVE"|
|12–15|"fmt"|
|16–19|16|
|20–21|1|
|22–23|1|
|24–27|16000|
|28–31|32000|
|32–33|2|
|34–35|16|
|36–39|"data"|
|40–43|0|

Обратите внимание, что общий размер файла (в байтах 4–7) и размер "data" (в байтах 40–43) равен нулю. Это нормально для сценария потоковой передачи, где общий размер не обязательно известен заранее.

После отправки заголовка WAV (RIFF) клиент отправляет блоки звуковых данных. Обычно клиент передает потоки фиксированного размера, представляющие фиксированную продолжительность (например, поток 100 мс звука за раз).

### <a name="signal-the-end-of-the-utterance"></a>Сигнал об окончании фразы
API перевода речи возвращает расшифровку и перевод аудиопотока во время отправки аудио. Окончательная расшифровка, окончательный перевод и переведенные звуковые файлы будут возвращены вам только после окончания фразы. В некоторых случаях может понадобиться принудительное окончание фразы. Пожалуйста, пошлите 2,5 секунды молчания, чтобы закончить фразу.

### <a name="final-result"></a>Конечный результат
Окончательный результат распознавания речи создается в конце фразы. Результат передается от службы клиенту с использованием сообщения WebSocket типа Text. Содержимое сообщения — это сериализация объекта JSON со следующими свойствами:

* `type`: Строковая константа для определения типа результата. Значение является конечным для окончательных результатов.
* `id`: Идентификатор строки, присвоенный для результата распознавания.
* `recognition`: Распознанный текст на исходном языке. В ​​случае ложного распознавания текст может быть пустой строкой.
* `translation`: Распознанный текст, переведенный на целевой язык.
* `audioTimeOffset`: Смещение времени начала распознавания в тактах (1 такт = 100 наносекунд). Смещение относится к началу потоковой передачи.
* `audioTimeSize`: Время распознавания в тактах (100 наносекунд).
* `audioStreamPosition`: Смещение начала распознавания в байтах. Смещение относится к началу потоковой передачи.
* `audioSizeBytes`: Размер распознавания (в байтах).

Обратите внимание, что позиционирование распознавания в потоке звука по умолчанию не включено в результаты. Компонент `TimingInfo` должен быть выбран клиентом (см. параметр `features`).

Пример конечного результата имеет следующий вид:

```
{
  type: "final"
  id: "23",
  recognition: "what was said",
  translation: "translation of what was said",
  audioStreamPosition: 319680,
  audioSizeBytes: 35840,
  audioTimeOffset: 2731600000,
  audioTimeSize: 21900000
}
```

### <a name="partial-result"></a>Частичный результат
Частичные или промежуточные результаты распознавания речи не передаются в клиент по умолчанию. Клиент может использовать параметр запроса функций, чтобы запросить их.

Частичный результат передается от службы к клиенту с помощью сообщения WebSocket типа Text. Содержимое сообщения — это сериализация объекта JSON со следующими свойствами:

* `type`: Строковая константа для определения типа результата. Значение — partial для частичных результатов.
* `id`: Идентификатор строки, присвоенный для результата распознавания.
* `recognition`: Распознанный текст на исходном языке.
* `translation`: Распознанный текст, переведенный на целевой язык.
* `audioTimeOffset`: Смещение времени начала распознавания в тактах (1 такт = 100 наносекунд). Смещение относится к началу потоковой передачи.
* `audioTimeSize`: Время распознавания в тактах (100 наносекунд).
* `audioStreamPosition`: Смещение начала распознавания в байтах. Смещение относится к началу потоковой передачи.
* `audioSizeBytes`: Размер распознавания (в байтах).

Обратите внимание, что позиционирование распознавания в потоке звука по умолчанию не включено в результаты. Компонент TimingInfo должен быть выбран клиентом (см. параметр features).

Пример конечного результата имеет следующий вид:

```
{
  type: "partial"
  id: "23.2",
  recognition: "what was",
  translation: "translation of what was",
  audioStreamPosition: 319680,
  audioSizeBytes: 25840,
  audioTimeOffset: 2731600000,
  audioTimeSize: 11900000
}
```

### <a name="text-to-speech"></a>Преобразование текста в речь
Когда включен компонент преобразования текста в речь (см. параметр `features` ниже), конечный результат сопровождается звуком произнесенного переведенного текста. Звуковые данные разделены на блоки и отправляются службой клиента как последовательность сообщений Websocket типа Binary. Клиент может обнаружить конец потока, проверив бит FIN каждого сообщения. В последнем двоичном сообщении для бита FIN будет задано значение один, чтобы обозначить конец потока. Формат потока зависит от значения параметра `format`.

### <a name="closing-the-connection"></a>Закрытие подключения
Когда клиентское приложение завершило потоковую передачу звука и получило последний окончательный результат, оно должно закрыть подключение, инициировать подтверждение закрытия WebSocket. При определенных условиях это может привести к разрыву подключения сервера. Клиентом могут быть получены следующие закрытые коды WebSocket:

* `1003 - Invalid Message Type`: Сервер завершает подключение, так как он не может принять полученный тип данных. Это обычно происходит, когда входящий звук не начинается с правильного заголовка.
* `1000 - Normal closure`: Соединение закрыто после выполнения запроса. Сервер закроет соединение, если звуковой файл не будет получен от клиента в течение длительного периода времени; когда в течение длительного периода времени передается тишина; когда сеанс достигает максимально допустимой продолжительности (приблизительно 90 минут).
* `1001 - Endpoint Unavailable`: Указывает, что сервер станет недоступным. Клиентское приложение может попытаться восстановить подключение с ограничением количества попыток.
* `1011 - Internal Server Error`: Подключение будет закрыто сервером из-за ошибки.

### <a name="parameters"></a>Параметры

|Параметр|Value|ОПИСАНИЕ|Тип параметра|Тип данных|
|:---|:---|:---|:---|:---|
|api-version|1.0|Версия API, запрошенная клиентом. Допустимые значения: `1.0`.|query   |строка|
|from|(пусто)   |Определяет язык входящей речи. Значение — один из идентификаторов языка в области `speech` в ответе от API языков.|query|строка|
|значение|(пусто)|Указывает язык, на который будет переведен текст. Значение — один из идентификаторов языка в области `text` в ответе от API языков.|query|строка|
|features|(пусто)   |Разделенный запятыми набор функций, выбранных клиентом. Доступные функции:<ul><li>`TextToSpeech`. Указывает, что служба должна возвращать переведенные звуковые файлы окончательного переведенного предложения.</li><li>`Partial`. Указывает, что служба должна возвращать результаты промежуточного распознавания, пока звуковой файл передается в службу.</li><li>`TimingInfo`. Указывает, что служба должна возвращать сведения о времени, связанные с каждым распознаванием.</li></ul>Например, клиент будет указывать `features=partial,texttospeech` для получения частичных результатов и преобразования текста в речь, но без данных о времени. Обратите внимание, что окончательные результаты всегда отправляются клиенту.|query|строка|
|voice|(пусто)|Определяет, какие голоса для преобразования текста в речь используются для переведенного текста. Значение — один из идентификаторов голоса в области tts в ответе от API языков. Если голос не указан, система автоматически выбирает его при включении функции преобразования текста в речь.|query|строка|
|свойства|(пусто)|Определяет формат потока преобразования текста в речь, возвращаемого службой. Доступные параметры:<ul><li>`audio/wav`: Аудиопоток звуковых сигналов. Клиент должен использовать заголовок WAV, чтобы правильно интерпретировать звуковой формат. Звук WAV для преобразования текста в речь — 16-битный, одноканальный PCM с частотой дискретизации 24 кГц или 16 кГц.</li><li>`audio/mp3`: Поток звуковых файлов в формате MP3.</li></ul>Значение по умолчанию — `audio/wav`.|query|строка|
|ProfanityAction    |(пусто)    |Указывает, как служба должна обрабатывать распознавания нецензурной лексики в речи. Допустимы следующие действия:<ul><li>`NoAction`: Ненормативная лексика остается без изменений.</li><li>`Marked`: Ненормативная лексика заменяется маркером. Подробнее см. параметр `ProfanityMarker`.</li><li>`Deleted`: Ненормативная лексика удаляется. Например, если слово `"jackass"` считается ненормативным, фраза `"He is a jackass."` станет `"He is a .".`.</li></ul>Значение по умолчанию — Marked.|query|строка|
|profanityMarker|(пусто)    |Указывает, как обрабатывается обнаруженная ненормативная лексика, когда `ProfanityAction` имеет значение `Marked`. Допустимые значения:<ul><li>`Asterisk`: Ненормативная лексика заменяется строкой `***`. Например, если слово `"jackass"` считается ненормативным, фраза `"He is a jackass."` станет `"He is a ***.".`.</li><li>`Tag`: Ненормативная лексика будет выделена XML-тегами. Например, если слово `"jackass"` считается ненормативным, фраза `"He is a jackass."` станет `"He is a <profanity>jackass</profanity>."`.</li></ul>Значение по умолчанию — `Asterisk`.|query|строка|
|Авторизация|(пусто)  |Указывает значение маркера носителя клиента. Используйте префикс `Bearer` со значением `access_token`, возвращаемым службой токенов проверки подлинности.|Верхний колонтитул   |строка|
|Ocp-Apim-Subscription-Key|(пусто)|Требуется, если заголовок `Authorization` не указан.|Верхний колонтитул|строка|
|access_token|(пусто)   |Альтернативный способ передачи допустимого маркера доступа OAuth. Маркер носителя обычно предоставляется с заголовком `Authorization`. Некоторые библиотеки websocket не позволяют коду клиента задавать заголовки. В этом случае клиент может использовать параметр запроса `access_token` для передачи допустимого маркера. При использовании маркера доступа для проверки подлинности, если заголовок `Authorization` не задан, тогда необходимо задать `access_token`. Если заданы заголовок и параметр запроса, параметр запроса не учитывается. Клиентам следует использовать только один метод для передачи маркера.|query|строка|
|subscription-key|(пусто)   |Альтернативный способ передачи ключа подписки. Некоторые библиотеки websocket не позволяют коду клиента задавать заголовки. В этом случае клиент может использовать параметр запроса `subscription-key` для передачи допустимого ключа подписки. При использовании ключа подписки для проверки подлинности, если заголовок `Ocp-Apim-Subscription-Key` не установлен, необходимо установить ключ подписки. Если заданы заголовок и параметр запроса, параметр запроса не учитывается. Клиентам следует использовать только один метод для передачи `subscription key`.|query|строка|
|X-ClientTraceId    |(пусто)    |Создаваемый клиентом GUID используется для трассировки запроса. Для правильного устранения неполадок клиенты должны предоставлять новое значение каждому запросу и вносить его в журнал.<br/>Вместо использования заголовка можно передать это значение с параметром запроса `X-ClientTraceId`. Если заданы заголовок и параметр запроса, параметр запроса не учитывается.|Верхний колонтитул|строка|
|X-CorrelationId|(пусто)    |Созданный клиентом идентификатор, используемый для корреляции нескольких каналов при общении. Чтобы обеспечить общение пользователей, можно создать несколько сеансов перевода речи. В такой ситуации все сеансы перевода речи используют один и тот же идентификатор корреляции для связывания каналов друг с другом. Это облегчает трассировку и диагностику. Идентификатор должен соответствовать такому правилу: `^[a-zA-Z0-9-_.]{1,64}$`.<br/>Вместо использования заголовка можно передать это значение с параметром запроса `X-CorrelationId`. Если заданы заголовок и параметр запроса, параметр запроса не учитывается.|Верхний колонтитул|строка|
|X-ClientVersion|(пусто)    |Определяет версию клиента приложения. Пример: "2.1.0.123".<br/>Вместо использования заголовка можно передать это значение с параметром запроса `X-ClientVersion`. Если заданы заголовок и параметр запроса, параметр запроса не учитывается.|Верхний колонтитул|строка|
|X-OsPlatform|(пусто)   |Определяет имя и версию операционной системы, в которой выполняется клиентское приложение. Примеры: Android 5.0, iOs 8.1.3, Windows 8.1.<br/>Вместо использования заголовка можно передать это значение с параметром запроса `X-OsPlatform`. Если заданы заголовок и параметр запроса, параметр запроса не учитывается.|Верхний колонтитул|строка|

### <a name="response-messages"></a>Ответные сообщения

|Код состояния HTTP|Причина|Модель ответа|Заголовки|
|:--|:--|:--|:--|
|101    |Обновление WebSocket.|Пример значения модели <br/> Объект {}|X-RequestId<br/>Значение, идентифицирующее запрос для устранения неполадок.<br/>строка|
|400    |Недопустимый запрос. Проверьте входные параметры, чтобы убедиться, что они являются допустимыми. Объект ответа включает более подробное описание ошибки.|||
|401    |Не авторизовано. Убедитесь, что учетные данные заданы, что они являются допустимыми и что подписка Azure Data Market имеет хорошую репутацию и доступный баланс.|||
|500    |Произошла ошибка. Если ошибка продолжает возникать, сообщите об этом, указав идентификатор клиента (X-ClientTraceId) или идентификатор запроса (X-RequestId).|||
|503    |Сервер временно недоступен. Повторите запрос. Если ошибка продолжает возникать, сообщите об этом, указав идентификатор клиента (X-ClientTraceId) или идентификатор запроса (X-RequestId).|||
