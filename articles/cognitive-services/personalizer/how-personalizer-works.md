---
title: Персонализатор. Принцип его работы
titleSuffix: Azure Cognitive Services
description: Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы "Ранг" и "Вознаграждение". Циклы обучения не зависят друг от друга.
author: diberry
manager: nitinme
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: conceptual
ms.date: 06/07/2019
ms.author: diberry
ms.openlocfilehash: e55ccb508760c4473f71245c183948219f31985c
ms.sourcegitcommit: e3b0fb00b27e6d2696acf0b73c6ba05b74efcd85
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/30/2019
ms.locfileid: "68663910"
---
# <a name="how-personalizer-works"></a>Принцип работы Персонализатора

Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы **Ранг** и **Вознаграждение**. Циклы обучения не зависят друг от друга. Создайте цикл обучения для каждой части или для поведения приложения, которое вы хотите персонализировать.

Для каждого цикла **вызовите API ранжирования** на основе текущего контекста с помощью:

* списка возможных действий (элементы содержимого, среди которых можно выбрать главное действие);
* списка [возможностей содержимого](concepts-features.md) (контекстуально релевантные данные, такие как пользователь, содержимое и контекст).

API **ранжирования** решает, какую из следующих моделей использовать.

* _Воспользоваться_: текущая модель для определения лучшего действия на основе прошлых данных.
* _Изучить_: выбор другого действия вместо первого.

API **вознаграждения**:

* собирает данные для обучения модели, записывая характеристики и награды каждого вызова "Ранг";
* использует эти данные для обновления модели на основе параметров, указанных в _политике обучения_.

## <a name="architecture"></a>Архитектура

На следующем изображении показан архитектурный процесс вызовов "Ранг" и "Вознаграждение".

![Замещающий текст](./media/how-personalizer-works/personalization-how-it-works.png "Принцип работы персонализации")

1. Для определения ранга действия Персонализатор использует внутреннюю модель ИИ.
1. Служба решает, использовать ли текущую модель или исследовать новые варианты для модели.  
1. Результат ранжирования отправляется в EventHub.
1. Когда Персонализатор получает вознаграждение, оно отправляется в EventHub. 
1. "Ранг" и "Вознаграждение" связаны друг с другом.
1. Модель ИИ обновляется на основе результатов корреляции.
1. Механизм вывода обновляется с помощью новой модели. 

## <a name="research-behind-personalizer"></a>Исследование вне Персонализатора

Персонализатор базируется на новейших научных и исследовательских разработках в области [обучения с подкреплением](concepts-reinforcement-learning.md), включая статьи, исследовательскую деятельность и текущие области исследований в Microsoft Research.

## <a name="terminology"></a>Терминология

* **Цикл обучения**. Вы можете создать цикл обучения для каждой части своего приложения, которая может извлечь пользу из персонализации. Если у вас есть несколько сред для персонализации, создайте цикл для каждой из них. 

* **Действия**: Действия — это элементы содержимого, такие как продукты или рекламные акции, среди которых вы выбираете нужные. Персонализатор выбирает главное действие, называемое _Вознаграждением_, которое будет отображаться для ваших пользователей, через API ранжирования. Каждое действие может содержать функции, отправленные с запросом ранжирования.

* **Context**. Чтобы составить более точный ранг, предоставьте информацию о вашем контексте по следующему примеру:
    * ваш пользователь;
    * используемое устройство; 
    * Текущее время.
    * другие данные о текущей ситуации;
    * исторические данные о пользователе или контексте.

    Конкретное приложение может включать в себя другие контекстные сведения. 

* **[Функции](concepts-features.md)** . Единица информации об элементе содержимого или пользовательском контексте.

* **Награда**: Мера того, как пользователь отреагировал на возвращенное действие API ранжирования, в виде оценки от 0 до 1. Бизнес-логика задает значение от 0 до 1 в ​​зависимости от того, как этот выбор помог достичь ваших бизнес-целей персонализации. 

* **Изучение**. Служба "Персонализатор" рассматривает возможности вместо возвращения лучшего действия, выбирая другое действие для пользователя. Эта служба позволяет избежать смещения и застоя и может адаптироваться к текущему поведению пользователя путем изучения. 

* **Продолжительность эксперимента**. Период времени, в течение которого служба "Персонализатор" ожидает получения вознаграждения, начиная с момента вызова "Ранг" для этого события.

* **Неактивные события**. Неактивное событие — это событие, для которого вы совершаете вызов "Ранг", но не уверены в том, что пользователь увидит результат из-за решений клиентского приложения. Неактивные события позволяют создавать и сохранять результаты персонализации, а решение об их отмене принимать позже, что не повлияет на модель машинного обучения.

* **Модель**. Модель Персонализатора собирает все данные, полученные в результате изучения поведения пользователя, получая данные обучения из комбинации аргументов, которые вы отправляете вызовам "Ранг" и "Вознаграждение", и из поведения, определенного в политике обучения. 

* **Политика обучения**: Способ обучения модели для каждого события определяется с помощью некоторых мета-параметров, влияющих на работу алгоритмов в машинном обучении. Новые циклы персонализации будут начинаться с политики обучения по умолчанию, что может привести к умеренной производительности. При выполнении [оценок](concepts-offline-evaluation.md)Персонализация может создавать новые политики обучения, специально оптимизированные для вариантов использования вашего цикла. Персонализация будет значительно улучшена с помощью политик, оптимизированных для каждого конкретного цикла, созданного во время оценки.

## <a name="example-use-cases-for-personalizer"></a>Пример вариантов применения Персонализатора

* Уточнение и устранение неоднозначности намерений: обеспечьте удобство работы пользователей, когда их намерения неясны, предоставив им вариант, персонализированный для каждого пользователя.
* Подсказки по умолчанию для меню и параметров: в качестве первого шага бот предлагает самый вероятный элемент с учетом индивидуальных особенностей вместо безликого меню или списка альтернативных вариантов.
* Характеристики и стиль бота: в ботах, которые могут варьировать стиль, уровень детализации и стиль написания, рассмотрите возможность изменения этих характеристик с учетом индивидуальных особенностей.
* Содержимое уведомлений и предупреждений: решите, какой текст использовать для оповещений для более эффективного привлечения пользователей.
* Время уведомлений и предупреждений: изучите индивидуальные особенности относительно времени отправки уведомлений пользователям, чтобы эффективнее их привлекать.

## <a name="checklist-for-applying-personalizer"></a>Контрольный список для применения Персонализатора

Персонализатор можно применять в ситуациях, когда:

* У вас есть бизнес-цель или цель повышения удобства использования вашего приложения.
* В вашем приложении есть место, где принятие контекстуального решения о том, что показывать пользователям, поможет этой цели.
* Лучший выбор может и должен делаться на основе общего поведения пользователей и общей оценки вознаграждения.
* Использование машинного обучения для персонализации соответствует [руководствам по ответственному использованию](ethics-responsible-use.md) и выбору вашей команды.
* Решения можно выразить как ранжирование лучших вариантов ([действий](concepts-features.md#actions-represent-a-list-of-options)) при ограниченном наборе вариантов.
* Степень эффективности этого выбора можно вычислить с помощью бизнес-логики, измерив некоторые аспекты поведения пользователей и выразив их в виде числа от -1 до 1.
* Оценка вознаграждения не приносит слишком много смешанных или внешних факторов, в частности, продолжительность эксперимента достаточно мала, поэтому оценку вознаграждения можно вычислить, пока она еще полезна.
* Контекст для ранга можно выразить как словарь из по крайней мере 5 функций, которые могут помочь сделать правильный выбор и не включают личные сведения.
* У вас есть информация о каждом действии в виде словаря из минимум 5 атрибутов функций, которые могут помочь Персонализатору сделать правильный выбор.
* Вы можете хранить данные достаточно долго, чтобы накопить журнал с минимум 100 000 взаимодействий.

## <a name="machine-learning-considerations-for-applying-personalizer"></a>Рекомендации для машинного обучения по применению Персонализатора

Персонализатор основан на обучении с подкреплением, подходе к машинному обучению, который основан на предоставляемой обратной связи. 

Персонализатор будет учиться в ситуациях, в которых:
* Имеется достаточно событий для оптимальной персонализации, если проблема изменяется со временем (например, предпочтения новостей или моды). Персонализатор адаптируется к постоянным изменениям реального мира, однако результаты не будут оптимальными, если событий и данных будет недостаточно, чтобы учиться на них, а также открывать и осваивать новые шаблоны. Следует выбрать вариант использования, который применяется достаточно часто. Рассмотрите возможность поиска вариантов использования, которые попадаются по крайней мере 500 раз в день.
* В контексте и действиях достаточно функций для упрощения обучения.
* Не более 50 действий для ранжирования на один вызов.
* Параметры хранения данных позволяют Персонализатору собирать достаточно данных для выполнения автономных оценок и оптимизации политики. Обычно это по крайней мере 50 000 точек данных.

## <a name="how-to-use-personalizer-in-a-web-application"></a>Использование Персонализатора в веб-приложении

Добавление цикла в веб-приложение включает в себя:

* Определение того, какой вариант взаимодействия необходимо персонализировать, какие действия и функции есть в наличии, какие функции контекста необходимо использовать и какое вознаграждение необходимо настроить.
* Добавление ссылки на пакет SDK для персонализации в приложении.
* Вызов API ранжирования на момент готовности к персонализации.
* Сохранение eventId. Позже вы отправите вознаграждение с помощью API вознаграждения.
1. Вызовите операцию "Активировать" для события, когда будете уверены, что пользователь увидел вашу персонализированную страницу.
1. Дождитесь, пока пользователь выберет ранжированное содержимое. 
1. Вызовите API вознаграждения, чтобы указать эффективность выходных данных API ранжирования.

## <a name="how-to-use-personalizer-with-a-chat-bot"></a>Использование Персонализатора с чат-ботом

В этом примере показано, как использовать персонализацию, чтобы сделать предложение по умолчанию вместо того, чтобы каждый раз отправлять пользователю несколько меню или вариантов.

* Получите [код](https://github.com/Azure-Samples/cognitive-services-personalizer-samples/tree/master/samples/ChatbotExample) для этого примера.
* Настройте решение бота. Опубликуйте приложение LUIS. 
* Управляйте вызовами API ранжирования и вознаграждения для бота.
    * Добавьте код для управления обработкой намерения LUIS. Если в качестве намерения с самым высоким показателем возвращается значение **Нет** или показатель этого намерения ниже порогового значения бизнес-логики, отправьте список намерений в Персонализатор для ранжирования намерений.
    * Покажите список намерений пользователю в качестве доступных для выбора ссылок, в котором первое намерение является намерением с высшим приоритетом из ответа API ранжирования.
    * Запишите выбор пользователя и отправьте его в вызов API вознаграждения. 

### <a name="recommended-bot-patterns"></a>Рекомендуемые шаблоны ботов

* Осуществляйте вызовы API ранжирования Персонализатора всякий раз, когда необходимо устранить неоднозначность вместо того, чтобы кэшировать результаты для каждого пользователя. Результат устранения неоднозначности намерения может изменяться со временем для одного пользователя. Если позволить API ранжирования исследовать расхождения, ускорится обучение в целом.
* Выберите взаимодействие, общее для большого числа пользователей, чтобы у вас было достаточно данных для персонализации. Например, вводные вопросы подходят лучше, чем меньшие уточнения глубоко в графе диалога, к которому могут получить доступ только небольшое число пользователей.
* Используйте вызовы API ранжирования, чтобы включить диалоги "первая рекомендация подходит", в которых пользователь получает запрос "Хотите ли вы X?" или "Вы имели ввиду X?" и пользователь может просто подтвердить, вместо того, чтобы предоставлять варианты пользователю, где ему нужно выбирать из меню. Например, пользователь: "Я хочу заказать кофе", бот: "Вы хотите двойной эспрессо?". Таким образом сигнал вознаграждения также надежный, так как он относится непосредственно к одному предложению.

## <a name="how-to-use-personalizer-with-a-recommendation-solution"></a>Использование Персонализатора с решением рекомендаций

Используйте ваш рекомендательный механизм, чтобы отфильтровать большой каталог до нескольких элементов, которые затем могут быть представлены как 30 возможных действий, отправляемых в API ранжирования.

Механизмы рекомендаций можно использовать с Персонализатором:

* Настройте [решение рекомендаций](https://github.com/Microsoft/Recommenders/). 
* При отображении страницы вызовите модель рекомендаций, чтобы получить краткий список рекомендаций.
* Вызовите персонализацию для ранжирования выходных данных решения рекомендаций.
* Отправьте отзыв о действии пользователя с помощью вызова API вознаграждения.


## <a name="pitfalls-to-avoid"></a>Типичные недочеты

* Не используйте Персонализатор, в котором персонализированное поведение невозможно отследить для всех пользователей, а только для конкретных пользователей, или который работает на основе списка альтернативных вариантов конкретного пользователя. Например, использование Персонализатора, чтобы предложить заказ первой пиццы из списка из 20 пунктов меню, полезно, но предложение контакта для вызова из списка контактов пользователей, когда необходима помощь по уходу за ребенком (например, "Бабушка"), сложно назвать персонализацией в базе пользователей.


## <a name="adding-content-safeguards-to-your-application"></a>Добавление средств защиты содержимого в приложение

Если приложение допускает значительные расхождения в содержимом, отображаемом для пользователей, и некоторое содержимое может быть небезопасно или не подходит для некоторых пользователей, вам следует заранее составить план и принять надлежащие меры по обеспечению безопасности, чтобы уберечь пользователей от просмотра неприемлемого содержимого. Самый лучший шаблон для реализации мер безопасности: Самый лучший шаблон для реализации мер безопасности:
    * Получите список действий для ранжирования.
    * Отфильтруйте действия, неприемлемые для аудитории.
    * Ранжируйте только эти приемлемые действия.
    * Отобразите действие с высшим рейтингом для пользователя.

В некоторых архитектурах приведенную выше последовательность может быть трудно реализовать. В этом случае есть альтернативный подход к реализации мер безопасности после ранжирования, но необходимо выполнить подготовку, чтобы действия, которые выходят за рамки мер по обеспечению безопасности, не использовались для обучения модели Персонализатора.

* Получите список действий для ранжирования, деактивировав обучение.
* Ранжируйте действия.
* Проверьте, является ли действие с высшим приоритетом приемлемым.
    * Если оно является приемлемым, активируйте обучение для этого ранжирования, а затем покажите его пользователю.
    * Если это действие не является приемлемым, не активируйте обучение для этого ранжирования и с использованием логики или альтернативных подходов примите решение о том, что следует показывать пользователю. Даже если используется второй вариант с высшим приоритетом, не активируйте обучение для этого ранжирования.

## <a name="verifying-adequate-effectiveness-of-personalizer"></a>Проверка эффективности Персонализатора

Периодически выполняя [автономные оценки](how-to-offline-evaluation.md), вы можете отслеживать эффективность Персонализатора.

## <a name="next-steps"></a>Следующие шаги

Общие сведения об [использовании Персонализатора](where-can-you-use-personalizer.md).
Выполнение [автономных вычислений](how-to-offline-evaluation.md)
