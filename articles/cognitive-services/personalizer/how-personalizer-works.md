---
title: Персонализатор. Принцип его работы
titleSuffix: Azure Cognitive Services
description: Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы "Ранг" и "Вознаграждение". Циклы обучения не зависят друг от друга.
author: edjez
manager: nitinme
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: overview
ms.date: 05/07/2019
ms.author: edjez
ms.openlocfilehash: 6b2237f27fba5eaf952932cd6592052649400b96
ms.sourcegitcommit: 4b9c06dad94dfb3a103feb2ee0da5a6202c910cc
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/02/2019
ms.locfileid: "65025496"
---
# <a name="how-personalizer-works"></a>Принцип работы Персонализатора

Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы **Ранг** и **Вознаграждение**. Циклы обучения не зависят друг от друга. Создайте цикл обучения для каждой части или для поведения приложения, которое вы хотите персонализировать.

Для каждого цикла **вызовите API ранжирования** на основе текущего контекста с помощью:

* списка возможных действий (элементы содержимого, среди которых можно выбрать главное действие);
* списка [возможностей содержимого](concepts-features.md) (контекстуально релевантные данные, такие как пользователь, содержимое и контекст).

API **ранжирования** решает, какую из следующих моделей использовать.

* _Воспользоваться_: текущая модель для определения лучшего действия на основе прошлых данных.
* _Изучить_: выбор другого действия вместо первого.

API **вознаграждения**:

* собирает данные для обучения модели, записывая характеристики и награды каждого вызова "Ранг";
* использует эти данные для обновления модели на основе параметров, указанных в _политике обучения_.

## <a name="architecture"></a>Архитектура

На следующем изображении показан архитектурный процесс вызовов "Ранг" и "Вознаграждение".

![Замещающий текст](./media/how-personalizer-works/personalization-how-it-works.png "Принцип работы персонализации")

1. Для определения ранга действия Персонализатор использует внутреннюю модель ИИ.
1. Служба решает, использовать ли текущую модель или исследовать новые варианты для модели.  
1. Результат ранжирования отправляется в EventHub.
1. Когда Персонализатор получает вознаграждение, оно отправляется в EventHub. 
1. "Ранг" и "Вознаграждение" связаны друг с другом.
1. Модель ИИ обновляется на основе результатов корреляции.
1. Механизм вывода обновляется с помощью новой модели. 

## <a name="research-behind-personalizer"></a>Исследование вне Персонализатора

Персонализатор базируется на новейших научных и исследовательских разработках в области [обучения с подкреплением](concepts-reinforcement-learning.md), включая статьи, исследовательскую деятельность и текущие области исследований в Microsoft Research.

## <a name="terminology"></a>Терминология

* **Цикл обучения**. Вы можете создать цикл обучения для каждой части своего приложения, которая может извлечь пользу из персонализации. Если у вас есть несколько сред для персонализации, создайте цикл для каждой из них. 

* **Действия**: Действия — это элементы содержимого, такие как продукты или рекламные акции, среди которых вы выбираете нужные. Персонализатор выбирает главное действие, называемое _Вознаграждением_, которое будет отображаться для ваших пользователей, через API ранжирования. Каждое действие может содержать функции, отправленные с запросом ранжирования.

* **Context**. Чтобы составить более точный ранг, предоставьте информацию о вашем контексте по следующему примеру:
    * ваш пользователь;
    * используемое устройство; 
    * Текущее время.
    * другие данные о текущей ситуации;
    * исторические данные о пользователе или контексте.

    Конкретное приложение может включать в себя другие контекстные сведения. 

* **[Функции](concepts-features.md)**. Единица информации об элементе содержимого или пользовательском контексте.

* **Награда**: Мера того, как пользователь отреагировал на возвращенное действие API ранжирования, в виде оценки от 0 до 1. Бизнес-логика задает значение от 0 до 1 в ​​зависимости от того, как этот выбор помог достичь ваших бизнес-целей персонализации. 

* **Изучение**. Служба "Персонализатор" рассматривает возможности вместо возвращения лучшего действия, выбирая другое действие для пользователя. Эта служба позволяет избежать смещения и застоя и может адаптироваться к текущему поведению пользователя путем изучения. 

* **Продолжительность эксперимента**. Период времени, в течение которого служба "Персонализатор" ожидает получения вознаграждения, начиная с момента вызова "Ранг" для этого события.

* **Неактивные события**. Неактивное событие — это событие, для которого вы совершаете вызов "Ранг", но не уверены в том, что пользователь увидит результат из-за решений клиентского приложения. Неактивные события позволяют создавать и сохранять результаты персонализации, а решение об их отмене принимать позже, что не повлияет на модель машинного обучения.

* **Модель**. Модель Персонализатора собирает все данные, полученные в результате изучения поведения пользователя, получая данные обучения из комбинации аргументов, которые вы отправляете вызовам "Ранг" и "Вознаграждение", и из поведения, определенного в политике обучения. 

## <a name="next-steps"></a>Дополнительная информация

Общие сведения об [использовании Персонализатора](where-can-you-use-personalizer.md).