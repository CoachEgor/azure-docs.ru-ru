---
title: Персонализатор. Принцип его работы
titleSuffix: Azure Cognitive Services
description: Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы "Ранг" и "Вознаграждение". Циклы обучения не зависят друг от друга.
author: diberry
manager: nitinme
ms.service: cognitive-services
ms.subservice: personalizer
ms.topic: conceptual
ms.date: 10/23/2019
ms.author: diberry
ms.openlocfilehash: 902bf84ebf090cf9f0f886ad1e774ff7bdfeca93
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2019
ms.locfileid: "73490755"
---
# <a name="how-personalizer-works"></a>Принцип работы Персонализатора

Персонализатор использует машинное обучение для обнаружения действия, которое следует применять в контексте. Каждый цикл обучения содержит модель, которая обучается исключительно на данных, отправленных ей через вызовы **Ранг** и **Вознаграждение**. Циклы обучения не зависят друг от друга. Создайте цикл обучения для каждой части или для поведения приложения, которое вы хотите персонализировать.

Для каждого цикла **вызовите API ранжирования** на основе текущего контекста с помощью:

* списка возможных действий (элементы содержимого, среди которых можно выбрать главное действие);
* списка [возможностей содержимого](concepts-features.md) (контекстуально релевантные данные, такие как пользователь, содержимое и контекст).

API **ранжирования** решает, какую из следующих моделей использовать.

* _Эксплойт_. Текущая модель для выбора оптимального действия на основе прошлых данных.
* _Обзор_. Выберите другое действие вместо самого верхнего действия.

API **вознаграждения**:

* собирает данные для обучения модели, записывая характеристики и награды каждого вызова "Ранг";
* Использует эти данные для обновления модели на основе конфигурации, указанной в _политике обучения_.

## <a name="architecture"></a>Архитектура

На следующем изображении показан архитектурный процесс вызовов "Ранг" и "Вознаграждение".

![замещающий текст](./media/how-personalizer-works/personalization-how-it-works.png "Принцип работы персонализации")

1. Для определения ранга действия Персонализатор использует внутреннюю модель ИИ.
1. Служба решает, использовать ли текущую модель или исследовать новые варианты для модели.  
1. Результат ранжирования отправляется в EventHub.
1. Когда Персонализатор получает вознаграждение, оно отправляется в EventHub. 
1. "Ранг" и "Вознаграждение" связаны друг с другом.
1. Модель ИИ обновляется на основе результатов корреляции.
1. Механизм вывода обновляется с помощью новой модели. 

## <a name="research-behind-personalizer"></a>Исследование вне Персонализатора

Персонализатор базируется на новейших научных и исследовательских разработках в области [обучения с подкреплением](concepts-reinforcement-learning.md), включая статьи, исследовательскую деятельность и текущие области исследований в Microsoft Research.

## <a name="terminology"></a>Терминология

* **Цикл обучения**. Вы можете создать цикл обучения для каждой части приложения, который может использовать преимущества персонализации. Если у вас есть несколько сред для персонализации, создайте цикл для каждой из них. 

* **Действия**. действия — это элементы содержимого, например продукты или рекламные акции, которые можно выбрать. Персонализатор выбирает главное действие, называемое _Вознаграждением_, которое будет отображаться для ваших пользователей, через API ранжирования. Каждое действие может содержать функции, отправленные с запросом ранжирования.

* **Контекст**: чтобы предоставить более точный рейтинг, укажите сведения о контексте, например:
    * ваш пользователь;
    * используемое устройство; 
    * Текущее время.
    * другие данные о текущей ситуации;
    * исторические данные о пользователе или контексте.

    Конкретное приложение может включать в себя другие контекстные сведения. 

* **[Features](concepts-features.md)** — единица сведений об элементе содержимого или контексте пользователя.

* **Награда**— это мера того, как пользователь ответил на действие, возвращенное API ранжирования, в виде показателя от 0 до 1. Бизнес-логика задает значение от 0 до 1 в ​​зависимости от того, как этот выбор помог достичь ваших бизнес-целей персонализации. 

* **Исследование**. служба персонализации изучает, когда, вместо того, чтобы возвращать лучшее действие, он выбирает другое действие для пользователя. Эта служба позволяет избежать смещения и застоя и может адаптироваться к текущему поведению пользователя путем изучения. 

* **Длительность эксперимента**. время, в течение которого служба персонализации ожидает получения наград, начиная с момента вызова ранжирования для этого события.

* **Неактивные события**. неактивное событие — это одно из событий, где вы вызывали Rank, но вы не уверены, что пользователь увидит результат, из-за принятия решений о клиентских приложениях. Неактивные события позволяют создавать и сохранять результаты персонализации, а решение об их отмене принимать позже, что не повлияет на модель машинного обучения.

* **Модель**. модель персонализации захватывает все данные о поведении пользователей, получая их сочетание с сочетаниями аргументов, отправляемых в вызовы ранжирования и вознаграждений, и с помощью поведения обучения, определенного политикой обучения. 

* **Политика обучения**. как Персонализация обучение модели на каждом событии будет определяться с помощью некоторых мета-параметров, влияющих на работу алгоритмов машинного обучения. Новые циклы персонализации будут начинаться с политики обучения по умолчанию, что может привести к умеренной производительности. При выполнении [оценок](concepts-offline-evaluation.md)Персонализация может создавать новые политики обучения, специально оптимизированные для вариантов использования вашего цикла. Персонализация будет значительно улучшена с помощью политик, оптимизированных для каждого конкретного цикла, созданного во время оценки.

## <a name="example-use-cases-for-personalizer"></a>Пример вариантов применения Персонализатора

* Уточнение и устранение неоднозначности намерений: обеспечьте удобство работы пользователей, когда их намерения неясны, предоставив им вариант, персонализированный для каждого пользователя.
* Подсказки по умолчанию для меню и параметров: в качестве первого шага бот предлагает самый вероятный элемент с учетом индивидуальных особенностей вместо безликого меню или списка альтернативных вариантов.
* Характеристики и стиль бота: в ботах, которые могут варьировать стиль, уровень детализации и стиль написания, рассмотрите возможность изменения этих характеристик с учетом индивидуальных особенностей.
* Содержимое уведомлений и предупреждений: решите, какой текст использовать для оповещений для более эффективного привлечения пользователей.
* Время уведомлений и предупреждений: изучите индивидуальные особенности относительно времени отправки уведомлений пользователям, чтобы эффективнее их привлекать.

## <a name="how-to-use-personalizer-in-a-web-application"></a>Использование Персонализатора в веб-приложении

Добавление цикла в веб-приложение включает в себя:

* Определение того, какой вариант взаимодействия необходимо персонализировать, какие действия и функции есть в наличии, какие функции контекста необходимо использовать и какое вознаграждение необходимо настроить.
* Добавление ссылки на пакет SDK для персонализации в приложении.
* Вызов API ранжирования на момент готовности к персонализации.
* Сохранение eventId. Позже вы отправите вознаграждение с помощью API вознаграждения.
1. Вызовите операцию "Активировать" для события, когда будете уверены, что пользователь увидел вашу персонализированную страницу.
1. Дождитесь, пока пользователь выберет ранжированное содержимое. 
1. Вызовите API вознаграждения, чтобы указать эффективность выходных данных API ранжирования.

## <a name="how-to-use-personalizer-with-a-chat-bot"></a>Использование Персонализатора с чат-ботом

В этом примере показано, как использовать персонализацию, чтобы сделать предложение по умолчанию вместо того, чтобы каждый раз отправлять пользователю несколько меню или вариантов.

* Получите [код](https://github.com/Azure-Samples/cognitive-services-personalizer-samples/tree/master/samples/ChatbotExample) для этого примера.
* Настройте решение бота. Опубликуйте приложение LUIS. 
* Управляйте вызовами API ранжирования и вознаграждения для бота.
    * Добавьте код для управления обработкой намерения LUIS. Если в качестве намерения с самым высоким показателем возвращается значение **Нет** или показатель этого намерения ниже порогового значения бизнес-логики, отправьте список намерений в Персонализатор для ранжирования намерений.
    * Покажите список намерений пользователю в качестве доступных для выбора ссылок, в котором первое намерение является намерением с высшим приоритетом из ответа API ранжирования.
    * Запишите выбор пользователя и отправьте его в вызов API вознаграждения. 

### <a name="recommended-bot-patterns"></a>Рекомендуемые шаблоны ботов

* Осуществляйте вызовы API ранжирования Персонализатора всякий раз, когда необходимо устранить неоднозначность вместо того, чтобы кэшировать результаты для каждого пользователя. Результат устранения неоднозначности намерения может изменяться со временем для одного пользователя. Если позволить API ранжирования исследовать расхождения, ускорится обучение в целом.
* Выберите взаимодействие, общее для большого числа пользователей, чтобы у вас было достаточно данных для персонализации. Например, вводные вопросы подходят лучше, чем меньшие уточнения глубоко в графе диалога, к которому могут получить доступ только небольшое число пользователей.
* Используйте вызовы API ранжирования, чтобы включить диалоги "первая рекомендация подходит", в которых пользователь получает запрос "Хотите ли вы X?" или "Вы имели ввиду X?" и пользователь может просто подтвердить, вместо того, чтобы предоставлять варианты пользователю, где ему нужно выбирать из меню. Например, пользователь: "Я хочу заказать кофе", бот: "Вы хотите двойной эспрессо?". Таким образом сигнал вознаграждения также надежный, так как он относится непосредственно к одному предложению.

## <a name="how-to-use-personalizer-with-a-recommendation-solution"></a>Использование Персонализатора с решением рекомендаций

Используйте ваш рекомендательный механизм, чтобы отфильтровать большой каталог до нескольких элементов, которые затем могут быть представлены как 30 возможных действий, отправляемых в API ранжирования.

Механизмы рекомендаций можно использовать с Персонализатором:

* Настройте [решение рекомендаций](https://github.com/Microsoft/Recommenders/). 
* При отображении страницы вызовите модель рекомендаций, чтобы получить краткий список рекомендаций.
* Вызовите персонализацию для ранжирования выходных данных решения рекомендаций.
* Отправьте отзыв о действии пользователя с помощью вызова API вознаграждения.


## <a name="pitfalls-to-avoid"></a>Типичные недочеты

* Не используйте Персонализатор, в котором персонализированное поведение невозможно отследить для всех пользователей, а только для конкретных пользователей, или который работает на основе списка альтернативных вариантов конкретного пользователя. Например, использование Персонализатора, чтобы предложить заказ первой пиццы из списка из 20 пунктов меню, полезно, но предложение контакта для вызова из списка контактов пользователей, когда необходима помощь по уходу за ребенком (например, "Бабушка"), сложно назвать персонализацией в базе пользователей.


## <a name="adding-content-safeguards-to-your-application"></a>Добавление средств защиты содержимого в приложение

Если приложение допускает значительные расхождения в содержимом, отображаемом для пользователей, и некоторое содержимое может быть небезопасно или не подходит для некоторых пользователей, вам следует заранее составить план и принять надлежащие меры по обеспечению безопасности, чтобы уберечь пользователей от просмотра неприемлемого содержимого. Самый лучший шаблон для реализации мер безопасности:
    * Получите список действий для ранжирования.
    * Отфильтруйте действия, неприемлемые для аудитории.
    * Ранжируйте только эти приемлемые действия.
    * Отобразите действие с высшим рейтингом для пользователя.

В некоторых архитектурах приведенную выше последовательность может быть трудно реализовать. В этом случае есть альтернативный подход к реализации мер безопасности после ранжирования, но необходимо выполнить подготовку, чтобы действия, которые выходят за рамки мер по обеспечению безопасности, не использовались для обучения модели Персонализатора.

* Получите список действий для ранжирования, деактивировав обучение.
* Ранжируйте действия.
* Проверьте, является ли действие с высшим приоритетом приемлемым.
    * Если оно является приемлемым, активируйте обучение для этого ранжирования, а затем покажите его пользователю.
    * Если это действие не является приемлемым, не активируйте обучение для этого ранжирования и с использованием логики или альтернативных подходов примите решение о том, что следует показывать пользователю. Даже если используется второй вариант с высшим приоритетом, не активируйте обучение для этого ранжирования.

## <a name="verifying-adequate-effectiveness-of-personalizer"></a>Проверка эффективности Персонализатора

Периодически выполняя [автономные оценки](how-to-offline-evaluation.md), вы можете отслеживать эффективность Персонализатора.

## <a name="next-steps"></a>Дальнейшие действия

Общие сведения об [использовании Персонализатора](where-can-you-use-personalizer.md).
Выполнение [автономных вычислений](how-to-offline-evaluation.md)
