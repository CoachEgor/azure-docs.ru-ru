---
title: Настройка Персонализатора
description: Конфигурация сервиса включает в себя то, как сервис рассматривает результаты, как часто он исследует, как часто переобучается модель и сколько данных хранится.
ms.topic: conceptual
ms.date: 02/19/2020
ms.openlocfilehash: ac31a9f907defeb44dbd4748a4395d3aec34d30c
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79219360"
---
# <a name="configure-personalizer-learning-loop"></a>Настройка цикла обучения персонализатора

Конфигурация сервиса включает в себя то, как сервис рассматривает результаты, как часто он исследует, как часто переобучается модель и сколько данных хранится.

Нанастройка цикла обучения на странице **Конфигурации** на портале Azure для этого ресурса Personalizer.

<a name="configure-service-settings-in-the-azure-portal"></a>
<a name="configure-reward-settings-for-the-feedback-loop-based-on-use-case"></a>

## <a name="configure-rewards-for-the-feedback-loop"></a>Настройка наград за цикл обратной связи

Настройте службу для использования наград в учебном цикле. Изменения в следующих значениях сбросить текущую модель Personalizer и переучивать ее за последние 2 дня данных.

> [!div class="mx-imgBorder"]
> ![Настройка значений вознаграждения для цикла обратной связи](media/settings/configure-model-reward-settings.png)

|Значение|Назначение|
|--|--|
|Время ожидания результата|Задает продолжительность времени, во время которого Персонализатор будет собирать результаты значений для вызова ранжирования, начиная с момента, когда вызов ранжирования происходит. Это значение устанавливается, спрашивая: "Как долго Personalizer должен ждать награды звонки?" Любой результат, полученный после этого окна, будет зарегистрирован, но не будет использоваться для обучения.|
|Результат по умолчанию|Если в течение времени ожидания результата, связанного с вызовом ранжирования, Персонализатор не получит результативный вызов, Персонализатор назначит результат по умолчанию. По умолчанию и в большинстве сценариев Вознаграждение по умолчанию равен нулю (0).|
|Агрегирование результата|Если за один и тот же вызов API ранжирования получено несколько результатов, используется следующий метод агрегации: **сумма** или **самое раннее**. Самое раннее выбирает самую раннюю полученную оценку и отклоняет остальные. Это полезно, если вы хотите уникальную награду среди возможных дубликатов звонков. |

После изменения этих значений, убедитесь, что выбрать **Сохранить**.

## <a name="configure-exploration-to-allow-the-learning-loop-to-adapt"></a>Настройка исследования, чтобы позволить циклу обучения адаптироваться

Персонализация позволяет открывать новые закономерности и адаптироваться к изменениям поведения пользователей с течением времени, изучая альтернативы, а не используя прогноз обученной модели. Значение **исследования** определяет, какой процент вызовов ранга отвечает с помощью исследования.

Изменения в этом значении сбросить текущую модель Personalizer и переучивают ее за последние 2 дня.

![Значение исследования определяет, какой процент вызовов ранга отвечает с помощью разведки](media/settings/configure-exploration-setting.png)

После изменения этого значения, убедитесь, что выбрать **Сохранить**.

<a name="model-update-frequency"></a>

## <a name="configure-model-update-frequency-for-model-training"></a>Настройка модели обновления частоты для обучения модели

**Частота обновления модели** устанавливает частоту, как часто обучается модель.

|Настройка частоты|Назначение|
|--|--|
|1 минута|Частоты одноминутного обновления полезны при **отладке** кода приложения с помощью Personalizer, выполнения демонстраций или интерактивного тестирования аспектов машинного обучения.|
|15 минут|Частоты обновления высокой модели полезны для ситуаций, когда требуется **внимательно отслеживать изменения** в поведении пользователей. Это могут быть сайты с новостями, вирусным содержимым или торговлей в режиме реального времени. В таких сценариях модель можно обновлять каждые 15 минут. |
|1 час|В большинстве других случаев целесообразно задать меньшую частоту обновления.|

![Параметр "Частота обновления модели" задает частоту повторного обучения новой модели Персонализатора.](media/settings/configure-model-update-frequency-settings-15-minutes.png)

После изменения этого значения, убедитесь, что выбрать **Сохранить**.

## <a name="data-retention"></a>Хранение данных

**Период хранения данных** устанавливает, сколько дней Персонализатор хранит журналы данных. Журналы прошлых данных необходимы для выполнения [автономных вычислений](concepts-offline-evaluation.md), которые используются для измерения эффективности Персонализатора и оптимизации политики обучения.

После изменения этого значения, убедитесь, что выбрать **Сохранить**.

<a name="clear-data-for-your-learning-loop"></a>

## <a name="settings-that-include-resetting-the-model"></a>Настройки, включающие сброс модели

Следующие действия включают немедленную переподготовку модели с данными за последние 2 дня.

* Выигрыш
* Исследование

Чтобы [очистить](how-to-manage-model.md) все данные, используйте страницу «Модель и настройки обучения».

## <a name="next-steps"></a>Дальнейшие действия

[Узнайте, как управлять моделью](how-to-manage-model.md)
