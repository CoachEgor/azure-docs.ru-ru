---
title: Что такое Azure Content Moderator?
titleSuffix: Azure Cognitive Services
description: Узнайте, как использовать Content Moderator для отслеживания, пометки, оценки и фильтрации неподходящего материала, создаваемого пользователями.
services: cognitive-services
author: PatrickFarley
manager: nitinme
ms.service: cognitive-services
ms.subservice: content-moderator
ms.topic: overview
ms.date: 07/03/2019
ms.author: pafarley
ms.openlocfilehash: a78a92a33075a97ddadb2e1fe677b7ded541d12c
ms.sourcegitcommit: 7c4de3e22b8e9d71c579f31cbfcea9f22d43721a
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/26/2019
ms.locfileid: "68565590"
---
# <a name="what-is-azure-content-moderator"></a>Что такое Azure Content Moderator?

API Azure Content Moderator — это когнитивная служба, которая проверяет текст, изображения и видео на наличие материалов, потенциально оскорбительных, представляющих риск или нежелательных по иным причинам. При обнаружении таких материалов служба применяет к содержимому соответствующие метки (флаги). Затем приложение может обрабатывать помеченное содержимое для обеспечения соответствия нормативным требованиям или оставлять его как предполагаемую среду для пользователей. Сведения о том, что означают различные флаги содержимого, см. в разделе об [API модерации](#moderation-apis).

## <a name="where-it-is-used"></a>Сценарии использования

Ниже приведены несколько сценариев, в которых разработчик программного обеспечения или команда используют Content Moderator:

- интернет-магазины с модерацией каталогов продукции и создаваемого пользователями содержимого;
- компании-разработчики игр, которые модерируют создаваемые пользователями игровые артефакты и чаты;
- социальные платформы для обмена сообщениями с модерацией изображений, текста и видео, добавляемых пользователями;
- корпоративные медиакомпании, внедряющие централизованную модерацию своего содержимого;
- поставщики образовательных решений K-12, фильтрующие неуместное содержимое для учащихся и преподавателей.

> [!NOTE]
> Вы не можете использовать Content Moderator для проверки изображений на наличие сцен противозаконной эксплуатации детей. Однако уполномоченные организации могут использовать [облачную службу PhotoDNA](https://www.microsoft.com/photodna "Microsoft PhotoDNA Cloud Service") для этих целей.

## <a name="what-it-includes"></a>Компоненты

Служба Content Moderator состоит из нескольких API веб-службы, доступных через вызовы REST и пакет SDK для .NET. Она также содержит средство пользовательской проверки, с помощью которого человек может помочь службе и улучшить или оптимизировать ее функцию модерации.

## <a name="moderation-apis"></a>API модерации

В службу Content Moderator входят API модерации, которые проверяют содержимое на наличие потенциально неприемлемых или нежелательных материалов.

![Блок-схема API модерации в Content Moderator](images/content-moderator-mod-api.png)

Различные типы API модерации описаны в следующей таблице.

| Группа API | ОПИСАНИЕ |
| ------ | ----------- |
|[**Модерация текста**](text-moderation-api.md)| Просматривает текст на наличие оскорбительного содержимого, содержимого сексуального или непристойного характера, содержимого с ненормативной лексикой и персональными данными.|
|[**Пользовательские списки терминов**](try-terms-list-api.md)| Проверяет текст с использованием пользовательского списка терминов помимо встроенных терминов. Используйте пользовательские списки для блокировки или разрешения содержимого в соответствии с собственными политиками содержимого.|  
|[**Модерация изображений**](image-moderation-api.md)| Проверяет изображения на наличие непристойного содержимого или содержимого для взрослых, выявляет в изображениях текст с помощью функции распознавания текста, а также распознает лица.|
|[**Пользовательские списки изображений**](try-image-list-api.md)| Проверяет изображения с использованием пользовательского списка изображений. Используйте пользовательский список изображений для фильтрации экземпляров часто встречающегося содержимого, которое вы не хотите классифицировать еще раз.|
|[**Модерация видео**](video-moderation-api.md)| Проверяет видео на наличие непристойного содержимого или содержимого для взрослых и возвращает метки времени для указанного содержимого.|

## <a name="review-apis"></a>Просмотр API-интерфейсов

API проверки позволяют интегрировать работу конвейера модерации и модераторов-людей. Используйте операции [Задания](review-api.md#jobs), [Проверки](review-api.md#reviews) и [Рабочий процесс](review-api.md#workflows) для создания и автоматизации рабочих процессов с участием человека при помощи [средства проверки](#the-review-tool) (см. ниже).

> [!NOTE]
> API рабочих процессов еще недоступен в пакете SDK для .NET, но его уже можно использовать с конечной точкой REST.

![Блок-схема API проверки в Content Moderator](images/content-moderator-rev-api.png)

## <a name="the-review-tool"></a>Инструмент проверки

Служба Content Moderator также имеет [средство проверки](Review-Tool-User-Guide/human-in-the-loop.md), в котором находятся результаты проверки для обработки людьми. Пользовательские входные данные не обучают службу, но объединенная работа службы и команд пользовательской проверки позволяет разработчикам найти баланс между эффективностью и точностью. Средство проверки также имеет удобный интерфейс, в котором доступны разнообразные ресурсы Content Moderator.

![Домашняя страница средства пользовательской проверки Content Moderator](images/homepage.PNG)

## <a name="data-privacy-and-security"></a>Конфиденциальность и безопасность данных

Как и в случае со всеми другими Cognitive Services, разработчикам, использующим службу Content Moderator, следует учитывать политику корпорации Майкрософт касательно клиентских данных. Дополнительные сведения см. на [странице о Cognitive Services](https://www.microsoft.com/trustcenter/cloudservices/cognitiveservices) Центра управления безопасностью Майкрософт.

## <a name="next-steps"></a>Дополнительная информация

Инструкции по началу работы со службой Content Moderator см. в статье [Краткое руководство. Знакомство с Content Moderator](quick-start.md).