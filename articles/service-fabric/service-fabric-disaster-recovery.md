---
title: Аварийное аварийное восстановление Azure Service Fabric
description: Служба обслуживания Azure Предлагает возможности для борьбы со стихийными бедствиями. В этой статье описаны типы сбоев, которые могут возникать, и приведены способы их устранения.
author: masnider
ms.topic: conceptual
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: b29985d40ae3a1bf582099e998e000fed83460f6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79371653"
---
# <a name="disaster-recovery-in-azure-service-fabric"></a>Аварийное восстановление в Azure Service Fabric
Важнейшей частью обеспечения высокой доступности является обеспечение того, чтобы службы могли пережить все различные типы сбоев. Это особенно важно для сбоев, которые являются незапланированными и вне вашего контроля. 

В этой статье описаны некоторые распространенные режимы сбоев, которые могут быть катастрофами, если не смоделировать и управлять правильно. Он также обсуждает меры по смягчению последствий и действиям, которые необходимо предпринять в случае катастрофы в любом случае. Цель состоит в том, чтобы ограничить или исключить риск простоя или потери данных, когда происходят сбои, запланированные или иные.

## <a name="avoiding-disaster"></a>Предотвращение аварий
Основная цель Службы Azure Fabric — помочь вам смоделировать среду и службы таким образом, чтобы общие типы сбоев не были катастрофами. 

В целом существует два типа сценариев аварий/неудач:
- Сбои оборудования или программного обеспечения
- Проблемы с работоспособностью

### <a name="hardware-and-software-faults"></a>Сбои оборудования или программного обеспечения
Сбои оборудования и программного обеспечения — непредсказуемы. Самый простой способ выжить неисправностей работает больше копий службы через аппаратных или программных границ неисправностей. 

Например, если служба работает только на одной машине, отказ одной машины является катастрофой для этой службы. Простой способ избежать этой катастрофы заключается в том, чтобы убедиться, что служба работает на нескольких машинах. Тестирование также необходимо для обеспечения того, чтобы сбой одной машины не нарушал работу службы. Планирование емкости гарантирует, что экземпляр замены может быть создан в другом месте и что сокращение емкости не перегружает оставшиеся службы. 

Этот шаблон работает независимо от того, какой сбой вы пытаетесь предотвратить. Например, если вы обеспокоены сбоем SAN, вы столкнетесь с несколькими SANs. Если вы хотите избежать выхода из строя серверов и серверных стоек, используйте несколько серверов и серверных стоек. Если вас беспокоит потеря центров обработки данных, служба должна работать в нескольких регионах Azure, в нескольких зонах доступности Azure или в собственных центрах обработки данных. 

Когда служба охватывает несколько физических экземпляров (машины, стойки, центры обработки данных, регионы), вы все равно подвержены некоторым типам одновременных сбоев. Но одиночные и даже множественные сбои определенного типа (например, сбой одной виртуальной машины или сетевой ссылки) обрабатываются автоматически и поэтому больше не являются "катастрофой". 

Service Fabric предоставляет механизмы для расширения кластера и обрабатывает, возвращая неузлы и службы. Service Fabric также позволяет запускать многие экземпляры ваших служб, чтобы предотвратить незапланированные сбои, перерастающих в реальные катастрофы.

Могут быть причины, по которым развертывание достаточно большое, чтобы охватывать сбои, невозможно. Например, для этого может потребоваться больше аппаратных ресурсов, чем вы готовы заплатить по отношению к вероятности сбоя. Когда вы имеете дело с распределенными приложениями, дополнительные затраты на связь или воспроизведение состояния на географических расстояниях могут привести к неприемлемой задержке. Этот уровень отличается для каждого приложения. 

При конкретном сбое программного обеспечения неисправность может быть в службе, которую вы пытаетесь масштабировать. В этом случае больше копий не предотвращают катастрофу, так как условие сбоя коррелирует во всех экземплярах.

### <a name="operational-faults"></a>Проблемы с работоспособностью
Даже если служба располагается во множестве географических регионов с большим количеством избыточных данных, она по-прежнему может столкнуться с катастрофическими событиями. Например, кто-то может случайно перенастроить имя DNS для службы или удалить его направо. 

Например, предположим, что имеется служба Service Fabric с отслеживанием состояния и кто-то случайно ее удалил. Если нет каких-либо других смягчения, что услуга и все государства, что она была в настоящее время нет. Для этих типов функциональных аварий (ошибок) требуются другие методы устранения рисков и шаги для восстановления, отличные от обычных незапланированных сбоев. 

Наилучшим способом избежать такого рода эксплуатационных сбоев являются:
- Ограничьте оперативный доступ к окружающей среде.
- Строго проверяйте опасные операции.
- Навложете автоматизацию, предотвратите изменения руководства или вне диапазона и проверяем конкретные изменения в отношении среды перед их принятием.
- Убедитесь, что разрушительные операции являются "мягкими". Мягкие операции не всменяются немедленно или могут быть отменены в течение временного окна.

Service Fabric предоставляет механизмы для предотвращения эксплуатационных сбоев, такие как обеспечение [ролевой](service-fabric-cluster-security-roles.md) системы управления доступом для кластерных операций. Однако для предотвращения большинства таких функциональных сбоев требуются организационные усилия и другие методы. Service Fabric предоставляет механизмы для выживших эксплуатационных неисправностей, в первую очередь [резервного копирования и восстановления для государственных услуг.](service-fabric-backuprestoreservice-quickstart-azurecluster.md)

## <a name="managing-failures"></a>Обработка сбоев
Целью Service Fabric является автоматическое управление сбоями. Но для обработки некоторых типов сбоев службы должны иметь дополнительный код. Другие типы сбоев _не_ должны быть автоматически устранены по соображениям безопасности и непрерывности бизнеса. 

### <a name="handling-single-failures"></a>Обработка единичных сбоев
Единичные компьютеры могут выйти из строя по множеству причин. Иногда это аппаратные причины, такие как источники питания и сбои сетевого оборудования. а в других — сбои программного обеспечения. К ним относятся сбои операционной системы и самой службы. Service Fabric автоматически обнаруживает эти типы сбоев, в том числе случаи, когда машина становится изолированной от других машин из-за проблем с сетью.

Независимо от типа службы выполнение одного экземпляра приводит к простою службы, если по какой-либо причине происходит сбой этой копии. 

Для обработки любого сбоя, самое простое, что вы можете сделать, это убедиться, что ваши службы работают на более чем одном узлах по умолчанию. Для услуг без гражданства, убедитесь, что `InstanceCount` больше, чем 1. Для служб состояния минимальная рекомендация заключается в том, что `TargetReplicaSetSize` и `MinReplicaSetSize` оба установлены на 3. Запуск нескольких копий кода службы гарантирует, что служба может автоматически обработать любой единичный отказ. 

### <a name="handling-coordinated-failures"></a>Обработка координированных сбоев
Скоординированные сбои в кластере могут быть вызваны либо запланированными или незапланированными сбоями в инфраструктуре, либо сбоями в работе программного обеспечения. Service Fabric моделирует зоны инфраструктуры, в которых можно сделать скоординированные сбои в качестве *доменов неисправностей.* Области, которые будут испытывать скоординированные изменения программного обеспечения моделируются как *обновления доменов.* Для получения дополнительной информации о доменах неисправностей, обновлении доменов и топологии кластеров [см.](service-fabric-cluster-resource-manager-cluster-description.md)

По умолчанию Service Fabric учитывает неисправность и обновление доменов при планировании, где должны работать ваши службы. По умолчанию Service Fabric пытается убедиться, что ваши службы работают в нескольких доменах неисправности и обновления, так что в случае запланированных или незапланированных изменений ваши службы остаются доступными. 

Например, предположим, что отказ источника питания приводит к тому, что все машины на стойке выводят из строя одновременно. С несколькими копиями службы работает, потеря многих машин в неисправности домена сбой превращается в просто еще один пример одного сбоя для службы. Именно поэтому управление доменами неисправностей и обновления имеет решающее значение для обеспечения высокой доступности ваших услуг. 

При запуске службы Fabric в Azure домены сбоем и доменами обновления управляются автоматически. В других средах их может и не быть. Если вы строите свои собственные кластеры на месте, не забудьте сопоставить и спланировать макет домена неисправности правильно.

Области обновления полезны для моделирования областей, где программное обеспечение будет обновляться в то же время. Из-за этого домены обновления также часто определяют границы, в которых программное обеспечение упускается во время запланированных обновлений. Обновления Service Fabric и ваших служб следуют той же модели. Для получения дополнительной информации о обновлениях, обновлениях доменов и модели работы Service Fabric, которая помогает предотвратить непреднамеренные изменения, влияющие на кластер и службу, см.:

 - [Обновление приложения](service-fabric-application-upgrade.md)
 - [Учебник по обновлению приложений](service-fabric-application-upgrade-tutorial.md)
 - [Модель здоровья сервисной ткани](service-fabric-health-introduction.md)

Вы можете визуализировать макет кластера с помощью кластерной карты, представленной в [Service Fabric Explorer:](service-fabric-visualizing-your-cluster.md)

<center>

![Узлы распространяются по развидам в Service Fabric Explorer][sfx-cluster-map]
</center>

> [!NOTE]
> Моделирование областей сбоя, обновление, запуск многих экземпляров кода службы и состояния, правила размещения, чтобы убедиться, что ваши службы работают в разломах и обновления доменов, и встроенный мониторинг работоспособности — это лишь *некоторые* из функций, которые предоставляет Service Fabric для поддержания нормальных операционных проблем и сбоев, превращающихся в стихийные бедствия. 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a>Обработка одновременных сбоев оборудования или программного обеспечения
Мы говорили об отдельных неудачах. Как вы можете видеть, они просты в обращении как для служб без состояния, так и для служб состояния, просто сохраняя больше копий кода (и состояния), работая в разбое и обновлении доменов. 

Также возможно возникновение нескольких одновременных случайных сбоев. Это, скорее всего, приведет к простою или фактической катастрофы.


#### <a name="stateless-services"></a>Услуги без гражданства
В экземпляре для службы без состояния указывается нужное количество экземпляров, которые необходимо запустить. При сбое любого (или всех) экземпляров Service Fabric автоматически создается замена экземпляров на других узлах. Service Fabric продолжает создавать замены до тех пор, пока служба не вернется к желаемому количеству экземпляров.

Например, предположим, что служба `InstanceCount` без гражданства имеет значение -1. Это значение означает, что один экземпляр должен работать на каждом узлах кластера. Если некоторые из этих экземпляров не удаются, Служба Fabric обнаружит, что служба не находится в нужном состоянии, и попытается создать экземпляры на узлах, где они отсутствуют.

#### <a name="stateful-services"></a>Государственные услуги
Существует два типа государственных услуг:
- Состояние с упорным состоянием.
- Состояние с неупорным состоянием. (Государство хранится в памяти.)

Восстановление после сбоя службы stateful зависит от типа службы stateful, количества реплик службы и количества копий, сданных.

В службе состояния входящие данные реплицируются между репликами (первичными и любыми активными второстепенными). Если большинство реплик получают данные, данные считаются *завершенными кворумом.* (Для пяти реплик три будут кворумом.) Это означает, что в любой момент будет по крайней мере кворум реплик с последними данными. Если реплики терпят неудачу (скажем, два из пяти), мы можем использовать значение кворума для расчета, можем ли мы восстановиться. (Поскольку остальные три из пяти реплик все еще вверх, это гарантирует, что по крайней мере одна реплика будет иметь полные данные.)

При сходе кворума реплик объявляется в состоянии *потери кворума.* Скажем, раздел имеет пять реплик, что означает, что по крайней мере три гарантированно имеют полные данные. Если кворум (три из пяти) реплик выходит из строя, Service Fabric не может определить, достаточно ли у остальных реплик (два из пяти) данных для восстановления раздела. В тех случаях, когда Service Fabric обнаруживает потери кворума, ее поведение по умолчанию заключается в предотвращении дополнительных записей в раздел, объявлении потери кворума и ожидании восстановления кворума реплик.

Определение того, произошла ли катастрофа для службы состояния, а затем управление ею следует за тремя этапами:

1. Определение того, была ли потеря кворума или нет.
   
   Потеря кворума объявляется, когда большинство копий службы состояния не работает в то же время.
2. Определение того, является ли потеря кворума постоянной или нет.
   
   В большинстве случаев сбои являются временными. Процессы перезапускаются, узлы перезапускаются, виртуальные машины перезапускаются, а сетевые перегородки заживают. Иногда, однако, неудачи являются постоянными. Постоянны ли сбои или нет, зависит от того, сохраняется ли состояние службы или же она хранит ее только в памяти: 
   
   - Для служб без сохраненного состояния потеря кворума или нескольких реплик _немедленно_ приводит к постоянной потере кворума. Когда платформа Service Fabric обнаруживает потерю кворума в непостоянной службе с отслеживанием состояния, она немедленно переходит к шагу 3, объявляя (возможную) потерю данных. Переход к потере данных имеет смысл, потому что Service Fabric знает, что нет смысла ждать реплики, чтобы вернуться. Даже если они восстановятся, данные будут потеряны из-за неустоянного характера службы.
   - Для настойчивых служб состояния сбой кворума или нескольких реплик заставляет Service Fabric ждать возвращения реплик и восстановления кворума. Это приводит к сбою любых операций _записи_ в затронутые секции (или наборы реплик) службы. Тем не менее, считывание все еще может быть возможным с меньшими гарантиями согласованности. Время, которое служба Ожидает восстановления кворума по умолчанию, *бесконечно,* поскольку продолжение является (потенциальным) событием потери данных и несет в себе другие риски. Это означает, что Service Fabric не будет переходить к следующему шагу, если администратор не предпримет действия для объявления потери данных.
3. Определение потери данных и восстановление из резервных ups.

   Если потери кворума были объявлены (автоматически или в результате административных действий), служба Fabric и службы переходят к определению фактического утерянного данных. На данный момент, Service Fabric также знает, что другие реплики не возвращаются. Это решение принимается в момент прекращения ожидания восстановления потери кворума. Лучше всего заморозить службу и дождаться помощи администратора.
   
   Когда Service Fabric `OnDataLossAsync` вызывает метод, это всегда из-за _предполагаемой_ потери данных. Service Fabric всегда направляет этот вызов к _лучшей_ оставшейся реплике. Это любая реплика с лучшим показателем состояния. 
   
   Причина, по которой мы всегда _говорим, что предполагаемая_ потеря данных заключается в том, что оставшаяся реплика имеет все то же состояние, что и основной, когда кворум был потерян. Однако возможность сравнить состояние для Service Fabric или операторов отсутствует.     
   
   Что же дает типичная реализация метода `OnDataLossAsync`?
   1. Срабатывая журналы реализации `OnDataLossAsync` и отключаются все необходимые административные оповещения.
   1. Обычно реализация приостанавливается и ждет дальнейших решений и ручных действий. Это происходит потому, что даже при наличии резервных копирований, они, возможно, должны быть подготовлены. 
   
      Например, если две разные службы координируют информацию, эти резервные копирования, возможно, потребуется изменить, чтобы гарантировать, что после восстановления информация, о чем заботятся эти две службы, является последовательной. 
   1. Часто есть некоторые другие телеметрии или выхлопных газов от службы. Эти метаданные могут содержаться в других службах или в журналах. Эта информация может быть использована по мере необходимости, чтобы определить, были ли какие-либо вызовы, полученные и обработанные на первичном, которые не присутствовали в резервной копии или реплицировались в данную реплику. Эти вызовы могут быть воспроизведены или добавлены в резервную часть, прежде чем восстановление возможно.  
   1. Реализация сравнивает состояние оставшейся реплики с состоянием, содержащимся в любых доступных резервных копиях. Если вы используете надежные коллекции Service Fabric, для этого имеются [инструменты и процессы.](service-fabric-reliable-services-backup-restore.md) Цель состоит в том, чтобы увидеть, достаточно ли состояния в реплике, и увидеть, что резервное копирование может отсутствовать.
   1. После завершения сравнения и завершения восстановления (при необходимости) код службы должен **вернуться,** если были внесены какие-либо изменения состояния. Если реплика определила, что это лучшая доступная копия состояния и не внесла никаких изменений, код **возвращается ложным.** 
   
      Значение **истины** указывает на то, что любые _другие_ оставшиеся реплики могут теперь быть несовместимыми с этим. Они будут удалены и пересозданы из этой реплики. Значение **ложного** указывает на то, что никаких изменений состояния не было сделано, так что другие реплики могут сохранить то, что у них есть. 

Крайне важно, чтобы авторы служб ы практиковали потенциальные сценарии потери данных и сбоев до развертывания служб в производстве. Чтобы защититься от возможности потери данных, важно периодически [резервное копирование состояния](service-fabric-reliable-services-backup-restore.md) любого из ваших служб состояния в гео-излишним хранилище. 

Вы также должны убедиться, что у вас есть возможность восстановить состояние. Поскольку резервные копирования различных служб используются в разное время, необходимо обеспечить, чтобы после восстановления ваши службы имели последовательное представление друг о друге. 

Например, рассмотрим ситуацию, когда одна служба генерирует номер и хранит его, а затем отправляет его в другой сервис, который также хранит его. После восстановления вы можете обнаружить, что вторая служба имеет номер, а первая нет, потому что ее резервное копирование не включает эту операцию.

Если вы обнаружите, что оставшиеся реплики недостаточны для продолжения в сценарии потери данных, и вы не можете восстановить состояние службы с помощью телеметрии или выхлопных газов, частота резервных копий определяет наилучшую цель точки восстановления (RPO). Service Fabric предоставляет множество инструментов для тестирования различных сценариев сбоев, включая постоянный кворум и потерю данных, что требует восстановления от резервного копирования. Эти сценарии включены в состав инструментов тестируемости в Service Fabric, управляемых Службой анализа неисправностей. Для получения дополнительной информации об этих инструментах и шаблонах [см.](service-fabric-testability-overview.md) 

> [!NOTE]
> Системные службы также могут пострадать от потери кворума. Воздействие характерно для соответствующей службы. Например, потеря кворума в службе именования влияет на разрешение имен, в то время как потеря кворума в службе Failover Manager блокирует создание новых служб и сбоев. 
> 
> Службы системы Service Fabric следуют той же схеме, что и ваши службы для государственного управления, но мы не рекомендуем пытаться вывести их из потери кворума и привести к потенциальной потере данных. Вместо этого мы рекомендуем [вам обратиться за поддержкой,](service-fabric-support.md) чтобы найти решение, ориентированное на вашу ситуацию. Это, как правило, предпочтительнее просто ждать, пока вниз реплики возвращения.
>

#### <a name="troubleshooting-quorum-loss"></a>Потеря кворума по устранению неполадок

Реплики могут периодически снижаться из-за переходного отказа. Подождите некоторое время, как служба Ткань пытается воспитывать их. Если реплики были вниз для более чем ожидаемой продолжительности, следуйте этим действиям устранения неполадок:
- Реплики могут быть сбой. Проверьте отчеты о работоспособности уровня реплики и журналы приложений. Соберите аварийные свалки и примите необходимые меры для восстановления.
- Процесс реплики может стать безответным. Проинспектируйте журналы приложений, чтобы проверить это. Соберите процесс сброса, а затем остановить процесс безответа. Сервис Fabric создаст процесс замены и попытается вернуть реплику.
- Узлы, вмещающие реплики, могут быть недоумена. Перезапустите базовую виртуальную машину, чтобы поднять узлы.

Иногда может быть невозможно восстановить реплики. Например, диски не сработали или машины физически не отвечая. В этих случаях, Сервис Ткань должна быть сказано не ждать восстановления реплики.

Не *not* используйте эти методы, если потенциальная потеря данных недопустима для передачи сервиса в онлайн. В этом случае, все усилия должны быть сделаны для восстановления физических машин.

Следующие действия могут привести к потере данных. Проверьте, прежде чем следовать за ними.
   
> [!NOTE]
> Это _никогда не_ безопасно использовать эти методы, кроме как в целевой способ против конкретных разделов. 
>

- Используйте `Repair-ServiceFabricPartition -PartitionId` `System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` или API. Этот API позволяет указать идентификатор раздела для перехода от потери кворума и потенциальной потери данных.
- Если кластер сталкивается с частыми сбоями, которые приводят к тому, что службы переходят в состояние потери кворума, и _возможная потеря данных является приемлемой,_ указание соответствующего значения [quorumLossWaitDuration](https://docs.microsoft.com/powershell/module/servicefabric/update-servicefabricservice?view=azureservicefabricps) может помочь вашей службе автоматически восстановиться. Service Fabric будет ждать `QuorumLossWaitDuration` предоставленного значения (по умолчанию бесконечен) перед выполнением восстановления. Мы *не* рекомендуем этот метод, поскольку он может привести к непредвиденным потерям данных.

## <a name="availability-of-the-service-fabric-cluster"></a>Доступность кластера Service Fabric
В целом кластер Service Fabric представляет собой высокораспределенную среду без каких-либо отдельных точек сбоя. Сбой какого-либо одного узла не вызовет проблем с доступностью или надежностью для кластера, главным образом потому, что службы системы Service Fabric следуют тем же рекомендациям, которые были предоставлены ранее. То есть они всегда работают с тремя или более репликами по умолчанию, а системные службы, которые являются апостерами, работают на всех узлах. 

Базовые сетевые подключения Service Fabric и уровни определения сбоев являются полностью распределенными. Большинство системных служб могут быть перестроены на основе метаданных в кластере или повторно синхронизировать свое состояние из других мест. Доступность кластера может быть скомпрометирована, если системные службы попадут в ситуации кворума-потери, подобные описанным ранее. В этих случаях вы не сможете выполнять определенные операции в кластере (например, начать обновление или развертывание новых служб), но сам кластер все еще готов. 

Службы в запущенном кластере будут продолжать работать в этих условиях, если они не требуют записи в системные службы для продолжения работы. Например, если Failover Manager находится в убытке кворума, все службы будут продолжать работать. Но любые службы, которые не смогут автоматически перезапустить, потому что это требует участия Failover Manager. 

### <a name="failures-of-a-datacenter-or-an-azure-region"></a>Сбои в работе центра обработки данных или региона Azure
В редких случаях физический центр обработки данных может временно стать недоступен из-за потери питания или подключения к сети. В этих случаях кластеры Service Fabric, а также службы в таких центрах обработки данных или в регионе Azure будут недоступны. Тем не менее _данные сохраняются_. 

Просмотреть обновления сбоев для кластеров, запущенных в Azure, можно на [странице состояния Azure][azure-status-dashboard]. В крайне маловероятном случае частичного или полного уничтожения физического центра обработки данных любые размещенные там кластеры Service Fabric или службы внутри них могут быть потеряны. Эта потеря включает в себя любое состояние, не подкрепленное за пределами этого центра обработки данных или региона.

Существуют две различные стратегии выживания в постоянном или устойчивом сбое одного центра обработки данных или региона: 

- Запустите отдельные кластеры Service Fabric в нескольких таких регионах и используйте некоторый механизм для сбоя и сбоя между этими средами. Такая многокластерная активная/активная или активная/пассивная модель требует дополнительного кода управления и операций. Эта модель также требует координации резервных отслужб из служб в одном центре обработки данных или регионе, чтобы они были доступны в других центрах обработки данных или регионах, когда один из них не удается. 
- Запустите кластер Service Fabric, охватывающий несколько центров обработки данных или регионов. Минимальной поддерживаемой конфигурацией для этой стратегии являются три центра обработки данных или регионы. Но рекомендуется пять. 
  
  Эта модель требует более сложной топологии кластера. Однако преимущество заключается в том, что сбой одного центра обработки данных или региона преобразуется из аварийного в обычный сбой. Эти ошибки можно обрабатывать с помощью механизмов, которые применимы для кластеров в одном регионе. Домены неисправностей, обновления доменов и правил размещения Service Fabric обеспечивают распределение рабочих нагрузок, чтобы они передавали обычные сбои. 
  
  Для получения дополнительной информации о политиках, которые могут [Placement policies for Service Fabric services](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)помочь в работе служб в этом типе кластера, см.

### <a name="random-failures-that-lead-to-cluster-failures"></a>Случайные сбои, привехи к сбоям кластера
Сервис Ная фабрина имеет концепцию *семенных узлов.* Это узлы, которые поддерживают доступность базового кластера. 

Узлы семян помогают гарантировать, что кластер остается на подъеме, устанавливая договоры аренды с другими узлами и выступая в качестве тай-брейков во время определенных видов сбоев. Если случайные сбои удаляют большинство узлов семян в кластере и они не возвращаются быстро, кластер автоматически выключается. Затем кластер выходит из строя. 

В Azure поставщик ресурсов Service Fabric управляет конфигурациями кластеров Service Fabric. По умолчанию Поставщик ресурсов распределяет узлы семян по развиным и обновляет домены для *типа основного узла.* Если тип основного узла помечен как серебряный или золотой прочности, при удалении семенного узла (либо путем масштабирования в типе основного узла, либо путем ручного удаления), кластер будет пытаться продвинуть другой узло без семян из доступной емкости основного типа узла. Эта попытка не увенчанет неудачу, если у вас меньше доступной емкости, чем требуется уровень надежности кластера для основного типа узла.

В обоих автономных кластерах Service Fabric и Azure основным типом узлов является тип, который запускает семена. При определении типа основного узла Service Fabric автоматически использует количество узлов, предоставляемых путем создания до девяти узла семян и семи копий каждой системной службы. Если набор случайных сбоев вынимает большинство этих реплик одновременно, системные службы введут потери кворума. Если большинство начальных узлов выйдут из строя, работа кластера будет прекращена.

## <a name="next-steps"></a>Дальнейшие действия
- Узнайте, как смоделировать различные сбои с помощью [платформы тестируемости.](service-fabric-testability-overview.md)
- Ознакомьтесь с другими материалами по аварийному восстановлению и обеспечению высокой доступности. Корпорация Майкрософт опубликовала множество руководств по этим темам. Хотя некоторые из этих ресурсов относятся к конкретным методам использования в других продуктах, они содержат много общих рекомендаций, которые можно применить в контексте Service Fabric:
  - [Контрольный список доступности](/azure/architecture/checklist/resiliency-per-service)
  - [Отработка аварийного восстановления](../sql-database/sql-database-disaster-recovery-drills.md)
  - [Аварийное восстановление и высокий уровень доступности для приложений Azure][dr-ha-guide]
- Узнайте о [вариантах поддержки Service Fabric](service-fabric-support.md).


<!-- External links -->

[repair-partition-ps]: https://msdn.microsoft.com/library/mt163522.aspx
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: https://msdn.microsoft.com/library/azure/dn251004.aspx


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png
