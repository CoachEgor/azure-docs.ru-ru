---
title: Аварийное восстановление Service Fabric Azure
description: Azure Service Fabric предлагает возможности, необходимые для устранения всех типов сбоев. В этой статье описаны типы сбоев, которые могут возникать, и приведены способы их устранения.
author: masnider
ms.topic: conceptual
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: f9bde0f81dc364aaa09dc9763f2014d83f992371
ms.sourcegitcommit: f915d8b43a3cefe532062ca7d7dbbf569d2583d8
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/05/2020
ms.locfileid: "78298300"
---
# <a name="disaster-recovery-in-azure-service-fabric"></a>Аварийное восстановление в Azure Service Fabric
Для обеспечения высокого уровня доступности крайне важно гарантировать продолжение работы всех типов служб при любых сбоях. Это особенно важно в ситуациях незапланированных сбоев, которые находятся вне вашего контроля. В этой статье описываются некоторые часто встречающиеся виды сбоев, которые могут привести к авариям, если их не смоделировать и не взять под контроль должным образом. Также рассматриваются способы устранения рисков и действия при аварии, если она все таки произошла. Цель этого руководства — помочь ограничить или избежать простоя и потери данных, при которых возникают сбои, запланированные или случайные.

## <a name="avoiding-disaster"></a>Предотвращение аварий
Основная цель Service Fabric — помочь в моделировании среды и служб таким образом, чтобы общие типы сбоев не приводили к авариям. 

В основном существует два типа сценариев аварий и сбоев:

1. Сбои оборудования или программного обеспечения.
2. Проблемы с работоспособностью

### <a name="hardware-and-software-faults"></a>Сбои оборудования или программного обеспечения
Сбои оборудования и программного обеспечения — непредсказуемы. Самый простой способ предотвратить сбой — запускать несколько копий службы, распределенных на границах сбоя оборудования или программного обеспечения. Например, если служба выполняется только на одном конкретном компьютере, тогда сбой на таком компьютере приведет к аварии этой службы. Простой способ предотвратить этот сбой — убедиться, что служба действительно работает на нескольких компьютерах. Тестирование также необходимо, чтобы гарантировать, что сбой одного компьютера не нарушит работу выполняемой службы. Планирование ресурсов гарантирует, что можно создать экземпляр для замены в другом расположении и что снижение производительности не приведет к перегрузке оставшихся служб. Этот шаблон работает независимо от того, какой сбой вы пытаетесь предотвратить. Например, если выбран диапазон 10.0.0.0/20 для виртуальной сети, для пространства клиентских адресов можно выбрать 10.1.0.0/24. Если вы хотите избежать сбоев сети хранения данных, храните данные в нескольких сетях SAN. Если вы хотите избежать выхода из строя серверов и серверных стоек, используйте несколько серверов и серверных стоек. Если вы хотите предотвратить потерю центров обработки данных, службу следует запускать в нескольких регионах или центрах обработки данных Azure. 

При работе в таком режиме вы по-прежнему подвержены некоторым видам одновременных отказов, но при этом единичные и даже множественные сбои определенного типа (например, сбой одной виртуальной машины или сетевого соединения) обрабатываются автоматически, не приводя к аварии. Service Fabric предоставляет много механизмов развертывания кластера и управляет восстановлением работоспособности узлов и служб. Service Fabric также позволяет запускать несколько экземпляров служб во избежание аварий вследствие такого рода незапланированных сбоев.

Возможны ситуации, когда запуск развертывания, охватывающего все сбои, не представляется возможным. Например, может потребоваться больше аппаратных ресурсов, чем вы готовы оплатить, чтобы предотвратить сбои. При работе с распределенными приложениями дополнительные прыжки или репликация состояний между географическими регионами могут привести к неприемлемому уровню задержек. Этот уровень отличается для каждого приложения. В частности при сбоях программного обеспечения ошибка может возникнуть в службе, которую вы пытаетесь масштабировать. В этом случае дополнительные копии не предотвращают аварию, так как условие сбоя касается всех экземпляров.

### <a name="operational-faults"></a>Проблемы с работоспособностью
Даже если служба располагается во множестве географических регионов с большим количеством избыточных данных, она по-прежнему может столкнуться с катастрофическими событиями. Например, если кто-то случайно перенастроит DNS-имя службы или удалит его. Например, предположим, что имеется служба Service Fabric с отслеживанием состояния и кто-то случайно ее удалил. При отсутствии других планов по устранению рисков эта служба и все сведения о ее состоянии исчезнут. Для этих типов функциональных аварий (ошибок) требуются другие методы устранения рисков и шаги для восстановления, отличные от обычных незапланированных сбоев. 

Лучшие способы предотвращения подобных функциональных ошибок:
1. Ограничение оперативного доступа к среде.
2. Строгий аудит небезопасных операций.
3. Внедрение автоматизации, запрет изменений вручную или внештатных изменений и проверка определенных изменений в фактической среде перед их применением.
4. Гарантирование, что разрушительные операции будут "мягкими". "Мягкие операции" не вступают в силу немедленно и могут быть отменены в рамках определенного временного окна.

Service Fabric предоставляет некоторые механизмы для предотвращения функциональных сбоев, например обеспечение управления доступом на основе [ролей](service-fabric-cluster-security-roles.md) для операций с кластером. Однако для предотвращения большинства таких функциональных сбоев требуются организационные усилия и другие методы. Service Fabric предоставляет ряд механизмов для преодоления функциональных ошибок, в частности резервное копирование и восстановление служб с отслеживанием состояния.

## <a name="managing-failures"></a>Обработка сбоев
Целью Service Fabric почти всегда является автоматическая обработка сбоев. Тем не менее для обработки некоторых типов сбоев службам потребуется дополнительный код. Другие типы сбоев _не_ должны обрабатываться автоматически по причинам обеспечения непрерывности бизнес-процессов и безопасности. 

### <a name="handling-single-failures"></a>Обработка единичных сбоев
Единичные компьютеры могут выйти из строя по множеству причин. В некоторых случаях — это сбои оборудования, как например сбои источников питания или сетевого оборудования, а в других — сбои программного обеспечения. К последним относятся сбои операционной системы и самих служб. Service Fabric автоматически обнаруживает эти типы сбоев, включая ситуации, когда компьютер становится изолирован от других компьютеров из-за проблем с сетью.

Независимо от типа службы выполнение одного экземпляра приводит к простою службы, если по какой-либо причине происходит сбой этой копии. 

Для обработки любого единичного отказа следует обеспечить выполнение служб на нескольких узлах по умолчанию. Для служб без отслеживания состояния это можно сделать, задав для параметра `InstanceCount` значение больше 1. Для служб с отслеживанием состояния минимальное рекомендуемое значение всегда должно быть `TargetReplicaSetSize`, а значение `MinReplicaSetSize` — по крайней мере 3. Запуск нескольких копий кода службы гарантирует, что служба может автоматически обработать любой единичный отказ. 

### <a name="handling-coordinated-failures"></a>Обработка координированных сбоев
Скоординированные сбои могут происходить в кластере вследствие любых запланированных или незапланированных сбоев инфраструктуры и изменений или запланированных изменений программного обеспечения. Service Fabric моделирует зоны инфраструктуры, в которых возникают скоординированные сбои, как домены сбоя. Области, в которых будут возникать координируемые изменения программного обеспечения, моделируются как домены обновления. Дополнительные сведения о доменах сбоя и обновления см. [в этом документе](service-fabric-cluster-resource-manager-cluster-description.md), в котором описываются определение и топология кластера.

По умолчанию Service Fabric учитывает домены сбоя и обновления при планировании места запуска служб. По умолчанию Service Fabric пытается обеспечить выполнение служб в нескольких доменах сбоя и обновления, чтобы в случае запланированных или незапланированных изменений службы оставались доступными. 

Например, предположим, что сбой источника питания вызывает одновременный сбой стойки компьютеров. При выполнении нескольких копий службы потеря нескольких компьютеров в домене сбоя будет являться примером единичного сбоя для данной службы. Именно поэтому управление доменами сбоя крайне важно для обеспечения высокого уровня доступности служб. При запуске Service Fabric в Azure домены сбоя обрабатываются автоматически. В других средах это может быть не так. При создании кластеров в локальной среде обеспечьте соответствующее сопоставление и планирование структуры домена сбоя.

Домены обновления можно использовать для моделирования областей, в которых программное обеспечение будет обновляться в одно время. По этой причине домены обновления также часто определяют границы, где программное обеспечение прекращает работу во время запланированного обновления. Обновления Service Fabric и ваших служб следуют той же модели. Дополнительные сведения о последовательном обновлении, доменах обновления и модели работоспособности Service Fabric, которая помогает предотвратить непредвиденные изменения, влияющие на кластер и службы, см. в следующих статьях:

 - [Обновление приложения](service-fabric-application-upgrade.md)
 - [Руководство по обновлению приложений Service Fabric с помощью Visual Studio](service-fabric-application-upgrade-tutorial.md)
 - [Общие сведения о наблюдении за работоспособностью системы в Service Fabric](service-fabric-health-introduction.md)

Для визуализации структуры кластера можно использовать схему кластера в [Service Fabric Explorer](service-fabric-visualizing-your-cluster.md):

<center>

![узлы, распределенные между доменами сбоя в Service Fabric Explorer][sfx-cluster-map]
</center>

> [!NOTE]
> Моделирование областей сбоя, последовательных обновлений, выполнение множества экземпляров кода и состояния службы, правила размещения для обеспечения выполнения служб на доменах сбоя и обновления, а также встроенный мониторинг работоспособности — только **некоторые** функции, которые Service Fabric предоставляет для предотвращения аварий вследствие обычных функциональных проблем и ошибок. 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a>Обработка одновременных сбоев оборудования или программного обеспечения
Выше речь шла о единичных сбоях. Как видите, можно легко обрабатывать сбои служб с отслеживанием состояния и без отслеживания за счет выполнения нескольких копий кода (и состояния) на доменах сбоя и обновления. Также возможно возникновение нескольких одновременных случайных сбоев. Такие сбои с большей вероятностью могут привести к фактической аварии.


### <a name="random-failures-leading-to-service-failures"></a>Случайные сбои, вызывающие сбои службы

#### <a name="stateless-services"></a>Службы без отслеживания состояния
`InstanceCount` для службы укажите необходимое количество экземпляров, которые должны выполняться. Если любые (или все) экземпляры завершаются сбоем, Service Fabric ответит, автоматически создавая замещающие экземпляры на других узлах. Service Fabric продолжит создавать замены до тех пор, пока служба не вернется к нужному количеству экземпляров.
Другой пример: Если служба без отслеживания состояния имеет `InstanceCount`-1, то есть один экземпляр должен выполняться на каждом из узлов в кластере. Если некоторые из этих экземпляров были бы неудачными, Service Fabric обнаружит, что служба не находится в нужном состоянии, и попытается создать экземпляры на узлах, где они отсутствуют.

#### <a name="stateful-services"></a>Службы с отслеживанием состояния
Существует два типа служб с отслеживанием состояния:
1. Отслеживание состояния с сохранением состояния
2. С отслеживанием состояния с несохраняемым состоянием (состояние хранится в памяти)

Восстановление после сбоя службы с отслеживанием состояния зависит от типа службы с отслеживанием состояния и количества реплик, которые имела служба, и количества сбоев.

Что такое кворум?
В службе с отслеживанием состояния входящие данные реплицируются между репликами (первичной и активная вторичная реплика). Если большая часть реплик получает данные, данные считаются зафиксированным кворумом (для 5 реплик, 3 будет _кворумом_). Это означает, что в любой момент гарантируется, что будет существовать по крайней мере кворум реплик с последними данными. Если произошел сбой реплики (например, 2 из 5 реплик), можно использовать значение кворума, чтобы вычислить, можно ли выполнить восстановление (так как оставшиеся 3 из 5 реплик по-прежнему остаются включенными), гарантируется, что по крайней мере одна реплика будет иметь полные данные.

Что такое потери кворума?
При сбое кворума реплик секции объявляются так, чтобы быть в состоянии потери кворума. Предположим, что Секция имеет 5 реплик, что означает, что по меньшей мере 3 гарантирует полноту данных. Если кворум (3 из 5) реплик завершился неудачей, то Service Fabric не сможет определить, достаточно ли для восстановления секции данные оставшихся реплик (2 из 5).

Определение, случился ли сбой службы с отслеживанием состояния, и его обработка состоят из трех этапов:

1. Определение, произошла ли потеря кворума.
    - Потери кворума объявляются, когда большинство реплик службы с отслеживанием состояния переключается в одно и то же время.
2. Определение, является ли потеря кворума постоянной.
   - В большинстве случаев сбои являются временными. Перезапускаются процессы, узлы и виртуальные машины, а также выполняется автоматическое восстановление секций сети. Однако иногда сбои являются постоянными. 
     - Для служб без сохраненного состояния потеря кворума или нескольких реплик _немедленно_ приводит к постоянной потере кворума. Когда Service Fabric обнаруживает потери кворума в непостоянной службе с отслеживанием состояния, немедленно переходит к шагу 3 путем объявления (возможной) потери данных. Переход к потере данных имеет смысл, поскольку Service Fabric известно, что нет смысла в ожидании возврата реплик, так как даже если они были восстановлены из-за непостоянного характера службы, данные теряются.
     - Для постоянных служб с отслеживанием состояния сбой кворума или нескольких реплик приводит к тому, что Service Fabric дожидаться возврата реплик и восстановления кворума. Это приводит к сбою любых операций _записи_ в затронутые секции (или наборы реплик) службы. Тем не менее операции чтения по-прежнему могут выполняться с пониженным уровнем обеспечения согласованности. Период времени по умолчанию, на протяжении которого Service Fabric ожидает восстановления кворума, является бесконечным, так как в противном случае может возникнуть вероятность потери данных и другие риски.
3. Определение наличия фактической потери данных и восстановление из резервных копий
   
   Когда Service Fabric вызывает метод `OnDataLossAsync`, это всегда происходит по причине _возможной_ потери данных. Service Fabric всегда направляет этот вызов к _лучшей_ оставшейся реплике. Это любая реплика с лучшим показателем состояния. Данные считаются _потенциально_ утерянными, так как возможно, что оставшаяся реплика фактически имеет состояние, аналогичное состоянию первичной реплики перед ее выходом из строя. Однако возможность сравнить состояние для Service Fabric или операторов отсутствует. На этом этапе Service Fabric также определяет, что реплики не будут восстановлены. Это решение принимается в момент прекращения ожидания восстановления потери кворума. Лучше всего заморозить службу и дождаться помощи администратора. Что же дает типичная реализация метода `OnDataLossAsync`?
   1. Во-первых, запись о запуске `OnDataLossAsync` и запуск необходимых административных оповещений.
   1. Обычно на этом этапе следует ожидать дальнейших решений и выполнения действий вручную. Ведь даже если резервные копии доступны, их нужно подготовить. Например, если две разные службы обмениваются данными, их резервные копии может потребоваться изменить, чтобы обеспечить согласованность этих данных после выполнения восстановления. 
   1. Часто также существует другая телеметрия или данные, получаемые от службы. Эти метаданные могут содержаться в других службах или в журналах. Эти сведения можно использовать для определения того, были ли получены и обработаны в первичной реплике вызовы, которые отсутствовали в резервной копии либо были реплицированы в эту конкретную реплику. Может потребоваться воспроизвести или добавить эти данные к резервной копии, прежде чем восстановление станет возможным.  
   1. Сравнения состояния оставшейся реплики с состоянием в доступных резервных копиях. При использовании надежных коллекций Service Fabric для этого можно использовать средства и процедуры, описанные в [этой статье](service-fabric-reliable-services-backup-restore.md). Это необходимо, чтобы определить, является ли состояние в реплике достаточным, а также какие данные могут отсутствовать в резервной копии.
   1. После завершения сравнения и при необходимости выполнения восстановления код службы должен вернуть значение true, если были внесены изменения состояния. Если реплика определяется как лучшая доступная копия состояния и изменения не вносятся, возвращается значение false. Значение true указывает, что все _остальные_ оставшиеся реплики теперь не согласованы с этой репликой. Они будут удалены и пересозданы из этой реплики. Значение false указывает, что не было внесено никаких изменений состояния, поэтому другие реплики можно оставить. 

Очень важно, чтобы разработчики службы смоделировали потенциальную потерю данных и сценарии сбоев, прежде чем развертывать службы в рабочей среде. Чтобы избежать возможной потери данных, важно периодически выполнять [резервное копирование состояния](service-fabric-reliable-services-backup-restore.md) служб с отслеживанием состояния в любое геоизбыточное хранилище. Также необходимо убедиться, что имеется возможность его восстановить. Поскольку резервные копии различных служб создаются в разное время, необходимо убедиться, что после восстановления службы имеют согласованное представление друг о друге. Например, рассмотрим ситуацию, где одна служба создает число и сохраняет его, а затем отправляет его в другую службу, которая также его сохраняет. После восстановления может выясниться, что вторая служба сохранила номер, а первая нет, так как ее резервное копирование не предусматривает этой операции.

Если оставшихся реплик недостаточно для восстановления в случае потери данных и невозможно восстановить состояние службы из данных телеметрии или выходных данных, частота резервного копирования определяет лучшую целевую точку восстановления (RPO). Service Fabric предоставляет множество средств для тестирования различных сценариев сбоя, включая постоянный кворум и потерю данных, при которой требуется восстановление из резервной копии. Эти сценарии включены как часть средств тестирования Service Fabric, управляемых службой анализа сбоев. Дополнительные сведения об этих средствах и шаблонах см. [здесь](service-fabric-testability-overview.md). 

> [!NOTE]
> Системные службы также могут испытывать потерю кворума, причем серьезность влияния зависит от конкретной службы. Например, потеря кворума в службе именования влияет на разрешение имен, тогда как потеря кворума в службе диспетчера отработки отказа блокирует создание службы и переход на другой ресурс. Хотя системные службы Service Fabric следуют тому же шаблону, что и службы для управления состоянием, не рекомендуем пытаться переместить их за пределы потери кворума в состояние потенциальной потери данных. Вместо этого рекомендуется [обратиться за помощью](service-fabric-support.md) в поиске решения, применимого конкретно к вашей ситуации.  Обычно достаточно дождаться возврата реплик в работоспособное состояние.
>

#### <a name="troubleshooting-quorum-loss"></a>Устранение потерь кворума

Реплики могут периодически работать из-за временной ошибки. Подождите некоторое время, пока Service Fabric попытается их перенести. Если реплики были отключены в течение более чем ожидаемого времени, выполните следующие действия по устранению неполадок.
- Реплики могут быть аварийными. Проверьте отчеты о работоспособности на уровне реплик и журналы приложений. Собирайте аварийные дампы и примите необходимые меры для восстановления.
- Процесс реплики мог перестать отвечать на запросы. Проверьте журналы приложений, чтобы проверить это. Собирайте дамп процесса, а затем завершайте процесс, не отвечающий на запросы. Service Fabric создаст процесс замены и попытается восстановить реплику.
- Узлы, на которых размещены реплики, могут быть отключены. Перезапустите базовую виртуальную машину, чтобы отобразить узлы.

Возможны ситуации, когда невозможно восстановить реплики. Например, возможно, произошел сбой дисков или компьютеры физически не отвечают. В таких случаях Service Fabric необходимо сообщить, чтобы не ждать восстановления реплики.
НЕ используйте эти методы, если потенциальная потеря данных неприемлема для перевода службы в оперативный режим. в этом случае необходимо выполнить все усилия по восстановлению физических компьютеров.

Следующие шаги могут привести к утере данных. прежде чем приступать к их выполнению, убедитесь в следующем.
   
> [!NOTE]
> Использовать эти методы, кроме, в качестве целевого способа для конкретных секций _нельзя_ . 
>

- Используйте `Repair-ServiceFabricPartition -PartitionId` или `System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)` API. Этот API позволяет указать идентификатор секции для восстановления из Куорумлосс с возможной потерей данных.
- Если кластер сталкивается с частыми сбоями, в результате чего службы переходят в состояние потери кворума, и возможная _потеря данных приемлема_, указание соответствующего значения [куорумлоссваитдуратион](https://docs.microsoft.com/powershell/module/servicefabric/update-servicefabricservice?view=azureservicefabricps) может помочь в автоматическом восстановлении службы. Service Fabric будет ждать предоставленного Куорумлоссваитдуратион (по умолчанию бесконечно) перед выполнением восстановления. Этот метод _не рекомендуется_ , поскольку это может привести к непредвиденным потерям данных.

## <a name="availability-of-the-service-fabric-cluster"></a>Доступность кластера Service Fabric
Как правило, сам по себе кластер Service Fabric является высоко распределенной средой без единичных точек отказа. Сбой одного из узлов не приведет к проблемам доступности или надежности кластера, в основном в связи с тем, что системные службы Service Fabric следуют тем же правилам: всегда выполняется не менее трех реплик по умолчанию и эти системные службы без отслеживания состояния выполняются на всех узлах. Базовые сетевые подключения Service Fabric и уровни определения сбоев являются полностью распределенными. Большинство системных служб могут быть перестроены на основе метаданных в кластере или повторно синхронизировать свое состояние из других мест. Доступность кластера может быть нарушена, если системные службы окажутся в ситуации потери кворума, как описано выше. В таких случаях вы не сможете выполнять определенные операции в кластере, такие как запуск обновлений или развертывание новых служб, но сам кластер по-прежнему будет работать. В этих условиях уже запущенные службы продолжают работу, если только им не требуется выполнять операции записи в системные службы, чтобы продолжать работу. Например, если диспетчер отработки отказов теряет кворум, все службы продолжат работу, но те службы, работа которых завершилась сбоем, не смогут автоматически перезапуститься, поскольку для этого требуется участие диспетчера отработки отказов. 

### <a name="failures-of-a-datacenter-or-azure-region"></a>Сбои в центре обработки данных или регионе Azure
В редких случаях физические центры обработки данных могут стать временно недоступными из-за отключения питания или потери сетевого подключения. В этих случаях кластеры Service Fabric, а также службы в таких центрах обработки данных или в регионе Azure будут недоступны. Тем не менее _данные сохраняются_. Для кластеров, работающих в Azure, можно просматривать обновления на [странице состояния Azure][azure-status-dashboard]. В крайне маловероятном случае полного или частичного разрушения физического центра обработки данных будут потеряны все размещенные в нем кластеры Service Fabric вместе со службами. Сюда входят все состояния, для которых не были созданы резервные копии за пределами этого центра обработки данных или региона.

Есть две разные стратегии предотвращения постоянного или неустранимого сбоя в одном центре обработки данных или регионе. 

1. Запустите отдельные кластеры Service Fabric в нескольких регионах и используйте механизм для отработки отказа и восстановления размещения между этими средами. Для такой мультикластерной модели типа "активный — активный" или "активный — пассивный" требуется дополнительный код для управления и операций. Также требуется координация резервных копий служб в одном центре обработки данных или регионе, чтобы они были доступны в других центрах обработки данных или регионах в случае сбоя. 
2. Запустите кластер Service Fabric, охватывающий несколько центров обработки данных или регионов. Минимальные требования для такой конфигурации — три центра обработки данных или региона. Но рекомендуется пять. Это предполагает более сложную топологию кластера. Однако преимуществом такой модели является тот факт, что сбой в одном центре обработки данных или регионе преобразуется из аварии в обычный сбой. Эти ошибки можно обрабатывать с помощью механизмов, которые применимы для кластеров в одном регионе. Домены сбоя, домены обновления и правила размещения Service Fabric гарантируют, что нагрузки распределяются таким образом, чтобы выдерживать обычные сбои. Дополнительные сведения о политиках, которые помогают работать службам в таком типе кластеров, см. в статье [Политики размещения для служб Service Fabric](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)

### <a name="random-failures-leading-to-cluster-failures"></a>Случайные сбои, вызывающие сбои кластеров
Service Fabric реализует концепцию начальных узлов. Это узлы, которые поддерживают доступность базового кластера. Эти узлы гарантируют работу кластера, арендуя другие узлы и выступая в роли прерывателя связи во время определенных сбоев сети. Если случайные сбои удаляют большинство начальных узлов в кластере и не возвращаются, то кольцо Федерации кластера сворачивается по мере утери кворума начального узла и сбоя кластера. В Azure поставщик ресурсов Service Fabric управляет конфигурациями кластера Service Fabric, и по умолчанию распространяет начальные узлы в домены сбоя и обновления типа первичного узла. Если первичный узел NodeType помечен как серебро или Золотой уровень устойчивости, то при удалении узла начального значения с помощью масштабирования в первичном NodeType или ручного удаления узла начального значения кластер попытается повысить другой доступный неначальный узел из основного узла NodeType. При наличии меньшего объема доступной емкости, чем требуется уровню надежности кластера для типа первичного узла, и не будет работать.

В автономных кластерах Service Fabric и в Azure первичный узел управляет начальными узлами. При определении типа первичного узла Service Fabric автоматически использует преимущество количества предоставленных узлов и создает до 9 начальных узлов и 7 реплик каждой системной службы. Если большинство этих реплик системных служб одновременно выйдут из строя в результате ряда случайных сбоев, системные службы потеряют кворум, как описано выше. Если большинство начальных узлов выйдут из строя, работа кластера будет прекращена.

## <a name="next-steps"></a>Дальнейшие действия
- Узнайте, как моделировать различные сбои с помощью [платформы тестирования](service-fabric-testability-overview.md)
- Ознакомьтесь с другими материалами по аварийному восстановлению и обеспечению высокой доступности. Корпорация Майкрософт опубликовала множество руководств по этим темам. Несмотря на то, что некоторые из этих документов посвящены конкретным методам для других продуктов, они содержат целый ряд общих практических рекомендаций, которые можно применять в контексте Service Fabric.
  - [Контрольный список для обеспечения доступности](/azure/architecture/checklist/resiliency-per-service)
  - [Отработка аварийного восстановления](../sql-database/sql-database-disaster-recovery-drills.md)
  - [Аварийное восстановление и высокий уровень доступности для приложений Azure][dr-ha-guide]
- [Сведения о вариантах поддержки Service Fabric](service-fabric-support.md)


<!-- External links -->

[repair-partition-ps]: https://msdn.microsoft.com/library/mt163522.aspx
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: https://msdn.microsoft.com/library/azure/dn251004.aspx


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png
