---
title: Общие шаблоны запросов в Azure Stream Analytics
description: В этой статье описываются несколько общих шаблонов запросов и макетов, которые полезны в Azure Stream Analyticsных заданиях.
services: stream-analytics
author: rodrigoaatmicrosoft
ms.author: rodrigoa
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/18/2019
ms.openlocfilehash: aa8bd6e89dd47c4e972a860691d1bc3779ba5bc7
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "75982315"
---
# <a name="common-query-patterns-in-azure-stream-analytics"></a>Общие шаблоны запросов в Azure Stream Analytics

Запросы в Azure Stream Analytics выражаются на языке запросов на основе SQL. Эти языковые конструкции описаны в [справочнике по языку запросов Stream Analytics](/stream-analytics-query/stream-analytics-query-language-reference). 

Структура запросов может выразить простую логику передачи данных событий из одного входного потока в выходное хранилище данных. Кроме того, это может привести к расширенному соответствию шаблону и временному анализу для вычисления статистических выражений в различных окнах времени, как в разделе [Создание решения IOT с помощью Stream Analytics](stream-analytics-build-an-iot-solution-using-stream-analytics.md) Guide. Можно объединять данные из нескольких входов для объединения потоковых событий, а также выполнять поиск по статическим эталонным данным, чтобы расширить значения событий. Можно также записывать данные в несколько выходов.

В этой статье описаны решения для нескольких распространенных шаблонов запросов, основанных на реальных сценариях.

## <a name="supported-data-formats"></a>Поддерживаемые форматы данных

Azure Stream Analytics поддерживает обработку событий в форматах CSV, JSON и Avro.

Данные JSON и Avro могут содержать сложные типы, такие как вложенные объекты (записи) или массивы. Дополнительные сведения о работе с этими сложными типами данных см. в статье [анализ данных JSON и Avro](stream-analytics-parsing-json.md) .

## <a name="simple-pass-through-query"></a>Простой передаваемый запрос

Простой передаваемый запрос можно использовать для копирования входных данных потока в выходные данные. Например, если поток данных, содержащий сведения об автомобилях в реальном времени, необходимо сохранить в базе данных SQL для анализа писем, то задание будет выполняться простым передаваемым запросом.

**Входные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выходные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Запрос**:

```SQL
SELECT
    *
INTO Output
FROM Input
```

Запрос **SELECT** * проецирует все поля входящего события и отправляет их в выходные данные. Аналогичным образом, **SELECT** можно также использовать только для проецирования обязательных полей из входных данных. В этом примере, *Если необходимо сохранить* только те поля *, которые необходимы* для сохранения, то эти поля можно указать в инструкции **SELECT** .

**Входные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выходные данные**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:04.0000000Z |

**Запрос**:

```SQL
SELECT
    Make, Time
INTO Output
FROM Input
```
## <a name="data-aggregation-over-time"></a>Агрегирование данных с течением времени

Для вычисления данных по временному окну данные можно объединить. В этом примере число вычислено за последние 10 минут для каждого конкретного автомобиля.

**Входные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выходные данные**:

| Производитель | Count |
| --- | --- |
| Make1 | 2 |
| Make2 | 1 |

**Запрос**:

```SQL
SELECT
    Make,
    COUNT(*) AS Count
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

Эта статистическая обработка группирует автомобили *, выполнив и* подсчитает их каждые 10 секунд. У выходных данных есть *Марка* и *количество* автомобилей, которые проходили через платный.

TumblingWindow — это оконная функция, используемая для группирования событий. Агрегирование можно применять ко всем сгруппированным событиям. Дополнительные сведения см. в разделе функции для работы с [окнами](stream-analytics-window-functions.md).

Дополнительные сведения о статистической обработке см. в разделе [агрегатные функции](/stream-analytics-query/aggregate-functions-azure-stream-analytics).

## <a name="data-conversion"></a>Преобразование данных

Данные можно привести в режиме реального времени с помощью метода **Cast** . Например, масса автомобиля может быть преобразован из типа **nvarchar (max)** в тип **bigint** и использоваться для числового вычисления.

**Входные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выходные данные**:

| Производитель | Вес |
| --- | --- |
| Make1 |3000 |

**Запрос**:

```SQL
SELECT
    Make,
    SUM(CAST(Weight AS BIGINT)) AS Weight
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

Используйте оператор **Cast** для указания типа данных. См. список поддерживаемых типов данных в [типах данных (Azure Stream Analytics)](/stream-analytics-query/data-types-azure-stream-analytics).

Дополнительные сведения о [функциях преобразования данных](/stream-analytics-query/conversion-functions-azure-stream-analytics).

## <a name="string-matching-with-like-and-not-like"></a>Совпадение строк с LIKE, а не LIKE

**Like** и **Not Like** можно использовать для проверки соответствия поля определенному шаблону. Например, можно создать фильтр, возвращающий только те печатные формы, которые начинаются с буквы "A" и заканчиваются цифрой 9.

**Входные данные**:

| Производитель | License_plate | Время |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Выходные данные**:

| Производитель | License_plate | Время |
| --- | --- | --- |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Запрос**:

```SQL
SELECT
    *
FROM
    Input TIMESTAMP BY Time
WHERE
    License_plate LIKE 'A%9'
```

Чтобы проверить значение поля **License_plate** , используйте инструкцию **Like** . Оно должно начинаться с буквы "A" и содержать любую строку из нуля или более символов и заканчиваться номером 9.

## <a name="specify-logic-for-different-casesvalues-case-statements"></a>Указание логики для различных случаев и значений (операторы CASE)

Операторы **case** могут предоставлять различные вычисления для разных полей на основе определенного критерия. Например, можно назначить полосу "A" автомобилям *Make1* и Lane "B" в любые другие дела.

**Входные данные**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходные данные**:

| Производитель |Dispatch_to_lane | Время |
| --- | --- | --- |
| Make1 |Конкретного |2015-01-01T00:00:01.0000000Z |
| Make2 |& |2015-01-01T00:00:02.0000000Z |

**Решение**.

```SQL
SELECT
    Make
    CASE
        WHEN Make = "Make1" THEN "A"
        ELSE "B"
    END AS Dispatch_to_lane,
    System.TimeStamp() AS Time
FROM
    Input TIMESTAMP BY Time
```

Выражение **case** сравнивает выражение с набором простых выражений, чтобы определить его результат. В этом примере транспортные средства *Make1* передаются в полосу "A", а транспортные и другие делаются в полосе "B".

Дополнительные сведения см. в разделе [выражение CASE](/stream-analytics-query/case-azure-stream-analytics).

## <a name="send-data-to-multiple-outputs"></a>Отправка данных на несколько выходов

Для вывода данных в различные приемники вывода можно использовать несколько инструкций **SELECT** . Например, один **вариант SELECT** может выводить оповещение на основе порогового значения, в то время как другой может выводить события в хранилище BLOB-объектов.

**Входные данные**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходные ArchiveOutput**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходные алертаутпут**:

| Производитель | Время | Count |
| --- | --- | --- |
| Make2 |2015-01-01T00:00:10.0000000Z |3 |

**Запрос**:

```SQL
SELECT
    *
INTO
    ArchiveOutput
FROM
    Input TIMESTAMP BY Time

SELECT
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count]
INTO
    AlertOutput
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING
    [Count] >= 3
```

Предложение **Into** сообщает Stream Analytics, в какой из выходных данных записывать данные. Первый объект **SELECT** определяет передаваемый запрос, который получает данные из входных данных и отправляет их в выход с именем **ArchiveOutput**. Второй запрос выполняет некоторые простые статистические вычисления и фильтрацию перед отправкой результатов в нисходящий вывод системы предупреждений с именем **алертаутпут**.

Обратите внимание, что предложение **with** можно использовать для определения нескольких блоков вложенных запросов. Этот параметр имеет преимущество при открытии меньшего числа модулей чтения для источника входных данных.

**Запрос**:

```SQL
WITH ReaderQuery AS (
    SELECT
        *
    FROM
        Input TIMESTAMP BY Time
)

SELECT * INTO ArchiveOutput FROM ReaderQuery

SELECT 
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count] 
INTO AlertOutput 
FROM ReaderQuery
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING [Count] >= 3
```

Дополнительные сведения см. в [предложении **with** ](/stream-analytics-query/with-azure-stream-analytics).

## <a name="count-unique-values"></a>Число уникальных значений

**Count** и **DISTINCT** можно использовать для подсчета количества уникальных значений полей, отображаемых в потоке в течение временного интервала. Запрос можно создать, чтобы вычислить количество уникальных пошаговых *машин,* прошедших через платный стенд, в 2-секундном окне.

**Входные данные**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Проверки**

| Count_make | Время |
| --- | --- |
| 2 |2015-01-01T00:00:02.000Z |
| 1 |2015-01-01T00:00:04.000Z |

**Выбор**

```SQL
SELECT
     COUNT(DISTINCT Make) AS Count_make,
     System.TIMESTAMP() AS Time
FROM Input TIMESTAMP BY TIME
GROUP BY 
     TumblingWindow(second, 2)
```

Функция **Count (DISTINCT)** возвращает количество уникальных значений в столбце **создать** в пределах временного интервала.
Дополнительные сведения см. в разделе [агрегатная функция **Count** ](/stream-analytics-query/count-azure-stream-analytics).

## <a name="calculation-over-past-events"></a>Вычисление по прошлым событиям

Функцию **Lag** можно использовать для просмотра прошлых событий в течение временного интервала и сравнения их с текущим событием. Например, можно выпустить текущий автомобиль, если он отличается от последнего автомобиля, который проходил через платный звонок.

**Входные данные**:

| Производитель | Время |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Выходные данные**:

| Производитель | Время |
| --- | --- |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Запрос**:

```SQL
SELECT
    Make,
    Time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(minute, 1)) <> Make
```

Используйте **запаздывание** для просмотра входного потока на одно событие назад, получения значения *make* и сравнения его *с значением Current* события и вывода события.

Дополнительные сведения см. в разделе [**запаздывание**](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="retrieve-the-first-event-in-a-window"></a>Получение первого события в окне

**Сначала** можно использовать для получения первого события в временном окне. Например, выводить первые сведения о автомобилях каждые 10 минут.

**Входные данные**:

| License_plate | Производитель | Время |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выходные данные**:

| License_plate | Производитель | Время |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |

**Запрос**:

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) = 1
```

**Также можно** секционировать данные и вычислить первое событие для каждого *конкретного автомобиля,* который будет найден каждые 10 минут.

**Выходные данные**:

| License_plate | Производитель | Время |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос**:

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) OVER (PARTITION BY Make) = 1
```

Дополнительные сведения см. в руководстве по [**первому**](/stream-analytics-query/isfirst-azure-stream-analytics).

## <a name="return-the-last-event-in-a-window"></a>Возврат последнего события в окне

По мере того, как события потребляются системой в режиме реального времени, отсутствует функция, которая может определить, будет ли событие доставлено последним в течение этого периода времени. Для этого входной поток должен быть соединен с другим, где время события — это максимальное время для всех событий в этом окне.

**Входные данные**:

| License_plate | Производитель | Время |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выходные данные**:

| License_plate | Производитель | Время |
| --- | --- | --- |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос**:

```SQL
WITH LastInWindow AS
(
    SELECT 
        MAX(Time) AS LastEventTime
    FROM 
        Input TIMESTAMP BY Time
    GROUP BY 
        TumblingWindow(minute, 10)
)

SELECT 
    Input.License_plate,
    Input.Make,
    Input.Time
FROM
    Input TIMESTAMP BY Time 
    INNER JOIN LastInWindow
    ON DATEDIFF(minute, Input, LastInWindow) BETWEEN 0 AND 10
    AND Input.Time = LastInWindow.LastEventTime
```

Первый шаг в запросе находит максимальную отметку времени в 10-минутных окнах, то есть метку времени последнего события для этого окна. Второй шаг соединяет результаты первого запроса с исходным потоком, чтобы найти событие, которое соответствует последним штампам времени в каждом окне. 

**DateDiff** — это функция для определенной даты, которая сравнивает и возвращает разницу во времени между двумя полями DateTime. Дополнительные сведения см. в разделе [функции даты](https://docs.microsoft.com/stream-analytics-query/date-and-time-functions-azure-stream-analytics).

Дополнительные сведения о присоединении потоков см. в разделе [**соединение**](/stream-analytics-query/join-azure-stream-analytics).


## <a name="correlate-events-in-a-stream"></a>Сопоставление событий в потоке

Корреляция событий в одном потоке может осуществляться путем просмотра прошлых событий с помощью функции **Lag** . Например, выходные данные могут создаваться каждый раз, когда два последовательных автомобиля из одного и того же *делаются* через платный за последние 90 секунд.

**Входные данные**:

| Производитель | License_plate | Время |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make1 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make2 |DEF-987 |2015-01-01T00:00:03.0000000Z |
| Make1 |GHI-345 |2015-01-01T00:00:04.0000000Z |

**Выходные данные**:

| Производитель | Время | Current_car_license_plate | First_car_license_plate | First_car_time |
| --- | --- | --- | --- | --- |
| Make1 |2015-01-01T00:00:02.0000000Z |AAA-999 |ABC-123 |2015-01-01T00:00:01.0000000Z |

**Запрос**:

```SQL
SELECT
    Make,
    Time,
    License_plate AS Current_car_license_plate,
    LAG(License_plate, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_license_plate,
    LAG(Time, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(second, 90)) = Make
```

Функция **Lag** может взглянуть на входной поток на одно событие назад и получить значение *make* , *сравнив это с значением текущего* события.  После выполнения условия данные из предыдущего события можно прогнозировать с помощью **Lag** в инструкции **SELECT** .

Дополнительные сведения см. в разделе [запаздывание](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="detect-the-duration-between-events"></a>Определение промежутка между событиями

Длительность события может быть вычислена путем просмотра последнего события запуска после получения события окончания. Этот запрос может быть полезен для определения времени, затрачиваемого пользователем на страницу или функцию.

**Входные данные**:  

| User (Пользователь) | Функция | событие | Время |
| --- | --- | --- | --- |
| user@location.com |RightMenu |Начало |2015-01-01T00:00:01.0000000Z |
| user@location.com |RightMenu |Конец |2015-01-01T00:00:08.0000000Z |

**Выходные данные**:  

| User (Пользователь) | Функция | Duration |
| --- | --- | --- |
| user@location.com |RightMenu |7 |

**Запрос**:

```SQL
SELECT
    [user],
    feature,
    DATEDIFF(
        second,
        LAST(Time) OVER (PARTITION BY [user], feature LIMIT DURATION(hour, 1) WHEN Event = 'start'),
        Time) as duration
FROM input TIMESTAMP BY Time
WHERE
    Event = 'end'
```

**Последняя** функция может использоваться для получения последнего события в определенном условии. В этом примере условие — это событие типа Start, которое позволяет секционировать Поиск по **секционированию по** пользователю и функции. Таким образом, каждый пользователь и функция рассматриваются независимо при поиске события Start. **Предельная длительность** ограничивает время поиска на 1 час между событиями End и Start.

## <a name="detect-the-duration-of-a-condition"></a>Определение продолжительности условия

Для условий, охватывающих несколько событий, можно использовать функцию **Lag** для указания длительности этого условия. Предположим, произошла ошибка, которая привела к неправильному отображению массы всех автомобилей (больше 20 000 фунтов). Необходимо вычислить длительность ошибки.

**Входные данные**:

| Производитель | Время | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |2000 |
| Make2 |2015-01-01T00:00:02.0000000Z |25000 |
| Make1 |2015-01-01T00:00:03.0000000Z |26000 |
| Make2 |2015-01-01T00:00:04.0000000Z |25000 |
| Make1 |2015-01-01T00:00:05.0000000Z |26000 |
| Make2 |2015-01-01T00:00:06.0000000Z |25000 |
| Make1 |2015-01-01T00:00:07.0000000Z |26000 |
| Make2 |2015-01-01T00:00:08.0000000Z |2000 |

**Выходные данные**:

| Start_fault | End_fault |
| --- | --- |
| 2015-01-01T00:00:02.000Z |2015-01-01T00:00:07.000Z |

**Запрос**:

```SQL
WITH SelectPreviousEvent AS
(
SELECT
    *,
    LAG([time]) OVER (LIMIT DURATION(hour, 24)) as previous_time,
    LAG([weight]) OVER (LIMIT DURATION(hour, 24)) as previous_weight
FROM input TIMESTAMP BY [time]
)

SELECT 
    LAG(time) OVER (LIMIT DURATION(hour, 24) WHEN previous_weight < 20000 ) [Start_fault],
    previous_time [End_fault]
FROM SelectPreviousEvent
WHERE
    [weight] < 20000
    AND previous_weight > 20000
```
Первая инструкция **SELECT** сопоставляет текущее измерение веса с предыдущим измерением и объединяет его с текущим измерением. Второй **SELECT** возвращается к последнему событию, где *previous_weight* меньше 20000, где текущий вес меньше 20000, а *previous_weight* текущего события превышает 20000.

End_fault — текущее неисправное событие, в котором произошло сбой предыдущего события, а Start_fault является последним неисправной событием.

## <a name="periodically-output-values"></a>Периодические выходные значения

В случае неправильного или неправильного события выходные данные стандартного интервала могут формироваться из более разреженных входных данных. Например, создавайте каждые 5 секунд событие, сообщающее последнюю видимую точку данных.

**Входные данные**:

| Время | Значение |
| --- | --- |
| "2014-01-01T06:01:00" |1 |
| "2014-01-01T06:01:05" |2 |
| "2014-01-01T06:01:10" |3 |
| "2014-01-01T06:01:15" |4 |
| "2014-01-01T06:01:30" |5 |
| "2014-01-01T06:01:35" |6 |

**Выходные данные (первые 10 строк)**:

| Window_end | Last_event. Таймаут | Last_event. Значений |
| --- | --- | --- |
| 2014-01-01T14:01:00.000Z |2014-01-01T14:01:00.000Z |1 |
| 2014-01-01T14:01:05.000Z |2014-01-01T14:01:05.000Z |2 |
| 2014-01-01T14:01:10.000Z |2014-01-01T14:01:10.000Z |3 |
| 2014-01-01T14:01:15.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:20.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:25.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:30.000Z |2014-01-01T14:01:30.000Z |5 |
| 2014-01-01T14:01:35.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:40.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:45.000Z |2014-01-01T14:01:35.000Z |6 |

**Запрос**:

```SQL
SELECT
    System.Timestamp() AS Window_end,
    TopOne() OVER (ORDER BY Time DESC) AS Last_event
FROM
    Input TIMESTAMP BY Time
GROUP BY
    HOPPINGWINDOW(second, 300, 5)
```

Этот запрос создает события каждые 5 секунд и выводит последнее событие, полученное ранее. **HOPPINGWINDOW** длительность определяет, насколько далеко будет выглядеть запрос, чтобы найти Последнее событие.

Дополнительные сведения см. в [окне прыгающее»](/stream-analytics-query/hopping-window-azure-stream-analytics).

## <a name="process-events-with-independent-time-substreams"></a>Обработка событий с независимым временем (подпотоки)

События могут поступать с опозданием или не по порядку из-за рассинхронизации часов поставщиков событий, секций или сетевой задержки.
Например, часы устройства для *TollID* 2 — 5 секунд после *TollID* 1, а часы устройства для *TollID* 3 — десять секунд за *TollID* 1. Вычисление может выполняться независимо для каждого сбора, учитывая только свои данные часов в качестве отметки времени.

**Входные данные**:

| LicensePlate | Производитель | Время | ИД пункта сбора |
| --- | --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:01.0000000Z | 1 |
| YHN 6970 |Make2 |2015-07-27T00:00:05.0000000Z | 1 |
| QYF 9358 |Make1 |2015-07-27T00:00:01.0000000Z | 2 |
| GXF 9462 |Make3 |2015-07-27T00:00:04.0000000Z | 2 |
| VFE 1616 |Make2 |2015-07-27T00:00:10.0000000Z | 1 |
| RMV 8282 |Make1 |2015-07-27T00:00:03.0000000Z | 3 |
| MDR 6128 |Make3 |2015-07-27T00:00:11.0000000Z | 2 |
| YZK 5704 |Make4 |2015-07-27T00:00:07.0000000Z | 3 |

**Выходные данные**:

| ИД пункта сбора | Count |
| --- | --- |
| 1 | 2 |
| 2 | 2 |
| 1 | 1 |
| 3 | 1 |
| 2 | 1 |
| 3 | 1 |

**Запрос**:

```SQL
SELECT
      TollId,
      COUNT(*) AS Count
FROM input
      TIMESTAMP BY Time OVER TollId
GROUP BY TUMBLINGWINDOW(second, 5), TollId
```

Предложение **timestamp on by** просматривает каждую временную шкалу устройства независимо с помощью подпотоков. Событие OUTPUT для каждого *TollID* формируется по мере их выгрузки, что означает, что события зависят от каждого *TollID* , а не переупорядочиваются так, как если бы все устройства были в одном часовом плане.

Дополнительные сведения см. в разделе [Метка времени](/stream-analytics-query/timestamp-by-azure-stream-analytics#over-clause-interacts-with-event-ordering)на.

## <a name="remove-duplicate-events-in-a-window"></a>Удаление повторяющихся событий за период

При выполнении операции, такой как вычисление средних значений событий за заданный период времени, повторяющиеся события должны быть отфильтрованы. В следующем примере второе событие является дубликатом первого.

**Входные данные**:  

| deviceId | Время | Атрибут | Значение |
| --- | --- | --- | --- |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 2 |2018-07-27T00:00:01.0000000Z |температура; |40 |
| 1 |2018-07-27T00:00:05.0000000Z |температура; |60 |
| 2 |2018-07-27T00:00:05.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:10.0000000Z |температура; |100 |

**Выходные данные**:  

| AverageValue | deviceId |
| --- | --- |
| 70 | 1 |
|45 | 2 |

**Запрос**:

```SQL
With Temp AS (
SELECT
    COUNT(DISTINCT Time) AS CountTime,
    Value,
    DeviceId
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Value,
    DeviceId,
    SYSTEM.TIMESTAMP()
)

SELECT
    AVG(Value) AS AverageValue, DeviceId
INTO Output
FROM Temp
GROUP BY DeviceId,TumblingWindow(minute, 5)
```

**COUNT(DISTINCT Time)** возвращает количество уникальных значений в столбце "Время" в течение определенного интервала. Выходные данные первого шага можно затем использовать для вычисления среднего значения для каждого устройства путем удаления дубликатов.

Дополнительные сведения см. в разделе [Count (отдельное время)](/stream-analytics-query/count-azure-stream-analytics).

## <a name="session-windows"></a>Окна сеанса

Окно сеанса — это окно, которое поддерживает расширение по мере возникновения событий и закрывается для вычислений, если после определенного промежутка времени не было получено никакого события или если окно достигает максимального значения длительности.
Это окно особенно полезно при расчете данных взаимодействия с пользователем. Окно запускается, когда пользователь начинает взаимодействовать с системой и закрывается, когда больше событий не наблюдается, что означает, что пользователь остановил взаимодействие.
Например, пользователь взаимодействует с веб-страницей, в которой регистрируется число щелчков. окно сеанса можно использовать для определения времени, в течение которого пользователь взаимодействует с сайтом.

**Входные данные**:

| User_id | Время | URL-адрес |
| --- | --- | --- |
| 0 | 2017-01-26T00:00:00.0000000 Z | "www.example.com/a.html" |
| 0 | 2017-01-26T00:00:20.0000000 Z | "www.example.com/b.html" |
| 1 | 2017-01-26T00:00:55.0000000 Z | "www.example.com/c.html" |
| 0 | 2017-01-26T00:01:10.0000000 Z | "www.example.com/d.html" |
| 1 | 2017-01-26T00:01:15.0000000 Z | "www.example.com/e.html" |

**Выходные данные**:

| User_id | StartTime | EndTime | Duration_in_seconds |
| --- | --- | --- | --- |
| 0 | 2017-01-26T00:00:00.0000000 Z | 2017-01-26T00:01:10.0000000 Z | 70 |
| 1 | 2017-01-26T00:00:55.0000000 Z | 2017-01-26T00:01:15.0000000 Z | 20 |

**Запрос**:

``` SQL
SELECT
    user_id,
    MIN(time) as StartTime,
    MAX(time) as EndTime,
    DATEDIFF(second, MIN(time), MAX(time)) AS duration_in_seconds
FROM input TIMESTAMP BY time
GROUP BY
    user_id,
    SessionWindow(minute, 1, 60) OVER (PARTITION BY user_id)
```

В поле **Выбор** проецируется данные, относящиеся к взаимодействию с пользователем, а также время взаимодействия. Группирование данных по пользователям и **сессионвиндов** , которые закрываются, если взаимодействие не происходит в течение 1 минуты с максимальным размером окна 60 минут.

Дополнительные сведения о **сессионвиндов**см. в [окне сеанса](/stream-analytics-query/session-window-azure-stream-analytics) .

## <a name="language-extensibility-with-user-defined-function-in-javascript-and-c"></a>Расширяемость языков с помощью определяемой пользователем функции в JavaScript и C #

Язык запросов Azure Stream Analytics можно расширить с помощью пользовательских функций, написанных на языке JavaScript или C#. Определяемые пользователем функции (UDF) — это пользовательские или сложные вычисления, которые нельзя легко выразить с помощью языка **SQL** . Эти пользовательские функции можно определить один раз и использовать в запросе несколько раз. Например, определяемая пользователем функция может использоваться для преобразования шестнадцатеричного значения *nvarchar (max)* в значение *bigint* .

**Входные данные**:

| Device_id | хексвалуе |
| --- | --- |
| 1 | B4 |
| 2 | "11B" |
| 3 | "121" |

**Выходные данные**:

| Device_id | Decimal |
| --- | --- |
| 1 | 180 |
| 2 | 283 |
| 3 | 289 |

```JavaScript
function hex2Int(hexValue){
    return parseInt(hexValue, 16);
}
```

```C#
public static class MyUdfClass {
    public static long Hex2Int(string hexValue){
        return int.Parse(hexValue, System.Globalization.NumberStyles.HexNumber);
    }
}
```

```SQL
SELECT
    Device_id,
    udf.Hex2Int(HexValue) AS Decimal
From
    Input
```

Определяемая пользователем функция будет вычислять значение *bigint* из хексвалуе при каждом потреблении события.

Дополнительные сведения см. в разделе [JavaScript](/azure/stream-analytics/stream-analytics-javascript-user-defined-functions) и [C#](/azure/stream-analytics/stream-analytics-edge-csharp-udf).

## <a name="advanced-pattern-matching-with-match_recognize"></a>Расширенное сопоставление шаблонов с MATCH_RECOGNIZE

**MATCH_RECOGNIZE** — это расширенный механизм сопоставления шаблонов, который можно использовать для сопоставления последовательности событий с четко определенным шаблоном регулярного выражения.
Например, при наличии двух последовательных предупреждений, которые необходимо уведомлять администратора, в режиме реального времени выполняется мониторинг сети ATM.

**Входные данные**:

| ATM_id | Operation_id | Return_Code | Время |
| --- | --- | --- | --- |
| 1 | "Ввод ПИН-кода" | Success | 2017-01-26T00:10:00.0000000 Z |
| 2 | "Открытие денежного слота" | Success | 2017-01-26T00:10:07.0000000 Z |
| 2 | "Закрытие денежного слота" | Success | 2017-01-26T00:10:11.0000000 Z |
| 1 | "Ввод количества при аннулировании" | Success | 2017-01-26T00:10:08.0000000 Z |
| 1 | "Открытие денежного слота" | ! | 2017-01-26T00:10:14.0000000 Z |
| 1 | "Печать банковского баланса" | ! | 2017-01-26T00:10:19.0000000 Z |

**Выходные данные**:

| ATM_id | First_Warning_Operation_id | Warning_Time |
| --- | --- | --- |
| 1 | "Открытие денежного слота" | 2017-01-26T00:10:14.0000000 Z |

```SQL
SELECT *
FROM intput TIMESTAMP BY time OVER ATM_id
MATCH_RECOGNIZE (
    PARTITON BY ATM_id
    LIMIT DURATION(minute, 1)
    MEASURES
        First(Warning.ATM_id) AS ATM_id,
        First(Warning.Operation_Id) AS First_Warning_Operation_id,
        First(Warning.Time) AS Warning_Time
    AFTER MATCH SKIP TO NEXT ROW
    PATTERN (Success* Warning{2,})
    DEFINE
        Success AS Succes.Return_Code = 'Success',
        Failure AS Warning.Return_Code <> 'Success'
) AS patternMatch
```

Этот запрос соответствует по крайней мере двум последовательным событиям сбоя и создает оповещение при выполнении условий.
**Шаблон** определяет регулярное выражение, которое будет использоваться в сопоставлении, в данном случае любое количество успешных операций, за которыми следует по крайней мере два последовательных сбоя.
Успех и неудача определяются с помощью Return_Codeого значения. После выполнения условия **меры** проецируются с *ATM_id*, первой и первой предупреждений.

Дополнительные сведения см. в разделе [MATCH_RECOGNIZE](/stream-analytics-query/match-recognize-stream-analytics).

## <a name="geofencing-and-geospatial-queries"></a>Геоограждение и геопространственные запросы
Azure Stream Analytics предоставляет встроенные геопространственные функции, которые можно использовать для реализации таких сценариев, как управление препарком, перестроение общего доступа, подключенные автомобили и отслеживание ресурсов.
Геопространственные данные могут быть приняты в формате геоjson или WKT в составе потока событий или ссылочных данных.
Например, компания, которая специализируется на производственных компьютерах для печати паспортов, может арендовать свои компьютеры в государственные и консулатес. Расположение этих компьютеров сильно контролируется, так как это позволяет избежать незаконного размещения и возможных использований для подделки паспортов. Каждый компьютер размещается с помощью средства регистрации GPS, эта информация передается обратно в Azure Stream Analyticsное задание.
Изготовитель хотел бы отследить расположение этих компьютеров и получать оповещения, если один из них покидает санкционированную область, так как они могут удаленно отключать, получать оповещения и получать оборудование.

**Входные данные**:

| Equipment_id | Equipment_current_location | Время |
| --- | --- | --- |
| 1 | "POINT (-122.13288797982818 47.64082002051315)" | 2017-01-26T00:10:00.0000000 Z |
| 1 | "POINT (-122.13307252987875 47.64081350934929)" | 2017-01-26T00:11:00.0000000 Z |
| 1 | "POINT (-122.13308862313283 47.6406508603241)" | 2017-01-26T00:12:00.0000000 Z |
| 1 | "POINT (-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00.0000000 Z |

**Ввод ссылочных данных**:

| Equipment_id | Equipment_lease_location |
| --- | --- |
| 1 | "POLYGON (-122.13326028450979 47.6409833866794,-122.13261655434621 47.6409833866794,-122.13261655434621 47.64061471602751,-122.13326028450979 47.64061471602751,-122.13326028450979 47.6409833866794))" |

**Выходные данные**:

| Equipment_id | Equipment_alert_location | Время |
| --- | --- | --- |
| 1 | "POINT (-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00.0000000 Z |

```SQL
SELECT
    input.Equipment_id AS Equipment_id,
    input.Equipment_current_location AS Equipment_current_location,
    input.Time AS Time
FROM input TIMESTAMP BY time
JOIN
    referenceInput 
    ON input.Equipment_id = referenceInput.Equipment_id
    WHERE 
        ST_WITHIN(input.Equipment_currenct_location, referenceInput.Equipment_lease_location) = 1
```

Запрос позволяет изготовителю автоматически отслеживать расположение компьютеров, получая оповещения при выходе компьютера из разрешенного геозоны. Встроенная геопространственные функция позволяет пользователям использовать данные GPS в запросе без библиотек сторонних производителей.

Дополнительные сведения см. в разделе [сценарии использования геопространственной и геопространственных статистических схем с Azure Stream Analyticsной](geospatial-scenarios.md) статьей.

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи посетите наш [Azure Stream Analytics Форум](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Следующие шаги
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
