---
title: Общие шаблоны запросов в Azure Stream Analytics
description: В этой статье описано несколько общих шаблонов запросов и конструкций, которые полезны для заданий Azure Stream Analytics.
services: stream-analytics
author: rodrigoaatmicrosoft
ms.author: rodrigoa
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/18/2019
ms.openlocfilehash: aa8bd6e89dd47c4e972a860691d1bc3779ba5bc7
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "75982315"
---
# <a name="common-query-patterns-in-azure-stream-analytics"></a>Общие шаблоны запросов в Azure Stream Analytics

Запросы в Azure Stream Analytics выражаются на языке запросов на основе SQL. Эти языковые конструкции описаны в [справочнике по языку запросов Stream Analytics](/stream-analytics-query/stream-analytics-query-language-reference). 

Конструкция запроса может выразить простую сквозную логику для перемещения данных событий из одного входного потока в хранилище выходных данных, или же она может выполнять богатый шаблон, соответствующий и временный анализ, для расчета агрегатов по различным временным окнам, как в [решении Build an IoT, используя](stream-analytics-build-an-iot-solution-using-stream-analytics.md) руководство Stream Analytics. Вы можете объединить данные из нескольких входов, чтобы объединить потоковые события, и вы можете сделать поиск в отношении статических справочных данных, чтобы обогатить значения событий. Можно также записывать данные на несколько выходов.

В этой статье излагаются решения нескольких общих шаблонов запросов на основе реальных сценариев.

## <a name="supported-data-formats"></a>Поддерживаемые форматы данных

Azure Stream Analytics поддерживает обработку событий в форматах CSV, JSON и Avro.

Данные JSON и Avro могут содержать сложные типы, такие как вложенные объекты (записи) или массивы. Для получения дополнительной информации о работе с этими сложными типами данных, обратитесь к статье [Parsing JSON и AVRO данных.](stream-analytics-parsing-json.md)

## <a name="simple-pass-through-query"></a>Простой сквозной запрос

Простой сквозной запрос может быть использован для копирования данных входиного потока на выходе. Например, если поток данных, содержащий информацию о транспортном средстве в реальном времени, должен быть сохранен в базе данных S'L для анализа букв, простой сквозной запрос будет выполнять эту работу.

**Входный вход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Запрос**:

```SQL
SELECT
    *
INTO Output
FROM Input
```

Запрос **SELECT** проецирует все поля входящего события и отправляет их на выход. Таким же образом, **SELECT** также может быть использован только для проекта требуемых полей от ввода. В этом примере, если автомобиль *Make* and *Time* являются единственными необходимыми полями, которые необходимо сохранить, эти поля могут быть указаны в заявлении **SELECT.**

**Входный вход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:04.0000000Z |

**Запрос**:

```SQL
SELECT
    Make, Time
INTO Output
FROM Input
```
## <a name="data-aggregation-over-time"></a>Агрегация данных с течением времени

Для вычисления информации в течение временного окна данные могут быть агрегированы вместе. В этом примере, подсчет вычисляется за последние 10 минут времени для каждого конкретного автомобиля сделать.

**Входный вход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |1000 |
| Make1 |2015-01-01T00:00:02.0000000Z |2000 |
| Make2 |2015-01-01T00:00:04.0000000Z |1500 |

**Выход**:

| Убедитесь, | Count |
| --- | --- |
| Make1 | 2 |
| Make2 | 1 |

**Запрос**:

```SQL
SELECT
    Make,
    COUNT(*) AS Count
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

Эта агрегация группирует автомобили по *Make* и считает их каждые 10 секунд. Выход имеет *Make* и *граф* автомобилей, которые прошли через платные.

TumblingWindow — это функция окон, используемая для совместной группы событий. Агрегация может быть применена ко всем сгруппированным событиям. Для получения дополнительной [информации](stream-analytics-window-functions.md)см.

Для получения дополнительной информации об агрегировании обратитесь к [агрегированным функциям.](/stream-analytics-query/aggregate-functions-azure-stream-analytics)

## <a name="data-conversion"></a>Преобразование данных

Данные могут быть отлиты в режиме реального времени с помощью метода **CAST.** Например, вес автомобиля можно преобразовать от типа **nvarchar (max)** к типу **bigint** и быть использованным на численном вычислении.

**Входный вход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |"1000" |
| Make1 |2015-01-01T00:00:02.0000000Z |"2000" |

**Выход**:

| Убедитесь, | Вес |
| --- | --- |
| Make1 |3000 |

**Запрос**:

```SQL
SELECT
    Make,
    SUM(CAST(Weight AS BIGINT)) AS Weight
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
```

Используйте заявление **CAST,** чтобы указать его тип данных. Просмотрите список поддерживаемых типов данных по [типам данных (Azure Stream Analytics)](/stream-analytics-query/data-types-azure-stream-analytics).

Для получения дополнительной информации о [функциях преобразования данных](/stream-analytics-query/conversion-functions-azure-stream-analytics).

## <a name="string-matching-with-like-and-not-like"></a>Строка соответствия с LIKE и НЕ LIKE

**LIKE** и **НЕ LIKE** могут быть использованы для проверки соответствия поля определенному шаблону. Например, фильтр может быть создан, чтобы вернуть только номерные знаки, которые начинаются с буквы "А" и заканчиваются номером 9.

**Входный вход**:

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Выход**:

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make2 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make3 |ABC-369 |2015-01-01T00:00:03.0000000Z |

**Запрос**:

```SQL
SELECT
    *
FROM
    Input TIMESTAMP BY Time
WHERE
    License_plate LIKE 'A%9'
```

Используйте выписку **LIKE** для проверки значения **License_plate** поля. Она должна начинаться с буквы "А", затем иметь любую строку с нулевым или более символами, заканчивающейся числом 9.

## <a name="specify-logic-for-different-casesvalues-case-statements"></a>Указание логики для различных случаев и значений (операторы CASE)

**Заявления CASE** могут предоставлять различные вычисления для различных областей, основываясь на определенном критерии. Например, присвоить полосу 'A' автомобилям *Make1* и полосе 'B' любому другому марке.

**Входный вход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выход**:

| Убедитесь, |Dispatch_to_lane | Time |
| --- | --- | --- |
| Make1 |"А" |2015-01-01T00:00:01.0000000Z |
| Make2 |"B" |2015-01-01T00:00:02.0000000Z |

**Решение**.

```SQL
SELECT
    Make
    CASE
        WHEN Make = "Make1" THEN "A"
        ELSE "B"
    END AS Dispatch_to_lane,
    System.TimeStamp() AS Time
FROM
    Input TIMESTAMP BY Time
```

Выражение **CASE** сравнивает выражение с набором простых выражений для определения его результата. В этом примере транспортные средства *Make1* отправляются на полосу 'A', в то время как транспортным средствам любого другого автомобиля будет назначена полоса 'B'.

Для получения дополнительной информации обратитесь к [выражению случая.](/stream-analytics-query/case-azure-stream-analytics)

## <a name="send-data-to-multiple-outputs"></a>Отправка данных на несколько выходов

Несколько инструкций **SELECT** могут быть использованы для вывода данных в различные выходные раковины. Например, один **SELECT** может вывести пороговое оповещение, в то время как другой может вывести события для хранения кабы.

**Входный вход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Вывод архиваВыход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выходное оповещение:**

| Убедитесь, | Time | Count |
| --- | --- | --- |
| Make2 |2015-01-01T00:00:10.0000000Z |3 |

**Запрос**:

```SQL
SELECT
    *
INTO
    ArchiveOutput
FROM
    Input TIMESTAMP BY Time

SELECT
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count]
INTO
    AlertOutput
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING
    [Count] >= 3
```

Пункт **INTO** сообщает Stream Analytics, к какой из выходов нужно написать данные. Первый **SELECT** определяет сквозной запрос, который получает данные из ввода и отправляет их на вывод под названием **ArchiveOutput.** Второй запрос выполняет простую агрегацию и фильтрацию перед отправкой результатов в систему оповещения ниже по течению под названием **AlertOutput.**

Обратите внимание, что оговорка **WITH** может использоваться для определения нескольких блоков подзапросов. Этот вариант имеет преимущество открытия меньше читателей к источнику ввода.

**Запрос**:

```SQL
WITH ReaderQuery AS (
    SELECT
        *
    FROM
        Input TIMESTAMP BY Time
)

SELECT * INTO ArchiveOutput FROM ReaderQuery

SELECT 
    Make,
    System.TimeStamp() AS Time,
    COUNT(*) AS [Count] 
INTO AlertOutput 
FROM ReaderQuery
GROUP BY
    Make,
    TumblingWindow(second, 10)
HAVING [Count] >= 3
```

Для получения дополнительной информации, обратитесь к [ **пункту С** ](/stream-analytics-query/with-azure-stream-analytics).

## <a name="count-unique-values"></a>Число уникальных значений

**COUNT** и **DISTINCT** можно использовать для подсчета количества уникальных значений поля, которые появляются в потоке в течение временного окна. Можно создать запрос, чтобы вычислить, сколько *уникальных* автомобилей прошло через платную кабину в 2-секундном окне.

**Входный вход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make1 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |
| Make2 |2015-01-01T00:00:03.0000000Z |

**Выход:**

| Count_make | Time |
| --- | --- |
| 2 |2015-01-01T00:00:02.000Z |
| 1 |2015-01-01T00:00:04.000Z |

**Запроса:**

```SQL
SELECT
     COUNT(DISTINCT Make) AS Count_make,
     System.TIMESTAMP() AS Time
FROM Input TIMESTAMP BY TIME
GROUP BY 
     TumblingWindow(second, 2)
```

**COUNT (DISTINCT Make)** возвращает количество определенных значений в столбце **Make** в течение временного окна.
Для получения дополнительной информации обратитесь к [агрегированной **функции COUNT.** ](/stream-analytics-query/count-azure-stream-analytics)

## <a name="calculation-over-past-events"></a>Расчет прошлых событий

Функция **LAG** может использоваться для изучения прошлых событий в течение временного окна и их сравнения с текущим событием. Например, текущий автомобиль сделать может быть выходом, если он отличается от последнего автомобиля, который прошел через платные.

**Входный вход**:

| Убедитесь, | Time |
| --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Выход**:

| Убедитесь, | Time |
| --- | --- |
| Make2 |2015-01-01T00:00:02.0000000Z |

**Запрос**:

```SQL
SELECT
    Make,
    Time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(minute, 1)) <> Make
```

Используйте **LAG,** чтобы заглянуть в поток ввода одного события назад, извлечения значения *Make* и сравнив его со значением *Make* текущего события и вывода события.

Для получения дополнительной информации, обратитесь к [**LAG**](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="retrieve-the-first-event-in-a-window"></a>Извлекать первое событие в окне

**IsFirst** можно использовать для получения первого события в временном окне. Например, ввод информации о первом автомобиле с интервалом в 10 минут.

**Входный вход**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выход**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |

**Запрос**:

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) = 1
```

**IsFirst** также может перегородку данных и вычислить первое событие для каждого конкретного автомобиля *Make,* найденный с каждым 10-минутным интервалом.

**Выход**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос**:

```SQL
SELECT 
    License_plate,
    Make,
    Time
FROM 
    Input TIMESTAMP BY Time
WHERE 
    IsFirst(minute, 10) OVER (PARTITION BY Make) = 1
```

Для получения дополнительной информации, обратитесь к [**IsFirst**](/stream-analytics-query/isfirst-azure-stream-analytics).

## <a name="return-the-last-event-in-a-window"></a>Вернуть последнее событие в окне

Поскольку события потребляются системой в режиме реального времени, нет функции, которая может определить, будет ли событие последним, кто прибудет на это окно времени. Для достижения этой цели поток ввода должен быть соединен с другим, где время события является максимальным временем для всех событий в этом окне.

**Входный вход**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:05.0000000Z |
| YZK 5704 |Make3 |2015-07-27T00:02:17.0000000Z |
| RMV 8282 |Make1 |2015-07-27T00:05:01.0000000Z |
| YHN 6970 |Make2 |2015-07-27T00:06:00.0000000Z |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| QYF 9358 |Make1 |2015-07-27T00:12:02.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Выход**:

| License_plate | Убедитесь, | Time |
| --- | --- | --- |
| VFE 1616 |Make2 |2015-07-27T00:09:31.0000000Z |
| MDR 6128 |Make4 |2015-07-27T00:13:45.0000000Z |

**Запрос**:

```SQL
WITH LastInWindow AS
(
    SELECT 
        MAX(Time) AS LastEventTime
    FROM 
        Input TIMESTAMP BY Time
    GROUP BY 
        TumblingWindow(minute, 10)
)

SELECT 
    Input.License_plate,
    Input.Make,
    Input.Time
FROM
    Input TIMESTAMP BY Time 
    INNER JOIN LastInWindow
    ON DATEDIFF(minute, Input, LastInWindow) BETWEEN 0 AND 10
    AND Input.Time = LastInWindow.LastEventTime
```

Первый шаг на запросе находит максимальную отметку времени в 10-минутных окнах, то есть отметку времени последнего события для этого окна. Второй шаг соединяет результаты первого запроса с исходным потоком, чтобы найти событие, которое соответствует последним штампам времени в каждом окне. 

**DATEDIFF** — это функция, связанная с датой, которая сравнивает и возвращает разницу во времени между двумя полями DateTime, для получения дополнительной информации отсылайте к [функциям даты.](https://docs.microsoft.com/stream-analytics-query/date-and-time-functions-azure-stream-analytics)

Для получения дополнительной информации о присоединении потоков, обратитесь к [**JOIN**](/stream-analytics-query/join-azure-stream-analytics).


## <a name="correlate-events-in-a-stream"></a>Коррелирует события в потоке

Коррелировать события в одном потоке можно, глядя на прошлые события с помощью функции **LAG.** Например, выход может быть сгенерирован каждый раз, когда два последовательных автомобиля из одного и того же *Make* проходят через платные за последние 90 секунд.

**Входный вход**:

| Убедитесь, | License_plate | Time |
| --- | --- | --- |
| Make1 |ABC-123 |2015-01-01T00:00:01.0000000Z |
| Make1 |AAA-999 |2015-01-01T00:00:02.0000000Z |
| Make2 |DEF-987 |2015-01-01T00:00:03.0000000Z |
| Make1 |GHI-345 |2015-01-01T00:00:04.0000000Z |

**Выход**:

| Убедитесь, | Time | Current_car_license_plate | First_car_license_plate | First_car_time |
| --- | --- | --- | --- | --- |
| Make1 |2015-01-01T00:00:02.0000000Z |AAA-999 |ABC-123 |2015-01-01T00:00:01.0000000Z |

**Запрос**:

```SQL
SELECT
    Make,
    Time,
    License_plate AS Current_car_license_plate,
    LAG(License_plate, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_license_plate,
    LAG(Time, 1) OVER (LIMIT DURATION(second, 90)) AS First_car_time
FROM
    Input TIMESTAMP BY Time
WHERE
    LAG(Make, 1) OVER (LIMIT DURATION(second, 90)) = Make
```

Функция **LAG** может заглянуть в поток ввода одного события назад и получить значение *Make,* сравнивая его со значением *Make* текущего события.  Как только условие выполнено, данные из предыдущего события могут быть проецированы с помощью **LAG** в выписке **SELECT.**

Для получения дополнительной информации, обратитесь к [LAG](/stream-analytics-query/lag-azure-stream-analytics).

## <a name="detect-the-duration-between-events"></a>Определение промежутка между событиями

Продолжительность события может быть вычислена, взглянув на последнее событие «Старт» после получения события «Конец». Этот запрос может быть полезен для определения времени, затрагиваемого пользователем на странице или объекте.

**Входный вход**:  

| Пользователь | Компонент | Событие | Time |
| --- | --- | --- | --- |
| user@location.com |RightMenu |Запуск |2015-01-01T00:00:01.0000000Z |
| user@location.com |RightMenu |Конец |2015-01-01T00:00:08.0000000Z |

**Выход**:  

| Пользователь | Компонент | Duration |
| --- | --- | --- |
| user@location.com |RightMenu |7 |

**Запрос**:

```SQL
SELECT
    [user],
    feature,
    DATEDIFF(
        second,
        LAST(Time) OVER (PARTITION BY [user], feature LIMIT DURATION(hour, 1) WHEN Event = 'start'),
        Time) as duration
FROM input TIMESTAMP BY Time
WHERE
    Event = 'end'
```

Функция **LAST** может быть использована для получения последнего события в определенном состоянии. В этом примере условие — это событие типа «Старт», разделив поиск пользователем и функцией **PARTITION BY.** Таким образом, при поиске события «Пуск» каждый пользователь и функция обрабатываются независимо. **LIMIT DURATION** ограничивает поиск во времени до 1 часа между событиями Конца и Начала.

## <a name="detect-the-duration-of-a-condition"></a>Определение продолжительности условия

Для условий, охватывающих несколько событий, функция **LAG** может быть использована для определения продолжительности этого состояния. Предположим, произошла ошибка, которая привела к неправильному отображению массы всех автомобилей (больше 20 000 фунтов). Необходимо вычислить длительность ошибки.

**Входный вход**:

| Убедитесь, | Time | Вес |
| --- | --- | --- |
| Make1 |2015-01-01T00:00:01.0000000Z |2000 |
| Make2 |2015-01-01T00:00:02.0000000Z |25000 |
| Make1 |2015-01-01T00:00:03.0000000Z |26000 |
| Make2 |2015-01-01T00:00:04.0000000Z |25000 |
| Make1 |2015-01-01T00:00:05.0000000Z |26000 |
| Make2 |2015-01-01T00:00:06.0000000Z |25000 |
| Make1 |2015-01-01T00:00:07.0000000Z |26000 |
| Make2 |2015-01-01T00:00:08.0000000Z |2000 |

**Выход**:

| Start_fault | End_fault |
| --- | --- |
| 2015-01-01T00:00:02.000Z |2015-01-01T00:00:07.000Z |

**Запрос**:

```SQL
WITH SelectPreviousEvent AS
(
SELECT
    *,
    LAG([time]) OVER (LIMIT DURATION(hour, 24)) as previous_time,
    LAG([weight]) OVER (LIMIT DURATION(hour, 24)) as previous_weight
FROM input TIMESTAMP BY [time]
)

SELECT 
    LAG(time) OVER (LIMIT DURATION(hour, 24) WHEN previous_weight < 20000 ) [Start_fault],
    previous_time [End_fault]
FROM SelectPreviousEvent
WHERE
    [weight] < 20000
    AND previous_weight > 20000
```
Первое заявление **SELECT** коррелирует текущее измерение веса с предыдущим измерением, проецируя его вместе с текущим измерением. Второй **SELECT** оглядывается на последнее событие, где *previous_weight* меньше, чем 20000, где текущий вес меньше, чем 20000 и *previous_weight* текущего события был больше, чем 20000.

End_fault является текущим неошибочным событием, в котором предыдущее событие было ошибочным, а Start_fault является последним неошибочным событием до этого.

## <a name="periodically-output-values"></a>Периодически значения вывода

В случае нерегулярных или отсутствующих событий, регулярный выход интервала может быть получен из более редких вводимых данных. Например, создавайте каждые 5 секунд событие, сообщающее последнюю видимую точку данных.

**Входный вход**:

| Time | Значение |
| --- | --- |
| "2014-01-01T06:01:00" |1 |
| "2014-01-01T06:01:05" |2 |
| "2014-01-01T06:01:10" |3 |
| "2014-01-01T06:01:15" |4 |
| "2014-01-01T06:01:30" |5 |
| "2014-01-01T06:01:35" |6 |

**Выходные данные (первые 10 строк)**:

| Window_end | Last_event. Время | Last_event. Значение |
| --- | --- | --- |
| 2014-01-01T14:01:00.000Z |2014-01-01T14:01:00.000Z |1 |
| 2014-01-01T14:01:05.000Z |2014-01-01T14:01:05.000Z |2 |
| 2014-01-01T14:01:10.000Z |2014-01-01T14:01:10.000Z |3 |
| 2014-01-01T14:01:15.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:20.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:25.000Z |2014-01-01T14:01:15.000Z |4 |
| 2014-01-01T14:01:30.000Z |2014-01-01T14:01:30.000Z |5 |
| 2014-01-01T14:01:35.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:40.000Z |2014-01-01T14:01:35.000Z |6 |
| 2014-01-01T14:01:45.000Z |2014-01-01T14:01:35.000Z |6 |

**Запрос**:

```SQL
SELECT
    System.Timestamp() AS Window_end,
    TopOne() OVER (ORDER BY Time DESC) AS Last_event
FROM
    Input TIMESTAMP BY Time
GROUP BY
    HOPPINGWINDOW(second, 300, 5)
```

Этот запрос создает события каждые 5 секунд и выводит последнее событие, полученное ранее. Длительность **HOPPINGWINDOW** определяет, как далеко назад запрос выглядит, чтобы найти последнее событие.

Для получения дополнительной информации обратитесь к [окном прыжков](/stream-analytics-query/hopping-window-azure-stream-analytics).

## <a name="process-events-with-independent-time-substreams"></a>Процесс событий с независимым временем (Подстримы)

События могут поступать с опозданием или не по порядку из-за рассинхронизации часов поставщиков событий, секций или сетевой задержки.
Например, часы устройства для *TollID* 2 отстают на пять секунд от *TollID* 1, а часы устройства для *TollID* 3 на десять секунд отстают от *TollID* 1. Вычисление может происходить независимо для каждого платного, учитывая только свои собственные данные часов в качестве метки времени.

**Входный вход**:

| LicensePlate | Убедитесь, | Time | ИД пункта сбора |
| --- | --- | --- | --- |
| DXE 5291 |Make1 |2015-07-27T00:00:01.0000000Z | 1 |
| YHN 6970 |Make2 |2015-07-27T00:00:05.0000000Z | 1 |
| QYF 9358 |Make1 |2015-07-27T00:00:01.0000000Z | 2 |
| GXF 9462 |Make3 |2015-07-27T00:00:04.0000000Z | 2 |
| VFE 1616 |Make2 |2015-07-27T00:00:10.0000000Z | 1 |
| RMV 8282 |Make1 |2015-07-27T00:00:03.0000000Z | 3 |
| MDR 6128 |Make3 |2015-07-27T00:00:11.0000000Z | 2 |
| YZK 5704 |Make4 |2015-07-27T00:00:07.0000000Z | 3 |

**Выход**:

| ИД пункта сбора | Count |
| --- | --- |
| 1 | 2 |
| 2 | 2 |
| 1 | 1 |
| 3 | 1 |
| 2 | 1 |
| 3 | 1 |

**Запрос**:

```SQL
SELECT
      TollId,
      COUNT(*) AS Count
FROM input
      TIMESTAMP BY Time OVER TollId
GROUP BY TUMBLINGWINDOW(second, 5), TollId
```

Положение **TIMESTAMP OVER BY** рассматривает каждую временную шкалу устройства независимо с помощью подстрипов. Событие вывода для каждого *TollID* генерируется по мере их расчета, что означает, что события в порядке по отношению к каждому *TollID* вместо того, чтобы быть переупорядочены, как если бы все устройства были на тех же часах.

Для получения дополнительной информации, обратитесь к [TIMESTAMP BY OVER](/stream-analytics-query/timestamp-by-azure-stream-analytics#over-clause-interacts-with-event-ordering).

## <a name="remove-duplicate-events-in-a-window"></a>Удаление повторяющихся событий за период

При выполнении операции, такой как вычисление средних значений событий за заданный период времени, повторяющиеся события должны быть отфильтрованы. В следующем примере второе событие является дубликатом первого.

**Входный вход**:  

| deviceId | Time | Атрибут | Значение |
| --- | --- | --- | --- |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:01.0000000Z |температура; |50 |
| 2 |2018-07-27T00:00:01.0000000Z |температура; |40 |
| 1 |2018-07-27T00:00:05.0000000Z |температура; |60 |
| 2 |2018-07-27T00:00:05.0000000Z |температура; |50 |
| 1 |2018-07-27T00:00:10.0000000Z |температура; |100 |

**Выход**:  

| AverageValue | deviceId |
| --- | --- |
| 70 | 1 |
|45 | 2 |

**Запрос**:

```SQL
With Temp AS (
SELECT
    COUNT(DISTINCT Time) AS CountTime,
    Value,
    DeviceId
FROM
    Input TIMESTAMP BY Time
GROUP BY
    Value,
    DeviceId,
    SYSTEM.TIMESTAMP()
)

SELECT
    AVG(Value) AS AverageValue, DeviceId
INTO Output
FROM Temp
GROUP BY DeviceId,TumblingWindow(minute, 5)
```

**COUNT(DISTINCT Time)** возвращает количество уникальных значений в столбце "Время" в течение определенного интервала. Вывод первого шага может быть использован для вычисления среднего показателя на устройство путем отбрасывания дубликатов.

Для получения дополнительной информации, обратитесь к [COUNT (DISTINCT Время)](/stream-analytics-query/count-azure-stream-analytics).

## <a name="session-windows"></a>Окна сессии

Окно сеанса — это окно, которое продолжает расширяться по мере возникновения событий и закрывается для вычислений, если событие не получено по истечении определенного периода времени или если окно достигает максимальной продолжительности.
Это окно особенно полезно при вычислении данных взаимодействия пользователей. Окно запускается, когда пользователь начинает взаимодействовать с системой и закрывается, когда больше не наблюдается событий, то есть пользователь перестал взаимодействовать.
Например, пользователь взаимодействует с веб-страницей, на которой регистрируется количество кликов, можно использовать окно сеанса, чтобы узнать, как долго пользователь взаимодействует с сайтом.

**Входный вход**:

| User_id | Time | URL-адрес |
| --- | --- | --- |
| 0 | 2017-01-26T00:00.0000000 | "www.example.com/a.html" |
| 0 | 2017-01-26T00:00:20.0000000 | "www.example.com/b.html" |
| 1 | 2017-01-26T00:00:55.00000000 | "www.example.com/c.html" |
| 0 | 2017-01-26T00:01:10.00000000 | "www.example.com/d.html" |
| 1 | 2017-01-26T00:01:15.00000000 | "www.example.com/e.html" |

**Выход**:

| User_id | StartTime | EndTime | Duration_in_seconds |
| --- | --- | --- | --- |
| 0 | 2017-01-26T00:00.0000000 | 2017-01-26T00:01:10.00000000 | 70 |
| 1 | 2017-01-26T00:00:55.00000000 | 2017-01-26T00:01:15.00000000 | 20 |

**Запрос**:

``` SQL
SELECT
    user_id,
    MIN(time) as StartTime,
    MAX(time) as EndTime,
    DATEDIFF(second, MIN(time), MAX(time)) AS duration_in_seconds
FROM input TIMESTAMP BY time
GROUP BY
    user_id,
    SessionWindow(minute, 1, 60) OVER (PARTITION BY user_id)
```

**SELECT** проецирует данные, имеющие отношение к взаимодействию с пользователем, вместе с продолжительностью взаимодействия. Группировка данных по пользователю и **SessionWindow,** который закрывается, если взаимодействие не происходит в течение 1 минуты, с максимальным размером окна 60 минут.

Для получения дополнительной информации о **SessionWindow**, обратитесь к [session Window](/stream-analytics-query/session-window-azure-stream-analytics) .

## <a name="language-extensibility-with-user-defined-function-in-javascript-and-c"></a>Расширяемость языка с функцией, определяемой пользователем в JavaScript и C #

Язык запросов Azure Stream Analytics может быть расширен с помощью пользовательских функций, написанных либо на javaScript, либо на языке C. Пользовательские определенные функции (UDF) — это пользовательские/сложные вычисления, которые не могут быть легко выражены с помощью языка **S'L.** Эти UDF можно определить один раз и использовать несколько раз в рамках запроса. Например, UDF может быть использован для преобразования значения гексадецимального *nvarchar (max)* в *большое* значение.

**Входный вход**:

| Device_id | HexValue |
| --- | --- |
| 1 | "B4" |
| 2 | "11B" |
| 3 | "121" |

**Выход**:

| Device_id | Decimal |
| --- | --- |
| 1 | 180 |
| 2 | 283 |
| 3 | 289 |

```JavaScript
function hex2Int(hexValue){
    return parseInt(hexValue, 16);
}
```

```C#
public static class MyUdfClass {
    public static long Hex2Int(string hexValue){
        return int.Parse(hexValue, System.Globalization.NumberStyles.HexNumber);
    }
}
```

```SQL
SELECT
    Device_id,
    udf.Hex2Int(HexValue) AS Decimal
From
    Input
```

Пользователь Определенная функция будет вычислять *bigint* значение от HexValue на каждом поглощенном событии.

Для получения дополнительной информации, обратитесь к [JavaScript](/azure/stream-analytics/stream-analytics-javascript-user-defined-functions) и [C .](/azure/stream-analytics/stream-analytics-edge-csharp-udf)

## <a name="advanced-pattern-matching-with-match_recognize"></a>Расширенный шаблон, соответствующий MATCH_RECOGNIZE

**MATCH_RECOGNIZE** является расширенным механизмом сопоставления шаблонов, который может быть использован для сопоставления последовательности событий с четко определенным шаблоном регулярного выражения.
Например, банкомат отслеживается в режиме реального времени на случай сбоев, во время работы банкомата, если есть два последовательных предупреждающих сообщения, о которых администратор должен быть уведомлен.

**Входный вход**:

| ATM_id | Operation_id | Return_Code | Time |
| --- | --- | --- | --- |
| 1 | "Вход ный пин" | Success | 2017-01-26T00:10:00000000 |
| 2 | "Открытие денежного слота" | Success | 2017-01-26T00:10:00000000 |
| 2 | "Закрытие денег слот" | Success | 2017-01-26T00:10:11.00000000 |
| 1 | "Ввод количества снятия" | Success | 2017-01-26T00:10:08.00000000 |
| 1 | "Открытие денежного слота" | "Предупреждение" | 2017-01-26T00:10:14.00000000 |
| 1 | "Печатный банковский баланс" | "Предупреждение" | 2017-01-26T00:10:19.00000000 |

**Выход**:

| ATM_id | First_Warning_Operation_id | Warning_Time |
| --- | --- | --- |
| 1 | "Открытие денежного слота" | 2017-01-26T00:10:14.00000000 |

```SQL
SELECT *
FROM intput TIMESTAMP BY time OVER ATM_id
MATCH_RECOGNIZE (
    PARTITON BY ATM_id
    LIMIT DURATION(minute, 1)
    MEASURES
        First(Warning.ATM_id) AS ATM_id,
        First(Warning.Operation_Id) AS First_Warning_Operation_id,
        First(Warning.Time) AS Warning_Time
    AFTER MATCH SKIP TO NEXT ROW
    PATTERN (Success* Warning{2,})
    DEFINE
        Success AS Succes.Return_Code = 'Success',
        Failure AS Warning.Return_Code <> 'Success'
) AS patternMatch
```

Этот запрос соответствует по крайней мере двум последовательным событиям сбоя и генерирует сигнал тревоги при выполнении условий.
**PATTERN** определяет регулярное выражение, используемое при сопоставлении, в данном случае, любого количества успешных операций, за которым следуют по крайней мере два последовательных сбоя.
Успех и неудача определяются с использованием Return_Code значения и как только условие выполнено, **MEASURES** проецируются с *ATM_id,* первая операция предупреждения и первое время предупреждения.

Для получения дополнительной информации, обратитесь к [MATCH_RECOGNIZE](/stream-analytics-query/match-recognize-stream-analytics).

## <a name="geofencing-and-geospatial-queries"></a>Геофенсинг и геопространственные запросы
Azure Stream Analytics предоставляет встроенные геопространственные функции, которые могут быть использованы для реализации таких сценариев, как управление автопарком, совместное использование аттракционов, подключенные автомобили и отслеживание активов.
Геопространственные данные могут попаставать либо в формате GeoJSON, либо WKT как часть потока событий или справочных данных.
Например, компания, специализирующаяся на производстве машин для печати паспортов, сдается в аренду правительствам и консульствам. Местонахождение этих машин в значительной степени контролируется, чтобы избежать неправильного размещения и возможного использования для подделки паспортов. Каждая машина оснащена GPS-трекером, эта информация передается обратно на задание Azure Stream Analytics.
Производитель хотел бы отслеживать местоположение этих машин и быть предупреждены, если один из них покидает разрешенный район, таким образом, они могут удаленно отключить, оповещения органов и получить оборудование.

**Входный вход**:

| Equipment_id | Equipment_current_location | Time |
| --- | --- | --- |
| 1 | "ТОЧКА(-122.13288797982818 47.64082002051315)" | 2017-01-26T00:10:00000000 |
| 1 | "ТОЧКА(-122.1330725298875 47.64081350934929)" | 2017-01-26T00:11:00000000 |
| 1 | "ТОЧКА(-122.13308862313283 47.6406508603241)" | 2017-01-26T00:12:00000000 |
| 1 | "ТОЧКА(-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00000000 |

**Справочные данные Ввода:**

| Equipment_id | Equipment_lease_location |
| --- | --- |
| 1 | "ПОЛИГОН(-122.133260284509 47.640983866794,-122.1326165544443333886666794,-122.1326166 1 47.640614716027751,-122.13326028450979 47.64061471661616160)" |

**Выход**:

| Equipment_id | Equipment_alert_location | Time |
| --- | --- | --- |
| 1 | "ТОЧКА(-122.13341048821462 47.64043760861279)" | 2017-01-26T00:13:00000000 |

```SQL
SELECT
    input.Equipment_id AS Equipment_id,
    input.Equipment_current_location AS Equipment_current_location,
    input.Time AS Time
FROM input TIMESTAMP BY time
JOIN
    referenceInput 
    ON input.Equipment_id = referenceInput.Equipment_id
    WHERE 
        ST_WITHIN(input.Equipment_currenct_location, referenceInput.Equipment_lease_location) = 1
```

Запрос позволяет производителю автоматически контролировать местоположение машин, получая оповещения, когда машина покидает разрешенную геоограждение. Встроенная геопространственная функция позволяет пользователям использовать данные GPS в запросе без сторонних библиотек.

Для получения дополнительной информации обратитесь к [сценариям геопространственного агрегирования Geofencing и геопространственного агрегирования в статье Azure Stream Analytics.](geospatial-scenarios.md)

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи попробуйте наш [форум Azure Stream Analytics.](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics)

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Начало использования аналитики потоков Azure](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
