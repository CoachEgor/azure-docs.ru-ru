---
title: Интеграция Azure Stream Analytics с Машинное обучение Azure
description: В этой статье описывается, как интегрировать Azure Stream Analytics задание с моделями Машинное обучение Azure.
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/19/2020
ms.openlocfilehash: 07fa72f086b676723279ee4b8efd927beb2692f0
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "81481969"
---
# <a name="integrate-azure-stream-analytics-with-azure-machine-learning-preview"></a>Интеграция Azure Stream Analytics с Машинное обучение Azure (Предварительная версия)

Вы можете реализовать модели машинного обучения в качестве определяемой пользователем функции (UDF) в заданиях Azure Stream Analytics для оценки и прогнозирования входных данных потоковой передачи в реальном времени. [Машинное обучение Azure](../machine-learning/overview-what-is-azure-ml.md) позволяет использовать любой популярный инструмент с открытым кодом, например Tensorflow, scikit-Training или PyTorch, для подготовки, обучения и развертывания моделей.

> [!NOTE]
> Эта функция доступна в общедоступной предварительной версии. Доступ к этой функции можно получить на портал Azure только с помощью [ссылки предварительный просмотр на портале Stream Analytics](https://aka.ms/asaportalpreview). Эта функция также доступна в последней версии [средств Stream Analytics для Visual Studio](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-tools-for-visual-studio-install).

## <a name="prerequisites"></a>Предварительные условия

Перед добавлением модели машинного обучения в качестве функции в задание Stream Analytics выполните следующие действия:

1. Используйте Машинное обучение Azure для [развертывания модели в качестве веб-службы](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where).

2. В скрипте оценки должны присутствовать [примеры входных и выходных данных](../machine-learning/how-to-deploy-and-where.md#example-entry-script) , которые используются машинное обучение Azure для создания спецификации схемы. Stream Analytics использует схему для понимания сигнатуры функции веб-службы.

3. Убедитесь, что веб-служба принимает и возвращает сериализованные данные JSON.

4. Разверните модель в [службе Azure Kubernetes](../machine-learning/how-to-deploy-and-where.md#choose-a-compute-target) для крупномасштабных развертываний в рабочей среде. Если веб-служба не может обрабатывать количество запросов, поступивших от задания, производительность задания Stream Analytics будет снижена, что влияет на задержку. Модели, развернутые в службе "экземпляры контейнеров Azure", сейчас не поддерживаются, но станут доступны в ближайшие месяцы.

## <a name="add-a-machine-learning-model-to-your-job"></a>Добавление модели машинного обучения в задание

Вы можете добавить функции Машинное обучение Azure в задание Stream Analytics непосредственно из портал Azure.

1. Перейдите к заданию Stream Analytics в портал Azure и выберите **функции** в разделе **топология задания**. Затем выберите **службу машинного обучения Azure** в раскрывающемся меню **Добавить** .

   ![Добавление пользовательской функции машинного обучения Azure](./media/machine-learning-udf/add-azureml-udf.png)

2. Заполните форму **машинное обучение Azure функции службы** со следующими значениями свойств:

   ![Настройка определяемой пользователем функции машинного обучения Azure](./media/machine-learning-udf/configure-azureml-udf.png)

В следующей таблице описаны все свойства функций службы машинного обучения Azure в Stream Analytics.

|Свойство|Описание|
|--------|-----------|
|Псевдоним функции|Введите имя для вызова функции в запросе.|
|Подписка|Ваша подписка Azure..|
|Рабочая область машинного обучения Azure|Машинное обучение Azure рабочей области, которая использовалась для развертывания модели в качестве веб-службы.|
|Развернутые приложения|Веб-служба, в которой размещается ваша модель.|
|Сигнатура функции|Сигнатура веб-службы выводится из спецификации схемы API. Если не удается загрузить подпись, убедитесь, что вы указали пример входных и выходных данных в скрипте оценки для автоматического создания схемы.|
|Число параллельных запросов на секцию|Это расширенная конфигурация для оптимизации высокопроизводительной пропускной способности. Это число представляет параллельные запросы, отправляемые из каждой секции задания в веб-службу. Задания с шестью единицами потоковой передачи (SU) и ниже имеют одну секцию. Задания с 12 пакетами SUs имеют две секции, 18 — три раздела и т. д.<br><br> Например, если в задании два раздела и этот параметр имеет значение 4, то в веб-службе будет содержаться восемь одновременных запросов от задания. В настоящее время общедоступной предварительной версии это значение по умолчанию равно 20 и не может быть обновлено.|
|Максимальное количество пакетов|Это расширенная конфигурация для оптимизации высокой пропускной способности. Это число представляет максимальное число событий, сгруппированных в одном запросе, отправленном в веб-службу.|

## <a name="supported-input-parameters"></a>Поддерживаемые входные параметры

Когда запрос Stream Analytics вызывает Машинное обучение Azure UDF, задание создает сериализованный запрос JSON к веб-службе. Запрос основан на схеме, зависящей от модели. Для [автоматического создания схемы](../machine-learning/how-to-deploy-and-where.md)необходимо предоставить пример входных и выходных данных в скрипте оценки. Схема позволяет Stream Analytics создавать сериализованный запрос JSON для любого из поддерживаемых типов данных, таких как NumPy, Pandas и PySpark. Несколько входных событий можно сгруппировать в одном запросе.

Следующий Stream Analytics запрос является примером того, как вызвать определяемую пользователем функцию Машинное обучение Azure:

```SQL
SELECT udf.score(<model-specific-data-structure>)
INTO output
FROM input
```

Stream Analytics поддерживает только передачу одного параметра для функций Машинное обучение Azure. Возможно, потребуется подготовить данные перед передачей их в качестве входных данных в UDF машинного обучения.

## <a name="pass-multiple-input-parameters-to-the-udf"></a>Передача нескольких входных параметров в определяемую пользователем функцию

Наиболее распространенными примерами входных данных для моделей машинного обучения являются NumPy массивы и кадры данных. Можно создать массив с помощью определяемой пользователем функции JavaScript и создать сериализованный JSON фрейм данных с помощью `WITH` предложения.

### <a name="create-an-input-array"></a>Создание входного массива

Вы можете создать определяемую пользователем функцию JavaScript, которая принимает *N* числовых входов и создает массив, который можно использовать в качестве входных данных для машинное обучение Azure UDF.

```javascript
function createArray(vendorid, weekday, pickuphour, passenger, distance) {
    'use strict';
    var array = [vendorid, weekday, pickuphour, passenger, distance]
    return array;
}
```

После добавления определяемой пользователем функции JavaScript в задание можно вызвать определяемую пользователем функцию Машинное обучение Azure с помощью следующего запроса:

```SQL
SELECT udf.score(
udf.createArray(vendorid, weekday, pickuphour, passenger, distance)
)
INTO output
FROM input
```

Ниже приведен пример запроса JSON.

```JSON
{
    "data": [
        ["1","Mon","12","1","5.8"],
        ["2","Wed","10","2","10"]
    ]
}
```

### <a name="create-a-pandas-or-pyspark-dataframe"></a>Создание кадра данных Pandas или PySpark

С помощью `WITH` предложения можно создать сериализованный фрагмент данных JSON, который можно передать в качестве входных данных для машинное обучение Azure UDF, как показано ниже.

Следующий запрос создает таблицу данных, выбирая необходимые поля и использующий в качестве входных данных кадр в Машинное обучение Azure UDF.

```SQL
WITH 
Dataframe AS (
SELECT vendorid, weekday, pickuphour, passenger, distance
FROM input
)

SELECT udf.score(Dataframe)
INTO output
FROM input
```

Следующий код JSON является примером запроса из предыдущего запроса:

```JSON
{
    "data": [{
            "vendorid": "1",
            "weekday": "Mon",
            "pickuphour": "12",
            "passenger": "1",
            "distance": "5.8"
        }, {
            "vendorid": "2",
            "weekday": "Tue",
            "pickuphour": "10",
            "passenger": "2",
            "distance": "10"
        }
    ]
}
```

## <a name="optimize-the-performance-for-azure-machine-learning-udfs"></a>Оптимизация производительности для Машинное обучение Azure UDF

При развертывании модели в службе Kubernetes Azure можно [профилировать модель, чтобы определить использование ресурсов](../machine-learning/how-to-deploy-and-where.md#profilemodel). Вы также можете [включить Application Insights для развертываний](../machine-learning/how-to-enable-app-insights.md) , чтобы понять частоту запросов, время отклика и частоту сбоев.

При наличии сценария с высокой пропускной способностью событий может потребоваться изменить следующие параметры в Stream Analytics для достижения оптимальной производительности с низкой задержкой.

1. Максимальное число пакетов.
2. Число параллельных запросов на секцию.

### <a name="determine-the-right-batch-size"></a>Определение правильного размера пакета

После развертывания веб-службы вы отправляете пример запроса с различными размерами пакетов, начиная с 50 и увеличивая его в порядке сотен. Например, 200, 500, 1000, 2000 и т. д. Вы заметите, что после определенного размера пакета задержка ответа увеличится. Точка, после которой увеличивается задержка ответа, должна быть максимальным числом пакетов для вашего задания.

### <a name="determine-the-number-of-parallel-requests-per-partition"></a>Определение числа параллельных запросов на секцию

При оптимальном масштабировании Stream Analytics задание должно иметь возможность отправить несколько параллельных запросов в веб-службу и получить ответ в течение нескольких миллисекунд. Задержка ответа веб-службы может напрямую влиять на задержку и производительность задания Stream Analytics. Если вызов из задания к веб-службе занимает много времени, то, скорее всего, будет возникать увеличение задержки водяного знака, а также увеличено число входных событий ввода.

Чтобы предотвратить такую задержку, убедитесь, что кластер Azure Kubernetes Service (AKS) был подготовлен с [правильным числом узлов и реплик](../machine-learning/how-to-deploy-azure-kubernetes-service.md#using-the-cli). Очень важно, чтобы веб-служба была высокодоступна и возвращала успешные ответы. Если ваше задание получает недоступную службу (503) от веб-службы, она будет постоянно повторяться с экспоненциальной обратной попыткой. Любой ответ, отличный от Success (200) и служба недоступна (503), приведет к переходу задания в состояние сбоя.

## <a name="next-steps"></a>Дальнейшие шаги

* [Руководство. Пользовательские функции JavaScript Azure Stream Analytics](stream-analytics-javascript-user-defined-functions.md)
* [Масштабирование задания Stream Analytics с помощью функции Машинное обучение Azure Studio (классическая модель)](stream-analytics-scale-with-machine-learning-functions.md)

