---
title: Выходные данные Azure Stream Analytics в Cosmos DB
description: Из этой статьи вы узнаете, как с помощью Azure Stream Analytics сохранять выходные данные в Azure Cosmos DB в формате JSON, что позволяет архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON.
services: stream-analytics
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 01/11/2019
ms.custom: seodec18
ms.openlocfilehash: aa4ac011a7b6258958ac1ac176fd63b18a4ef856
ms.sourcegitcommit: c31dbf646682c0f9d731f8df8cfd43d36a041f85
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/27/2019
ms.locfileid: "74560182"
---
# <a name="azure-stream-analytics-output-to-azure-cosmos-db"></a>Выходные данные Azure Stream Analytics в Azure Cosmos DB  
Stream Analytics позволяет направлять данные из [Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/) в формат JSON, позволяя архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON. В этом документе представлены некоторые рекомендации по реализации данной конфигурации.

Тем, кто не знаком с Cosmos DB, мы рекомендуем просмотреть [схему обучения работе с Azure Cosmos DB](https://azure.microsoft.com/documentation/learning-paths/documentdb/). 

> [!Note]
> В настоящее время Azure Stream Analytics поддерживает соединение только с Azure Cosmos DB при помощи **SQL API**.
> Другие API Azure Cosmos DB в данный момент не поддерживаются. Если указать модулю Azure Stream Analytics учетные записи Azure Cosmos DB, созданные при помощи других API, это может привести к неправильному сохранению данных. 

## <a name="basics-of-cosmos-db-as-an-output-target"></a>Основные сведения о Cosmos DB как объекте вывода данных
Azure Cosmos DB выходные данные в Stream Analytics позволяет записывать результаты обработки потока как выходные данные JSON в контейнеры Cosmos DB. Stream Analytics не создает контейнеры в базе данных, вместо этого требуется создать их заранее. Таким образом, стоимость выставления счетов за Cosmos DB контейнеров контролируется вами, и вы можете настроить производительность, согласованность и емкость контейнеров непосредственно с помощью [API-интерфейсов Cosmos DB](https://msdn.microsoft.com/library/azure/dn781481.aspx).

> [!Note]
> Необходимо добавить 0.0.0.0 в список разрешенных IP-адресов брандмауэра Azure Cosmos DB.

Ниже приведены некоторые параметры контейнера Cosmos DB.

## <a name="tune-consistency-availability-and-latency"></a>Настройка согласованности, доступности и задержки
В соответствии с требованиями приложения Azure Cosmos DB позволяет точно настраивать базу данных и контейнеры и принимать компромиссы между согласованностью, доступностью, задержкой и пропускной способностью. В зависимости от того, какие уровни согласованности чтения потребуются вашему сценарию для чтения и записи задержки, вы можете выбирать уровень согласованности в своей учетной записи базы данных. Пропускную способность можно увеличить, увеличив количество единиц запроса (RUs) в контейнере. Кроме того, по умолчанию Azure Cosmos DB позволяет выполнять синхронное индексирование для каждой операции CRUD в контейнере. Это еще один полезный параметр для контроля производительности операций чтения и записи в Azure Cosmos DB. Дополнительные сведения см. в статье об [изменении уровней согласованности в для базы данных и запросов](../cosmos-db/consistency-levels.md).

## <a name="upserts-from-stream-analytics"></a>Вставка и обновление Upsert в Stream Analytics
Stream Analytics интеграция с Azure Cosmos DB позволяет вставлять или обновлять записи в контейнере на основе заданного столбца идентификатора документа. Этот процесс называется также *Upsert*.

Stream Analytics использует оптимистичный подход Upsert, при котором обновления выполняются только тогда, когда операция вставки завершается ошибкой из-за конфликта с идентификатором документа. С уровнем совместимости 1,0 это обновление выполняется как исправление, поэтому оно позволяет частично обновлять документ, то есть добавлять новые свойства или заменять существующее свойство, выполняется постепенно. Тем не менее изменение значений свойств массива в документе JSON приводит к перезаписи всего массива, то есть массивы не объединяются. В 1,2 поведение Upsert изменяется для вставки или замены документа. Это описано далее в разделе уровень совместимости 1,2 ниже.

Если входящий документ JSON содержит существующее поле идентификатора, это поле автоматически используется в качестве столбца идентификаторов документов в Cosmos DB и все последующие операции записи обрабатываются следующим образом:
- для уникальных идентификаторов выполняется вставка;
- если для повторяющихся идентификаторов и параметра Document ID задано значение "ID", выполняется операция upsert;
- если для повторяющихся идентификаторов и параметра Document ID не задано значение, после первого документа возникает ошибка.

Если вы хотите сохранить <i>все</i> документы, включая документы с повторяющимся идентификатором, переименуйте поле идентификатора в запросе (с ключевым словом AS) и разрешите Cosmos DB автоматически создавать поле идентификатора или заменять идентификатор значением из другого столбца (с помощью ключевого слова AS или с помощью параметра Document ID).

## <a name="data-partitioning-in-cosmos-db"></a>Секционирование данных в Cosmos DB
[Неограниченные](../cosmos-db/partition-data.md) контейнеры для Azure Cosmos DB — это рекомендуемый способ секционирования данных, так как Azure Cosmos DB автоматически масштабирует разделы на основе рабочей нагрузки. При записи в неограниченные контейнеры Stream Analytics используется столько же параллельных модулей записи, сколько и на предыдущем шаге запроса или в схеме разбиения входных данных.
> [!NOTE]
> В настоящее время Azure Stream Analytics поддерживает только неограниченные контейнеры с ключами секции на верхнем уровне. Например, `/region` поддерживается. Вложенные ключи разделов (например, `/region/name`) не поддерживаются. 

В зависимости от выбранного ключа раздела может появиться следующее _предупреждение_:

`CosmosDB Output contains multiple rows and just one row per partition key. If the output latency is higher than expected, consider choosing a partition key that contains at least several hundred records per partition key.`

Важно выбрать свойство ключа секции, которое имеет несколько уникальных значений, и позволяет распределять рабочую нагрузку равномерно по этим значениям. В качестве естественного артефакта секционирования запросы, включающие один и тот же ключ секции, ограничиваются максимальной пропускной способностью одной секции. Кроме того, размер хранилища для документов, принадлежащих к одному и тому же ключу раздела, ограничен 10 ГБ. Идеальный ключ секции — это тот, который часто отображается в качестве фильтра в запросах и обеспечивает достаточную кратность, чтобы гарантировать масштабируемость решения.

Ключ секции также является границей для транзакций в хранимых процедурах и триггерах DocumentDB. Следует выбрать ключ секции, чтобы документы, которые выполняются в транзакциях, совместно используют одно и то же значение ключа секции. В статье [секционирование в Cosmos DB](../cosmos-db/partitioning-overview.md) содержатся дополнительные сведения о выборе ключа секции.

Для фиксированных Azure Cosmos DB контейнеров Stream Analytics не позволяет увеличивать или уменьшать масштаб по мере заполнения. Верхний предел их пропускной способности: 10 ГБ и 10 000 ЕЗ/с.  Чтобы перенести данные из контейнера фиксированного размера в контейнер неограниченного размера (например, с ключом секции и пропускной способностью не менее 1000 ЕЗ/с), вам нужно использовать [средство миграции данных](../cosmos-db/import-data.md) или [библиотеку канала изменений](../cosmos-db/change-feed.md).

Возможность записи в несколько фиксированных контейнеров является устаревшей и не рекомендуется для масштабирования задания Stream Analytics.

## <a name="improved-throughput-with-compatibility-level-12"></a>Улучшенная пропускная способность с уровнем совместимости 1,2
С уровнем совместимости 1,2 Stream Analytics поддерживает собственную интеграцию для выполнения операции записи в Cosmos DB. Это позволяет эффективно вести запись в Cosmos DB с максимально возможной пропускной способностью и эффективно обработкой запросов на регулирование. Улучшенный механизм записи доступен в соответствии с новым уровнем совместимости из-за разницы в поведении Upsert.  До 1,2, поведение Upsert заключается в вставке или объединении документа. В 1,2 поведение операции Upsert изменяется для вставки или замены документа.

До 1,2 использует пользовательскую хранимую процедуру для пакетной обработки Upsert документов на ключ секции в Cosmos DB, где пакет записывается как транзакция. Даже если одна запись достигает временной ошибки (регулирование), необходимо повторить весь пакет. Это сделано в сценариях даже с разумным регулированием относительно медленного регулирования. После сравнения показано, как эти задания будут вести себя с 1,2.

В следующем примере показаны два идентичных задания Stream Analytics, считывающие данные с одного концентратора событий. Оба Stream Analytics задания [полностью секционированы](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#embarrassingly-parallel-jobs) с транзитным запросом и записываются в идентичные контейнеры CosmosDB. Метрики слева находятся в задании с уровнем совместимости 1,0, а справа — с 1,2. Ключ секции Cosmos DB контейнера — это уникальный идентификатор GUID, поступающий из события ввода.

![Сравнение метрик Stream Analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-3.png)

Частота входящих событий в концентраторе событий составляет 2x выше, чем Cosmos DB контейнеров (20 000 RUs) настраивается на принимать, поэтому регулирование ожидается в Cosmos DB. Однако задание с 1,2ом постоянно записывается с более высокой пропускной способностью (события вывода в минуту) и с меньшим средним использованием SU%. В вашей среде это различие будет зависеть от нескольких дополнительных факторов, таких как выбор формата событий, входных событий и сообщений, ключей секций, запросов и т. д.

![Сравнение метрик Cosmos DB](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)

В 1,2 Stream Analytics более интеллектуальные при использовании 100% доступной пропускной способности в Cosmos DB с очень малой повторной отправкой от регулирования/ограничения скорости. Это обеспечивает более эффективное взаимодействие с другими рабочими нагрузками, такими как запросы, выполняющиеся в контейнере. Если вам нужно попробовать, как ASA масштабируется с Cosmos DB в качестве приемника для 1000 до 10000 сообщений в секунду, вот [проект примеров Azure](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-cosmosdb) , позволяющий это сделать.
Обратите внимание, что пропускная способность Cosmos DBа идентична 1,0 и 1,1. Поскольку 1,2 в настоящее время не является значением по умолчанию, можно [задать уровень совместимости](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-compatibility-level) для задания Stream Analytics с помощью портала или с помощью [вызова REST API создания задания](https://docs.microsoft.com/rest/api/streamanalytics/stream-analytics-job). *Настоятельно рекомендуется* использовать уровень совместимости 1,2 в ASA с Cosmos DB.



## <a name="cosmos-db-settings-for-json-output"></a>Параметры Cosmos DB для выходных данных JSON

При создании Cosmos DB как средства обработки выходных данных в Stream Analytics создается запрос информации, показанный ниже. В этом разделе объясняются определения свойств.

![экран выходных данных documentdb stream analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png)

|Поле           | Описание|
|-------------   | -------------|
|Псевдоним выходных данных    | Псевдоним для ссылки на эти выходные данные в запросе ASA.|
|Subscription    | Выберите подписку Azure.|
|Идентификатор учетной записи      | Имя или универсальный код ресурса (URI) конечной точки учетной записи Azure Cosmos DB.|
|Ключ учетной записи     | Общедоступный ключ доступа к учетной записи Azure Cosmos DB.|
|База данных        | Имя базы данных Azure Cosmos DB.|
|Имя контейнера | Имя используемого контейнера. `MyContainer` является примером допустимых входных данных — один контейнер с именем `MyContainer` должен существовать.  |
|Идентификатор документа     | Необязательный элемент. Имя столбца в выходных событиях используется как уникальный ключ, на котором должны основываться операции вставки или обновления. Если оставить это поле пустым, все события будут вставлены, без возможности обновления.|

После настройки выходных данных Cosmos DB их можно использовать в запросе в качестве целевого объекта [инструкции into](https://docs.microsoft.com/stream-analytics-query/into-azure-stream-analytics). При использовании выходных данных Cosmos DB, необходимо [явно задать ключ секции](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#partitions-in-sources-and-sinks). Выходная запись должна содержать столбец с учетом регистра, названный после ключа секции в Cosmos DB. Для достижения большей параллелизации оператору может потребоваться [Предложение PARTITION BY](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#embarrassingly-parallel-jobs) , использующее тот же столбец.

**Образец запроса**:

```SQL
    SELECT TollBoothId, PartitionId
    INTO CosmosDBOutput
    FROM Input1 PARTITION BY PartitionId
``` 

## <a name="error-handling-and-retries"></a>Обработка ошибок и повторные попытки

В случае временного сбоя, недоступности или регулирования службы при отправке событий в Cosmos DB Stream Analytics пытается завершить операцию неограниченное время. Однако повторные попытки не предпринимаются в случае сбоев таких типов:

- Несанкционированный (код ошибки HTTP 401)
- NotFound (код ошибки HTTP 404)
- Запрещено (код ошибки HTTP 403)
- BadRequest (код ошибки HTTP 400)
