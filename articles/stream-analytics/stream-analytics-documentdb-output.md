---
title: Выходные данные Azure Stream Analytics в Azure Cosmos DB
description: Из этой статьи вы узнаете, как с помощью Azure Stream Analytics сохранять выходные данные в Azure Cosmos DB в формате JSON, что позволяет архивировать данные и уменьшать задержки запросов в отношении неструктурированных данных JSON.
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 02/2/2020
ms.custom: seodec18
ms.openlocfilehash: e58e36b3caa5a5ecd137cb9cb61dad7ddb95ff3a
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79254447"
---
# <a name="azure-stream-analytics-output-to-azure-cosmos-db"></a>Выходные данные Azure Stream Analytics в Azure Cosmos DB  
Аналитика Azure Stream Analytics может настроить таргетинг [на Azure Cosmos DB](https://azure.microsoft.com/services/documentdb/) для вывода JSON, что позволяет архивировать данные и запросы с низкой задержкой на неструктурированных данных JSON. В этом документе представлены некоторые рекомендации по реализации данной конфигурации.

Если вы не знакомы с DB Azure Cosmos, обратитесь к [документации Azure Cosmos DB,](https://docs.microsoft.com/azure/cosmos-db/) чтобы начать работу. 

> [!Note]
> В настоящее время Stream Analytics поддерживает подключение к Azure Cosmos DB только через *API.*
> Другие API Azure Cosmos DB в данный момент не поддерживаются. Если вы указываете Stream Analytics на учетные записи DB Azure Cosmos, созданные с помощью других AAP, данные могут быть неправильно сохранены. 

## <a name="basics-of-azure-cosmos-db-as-an-output-target"></a>Основы Azure Cosmos DB в качестве цели вывода
Выход Azure Cosmos DB в Stream Analytics позволяет записывать результаты обработки потоков по мере вывода JSON в контейнеры Azure Cosmos DB. 

Stream Analytics не создает контейнеры в базе данных. Вместо этого, он требует, чтобы вы создали их заранее. Затем можно контролировать затраты на выставление счетов контейнеров Azure Cosmos DB. Вы также можете настроить производительность, согласованность и емкость контейнеров непосредственно с помощью [AA AA AA Azure Cosmos DB.](https://msdn.microsoft.com/library/azure/dn781481.aspx)

> [!Note]
> Необходимо добавить 0.0.0.0 в список разрешенных IP-адресов брандмауэра Azure Cosmos DB.

В следующих разделах подробно описаны некоторые варианты контейнеров для Azure Cosmos DB.

## <a name="tuning-consistency-availability-and-latency"></a>Согласованность настройки, доступность и задержка
В соответствии с требованиями к приложениям Azure Cosmos DB позволяет дорабатывать базу данных и контейнеры и идти на компромиссы между согласованностью, доступностью, задержкой и пропускной емкостью. 

В зависимости от того, какие уровни согласованности чтения потребуются вашему сценарию для чтения и записи задержки, вы можете выбирать уровень согласованности в своей учетной записи базы данных. Вы можете улучшить пропускную емкость путем расширения единиц запроса (RUs) на контейнере. 

Кроме того, по умолчанию Azure Cosmos DB позволяет синхронную индексацию каждой операции CRUD в контейнер. Это еще один полезный вариант для управления производительностью записи/чтения в Azure Cosmos DB. 

Для получения дополнительной информации просмотрите статью [«Изменить базу данных» и уровень согласованности запросов.](../cosmos-db/consistency-levels.md)

## <a name="upserts-from-stream-analytics"></a>Вставка и обновление Upsert в Stream Analytics
Интеграция Stream Analytics с Azure Cosmos DB позволяет вставлять или обновлять записи в контейнер ею на основе данной колонки **Document ID.** Это также называется *upsert*.

Stream Analytics использует оптимистичный подход upsert. Обновления происходят только в том случае, если вставка выходит из строя с конфликтом идентификатора документа. 

С уровнем совместимости 1.0 Stream Analytics выполняет это обновление как операцию PATCH, поэтому позволяет частично обновлять документ. Stream Analytics добавляет новые свойства или заменяет существующее свойство постепенно. Однако изменения значений свойств массивов в документе JSON приводят к перезаписи всего массива. То есть массив не сливается. 

С 1.2 поведение upsert изменяется для вставки или замены документа. В более позднем разделе об уровне совместимости 1.2 далее описывается это поведение.

Если входящий документ JSON имеет существующее поле идентификатора, это поле автоматически используется в качестве столбца **идентификатора документов** в Azure Cosmos DB. Любые последующие записи обрабатываются как таковые, что приводит к одной из следующих ситуаций:

- Уникальные идолвы приводят к вставке.
- Дублирование идентификаторов и **идентификатора документов,** установленных для **идентификации,** приводит к upsert.
- Дублирование идентификаторов и **идентификатор аидирования документов,** не установленных приводят к ошибке после первого документа.

Если вы хотите сохранить *все* документы, включая документы с дубликатом идентификатора, переименуйте поле идентификатора в запросе (с помощью ключевого слова **AS).** Позвольте DB Azure Cosmos создать поле идентификатора или заменить идентификатор на значение другого столбца (с помощью ключевого слова **AS** или с помощью параметра **идентификатора документа).**

## <a name="data-partitioning-in-azure-cosmos-db"></a>Раздел данных в Azure Cosmos DB
Azure Cosmos DB автоматически масштабирует разделы в зависимости от рабочей нагрузки. Поэтому мы рекомендуем [неограниченные](../cosmos-db/partition-data.md) контейнеры в качестве подхода к разделению данных. Когда Stream Analytics записывает в неограниченные контейнеры, он использует столько же параллельных авторов, как предыдущий шаг запроса или схему раздела ввода.

> [!NOTE]
> Azure Stream Analytics поддерживает только неограниченные контейнеры с ключами раздела на верхнем уровне. Например, `/region` поддерживается. Вложенные клавиши раздела (например, `/region/name`) не поддерживаются. 

В зависимости от выбора ключа раздела, вы можете получить это _предупреждение:_

`CosmosDB Output contains multiple rows and just one row per partition key. If the output latency is higher than expected, consider choosing a partition key that contains at least several hundred records per partition key.`

Важно выбрать свойство ключа раздела, которое имеет ряд различных значений, и что позволяет равномерно распределить рабочую нагрузку по этим значениям. Как естественный артефакт раздела, запросы, связанные с одним и тем же ключом раздела, ограничены максимальной пропускной стоимостью одного раздела. 

Размер хранилища для документов, принадлежащих к одному ключу раздела, ограничен 10 ГБ. Идеальным ключом раздела является ключ, который часто появляется в качестве фильтра в запросах и имеет достаточную кардинальность, чтобы гарантировать, что ваше решение масштабируемо.

Ключ раздела также является границей для транзакций в сохраненных процедурах и триггеров для Azure Cosmos DB. Необходимо выбрать ключ раздела таким образом, чтобы документы, которые происходят вместе в транзакциях, имели одно и то же значение ключа раздела. В статье [Раздел апартирования в Azure Cosmos DB](../cosmos-db/partitioning-overview.md) приводится более подробная информация о выборе ключа раздела.

Для стационарных dB-контейнеров Azure Cosmos, Stream Analytics не позволяет масштабировать или выходить после их полного. Они имеют верхний предел пропускной памяти 10 ГБ и 10 000 руб./с. Для переноса данных из стационарного контейнера в неограниченный контейнер (например, с не менее чем 1000 RU/s и ключом раздела) используйте [инструмент миграции данных](../cosmos-db/import-data.md) или [библиотеку подачи изменений.](../cosmos-db/change-feed.md)

Способность писать в несколько фиксированных контейнеров устраняется. Мы не рекомендуем его для масштабирования вашей работы Stream Analytics.

## <a name="improved-throughput-with-compatibility-level-12"></a>Улучшенная пропускная вылимка с уровнем совместимости 1.2
С уровнем совместимости 1.2 Stream Analytics поддерживает нативную интеграцию для массовой записи в Azure Cosmos DB. Эта интеграция позволяет эффективно записываться в Azure Cosmos DB при максимальном вхожжски и эффективной обработке запросов на регулирование. 

Улучшенный механизм письма доступен при новом уровне совместимости из-за разницы в поведении upsert. С уровнями до 1.2, поведение upsert является вставить или объединить документ. С 1.2 поведение upsert изменяется для вставки или замены документа.

С уровнями до 1.2, Stream Analytics использует пользовательскую процедуру хранения для навалом upsert документов на ключ раздела в Azure Cosmos DB. Там пакет пишется как транзакция. Даже если одна запись попадает в переходную ошибку (регулирование), вся партия должна быть повторена. Это делает сценарии даже разумным регулирование относительно медленно.

В следующем примере показаны две идентичные задания Stream Analytics, считывающие данные из того же ввода событий Azure. Оба задания Stream Analytics [полностью разделены](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#embarrassingly-parallel-jobs) с помощью проходного запроса и записываются в идентичные dB-контейнеры Azure Cosmos DB. Метрика слева от задания, настроенного с уровнем совместимости 1.0. Метрика справа настроена с 1.2. Ключ раздела контейнера Azure Cosmos DB является уникальным GUID, который исходит от ввода события.

![Сравнение метрик Stream Analytics](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-3.png)

Скорость входящих событий в концентрах событий в два раза выше, чем контейнеры Azure Cosmos DB (20 000 rUs) настроены для вхриса, поэтому регулирование ожидается в Azure Cosmos DB. Тем не менее, задание с 1.2 последовательно пишет на более высокой пропускной записи (выходные события в минуту) и с более низким средним использованием SU%. В вашей среде, эта разница будет зависеть от нескольких факторов. Эти факторы включают в себя выбор формата события, размера ввода события/сообщения, ключей раздела и запроса.

![Сравнение метрик Azure Cosmos DB](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-2.png)

С 1.2, Stream Analytics является более интеллектуальным в использовании 100 процентов доступной пропускной мощности в Azure Cosmos DB с очень немногими повторами от регулирования или ограничения скорости. Это обеспечивает лучший опыт для других рабочих нагрузок, таких как запросы, работающие на контейнере в то же время. Если вы хотите увидеть, как Stream Analytics масштабируется с Azure Cosmos DB в качестве раковины для 1000 до 10000 сообщений в секунду, попробуйте [этот пример проекта Azure.](https://github.com/Azure-Samples/streaming-at-scale/tree/master/eventhubs-streamanalytics-cosmosdb)

Пропускная мощность выхода Azure Cosmos DB идентична 1.0 и 1.1. Мы *настоятельно рекомендуем* использовать уровень совместимости 1.2 в Stream Analytics с Azure Cosmos DB.

## <a name="azure-cosmos-db-settings-for-json-output"></a>Настройки Azure Cosmos DB для вывода JSON

Использование Azure Cosmos DB в качестве вывода в Stream Analytics создает следующий запрос для получения информации.

![Информационные поля для потока выходов Azure Cosmos DB](media/stream-analytics-documentdb-output/stream-analytics-documentdb-output-1.png)

|Поле           | Описание|
|-------------   | -------------|
|Псевдоним выходных данных    | Псевдоним для обозначения этого вывода в запросе Stream Analytics.|
|Подписка    | Подписка Azure.|
|Идентификатор учетной записи      | Имя или универсальный код ресурса (URI) конечной точки учетной записи Azure Cosmos DB.|
|Ключ учетной записи     | Общедоступный ключ доступа к учетной записи Azure Cosmos DB.|
|База данных        | Имя базы данных Azure Cosmos DB.|
|Имя контейнера | Название контейнера, `MyContainer`например . Один контейнер `MyContainer` с именем должен существовать.  |
|Идентификатор документа     | Необязательный параметр. Имя столбца в выходных событиях используется как уникальный ключ, на котором должны основываться операции вставки или обновления. Если вы оставите его пустым, все события будут вставлены, без опции обновления.|

После настройки вывода Azure Cosmos DB можно использовать его в запросе в качестве цели [оператора INTO.](https://docs.microsoft.com/stream-analytics-query/into-azure-stream-analytics) При использовании таким образом вывода Azure Cosmos DB [необходимо четко установить ключ раздела.](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#partitions-in-sources-and-sinks) 

Выходная запись должна содержать столбец, чувствительный к случаям, названный в честь ключа раздела в Azure Cosmos DB. Для достижения большей параллелизации для оператора может потребоваться [положение PARTITION BY,](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-parallelization#embarrassingly-parallel-jobs) в котором используется один и тот же столбец.

Вот пример запроса:

```SQL
    SELECT TollBoothId, PartitionId
    INTO CosmosDBOutput
    FROM Input1 PARTITION BY PartitionId
``` 

## <a name="error-handling-and-retries"></a>Обработка ошибок и повторные попытки

Если происходит переходный сбой, недоступность или регулирование потоков, когда Stream Analytics отправляет события в Azure Cosmos DB, Stream Analytics перезапускается на неопределенный срок, чтобы успешно завершить операцию. Но он не пытается retries для следующих сбоев:

- Несанкционированный (код ошибки HTTP 401)
- Ненайдено (код ошибки HTTP 404)
- Запрещено (код ошибки HTTP 403)
- BadRequest (код ошибки HTTP 400)
