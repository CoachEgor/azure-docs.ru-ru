---
title: Вывод данных Azure Stream Analytics в Базу данных SQL Azure
description: Сведения о выводе данных в SQL Azure из Azure Stream Analytics, а также об увеличении пропускной способности операций записи.
services: stream-analytics
author: chetanmsft
ms.author: chetanmsft
manager: katiiceva
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 3/18/2019
ms.openlocfilehash: 4be73554df0b6bddaafe3910c80c855e127d79f1
ms.sourcegitcommit: d4dfbc34a1f03488e1b7bc5e711a11b72c717ada
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "60771657"
---
# <a name="azure-stream-analytics-output-to-azure-sql-database"></a>Вывод данных Azure Stream Analytics в Базу данных SQL Azure

В этой статье рассматриваются советы по улучшению пропускной способности операций записи при загрузке данных в Базу данных SQL Azure с использованием Azure Stream Analytics.

При выводе данных в SQL из Azure Stream Analytics поддерживается запись в параллельном режиме. Эта возможность реализует топологии заданий с [полной параллельной обработкой](stream-analytics-parallelization.md#embarrassingly-parallel-jobs), когда несколько секций выходных данных могут записывать в целевую таблицу в параллельном режиме. Тем не менее активации этой возможности в Azure Stream Analytics может быть недостаточно для увеличения пропускной способности, так как пропускная способность очень зависит от конфигурации Базы данных SQL Azure и схемы таблицы. Выбранные индексы, ключ кластеризации, коэффициент заполнения индекса и сжатие влияют на время загрузки таблиц. Дополнительные сведения о том, как оптимизировать Базу данных SQL Azure для улучшения производительности запросов и загрузки на основе внутренних тестов производительности, см. в статье [Настройка производительности в Базе данных SQL Azure](../sql-database/sql-database-performance-guidance.md). Упорядочение записей не гарантируется при записи в параллельном режиме в Базе данных SQL Azure.

Ниже приведены некоторые конфигурации каждой службы, которые позволяют повысить общую пропускную способность решения.

## <a name="azure-stream-analytics"></a>Azure Stream Analytics

- **Секционирование по наследованию**. Этот вариант конфигурации выходных данных SQL позволяет наследовать схему секционирования, используемую на предыдущем шаге запроса или с предыдущими входными данными. Если этот параметр включен, выполняется запись в таблицу на диске и присутствует задание с топологией [полной параллельной обработки](stream-analytics-parallelization.md#embarrassingly-parallel-jobs), будет прослеживаться лучшая пропускная способность. Такое секционирование автоматически выполняется для многих других [выходных данных](stream-analytics-parallelization.md#partitions-in-sources-and-sinks). Блокировка таблицы (TABLOCK) также отключается для массовой вставки, выполняемой при использовании этого параметра.

> [!NOTE] 
> При наличии более чем 8 секций входных данных может быть нецелесообразно использовать наследование схемы секционирования входных данных. Это максимальное ограничение было обнаружено в таблице с одним столбцом идентификаторов и кластеризованным индексом. В этом случае рассмотрите возможность использования [INTO](https://docs.microsoft.com/stream-analytics-query/into-azure-stream-analytics#into-shard-count) 8 в ваш запрос, чтобы явно указать количество записей выходных данных. В зависимости от этой схемы и выбранных индексов, результаты отличаются.

- **Размер пакета.** Конфигурация выходных данных SQL позволяет указать максимальный размер пакета выходных данных Azure Stream Analytics в зависимости от характера целевой таблицы или рабочей нагрузки. Размер пакета равен максимальному числу записей, отправляемых с каждой транзакцией массовой вставки. В кластеризованных индексах columnstore для пакетов с числом строк около [100 000](https://docs.microsoft.com/sql/relational-databases/indexes/columnstore-indexes-data-loading-guidance) можно использовать дополнительную параллелизацию, выполнять минимальное ведение журнала и блокировки. Оптимальным выбором могут быть таблицы на диске с 10 000 строк (по умолчанию) или меньше, так как большие размеры пакетов могут привести к укрупнению блокировки во время операции массовой вставки.

- **Настройка входных сообщений.** Если вы выполнили оптимизацию с использованием секционирования по наследованию и размера пакета, путем увеличения количества входных событий в сообщении на секцию можно дополнительно повысить пропускную способность записи. Путем настройки входных сообщений размеры пакетов в Azure Stream Analytics можно увеличивать вплоть до указанного размера, тем самым повышая пропускную способность. Это можно сделать с помощью [сжатия](stream-analytics-define-inputs.md) или увеличения размера входящего сообщения в концентратор событий или BLOB-объектов.

## <a name="sql-azure"></a>SQL Azure

- **Секционированная таблица и индексы.** Если использовать [секционированные](https://docs.microsoft.com/sql/relational-databases/partitions/partitioned-tables-and-indexes?view=sql-server-2017) таблицу SQL и индексы для таблицы с тем же столбцом в качестве ключа секции (например, PartitionId), можно значительно уменьшить состязания между секциями во время операций записи. Для секционированной таблицы потребуется создать [функцию](https://docs.microsoft.com/sql/t-sql/statements/create-partition-function-transact-sql?view=sql-server-2017) и [схему](https://docs.microsoft.com/sql/t-sql/statements/create-partition-scheme-transact-sql?view=sql-server-2017) секционирования в первичной файловой группе. Это приведет к повышению уровня доступности имеющихся данных при загрузке новых данных. Может быть достигнуто ограничение операций ввода-вывода журнала в зависимости от количества секций, которые можно увеличить, обновив номер SKU.

- **Предупреждение нарушений уникальных ключей.** Если в журнале действий Azure Stream Analytics появилось [несколько предупреждающих сообщений о нарушении ключа](stream-analytics-common-troubleshooting-issues.md#handle-duplicate-records-in-azure-sql-database-output), убедитесь, что на ваше задание не повлияли нарушения ограничений, которые могут произойти во время восстановления. Этого можно избежать, установив для индексов параметр [IGNORE\_DUP\_KEY](stream-analytics-common-troubleshooting-issues.md#handle-duplicate-records-in-azure-sql-database-output).

## <a name="azure-data-factory-and-in-memory-tables"></a>Служба "Фабрика данных Azure" и таблицы в памяти

- **Таблицы в памяти в качестве временной таблицы** — [таблиц в памяти](/sql/relational-databases/in-memory-oltp/in-memory-oltp-in-memory-optimization) позволяют очень высокую скорость загрузки, а данные должны помещаться в памяти. Тесты производительности демонстрируют, что массовая загрузка из таблицы в памяти в таблицу на диске примерно в 10 раз быстрее, чем во время непосредственной массовой вставки с помощью одного средства записи в дисковой таблице со столбцом идентификаторов и кластеризованным индексом. Чтобы использовать производительность массовой вставки, настройте [задание копирования с использованием службы "Фабрика данных Azure"](../data-factory/connector-azure-sql-database.md), позволяющее копировать данные из таблицы в памяти в таблицу на диске.

## <a name="avoiding-performance-pitfalls"></a>Избежание ошибок производительности в коде
Массовой вставке данных выполняется гораздо быстрее, чем загрузка данных с помощью одной операции вставки, так как повторяющиеся избегать использования передачи данных, синтаксический анализ инструкции insert, выполнив инструкцию и выполнив запись транзакции. Вместо этого более эффективный путь используется в подсистему хранилища для потоковой передачи данных. Программа установки этот путь обходится тем не менее, гораздо выше, чем одной инструкции insert в таблице на диске. Точка безубыточности достигается обычно около 100 строк, помимо какие массовой загрузки — почти всегда более эффективно. 

В случае низкой скорости поступления событий его можно легко создать размеры пакетов ниже, чем 100 строк, которые делает неэффективным bulk insert и использует слишком много места на диске. Чтобы обойти это ограничение, необходимо выполнить одно из следующих действий:
* Создание INSTEAD OF [триггера](/sql/t-sql/statements/create-trigger-transact-sql) использование простой инструкции insert для каждой строки.
* Используйте временную таблицу в памяти, как описано в предыдущем разделе.

Еще один сценарий возникает при записи в индекс некластеризованный columnstore (NCCI), где меньшего размера операции массовой вставки можно создать слишком много сегментов, которые могут вызвать сбой индекс. В этом случае рекомендуется вместо этого использовать индекс Clustered Columnstore.

## <a name="summary"></a>Сводка

Таким образом, если использовать функцию секционирования выходных данных в Azure Stream Analytics для выходных данных SQL, согласованная параллелизация задания с секционированной таблицей в SQL Azure может обеспечить значительные усовершенствования пропускной способности. Использование службы "Фабрика данных Azure" для оркестрации перемещения данных из таблицы в памяти в таблицы на диске позволяет достичь значительного увеличения пропускной способности. Если это целесообразно, повышение плотности сообщений также может быть важным фактором для улучшения общей пропускной способности.
