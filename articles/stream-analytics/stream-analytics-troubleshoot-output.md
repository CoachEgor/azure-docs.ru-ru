---
title: Устранение неполадок с выходными данными в Azure Stream Analytics
description: В этой статье описаны методы устранения неполадок с выходными подключениями в заданиях Azure Stream Analytics.
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/31/2020
ms.custom: seodec18
ms.openlocfilehash: 5652df0cf142af2ff96590368892530abcb3d667
ms.sourcegitcommit: edccc241bc40b8b08f009baf29a5580bf53e220c
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/24/2020
ms.locfileid: "82133227"
---
# <a name="troubleshoot-azure-stream-analytics-outputs"></a>Устранение неполадок с выходными данными в Azure Stream Analytics

В этой статье описаны распространенные проблемы с Azure Stream Analytics выходными подключениями, способы устранения проблем с выводом и способы устранения проблем. Во многих действиях по устранению неполадок необходимо включить ресурсы и другие журналы диагностики для задания Stream Analytics. Если журналы ресурсов не включены, см. раздел [Устранение неполадок Azure Stream Analytics с помощью журналов ресурсов](stream-analytics-job-diagnostic-logs.md).

## <a name="output-not-produced-by-job"></a>Выходные данные, не созданные заданием

1.  Проверьте подключение к портам вывода с помощью кнопки **Проверить подключение** для всех выходных данных.

2.  Просмотрите [**метрики мониторинга**](stream-analytics-monitoring.md) на вкладке **монитор** . Так как значения суммируются, метрики откладываются на несколько минут.
   * Если события ввода больше 0, задание может считывать входные данные. Если события ввода не больше 0, то возникает ошибка с входными данными задания. Дополнительные сведения об устранении неполадок подключения см. в статье [Устранение неполадок входных подключений](stream-analytics-troubleshoot-input.md) .
   * Если ошибки преобразования данных больше 0 и увеличиваться, см. Дополнительные сведения об ошибках преобразования данных [Azure Stream Analytics данных](data-errors.md) .
   * Если ошибки времени выполнения больше 0, задание может получить данные, но при обработке запроса будут выдаваться ошибки. Чтобы найти ошибки, перейдите к [журналам аудита](../azure-resource-manager/management/view-activity-logs.md) и выполните фильтрацию по состоянию *Сбой*.
   * Если Инпутевентс больше 0, а Аутпутевентс равен 0, то выполняется одно из следующих условий.
      * В результате обработки исходящие события не получены.
      * События или поля могут быть неправильно сформированы, что приводит к нулевому выходу после обработки запроса.
      * Заданию не удалось передать данные в приемник выходных данных из-за проблем с подключением или аутентификацией.

   В указанных случаях дополнительные сведения об этих ошибках можно получить в сообщениях журнала операций (включая сведения о самом событии), за исключением случаев, когда логика запроса отфильтровала все события. Если обработка нескольких событий приводит к возникновению ошибок, эти ошибки суммируются каждые 10 минут.

## <a name="job-output-is-delayed"></a>Выходные данные задания задерживаются

### <a name="first-output-is-delayed"></a>Первый фрагмент выходных данных задерживается

При запуске задания Stream Analytics считываются входные события, но при определенных обстоятельствах может произойти задержка формирования выходных данных.

Большие значения времени в элементах темпоральных запросов могут приводить к задержке выходных данных. Чтобы сформировать правильные выходные данные за большие периоды времени, задание потоковой передачи начинает считывать данные за самое последнее время (до семи дней назад) для охвата временного окна. В течение этого времени выходные данные не создаются, пока не будут считаны все необработанные входные события. Эта проблема может возникнуть, когда система обновляет задания потоковой передачи, тем самым перезапуская их. Такие обновления обычно происходят один раз каждые несколько месяцев.

Таким образом, проявляйте осторожность при проектировании запроса Stream Analytics. Если вы используете большое временное окно (более чем несколько часов, до семи дней) для темпоральных элементов в синтаксисе запроса задания, то это может привести к задержке первого фрагмента выходных данных при запуске или перезапуске задания.  

В качестве способа устранения этой задержки можно использовать методы параллелизации запросов (секционирование данных) или добавить дополнительные единицы потоковой передачи, чтобы повысить пропускную способность, пока задание наверстывает упущенное.  Дополнительные сведения см. в статье [Концепции контрольных точек и воспроизведения в Azure Stream Analytics](stream-analytics-concepts-checkpoint-replay.md).

Эти факторы влияют на своевременность генерации первого фрагмента выходных данных:

1. Использование агрегатов данных на основе периодов (оператор группирования GROUP BY по "переворачивающимся", "прыгающим" и "скользящим" окнам).
   - Для агрегатов "переворачивающихся" или "прыгающих" окон результаты создаются в конце оконного временного интервала.
   - Для "скользящего" окна результаты создаются, когда событие входит в это окно или выходит из него.
   - Если вы планируете использовать большой размер окна (> 1 часа), то лучше выбрать "прыгающее" или "скользящее" окно, чтобы вы могли чаще видеть выходные данные.

2. Использование темпоральных соединений (JOIN с DATEDIFF).
   - Соответствия генерируются, как только поступают оба экземпляра сопоставляемых событий.
   - Данные без соответствия (LEFT OUTER JOIN) создаются в конце окна DATEDIFF относительно каждого события с левой стороны.

3. Использование темпоральных аналитических функции (ISFIRST, LAST и LAG с LIMIT DURATION).
   - Для аналитических функций выходные данные создаются для каждого события без задержки.

### <a name="output-falls-behind"></a>Выходные данные запаздывают

Если вы обнаружите, что во время обычной работы задания выходные данные задерживаются (и задержка становится больше и больше), то можно выявить первопричины, проанализировав такие факторы:
- регулируется ли подчиненный приемник:
- регулируется ли вышестоящий источник данных;
- потребляет ли логика обработки в запросе много вычислительных ресурсов.

Чтобы просмотреть эти сведения, на портале Azure выберите задание потоковой передачи и щелкните **Схема заданий**. Для каждого набора входных данных есть метрика событий невыполненной работы секции. Если метрика невыполненной работы увеличивается, это сигнализирует об ограниченности ресурсов системы. Это может быть связано с регулированием приемника выходных данных или высокой загрузкой ЦП. Дополнительные сведения об использовании схемы заданий см. в статье [Отладка на основе данных с помощью схемы заданий](stream-analytics-job-diagram-with-metrics.md).

## <a name="key-violation-warning-with-azure-sql-database-output"></a>Предупреждение о нарушении ключа с выходными данными службы "База данных SQL Azure"

При настройке службы "База данных SQL Azure" для выходных данных задания Stream Analytics выполняется массовая вставка записей в целевую таблицу. Обычно Azure Stream Analytics гарантирует [по крайней мере однократную доставку](https://docs.microsoft.com/stream-analytics-query/event-delivery-guarantees-azure-stream-analytics) в приемник выходных данных. Но можно обеспечить и [исключительно однократную доставку]( https://blogs.msdn.microsoft.com/streamanalytics/2017/01/13/how-to-achieve-exactly-once-delivery-for-sql-output/) для выходных данных SQL. Для этого в таблице SQL нужно определить уникальное ограничение.

Когда в таблицу SQL, в которой настроены уникальные ограничения ключей, вставляются повторяющиеся записи, Azure Stream Analytics удаляет такую запись. Данные разделяются на пакеты, которые рекурсивно вставляются, пока не будет обнаружена повторяющаяся запись. Если задание потоковой передачи имеет значительное число повторяющихся строк, процесс разбиения и вставки должен игнорировать дубликаты по одному, что менее эффективно и занимает много времени. Если в журнале действий в течение последнего часа отображается несколько предупреждающих сообщений о нарушении ключа, вполне вероятно, что обработка выходных данных SQL замедляет выполнение всего задания.

Чтобы устранить эту проблему, нужно [настроить индекс]( https://docs.microsoft.com/sql/t-sql/statements/create-index-transact-sql), который вызывает нарушение ключа, включив параметр IGNORE_DUP_KEY. Этот параметр позволяет пропускать в SQL повторяющиеся значения при массовой вставке. В таком случае в SQL Azure вместо сообщения об ошибке отображается предупреждающее сообщение. Azure Stream Analytics больше не создают сообщения об ошибке при нарушении первичного ключа.

Если IGNORE_DUP_KEY настраивается для нескольких типов индексов, обратите внимание на следующее:

* IGNORE_DUP_KEY нельзя установить для первичного ключа или уникального ограничения, в котором используется ALTER INDEX. Индекс нужно удалить и создать повторно.  
* Вы можете задать параметр IGNORE_DUP_KEY для уникального индекса при помощи ALTER INDEX. Это ограничение отличается от PRIMARY KEY или UNIQUE и создается с использованием определения CREATE INDEX или INDEX.  

* IGNORE_DUP_KEY не применяется к индексам хранилища столбцов, так как нельзя обеспечить уникальность таких индексов.  

## <a name="column-names-are-lower-cased-by-azure-stream-analytics"></a>Имена столбцов записываются в нижнем регистре Azure Stream Analytics
При использовании исходного уровня совместимости (1,0) Azure Stream Analytics используется для изменения имен столбцов на нижний регистр. Это поведение было исправлено на более поздних уровнях совместимости. Чтобы сохранить вариант, мы советуем клиентам перейти на уровень совместимости 1,1 и более поздней версии. Дополнительные сведения об [уровне совместимости для Azure Stream Analyticsных заданий](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-compatibility-level)см. здесь.

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи посетите наш [Azure Stream Analytics Форум](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Следующие шаги

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
