---
title: Устранение неполадок с выходными данными в Azure Stream Analytics
description: В этой статье описаны методы устранения неполадок с выходными подключениями в заданиях Azure Stream Analytics.
services: stream-analytics
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/07/2018
ms.custom: seodec18
ms.openlocfilehash: a07ac40ad3adda486b5216e83d683e00ec93265d
ms.sourcegitcommit: 6a42dd4b746f3e6de69f7ad0107cc7ad654e39ae
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/07/2019
ms.locfileid: "67620793"
---
# <a name="troubleshoot-azure-stream-analytics-outputs"></a>Устранение неполадок с выходными данными в Azure Stream Analytics

На этой странице описываются распространенные проблемы с выходными подключениями и методы их устранения.

## <a name="output-not-produced-by-job"></a>Выходные данные, не созданные заданием 
1.  Проверьте подключение к портам вывода с помощью кнопки **Проверить подключение** для всех выходных данных.

2.  Проверьте [**метрики мониторинга**](stream-analytics-monitoring.md) на вкладке **Монитор**. Так как значения агрегированы, метрики задерживаются на несколько минут.
    - Если значение параметра "Входные события" больше 0, задание может читать данные. Если значение параметра "Входные события" меньше 0, сделайте следующее:
      - Чтобы узнать, используются ли в источнике данных допустимые данные, проверьте [обозреватель служебной шины](https://code.msdn.microsoft.com/windowsapps/Service-Bus-Explorer-f2abca5a). Эта проверка применяется, если задание использует концентратор событий в качестве точки ввода.
      - Проверьте формат сериализации и шифрования данных.
      - Если задание использует концентратор событий, проверьте, задано ли для текста сообщения значение *null*.
      
    - Если обнаружены ошибки преобразования данных и показатель растет, должны выполняться следующие условия:
      - Выходное событие не соответствует схеме целевого приемника. 
      - Схема событий может не соответствовать определенной или ожидаемой схеме событий в запросе.
      - В событии могут обнаружиться неожиданные типы данных в некоторых полях.
      
    - Если обнаружены ошибки среды выполнения, это означает, что задание может получать данные, но выдает ошибки при обработке запроса.
      - Чтобы найти ошибки, перейдите к [журналам аудита](../azure-resource-manager/resource-group-audit.md) и выполните фильтрацию по состоянию *Сбой*.
      
    - Если значение InputEvents больше 0, а OutputEvents равно 0, это означает, что выполняется одно из следующих условий:
      - В результате обработки исходящие события не получены.
      - События или его поля могут быть повреждены, и выходные события после обработки запроса не получены.
      - Заданию не удалось передать данные в приемник выходных данных из-за проблем с подключением или аутентификацией.
      
    - В указанных случаях дополнительные сведения об этих ошибках можно получить в сообщениях журнала операций (включая сведения о самом событии), за исключением случаев, когда логика запроса отфильтровала все события. Если обработка нескольких событий создает ошибки, Stream Analytics регистрирует в журналах операций первые три сообщения об ошибке того же типа в течение 10 минут. Затем дополнительные сообщения об идентичных ошибках скрываются, и появляется сообщение о том, что ошибки возникают слишком быстро, поэтому сообщения о них скрываются.
    
## <a name="job-output-is-delayed"></a>Выходные данные задания задерживаются

### <a name="first-output-is-delayed"></a>Первый фрагмент выходных данных задерживается
При запуске задания Stream Analytics считываются входные события, но при определенных обстоятельствах может произойти задержка формирования выходных данных.

Большие значения времени в элементах темпоральных запросов могут приводить к задержке выходных данных. Чтобы сформировать правильные выходные данные за большие периоды времени, задание потоковой передачи начинает считывать данные за самое последнее время (до семи дней назад) для охвата временного окна. В течение этого времени выходные данные не создаются, пока не будут считаны все необработанные входные события. Эта проблема может возникнуть, когда система обновляет задания потоковой передачи, тем самым перезапуская их. Такие обновления обычно происходят один раз каждые несколько месяцев. 

Таким образом, проявляйте осторожность при проектировании запроса Stream Analytics. Если вы используете большое временное окно (более чем несколько часов, до семи дней) для темпоральных элементов в синтаксисе запроса задания, то это может привести к задержке первого фрагмента выходных данных при запуске или перезапуске задания.  

В качестве способа устранения этой задержки можно использовать методы параллелизации запросов (секционирование данных) или добавить дополнительные единицы потоковой передачи, чтобы повысить пропускную способность, пока задание наверстывает упущенное.  Дополнительные сведения см. в статье [Концепции контрольных точек и воспроизведения в Azure Stream Analytics](stream-analytics-concepts-checkpoint-replay.md).

Эти факторы влияют на своевременность генерации первого фрагмента выходных данных:

1. Использование агрегатов данных на основе периодов (оператор группирования GROUP BY по "переворачивающимся", "прыгающим" и "скользящим" окнам).
   - Для агрегатов "переворачивающихся" или "прыгающих" окон результаты создаются в конце оконного временного интервала. 
   - Для "скользящего" окна результаты создаются, когда событие входит в это окно или выходит из него. 
   - Если вы планируете использовать большой размер окна (> 1 часа), то лучше выбрать "прыгающее" или "скользящее" окно, чтобы вы могли чаще видеть выходные данные.

2. Использование темпоральных соединений (JOIN с DATEDIFF).
   - Соответствия генерируются, как только поступают оба экземпляра сопоставляемых событий.
   - Данные без соответствия (LEFT OUTER JOIN) создаются в конце окна DATEDIFF относительно каждого события с левой стороны.

3. Использование темпоральных аналитических функции (ISFIRST, LAST и LAG с LIMIT DURATION).
   - Для аналитических функций выходные данные создаются для каждого события без задержки.

### <a name="output-falls-behind"></a>Выходные данные запаздывают
Если вы обнаружите, что во время обычной работы задания выходные данные задерживаются (и задержка становится больше и больше), то можно выявить первопричины, проанализировав такие факторы:
- регулируется ли подчиненный приемник:
- регулируется ли вышестоящий источник данных;
- потребляет ли логика обработки в запросе много вычислительных ресурсов.

Чтобы просмотреть эти сведения, на портале Azure выберите задание потоковой передачи и щелкните **Схема заданий**. Для каждого набора входных данных есть метрика событий невыполненной работы секции. Если метрика невыполненной работы увеличивается, это сигнализирует об ограниченности ресурсов системы. Это может быть связано с регулированием приемника выходных данных или высокой загрузкой ЦП. Дополнительные сведения об использовании схемы заданий см. в статье [Отладка на основе данных с помощью схемы заданий](stream-analytics-job-diagram-with-metrics.md).

## <a name="key-violation-warning-with-azure-sql-database-output"></a>Предупреждение о нарушении ключа с выходными данными службы "База данных SQL Azure"

При настройке службы "База данных SQL Azure" для выходных данных задания Stream Analytics выполняется массовая вставка записей в целевую таблицу. Обычно Azure Stream Analytics гарантирует [по крайней мере однократную доставку](https://docs.microsoft.com/stream-analytics-query/event-delivery-guarantees-azure-stream-analytics) в приемник выходных данных. Но можно обеспечить и [исключительно однократную доставку]( https://blogs.msdn.microsoft.com/streamanalytics/2017/01/13/how-to-achieve-exactly-once-delivery-for-sql-output/) для выходных данных SQL. Для этого в таблице SQL нужно определить уникальное ограничение. 

Когда в таблицу SQL, в которой настроены уникальные ограничения ключей, вставляются повторяющиеся записи, Azure Stream Analytics удаляет такую запись. Данные разделяются на пакеты, которые рекурсивно вставляются, пока не будет обнаружена повторяющаяся запись. Если задание потоковой передачи имеет значительное число повторяющихся строк, процесс разбиения и вставки должен игнорировать дубликаты по одному, что менее эффективно и занимает много времени. Если в журнале действий в течение последнего часа отображается несколько предупреждающих сообщений о нарушении ключа, вполне вероятно, что обработка выходных данных SQL замедляет выполнение всего задания. 

Чтобы устранить эту проблему, нужно [настроить индекс]( https://docs.microsoft.com/sql/t-sql/statements/create-index-transact-sql), который вызывает нарушение ключа, включив параметр IGNORE_DUP_KEY. Этот параметр позволяет пропускать в SQL повторяющиеся значения при массовой вставке. В таком случае в SQL Azure вместо сообщения об ошибке отображается предупреждающее сообщение. Azure Stream Analytics больше не создают сообщения об ошибке при нарушении первичного ключа.

Если IGNORE_DUP_KEY настраивается для нескольких типов индексов, обратите внимание на следующее:

* IGNORE_DUP_KEY нельзя установить для первичного ключа или уникального ограничения, в котором используется ALTER INDEX. Индекс нужно удалить и создать повторно.  
* Вы можете задать параметр IGNORE_DUP_KEY для уникального индекса при помощи ALTER INDEX. Это ограничение отличается от PRIMARY KEY или UNIQUE и создается с использованием определения CREATE INDEX или INDEX.  
* IGNORE_DUP_KEY не применяется к индексам хранилища столбцов, так как нельзя обеспечить уникальность таких индексов.  

## <a name="column-names-are-lower-cased-by-azure-stream-analytics"></a>Имена столбцов в нижнем регистре, службой Azure Stream Analytics
При использовании исходному уровню совместимости (1.0), Azure Stream Analytics используется для изменения имен столбцов в нижний регистр. Такое поведение было исправлено в более поздние версии уровни совместимости. Чтобы сохранить так, мы рекомендуем клиентам перейти на уровень совместимости 1.1 и более поздних версий. Дополнительные сведения можно найти на [уровне совместимости заданий Azure Stream Analytics](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-compatibility-level).


## <a name="get-help"></a>Получение справки

За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
