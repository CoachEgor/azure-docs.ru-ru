---
title: Устранение неполадок с выходными данными в Azure Stream Analytics
description: В этой статье описаны методы устранения неполадок с выходными подключениями в заданиях Azure Stream Analytics.
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: troubleshooting
ms.date: 03/31/2020
ms.custom: seodec18
ms.openlocfilehash: fc35e6a723afab3f230aa91e4b6895aead35e141
ms.sourcegitcommit: e132633b9c3a53b3ead101ea2711570e60d67b83
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/07/2020
ms.locfileid: "86037075"
---
# <a name="troubleshoot-azure-stream-analytics-outputs"></a>Устранение неполадок с выходными данными в Azure Stream Analytics

В этой статье описаны распространенные проблемы с выходными подключениями Azure Stream Analytics и способы их устранения. Для многих действий по устранению неполадок должны быть включены журналы ресурсов и другие журналы диагностики для задания Stream Analytics. Если журналы ресурсов еще не включены, воспользуйтесь статьей [Устранение неполадок в Azure Stream Analytics с помощью журналов ресурсов](stream-analytics-job-diagnostic-logs.md).

## <a name="the-job-doesnt-produce-output"></a>Задание не создает выходные данные

1. Проверьте подключение к портам вывода с помощью кнопки **Проверить подключение** для всех выходных данных.
1. Проверьте [метрики мониторинга](stream-analytics-monitoring.md) на вкладке **Монитор**. Так как значения агрегированы, метрики задерживаются на несколько минут.

   * Если значение в поле **Входные события** больше нуля, то задание может считывать входные данные. Если значение в поле **Входные события** не больше нуля, то это указывает на ошибку со входными данными задания. Дополнительные сведения см. в разделе [Устранение неполадок с входными подключениями](stream-analytics-troubleshoot-input.md).
   * Если значение в поле **Ошибки преобразования данных** больше нуля и увеличивается, обратитесь к статье [Ошибки преобразования данных Azure Stream Analytics](data-errors.md) для получения дополнительных сведений об ошибках преобразования данных.
   * Если значение в поле **Ошибки среды выполнения** больше нуля, это означает, что задание получает данные, но при обработке запроса выдает ошибки. Чтобы найти ошибки, перейдите к [журналам аудита](../azure-resource-manager/management/view-activity-logs.md) и выполните фильтрацию по состоянию **Сбой**.
   * Если значение в поле **Входные события** больше нуля, а значение в поле **Выходные события** равно нулю, то верно одно из следующих утверждений:
      * В результате обработки запроса исходящие события не получены.
      * События или его поля могут быть повреждены, и выходные события после обработки запроса не получены.
      * Заданию не удалось передать данные в приемник выходных данных из-за проблем с подключением или аутентификацией.

   Сведения об ошибках можно получить в сообщениях журнала операций (включая сведения о самом событии), за исключением случаев, когда логика запроса отфильтровала все события. Если обработка нескольких событий приводит к возникновению ошибок, то ошибки вычисляются каждые 10 минут.

## <a name="the-first-output-is-delayed"></a>Первый фрагмент выходных данных задерживается

При запуске задания Stream Analytics считываются входные события. Однако в некоторых обстоятельствах может возникнуть задержка с предоставлением выходных данных.

Большие значения времени в элементах темпоральных запросов могут приводить к задержке выходных данных. Чтобы сформировать правильные выходные данные за большие периоды времени, задание потоковой передачи считывает данные за самое последнее время для охвата временного окна (до семи дней назад). Выходные данные не создаются до тех пор, пока не будут считаны ожидающие входные события. Эта проблема может возникнуть, когда система обновляет задания потоковой передачи. При обновлении задание перезапускается. Такие обновления обычно происходят один раз каждые несколько месяцев.

Следует проявлять осторожность при проектировании запроса Stream Analytics. Если вы используете большое временное окно для темпоральных элементов в синтаксисе запроса задания, это может привести к задержке первого фрагмента выходных данных при запуске или перезапуске задания. Большим временным окно считается окно от нескольких часов до семи дней.

Одним из способов устранения этой задержки первых выходных данных является использование методов параллельной обработки запросов, таких как секционирование данных. Также можно добавить дополнительные единицы потоковой передачи, чтобы повысить пропускную способность до тех пор, пока задание не будет срабатывать.  Дополнительные сведения см. в статье [Концепции контрольных точек и воспроизведения в Azure Stream Analytics](stream-analytics-concepts-checkpoint-replay.md).

Эти факторы влияют на временные шкалы первого вывода:

* Использование агрегатов данных на основе периодов, таких как предложение группирования GROUP BY по "переворачивающимся", "прыгающим" и "скользящим" окнам.

  * Для агрегатов "переворачивающихся" или "прыгающих" окон результаты создаются в конце оконного временного интервала.
  * Для "скользящего" окна результаты создаются, когда событие входит в это окно или выходит из него.
  * Если вы планируете использовать окно большого размера, например более одного часа, лучше выбрать "прыгающее" или "скользящее" окно. Эти типы окон позволяют чаще видеть выходные данные.

* Использование темпоральных соединений, таких как JOIN с DATEDIFF.
  * Соответствия генерируются, как только поступают оба экземпляра сопоставляемых событий.
  * Данные без соответствия, такие как LEFT OUTER JOIN, создаются в конце окна DATEDIFF относительно каждого события с левой стороны.

* Использование темпоральных аналитических функций, таких как ISFIRST, LAST и LAG с LIMIT DURATION.
  * Для аналитических функций выходные данные создаются для каждого события без задержки.

## <a name="the-output-falls-behind"></a>Выходные данные запаздывают

Во время нормальной работы задания выходные данные могут иметь все большие и большие периоды задержки. Если выходные данные запаздывают, можно выявить основные причины, изучив следующие факторы:

* регулируется ли подчиненный приемник:
* регулируется ли вышестоящий источник данных;
* потребляет ли логика обработки в запросе много вычислительных ресурсов.

Чтобы просмотреть сведения о выходных данных, на портале Azure выберите задание потоковой передачи и нажмите **Схема заданий**. Для каждого набора входных данных есть метрика событий невыполненной работы секции. Если метрика увеличивается, это сигнализирует об ограниченности ресурсов системы. Такое увеличение может быть связано с регулированием приемника выходных данных или высокой загрузкой ЦП. Дополнительные сведения см. в статье [Отладка на основе данных с помощью схемы заданий](stream-analytics-job-diagram-with-metrics.md).

## <a name="key-violation-warning-with-azure-sql-database-output"></a>Предупреждение о нарушении ключа с выходными данными службы "База данных SQL Azure"

При настройке службы "База данных SQL Azure" для выходных данных задания Stream Analytics выполняется массовая вставка записей в целевую таблицу. Как правило, Azure Stream Analytics гарантирует [не менее одной доставки](https://docs.microsoft.com/stream-analytics-query/event-delivery-guarantees-azure-stream-analytics) в приемник выходных данных. Вы по-прежнему можете [выполнить однократную доставку]( https://blogs.msdn.microsoft.com/streamanalytics/2017/01/13/how-to-achieve-exactly-once-delivery-for-sql-output/) в выходные данные SQL, если для таблицы SQL определено уникальное ограничение.

При настройке уникальных ограничений для ключа в таблице SQL служба Azure Stream Analytics удаляет повторяющиеся записи. Данные разделяются на пакеты, которые рекурсивно вставляются, пока не будет обнаружена повторяющаяся запись. Процесс разбиения и вставки пропускает дубликаты по одному за раз. Для задания потоковой передачи,в котором имеется много повторяющихся строк, процесс является неэффективным и занимает много времени. Если в журнале действий в течение последнего часа отображается несколько предупреждающих сообщений о нарушении ключа, вполне вероятно, что обработка выходных данных SQL замедляет выполнение всего задания.

Чтобы устранить эту проблему, нужно [настроить индекс]( https://docs.microsoft.com/sql/t-sql/statements/create-index-transact-sql), который вызывает нарушение ключа, включив параметр IGNORE_DUP_KEY. Этот параметр позволяет SQL игнорировать дублирующиеся значения во время операций вставки. База данных SQL Azure просто выдает предупреждающее сообщение, а не ошибку. В результате Azure Stream Analytics больше не создает ошибки нарушения первичного ключа.

Если IGNORE_DUP_KEY настраивается для нескольких типов индексов, обратите внимание на следующее:

* IGNORE_DUP_KEY нельзя установить для первичного ключа или уникального ограничения, в котором используется ALTER INDEX. Индекс нужно удалить и создать повторно.  
* IGNORE_DUP_KEY можно задать с помощью инструкции ALTER INDEX для уникального индекса. Этот экземпляр отличается от ограничения PRIMARY KEY/UNIQUE и создается с помощью определения CREATE INDEX или INDEX.  
* Параметр IGNORE_DUP_KEY не применяется к индексам хранилища столбцов, так как нельзя обеспечить уникальность таких индексов.  

## <a name="column-names-are-lowercase-in-azure-stream-analytics-10"></a>Имена столбцов в Azure Stream Analytics (1.0) указаны строчными буквами

При использовании исходного уровня совместимости (1.0) Azure Stream Analytics преобразует символы имен столбцов в нижний регистр. На более поздних уровнях совместимости это поведение было исправлено. Чтобы сохранить регистр, перейдите на уровень совместимости 1.1 или более поздний. Дополнительные сведения см. в разделе [Уровень совместимости для заданий Stream Analytics](https://docs.microsoft.com/azure/stream-analytics/stream-analytics-compatibility-level).

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи воспользуйтесь [страницей вопросов и ответов о Microsoft Azure Stream Analytics](https://docs.microsoft.com/answers/topics/azure-stream-analytics.html).

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Azure Stream Analytics management REST API reference](https://msdn.microsoft.com/library/azure/dn835031.aspx) (Справочник по API-интерфейсу REST для управления Stream Analytics).
