---
title: Обнаружение аномалий в Azure Stream Analytics
description: В этой статье объясняется, как обнаруживать аномалии с помощью Azure Stream Analytics в сочетании со службой "Машинное обучение Azure".
services: stream-analytics
author: mamccrea
ms.author: mamccrea
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 06/21/2019
ms.openlocfilehash: e2fd226f1c605821f0fd595832b2cbe26d994fb4
ms.sourcegitcommit: 6a42dd4b746f3e6de69f7ad0107cc7ad654e39ae
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/07/2019
ms.locfileid: "67612335"
---
# <a name="anomaly-detection-in-azure-stream-analytics"></a>Обнаружение аномалий в Azure Stream Analytics

Azure Stream Analytics, доступный в облаке и в Azure IoT Edge, предлагает встроенные возможности обнаружения аномалий на основе машинного обучения, которые можно использовать для мониторинга двух наиболее часто встречающихся аномалий: временной и постоянной. С помощью функций **AnomalyDetection_SpikeAndDip** и **AnomalyDetection_ChangePoint** можно выполнять обнаружение аномалий непосредственно в задании Stream Analytics.

Модели машинного обучения предполагают наличие временных рядов с равномерной выборкой. Если временные ряды неоднородны, можно вставить шаг агрегирования с "переворачивающимся" окном перед вызовом обнаружения аномалий.

Операции обучения машины не поддерживают сезонных тенденций или несколькими вариативных корреляции в данный момент.

## <a name="model-behavior"></a>Поведение модели

Как правило, точность модели повышается с увеличением количества данных в скользящем окне. Данные в указанном скользящем окне обрабатываются как часть нормального диапазона значений для этого интервала времени. Модель рассматривает историю событий только через скользящее окно, чтобы проверить, является ли текущее событие аномальным. При перемещении скользящего окна старые значения исключаются из обучения модели.

Функции работают, устанавливая определенную норму, основанную на наблюдениях на этом этапе. Выбросы определяются путем сравнения с установленной нормой в пределах уровня достоверности. Размер окна должен основываться на минимальных событиях, необходимых для обучения модели нормальному поведению, чтобы при возникновении аномалии она могла его распознать.

Время отклика модели увеличивается с размером журнала, так как они нужны для сравнения с большего количества прошлых событиях. Рекомендуется включать только необходимое количество событий, чтобы повысить эффективность.

Разрывы во временных рядах могут произойти, потому что модель не получает события в определенные моменты времени. Эта ситуация разбирается по Stream Analytics, с помощью логики подстановки. Размер журнала, а также продолжительность времени для одного и того же скользящего окна используются для расчета средней скорости, с которой ожидаются события.

Доступные генератор аномалий [здесь](https://aka.ms/asaanomalygenerator) может использоваться для веб-канал центра Интернета вещей с данными с помощью различных аномалий шаблонов. С этими функциями обнаружения аномалий для чтения этот центр Интернета вещей и обнаружения аномалий можно настроить задание ASA.

## <a name="spike-and-dip"></a>Пики и спады

Временные аномалии в потоке событий временных рядов называются пиками и спадами. Пики и спады можно отслеживать с помощью оператора Машинного обучения [AnomalyDetection_SpikeAndDip](https://docs.microsoft.com/stream-analytics-query/anomalydetection-spikeanddip-azure-stream-analytics
).

![Пример аномалии пика и спада](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-spike-dip.png)

В том же скользящем окне, если второй пик меньше первого, вычисленная оценка меньшего пика, вероятно, недостаточно значительна по сравнению с оценкой первого пика в пределах указанного уровня достоверности. Вы можете попробовать уменьшить уровень достоверности модели для обнаружения таких аномалий. Однако если предупреждений становится слишком много, можно использовать более высокий интервал достоверности.

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 2-минутном скользящем окне с журналом со 120 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 95 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_SpikeAndDip(CAST(temperature AS float), 95, 120, 'spikesanddips')
            OVER(LIMIT DURATION(second, 120)) AS SpikeAndDipScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'Score') AS float) AS
    SpikeAndDipScore,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'IsAnomaly') AS bigint) AS
    IsSpikeAndDipAnomaly
INTO output
FROM AnomalyDetectionStep
```

## <a name="change-point"></a>Изменение точки

Постоянные аномалии в потоке событий временных рядов — это изменения в распределении значений в потоке событий, такие как изменения уровня и тенденции. В Stream Analytics такие аномалии обнаруживаются с помощью оператора [AnomalyDetection_ChangePoint](https://docs.microsoft.com/stream-analytics-query/anomalydetection-changepoint-azure-stream-analytics), основанного на Машинном обучении.

Постоянные изменения длятся гораздо дольше, чем пики и спады, и могут указывать на катастрофические события. Постоянные изменения обычно не видны невооруженным глазом, но их легко обнаружить с помощью оператора **AnomalyDetection_ChangePoint**.

На следующем рисунке показан пример изменения уровня:

![Пример аномалии изменения уровня](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-level-change.png)

На следующем рисунке показан пример изменения тенденции:

![Пример аномалии изменения тенденции](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-trend-change.png)

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 20-минутном скользящем окне с журналом с 1200 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 80 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_ChangePoint(CAST(temperature AS float), 80, 1200) 
        OVER(LIMIT DURATION(minute, 20)) AS ChangePointScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(ChangePointScores, 'Score') AS float) AS
    ChangePointScore,
    CAST(GetRecordPropertyValue(ChangePointScores, 'IsAnomaly') AS bigint) AS
    IsChangePointAnomaly
INTO output
FROM AnomalyDetectionStep

```

## <a name="performance-characteristics"></a>Характеристики производительности

Производительность этих моделей, зависит от размера журнала, длительность периода, нагрузки, и используется ли функция уровня секционирование. В этом разделе рассматриваются эти конфигурации, а также содержит примеры как для обеспечения скорости приема 1 КБ, 5K и 10 тысяч событий в секунду.

* **Размер журнала** -эти модели работают линейно с **размер журнала**. Чем дольше объема журнала, тем больше модели принимают для оценки новое событие. Это обусловлено моделей сравнения новое событие с каждым из прошлых событий в буфере.
* **Длительность периода** - **длительность периода** должны отражать время, необходимое для получения столько событий, как указано на размер журнала. Без этого количества событий в окне Azure Stream Analytics будет добавить отсутствующие значения. Таким образом потребление ресурсов ЦП зависит от размера журнала.
* **Событие загрузки** — чем больше **нагрузки**, тем больше рабочих, производится в моделях, которые влияют на потребление ресурсов ЦП. Задания можно масштабировать, делая усложненного параллелизма, при условии, что имеет смысл для бизнес-логики для использования более секций входных данных.
* **Функция уровня секционирование** - **функция уровня секционирование** делается с помощью ```PARTITION BY``` в вызове функции обнаружения аномалий. Этот тип секционирования добавляет дополнительные затраты ресурсов, как состояние должно храниться для нескольких моделей, в то же время. Функция уровня секционирование используется в сценариях, например секционирование на уровне устройства.

### <a name="relationship"></a>Связь
Размер журнала, длительность периода и общее событие нагрузки связаны следующим образом:

windowDuration (в мс) = 1000 * historySize / (всего входные данные события на с / число секций входных данных)

При секционировании функции через deviceId, добавьте «PARTITION BY deviceId» для вызова функции обнаружения аномалий.

### <a name="observations"></a>Наблюдения
В следующей таблице содержатся наблюдения пропускную способность для одного узла (6 единиц потоковой Передачи) для несекционированный вариант:

| Размер журнала (события) | Длительность периода (мс) | Общее количество входных событий в секунду |
| --------------------- | -------------------- | -------------------------- |
| 60 | 55 | 2,200 |
| 600 | 728 | 1,650 |
| 6000 | 10,910 | 1,100 |

В следующей таблице содержатся наблюдения пропускную способность для одного узла (6 единиц потоковой Передачи) для секционированных случая:

| Размер журнала (события) | Длительность периода (мс) | Общее количество входных событий в секунду | Количество устройств |
| --------------------- | -------------------- | -------------------------- | ------------ |
| 60 | 1,091 | 1,100 | 10 |
| 600 | 10,910 | 1,100 | 10 |
| 6000 | 218,182 | <550 | 10 |
| 60 | 21,819 | 550 | 100 |
| 600 | 218,182 | 550 | 100 |
| 6000 | 2,181,819 | <550 | 100 |

Пример кода для запуска конфигураций несекционированной находится в [репозитория потоковой передачи в масштабирования](https://github.com/Azure-Samples/streaming-at-scale/blob/f3e66fa9d8c344df77a222812f89a99b7c27ef22/eventhubs-streamanalytics-eventhubs/anomalydetection/create-solution.sh) примеров кода Azure. Код создает задание stream analytics не функция уровня секционирования, которая использует в качестве входных и выходных данных концентратора событий. Входной нагрузка создается с помощью тестовых клиентов. Каждое событие ввода — это документ json размером 1 КБ. События имитация устройства Интернета вещей отправляет данные JSON (для устройств до 1 КБ). Размер журнала, длительность периода и общее событие нагрузки отличаются по 2 секций входных данных.

> [!Note]
> Для более точного подсчета настраивать эти образцы для своего сценария.

### <a name="identifying-bottlenecks"></a>Выявление узких мест
Использование области метрики в задании Azure Stream Analytics для выявления узких мест в конвейере. Просмотрите **события ввода и вывода** для пропускной способности и [«Задержка водяной знак»](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) или **отложенных событий** для просмотра, если задание справляется со скоростью ввода. Для метрик в концентратор событий, искать **регулирование запросов** и соответствующим образом настроить пороговое значение единицы измерения. Метрики Cosmos DB, просмотрите **максимальное количество потребляемых единиц Запросов в секунду в диапазоне ключей разделов** под пропускной способности, чтобы обеспечить диапазонов ключей секций равномерно потребляются. Для базы данных SQL Azure, отслеживайте **ввода-ВЫВОДА журнала** и **ЦП**.

## <a name="anomaly-detection-using-machine-learning-in-azure-stream-analytics"></a>Обнаружение аномалий с помощью машинного обучения в Azure Stream Analytics

В следующем видеоролике показано, как обнаружить аномалии в реальном времени с помощью функций машинного обучения в Azure Stream Analytics. 

> [!VIDEO https://channel9.msdn.com/Shows/Azure-Friday/Anomaly-detection-using-machine-learning-in-Azure-Stream-Analytics/player]

## <a name="next-steps"></a>Следующие шаги

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

