---
title: Обнаружение аномалий в Azure Stream Analytics
description: В этой статье объясняется, как обнаруживать аномалии с помощью Azure Stream Analytics в сочетании со службой "Машинное обучение Azure".
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 06/21/2019
ms.openlocfilehash: 51b9c827d453eef2e2e75e1aa5222204eaa38d0e
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "77525538"
---
# <a name="anomaly-detection-in-azure-stream-analytics"></a>Обнаружение аномалий в Azure Stream Analytics

Azure Stream Analytics, доступный в облаке и в Azure IoT Edge, предлагает встроенные возможности обнаружения аномалий на основе машинного обучения, которые можно использовать для мониторинга двух наиболее часто встречающихся аномалий: временной и постоянной. С помощью функций **AnomalyDetection_SpikeAndDip** и **AnomalyDetection_ChangePoint** можно выполнять обнаружение аномалий непосредственно в задании Stream Analytics.

Модели машинного обучения предполагают наличие временных рядов с равномерной выборкой. Если временные ряды неоднородны, можно вставить шаг агрегирования с "переворачивающимся" окном перед вызовом обнаружения аномалий.

Операции машинного обучения в настоящее время не поддерживают тенденции сезонности или многовариантные корреляции.

## <a name="anomaly-detection-using-machine-learning-in-azure-stream-analytics"></a>Обнаружение аномалий с помощью машинного обучения в аналитике Azure Stream Analytics

Следующее видео демонстрирует, как обнаружить аномалию в режиме реального времени с помощью функций машинного обучения в Azure Stream Analytics. 

> [!VIDEO https://channel9.msdn.com/Shows/Internet-of-Things-Show/Real-Time-ML-Based-Anomaly-Detection-In-Azure-Stream-Analytics/player]

## <a name="model-behavior"></a>Поведение модели

Как правило, точность модели повышается с увеличением количества данных в скользящем окне. Данные в указанном скользящем окне обрабатываются как часть нормального диапазона значений для этого интервала времени. Модель рассматривает историю событий только через скользящее окно, чтобы проверить, является ли текущее событие аномальным. При перемещении скользящего окна старые значения исключаются из обучения модели.

Функции работают, устанавливая определенную норму, основанную на наблюдениях на этом этапе. Выбросы определяются путем сравнения с установленной нормой в пределах уровня достоверности. Размер окна должен основываться на минимальных событиях, необходимых для обучения модели нормальному поведению, чтобы при возникновении аномалии она могла его распознать.

Время отклика модели увеличивается с размером истории, поскольку ее необходимо сопоставить с большим числом прошлых событий. Рекомендуется включать только необходимое количество событий, чтобы повысить эффективность.

Разрывы во временных рядах могут произойти, потому что модель не получает события в определенные моменты времени. Эта ситуация обрабатывается Stream Analytics с использованием логики вычислений. Размер журнала, а также продолжительность времени для одного и того же скользящего окна используются для расчета средней скорости, с которой ожидаются события.

Генератор аномалий, доступный [здесь,](https://aka.ms/asaanomalygenerator) может быть использован для питания концентратора Iot с данными с различными шаблонами аномалий. Задание ASA может быть настроено с помощью этих функций обнаружения аномалий для чтения из этого концентратора Iot и обнаружения аномалий.

## <a name="spike-and-dip"></a>Пики и спады

Временные аномалии в потоке событий временных рядов называются пиками и спадами. Пики и спады можно отслеживать с помощью оператора Машинного обучения [AnomalyDetection_SpikeAndDip](https://docs.microsoft.com/stream-analytics-query/anomalydetection-spikeanddip-azure-stream-analytics
).

![Пример аномалии пика и спада](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-spike-dip.png)

В том же скользящем окне, если второй пик меньше первого, вычисленная оценка меньшего пика, вероятно, недостаточно значительна по сравнению с оценкой первого пика в пределах указанного уровня достоверности. Вы можете попробовать снизить уровень доверия модели для обнаружения таких аномалий. Однако если предупреждений становится слишком много, можно использовать более высокий интервал достоверности.

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 2-минутном скользящем окне с журналом со 120 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 95 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_SpikeAndDip(CAST(temperature AS float), 95, 120, 'spikesanddips')
            OVER(LIMIT DURATION(second, 120)) AS SpikeAndDipScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'Score') AS float) AS
    SpikeAndDipScore,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'IsAnomaly') AS bigint) AS
    IsSpikeAndDipAnomaly
INTO output
FROM AnomalyDetectionStep
```

## <a name="change-point"></a>Изменение точки

Постоянные аномалии в потоке событий временных рядов — это изменения в распределении значений в потоке событий, такие как изменения уровня и тенденции. В Stream Analytics такие аномалии обнаруживаются с помощью оператора [AnomalyDetection_ChangePoint](https://docs.microsoft.com/stream-analytics-query/anomalydetection-changepoint-azure-stream-analytics), основанного на Машинном обучении.

Постоянные изменения длятся гораздо дольше, чем пики и спады, и могут указывать на катастрофические события. Постоянные изменения обычно не видны невооруженным глазом, но их легко обнаружить с помощью оператора **AnomalyDetection_ChangePoint**.

На следующем рисунке показан пример изменения уровня:

![Пример аномалии изменения уровня](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-level-change.png)

На следующем рисунке показан пример изменения тенденции:

![Пример аномалии изменения тенденции](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-trend-change.png)

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 20-минутном скользящем окне с журналом с 1200 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 80 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_ChangePoint(CAST(temperature AS float), 80, 1200) 
        OVER(LIMIT DURATION(minute, 20)) AS ChangePointScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(ChangePointScores, 'Score') AS float) AS
    ChangePointScore,
    CAST(GetRecordPropertyValue(ChangePointScores, 'IsAnomaly') AS bigint) AS
    IsChangePointAnomaly
INTO output
FROM AnomalyDetectionStep

```

## <a name="performance-characteristics"></a>Характеристики производительности

Производительность этих моделей зависит от размера истории, продолжительности окна, нагрузки на событие и используемого раздела уровня функции. В этом разделе рассматриваются эти конфигурации и приведены образцы для поддержания коэффициентов приема 1K, 5K и 10K событий в секунду.

* **Размер истории** - Эти модели выполняют линейно с **размером истории.** Чем длиннее размер истории, тем больше времени модели забирают для оценки нового события. Это связано с тем, что модели сравнивают новое событие с каждым из прошлых событий в буфере истории.
* **Длительность окна** - **Продолжительность окна** должна отражать, сколько времени требуется, чтобы получить столько событий, сколько указано по размеру истории. Без такого количества событий в окне аналитика потоков Azure привязала бы недостающие значения. Таким образом, потребление процессора зависит от размера истории.
* **Нагрузка на события** - Чем больше **нагрузка на событие,** тем больше работы выполняется моделями, что влияет на потребление процессора. Задание можно масштабировать, сделав его неловко параллельным, предполагая, что бизнес-логике имеет смысл использовать больше входных разделов.
* **Разделивание** - уровня функциональности**Междугородная** функция выполняется с помощью ```PARTITION BY``` вызова функции обнаружения аномалий. Этот тип раздела добавляет накладные расходы, так как состояние должно быть сохранено для нескольких моделей одновременно. Разделивание уровня функции используется в таких сценариях, как раздел уровня устройства.

### <a name="relationship"></a>Связь
Размер истории, продолжительность окна и общая нагрузка на события связаны следующим образом:

windowDuration (в мс) - 1000 - historySize / (Общие входной события за sec / Количество входных разделов)

При разделении функции на deviceId добавьте "PARTITION BY deviceId" в вызов функции обнаружения аномалий.

### <a name="observations"></a>Наблюдения
Следующая таблица включает в себя наблюдения пропускной связи для одного узла (6 SU) для неразделенного случая:

| Размер истории (события) | Длительность окна (ms) | Общие вводимые события за сек |
| --------------------- | -------------------- | -------------------------- |
| 60 | 55 | 2200 |
| 600 | 728 | 1,650 |
| 6000 | 10,910 | 1100 |

Следующая таблица включает в себя наблюдения пропускной связи для одного узла (6 SU) для разделительного корпуса:

| Размер истории (события) | Длительность окна (ms) | Общие вводимые события за сек | Число устройств |
| --------------------- | -------------------- | -------------------------- | ------------ |
| 60 | 1,091 | 1100 | 10 |
| 600 | 10,910 | 1100 | 10 |
| 6000 | 218,182 | <550 | 10 |
| 60 | 21,819 | 550 | 100 |
| 600 | 218,182 | 550 | 100 |
| 6000 | 2,181,819 | <550 | 100 |

Пример кода для запуска неразделенных конфигураций выше находится в [репо Потоковой на шкале](https://github.com/Azure-Samples/streaming-at-scale/blob/f3e66fa9d8c344df77a222812f89a99b7c27ef22/eventhubs-streamanalytics-eventhubs/anomalydetection/create-solution.sh) azure Samples. Код создает работу аналитики потока без раздела уровня функции, которая использует концентратор событий в качестве ввода и вывода. Входная нагрузка генерируется с помощью тестовых клиентов. Каждое событие ввода — это документ 1KB json. События имитируют устройство IoT, отправляющее данные JSON (для устройств до 1K). Размер истории, продолжительность окна и общая нагрузка на события варьируются в течение 2 входных разделов.

> [!Note]
> Для более точной оценки настройте образцы в соответствии с вашим сценарием.

### <a name="identifying-bottlenecks"></a>Выявление узких мест
Используйте панель метрик в заданияaz stream Analytics для выявления узких мест в конвейере. Просмотрите **входные/выходные события** для пропускной записи и ["Задержка водяного знака"](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) или **невыполненные события,** чтобы увидеть, не соответствует ли работа скорости ввода. Для метрик концентратора событий ищите **тихие запросы** и соответствующим образом отрегулируйте пороговые единицы. Для метрик Cosmos DB просмотрите диапазон **ключа раздела Max, потребляемый RU/s на один** под пропуском, чтобы обеспечить равномерное потребление ключевых диапазонов разделов. Для Azure S'L DB следите за **журналом IO** и **процессором.**

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Начало использования аналитики потоков Azure](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

