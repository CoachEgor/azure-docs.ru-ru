---
title: Обнаружение аномалий в Azure Stream Analytics
description: В этой статье объясняется, как обнаруживать аномалии с помощью Azure Stream Analytics в сочетании со службой "Машинное обучение Azure".
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 06/21/2019
ms.openlocfilehash: e29ac6671d71ea02b432c9843541796984737c8b
ms.sourcegitcommit: f4f626d6e92174086c530ed9bf3ccbe058639081
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/25/2019
ms.locfileid: "75459608"
---
# <a name="anomaly-detection-in-azure-stream-analytics"></a>Обнаружение аномалий в Azure Stream Analytics

Azure Stream Analytics, доступный в облаке и в Azure IoT Edge, предлагает встроенные возможности обнаружения аномалий на основе машинного обучения, которые можно использовать для мониторинга двух наиболее часто встречающихся аномалий: временной и постоянной. С помощью функций **AnomalyDetection_SpikeAndDip** и **AnomalyDetection_ChangePoint** можно выполнять обнаружение аномалий непосредственно в задании Stream Analytics.

Модели машинного обучения предполагают наличие временных рядов с равномерной выборкой. Если временные ряды неоднородны, можно вставить шаг агрегирования с "переворачивающимся" окном перед вызовом обнаружения аномалий.

В настоящее время операции машинного обучения не поддерживают сезонностиные тенденции и несколько вариате корреляций.

## <a name="model-behavior"></a>Поведение модели

Как правило, точность модели повышается с увеличением количества данных в скользящем окне. Данные в указанном скользящем окне обрабатываются как часть нормального диапазона значений для этого интервала времени. Модель рассматривает историю событий только через скользящее окно, чтобы проверить, является ли текущее событие аномальным. При перемещении скользящего окна старые значения исключаются из обучения модели.

Функции работают, устанавливая определенную норму, основанную на наблюдениях на этом этапе. Выбросы определяются путем сравнения с установленной нормой в пределах уровня достоверности. Размер окна должен основываться на минимальных событиях, необходимых для обучения модели нормальному поведению, чтобы при возникновении аномалии она могла его распознать.

Время отклика модели увеличивается с учетом размера журнала, так как его необходимо сравнить с большим числом прошлых событий. Рекомендуется включать только необходимое количество событий, чтобы повысить эффективность.

Разрывы во временных рядах могут произойти, потому что модель не получает события в определенные моменты времени. Эта ситуация обрабатывается Stream Analytics с помощью логики добавления отсутствующих. Размер журнала, а также продолжительность времени для одного и того же скользящего окна используются для расчета средней скорости, с которой ожидаются события.

[Доступный генератор](https://aka.ms/asaanomalygenerator) аномалий можно использовать для передачи центра Интернета вещей с данными с разными шаблонами аномалии. Задание ASA можно настроить с помощью этих функций обнаружения аномалий для чтения из этого центра Интернета вещей и обнаружения аномалий.

## <a name="spike-and-dip"></a>Пики и спады

Временные аномалии в потоке событий временных рядов называются пиками и спадами. Пики и спады можно отслеживать с помощью оператора Машинного обучения [AnomalyDetection_SpikeAndDip](https://docs.microsoft.com/stream-analytics-query/anomalydetection-spikeanddip-azure-stream-analytics
).

![Пример аномалии пика и спада](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-spike-dip.png)

В том же скользящем окне, если второй пик меньше первого, вычисленная оценка меньшего пика, вероятно, недостаточно значительна по сравнению с оценкой первого пика в пределах указанного уровня достоверности. Можно попытаться уменьшить уровень достоверности модели, чтобы выявить такие аномалии. Однако если предупреждений становится слишком много, можно использовать более высокий интервал достоверности.

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 2-минутном скользящем окне с журналом со 120 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 95 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_SpikeAndDip(CAST(temperature AS float), 95, 120, 'spikesanddips')
            OVER(LIMIT DURATION(second, 120)) AS SpikeAndDipScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'Score') AS float) AS
    SpikeAndDipScore,
    CAST(GetRecordPropertyValue(SpikeAndDipScores, 'IsAnomaly') AS bigint) AS
    IsSpikeAndDipAnomaly
INTO output
FROM AnomalyDetectionStep
```

## <a name="change-point"></a>Изменение точки

Постоянные аномалии в потоке событий временных рядов — это изменения в распределении значений в потоке событий, такие как изменения уровня и тенденции. В Stream Analytics такие аномалии обнаруживаются с помощью оператора [AnomalyDetection_ChangePoint](https://docs.microsoft.com/stream-analytics-query/anomalydetection-changepoint-azure-stream-analytics), основанного на Машинном обучении.

Постоянные изменения длятся гораздо дольше, чем пики и спады, и могут указывать на катастрофические события. Постоянные изменения обычно не видны невооруженным глазом, но их легко обнаружить с помощью оператора **AnomalyDetection_ChangePoint**.

На следующем рисунке показан пример изменения уровня:

![Пример аномалии изменения уровня](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-level-change.png)

На следующем рисунке показан пример изменения тенденции:

![Пример аномалии изменения тенденции](./media/stream-analytics-machine-learning-anomaly-detection/anomaly-detection-trend-change.png)

Следующий пример запроса предполагает равномерную скорость ввода одного события в секунду в 20-минутном скользящем окне с журналом с 1200 событиями. Заключительная инструкция SELECT извлекает и выводит оценку и состояние аномалии с уровнем достоверности 80 %.

```SQL
WITH AnomalyDetectionStep AS
(
    SELECT
        EVENTENQUEUEDUTCTIME AS time,
        CAST(temperature AS float) AS temp,
        AnomalyDetection_ChangePoint(CAST(temperature AS float), 80, 1200) 
        OVER(LIMIT DURATION(minute, 20)) AS ChangePointScores
    FROM input
)
SELECT
    time,
    temp,
    CAST(GetRecordPropertyValue(ChangePointScores, 'Score') AS float) AS
    ChangePointScore,
    CAST(GetRecordPropertyValue(ChangePointScores, 'IsAnomaly') AS bigint) AS
    IsChangePointAnomaly
INTO output
FROM AnomalyDetectionStep

```

## <a name="performance-characteristics"></a>Характеристики производительности

Производительность этих моделей зависит от размера журнала, длительности окна, загрузки событий, а также от того, используется ли секционирование на уровне функции. В этом разделе обсуждаются эти конфигурации и приведены примеры того, как поддерживать скорости приема событий 1000, 5 КБ и 10000 в секунду.

* **Размер журнала** — эти модели работают линейно с **размером журнала**. Чем дольше размер журнала, тем дольше модели принимаются в качестве оценки нового события. Это обусловлено тем, что модели сравнивают новое событие с каждым из предыдущих событий в буфере журнала.
* **Длительность окна** — **длительность окна** должна отражать, сколько времени займет получение столько событий, сколько указано размером журнала. Без большого числа событий в окне Azure Stream Analytics аппроксимация недостающие значения. Таким образом, использование ЦП является функцией размера журнала.
* **Загрузка событий** — чем больше **нагрузка на событие**, тем больший объем работы, выполняемый моделями, который влияет на потребление ресурсов ЦП. Задание можно масштабировать, делая его непараллельным, предполагая, что бизнес-логика использует больше входных секций.
* **Секционирование на уровне функций** - **секционирования на уровне функций** выполняется с помощью ```PARTITION BY``` в вызове функции обнаружения аномалий. Этот тип секционирования добавляет дополнительную нагрузку, так как состояние должно поддерживаться для нескольких моделей одновременно. Секционирование на уровне функций используется в таких сценариях, как секционирование на уровне устройства.

### <a name="relationship"></a>Связь
Размер журнала, длительность окна и общая нагрузка события связаны следующим образом:

Виндовдуратион (в мс) = 1000 * Хисторисизе/(всего входных событий в секунду/число входных секций)

При секционировании функции по deviceId добавьте "PARTITION BY deviceId" в вызов функции обнаружения аномалий.

### <a name="observations"></a>Анализ результатов
В следующей таблице приведены наблюдения за пропускной способностью для одного узла (6 SU) для несекционированного варианта:

| Размер журнала (события) | Длительность окна (МС) | Всего входных событий в секунду |
| --------------------- | -------------------- | -------------------------- |
| 60 | 55 | 2 200 |
| 600 | 728 | 1 650 |
| 6000 | 10 910 | 1100 |

В следующей таблице приведены наблюдения за пропускной способностью для одного узла (6 SU) для секционированного варианта:

| Размер журнала (события) | Длительность окна (МС) | Всего входных событий в секунду | Число устройств |
| --------------------- | -------------------- | -------------------------- | ------------ |
| 60 | 1 091 | 1100 | 10 |
| 600 | 10 910 | 1100 | 10 |
| 6000 | 218 182 | < 550 | 10 |
| 60 | 21 819 | 550 | 100 |
| 600 | 218 182 | 550 | 100 |
| 6000 | 2 181 819 | < 550 | 100 |

Пример кода для выполнения несекционированных конфигураций, описанных выше, находится в репозитории в разделе " [потоковая передача](https://github.com/Azure-Samples/streaming-at-scale/blob/f3e66fa9d8c344df77a222812f89a99b7c27ef22/eventhubs-streamanalytics-eventhubs/anomalydetection/create-solution.sh) " примеров Azure. Код создает задание Stream Analytics без секционирования на уровне функций, которое использует концентратор событий в качестве входных и выходных данных. Входная нагрузка создается с помощью тестовых клиентов. Каждое событие ввода — это 1 КБ документ JSON. События имитируют устройство Интернета вещей, отправляющее данные JSON (для 1000 устройств). Размер журнала, длительность окна и общая нагрузка события изменяются по 2 входным секциям.

> [!Note]
> Чтобы получить более точную оценку, настройте примеры в соответствии с вашим сценарием.

### <a name="identifying-bottlenecks"></a>Определение узких мест
Используйте панель метрики в задании Azure Stream Analytics для выявления узких мест в конвейере. Просмотрите **события ввода-вывода** для пропускной способности и ["задержка водяного знака"](https://azure.microsoft.com/blog/new-metric-in-azure-stream-analytics-tracks-latency-of-your-streaming-pipeline/) , а также **событий с невыполненной записью** , чтобы определить, имеет ли задание скорость ввода. Для метрик концентратора событий ищите **регулируемые запросы** и соответственно скорректируйте пороговые единицы. Для метрик Cosmos DB ознакомьтесь с **максимальным потреблением единиц запросов в секунду на диапазон ключей секций** в разделе пропускная способность, чтобы обеспечить единообразное использование диапазонов ключей разделов. Для базы данных SQL Azure Отслеживайте **операции ввода-вывода журнала** и **ЦП**.

## <a name="anomaly-detection-using-machine-learning-in-azure-stream-analytics"></a>Обнаружение аномалий с помощью машинного обучения в Azure Stream Analytics

В следующем видео показано, как определить аномалию в режиме реального времени с помощью функций машинного обучения в Azure Stream Analytics. 

> [!VIDEO https://channel9.msdn.com/Shows/Azure-Friday/Anomaly-detection-using-machine-learning-in-Azure-Stream-Analytics/player]

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

