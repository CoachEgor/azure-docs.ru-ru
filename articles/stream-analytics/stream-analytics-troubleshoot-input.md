---
title: Устранение неполадок с входными подключениями для Azure Stream Analytics
description: В этой статье описаны методы устранения неполадок с входными подключениями в заданиях Azure Stream Analytics.
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/31/2020
ms.custom: seodec18
ms.openlocfilehash: 3d88123b3dd79e5707c5c19cbbae13c30cbdeb84
ms.sourcegitcommit: 27bbda320225c2c2a43ac370b604432679a6a7c0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/31/2020
ms.locfileid: "80409418"
---
# <a name="troubleshoot-input-connections"></a>Устранение неполадок с входными подключениями

В этой статье описаны общие проблемы с входными соединениями Azure Stream Analytics, как устранить проблемы ввода и как устранить проблемы. Многие этапы устранения неполадок требуют включения диагностических журналов для работы Stream Analytics. Если нет включенных диагностических журналов, [см.](stream-analytics-job-diagnostic-logs.md)

## <a name="input-events-not-received-by-job"></a>Входные события, не полученные заданием 

1.  Проверьте входное и выходное подключение. Проверьте подключение к портам ввода и вывода с помощью кнопки **Проверить подключение** для всех входных и выходных данных.

2.  Проверьте входные данные.

    1. Используйте кнопку [**«Образец данных»**](stream-analytics-sample-data-input.md) для каждого ввода. Загрузите данные выборки ввода.
        
    1. Осмотрите выборочные данные, чтобы понять схему и [типы данных.](https://docs.microsoft.com/stream-analytics-query/data-types-azure-stream-analytics)
    
    1. Проверьте [метрики концентратора событий,](../event-hubs/event-hubs-metrics-azure-monitor.md) чтобы обеспечить отправку событий. Метрики сообщений должны быть больше нуля, если концентраторы событий получают сообщения.

3.  Убедитесь, что вы выбрали временной диапазон в входином предварительном просмотре. Выберите **временной диапазон,** а затем введите продолжительность образца перед тестированием запроса.

## <a name="malformed-input-events-causes-deserialization-errors"></a>Неправильный формат входных событий, который приводит к ошибкам десериализации 

Если входной поток задания Stream Analytics содержит сообщения неправильного формата, возникают проблемы десериализации. Например, неправильное сообщение может быть вызвано отсутствием скобки или скобки в объекте JSON или неправильным форматом метки времени в поле времени. 
 
Когда задание Stream Analytics получает сообщение неправильного формата из входного набора данных, это сообщение отклоняется, а пользователь получает предупреждение. Предупреждающий символ отображается на плитке **входных данных** вашего задания Stream Analytics. Следующий символ предупреждения существует до тех пор, пока задание находится в состоянии выполнения:

![Плитка "Входные данные" Azure Stream Analytics](media/stream-analytics-malformed-events/stream-analytics-inputs-tile.png)

Включите журналы диагностики для просмотра деталей ошибки и сообщения (полезной нагрузки), вызвавшей ошибку. Существует несколько причин, по которым могут возникать ошибки десериализации. Для получения дополнительной информации о [Input data errors](data-errors.md#input-data-errors)конкретных ошибках десериализации см. Если журналы диагностики не включены, на портале Azure будет доступно краткое уведомление.

![Уведомление о предупреждении о входных данных](media/stream-analytics-malformed-events/warning-message-with-offset.png)

В тех случаях, когда полезная нагрузка сообщения превышает 32 кБ или находится в двоичном формате, запустите CheckMalformedEvents.cs код, доступный в [репозитории образцов GitHub.](https://github.com/Azure/azure-stream-analytics/tree/master/Samples/CheckMalformedEventsEH) При помощи этого кода считываются идентификатор раздела и смещение, а затем выводятся данные для этого смещения. 

## <a name="job-exceeds-maximum-event-hub-receivers"></a>Задание превышает максимальные приемники концентратора событий

Наилучшей практикой для использования концентраторов событий является использование нескольких групп потребителей для масштабируемости рабочих мест. Число модулей чтения в задании Stream Analytics для определенных входных данных влияет на число модулей чтения в одной группе потребителей. Точное число приемников зависит от сведений о внутренней реализации логики топологии развертывания и не предоставляется извне. Число модулей чтения можно изменить во время запуска или обновления задания.

Ошибка, которая отображается, когда число получателей превышает максимально допустимое: 

`The streaming job failed: Stream Analytics job has validation errors: Job will exceed the maximum amount of Event Hub Receivers.`

> [!NOTE]
> При изменении числа модулей чтения во время обновления задания временные предупреждения записываются в журналы аудита. Задания Stream Analytics восстанавливаются от этих временных сбоев автоматически.

### <a name="add-a-consumer-group-in-event-hubs"></a>Добавление группы потребителей в Центры событий

Чтобы добавить новую группу потребителей в экземпляр Центра событий, сделайте следующее.

1. Войдите на портал Azure.

2. Найдите свой концентратор событий.

3. Выберите **Центры событий** под заголовком **Сущности**.

4. Выберите имя концентратора событий.

5. На странице **Экземпляр Центров событий** под заголовком **Сущности** установите флажок **Группы потребителей**. Указана группа потребителей с именем **$Default**.

6. Выберите **+Группа потребителей**, чтобы добавить новую группу потребителей. 

   ![Добавление группы потребителей в Центры событий](media/stream-analytics-event-hub-consumer-groups/new-eh-consumer-group.png)

7. Вы указали группу потребителей, когда создавали входные данные в задании Stream Analytics для концентратора событий. **$Default** используется, когда не указано. После создания группы потребителей измените входные данные концентратора событий в задании Stream Analytics и укажите имя новой группы потребителей.

## <a name="readers-per-partition-exceeds-event-hubs-limit"></a>Превышение предельно допустимого числа модулей чтения каждого раздела для Центров событий

Если синтаксис запроса потоковой передачи ссылается на один и тот же входной ресурс концентратора событий несколько раз, обработчик заданий может использовать несколько читателей для каждого запроса из этой же группы потребителей. При наличии слишком большого количества ссылок в одной и той же группе потребителей задание может превысить установленный предел (пять ссылок) и вызвать ошибку. В таких случаях можно выполнять разделение с помощью нескольких групп входных данных в нескольких группах потребителей, используя решения, описанные в следующем разделе. 

Ниже представлены сценарии, в которых число модулей чтения каждого раздела превышает предельно допустимое число для Центров событий (пять).

* Несколько инструкций SELECT. При использовании нескольких инструкций SELECT, ссылающихся на **один** набор входных данных концентратора событий, каждая из них создает по приемнику.

* UNION. При использовании UNION несколько наборов входных данных могут ссылаться на **один** концентратор событий и на одну группу потребителей.

* SELF JOIN. При использовании операции SELF JOIN можно создать несколько ссылок на **один** концентратор событий.

Следующие рекомендации могут помочь справиться со сценариями, в которых число модулей чтения каждого раздела превышает предельно допустимое число для Центров событий (пять).

### <a name="split-your-query-into-multiple-steps-by-using-a-with-clause"></a>Разбиение запроса на несколько шагов с помощью предложения WITH

Предложение WITH задает временный именованный результирующий набор, на который можно создать ссылку в предложении FROM в запросе. Предложение WITH определяется в области выполнения одной инструкции SELECT.

Например, вместо этого запроса:

```SQL
SELECT foo 
INTO output1
FROM inputEventHub

SELECT bar
INTO output2
FROM inputEventHub 
…
```

Используйте этот:

```SQL
WITH data AS (
   SELECT * FROM inputEventHub
)

SELECT foo
INTO output1
FROM data

SELECT bar
INTO output2
FROM data
…
```

### <a name="ensure-that-inputs-bind-to-different-consumer-groups"></a>Привязка входных данных к разным группам потребителей

Создайте отдельные группы потребителей для запросов, в которых три или более наборов входных данных подключены к одной группе потребителей Центров событий. Для этого нужно создать дополнительные наборы входных данных Stream Analytics.

## <a name="get-help"></a>Получить справку

Для получения дополнительной помощи попробуйте наш [форум Azure Stream Analytics.](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics)

## <a name="next-steps"></a>Следующие шаги

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Начало использования аналитики потоков Azure](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
