---
title: Устранение неполадок с входными подключениями для Azure Stream Analytics
description: В этой статье описаны методы устранения неполадок с входными подключениями в заданиях Azure Stream Analytics.
author: sidram
ms.author: sidram
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/07/2018
ms.custom: seodec18
ms.openlocfilehash: dac3037f82c38980c9ac16685aa7fddac68a2e7b
ms.sourcegitcommit: f52ce6052c795035763dbba6de0b50ec17d7cd1d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/24/2020
ms.locfileid: "76720305"
---
# <a name="troubleshoot-input-connections"></a>Устранение неполадок с входными подключениями

На этой странице описываются распространенные проблемы с входными подключениями и методы их устранения.

## <a name="input-events-not-received-by-job"></a>Входные события, не полученные заданием 
1.  Проверьте подключение. Проверьте подключение к портам ввода и вывода с помощью кнопки **Проверить подключение** для всех входных и выходных данных.

2.  Проверьте входные данные.

    1. Чтобы убедиться, что входные данные передаются в концентратор событий, с помощью [обозревателя служебной шины](https://code.msdn.microsoft.com/windowsapps/Service-Bus-Explorer-f2abca5a) подключитесь к концентратору событий Azure (если концентратор событий используется как точка ввода).
        
    1. Используйте кнопку [**Выбор данных**](stream-analytics-sample-data-input.md) для каждого входного аргумента. Скачайте входные образцы данных.
        
    1. Изучите образец данных, чтобы понять форму данных, то есть схему и [типы данных](https://docs.microsoft.com/stream-analytics-query/data-types-azure-stream-analytics).

3.  Убедитесь, что в предварительной версии входных данных выбран временной диапазон. Выберите **выбрать диапазон времени**, а затем введите длительность выборки перед тестированием запроса.

## <a name="malformed-input-events-causes-deserialization-errors"></a>Неправильный формат входных событий, который приводит к ошибкам десериализации 
Если входной поток задания Stream Analytics содержит сообщения неправильного формата, возникают проблемы десериализации. Например, сообщение может иметь неправильный формат из-за отсутствия круглых или фигурных скобок в объекте JSON или неверного формата метки времени в соответствующем поле. 
 
Когда задание Stream Analytics получает сообщение неправильного формата из входного набора данных, это сообщение отклоняется, а пользователь получает предупреждение. На плитке **Входные данные** задания Stream Analytics отображается символ предупреждения. Этот символ отображается, пока задание находится в рабочем состоянии:

![Плитка "Входные данные" Azure Stream Analytics](media/stream-analytics-malformed-events/stream-analytics-inputs-tile.png)

Чтобы просмотреть сведения предупреждения, необходимо включить журналы диагностики. Для входных событий неправильного формата журналы выполнения содержат запись с сообщением, которое выглядит так: 
```
Could not deserialize the input event(s) from resource <blob URI> as json.
```

### <a name="what-caused-the-deserialization-error"></a>Причины появления ошибки десериализации
Вы можете предпринять следующие шаги, чтобы детально проанализировать входные события и получить четкое представление о том, что вызвало ошибку десериализации. Затем вы можете устранить проблему в источнике события, чтобы создавать события в правильном формате и не допустить повторения этой проблемы.

1. Перейдите к плитке входных данных и щелкните символы предупреждения, чтобы просмотреть список проблем.

2. На плитке сведений о входных данных отображается список предупреждений с подробными сведениями о каждой проблеме. Ниже приведен пример предупреждающего сообщения, в котором отображаются раздел, смещение и порядковые номера с данными JSON неправильного формата. 

   ![Предупреждающее сообщение со смещением от Stream Analytics](media/stream-analytics-malformed-events/warning-message-with-offset.png)
   
3. Чтобы найти данные JSON, которые были представлены в неправильном формате, запустите код CheckMalformedEvents.cs. Его можно найти в [репозитории примеров GitHub](https://github.com/Azure/azure-stream-analytics/tree/master/Samples/CheckMalformedEventsEH). При помощи этого кода считываются идентификатор раздела и смещение, а затем выводятся данные для этого смещения. 

4. После считывания данных можно проанализировать и исправить формат сериализации.

5. Вы также можете [считывать события из Центра Интернета вещей с помощью обозревателя служебной шины](https://code.msdn.microsoft.com/How-to-read-events-from-an-1641eb1b).

## <a name="job-exceeds-maximum-event-hub-receivers"></a>Превышение заданием максимального количества приемников концентратора событий
Мы рекомендуем использовать Центры событий с несколькими группами потребителей, чтобы обеспечить масштабируемость задания. Число модулей чтения в задании Stream Analytics для определенных входных данных влияет на число модулей чтения в одной группе потребителей. Точное число приемников зависит от сведений о внутренней реализации логики топологии развертывания и не предоставляется извне. Число модулей чтения можно изменить во время запуска или обновления задания.

Ошибка, которая отображается, когда число получателей превышает максимально допустимое: `The streaming job failed: Stream Analytics job has validation errors: Job will exceed the maximum amount of Event Hub Receivers.`

> [!NOTE]
> При изменении числа модулей чтения во время обновления задания временные предупреждения записываются в журналы аудита. Задания Stream Analytics восстанавливаются от этих временных сбоев автоматически.

### <a name="add-a-consumer-group-in-event-hubs"></a>Добавление группы потребителей в Центры событий
Чтобы добавить новую группу потребителей в экземпляр Центра событий, сделайте следующее.

1. Войдите на портал Azure.

2. Найдите концентраторы событий.

3. Выберите **Центры событий** под заголовком **Сущности**.

4. Выберите имя концентратора событий.

5. На странице **Экземпляр Центров событий** под заголовком **Сущности** установите флажок **Группы потребителей**. Указана группа потребителей с именем **$Default**.

6. Выберите **+Группа потребителей**, чтобы добавить новую группу потребителей. 

   ![Добавление группы потребителей в Центры событий](media/stream-analytics-event-hub-consumer-groups/new-eh-consumer-group.png)

7. Вы указали группу потребителей, когда создавали входные данные в задании Stream Analytics для концентратора событий. Название $Default используется, если группа не указана. После создания группы потребителей измените входные данные концентратора событий в задании Stream Analytics и укажите имя новой группы потребителей.


## <a name="readers-per-partition-exceeds-event-hubs-limit"></a>Превышение предельно допустимого числа модулей чтения каждого раздела для Центров событий

Если синтаксис запроса потоковой передачи ссылается на один и тот же входной ресурс концентратора событий несколько раз, обработчик заданий может использовать несколько читателей для каждого запроса из этой же группы потребителей. При наличии слишком большого количества ссылок в одной и той же группе потребителей задание может превысить установленный предел (пять ссылок) и вызвать ошибку. В таких случаях можно выполнять разделение с помощью нескольких групп входных данных в нескольких группах потребителей, используя решения, описанные в следующем разделе. 

Ниже представлены сценарии, в которых число модулей чтения каждого раздела превышает предельно допустимое число для Центров событий (пять).

* Несколько инструкций SELECT. При использовании нескольких инструкций SELECT, ссылающихся на **один** набор входных данных концентратора событий, каждая из них создает по приемнику.
* UNION. При использовании UNION несколько наборов входных данных могут ссылаться на **один** концентратор событий и на одну группу потребителей.
* SELF JOIN. При использовании операции SELF JOIN можно создать несколько ссылок на **один** концентратор событий.

Следующие рекомендации могут помочь справиться со сценариями, в которых число модулей чтения каждого раздела превышает предельно допустимое число для Центров событий (пять).

### <a name="split-your-query-into-multiple-steps-by-using-a-with-clause"></a>Разбиение запроса на несколько шагов с помощью предложения WITH

Предложение WITH задает временный именованный результирующий набор, на который можно создать ссылку в предложении FROM в запросе. Предложение WITH определяется в области выполнения одной инструкции SELECT.

Например, вместо этого запроса:

```SQL
SELECT foo 
INTO output1
FROM inputEventHub

SELECT bar
INTO output2
FROM inputEventHub 
…
```

Используйте этот:

```SQL
WITH data AS (
   SELECT * FROM inputEventHub
)

SELECT foo
INTO output1
FROM data

SELECT bar
INTO output2
FROM data
…
```

### <a name="ensure-that-inputs-bind-to-different-consumer-groups"></a>Привязка входных данных к разным группам потребителей

Создайте отдельные группы потребителей для запросов, в которых три или более наборов входных данных подключены к одной группе потребителей Центров событий. Для этого нужно создать дополнительные наборы входных данных Stream Analytics.

## <a name="get-help"></a>Справка

За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия

* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
* [Справочник по языку запросов Azure Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
