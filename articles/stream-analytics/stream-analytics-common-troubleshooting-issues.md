---
title: Распространенные проблемы в Azure Stream Analytics
description: В этой статье описан ряд распространенных проблем в Azure Stream Analytics и инструкции по их устранению.
services: stream-analytics
author: mamccrea
ms.author: mamccrea
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 12/06/2018
ms.custom: seodec18
ms.openlocfilehash: 0191c56e1140870b1710b48c4fa1189fd92a337b
ms.sourcegitcommit: d4dfbc34a1f03488e1b7bc5e711a11b72c717ada
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "61362122"
---
# <a name="common-issues-in-stream-analytics-and-steps-to-troubleshoot"></a>Распространенные проблемы в Stream Analytics и инструкции по их устранению

## <a name="troubleshoot-malformed-input-events"></a>Устранение неполадок в случае неправильного формата входных событий

 Если входной поток задания Stream Analytics содержит сообщения неправильного формата, возникают проблемы сериализации. Например, сообщение может иметь неправильный формат из-за отсутствия круглых или фигурных скобок в объекте JSON или неверного формата метки времени в соответствующем поле. 
 
 Когда задание Stream Analytics получает сообщение неправильного формата из входного набора данных, это сообщение отклоняется, а пользователь получает предупреждение. Символ предупреждения появляется на плитке **Входные данные** задания Stream Analytics (он отображается, пока задание находится в рабочем состоянии):

![Плитка "Входные данные" панели мониторинга Azure Stream Analytics](media/stream-analytics-malformed-events/stream-analytics-inputs-tile.png)

Чтобы просмотреть сведения предупреждения, включите журналы диагностики. Для входных событий неправильного формата журналы выполнения содержат запись с сообщением, которое выглядит так: "Message: Не удалось десериализовать входные события из ресурса \<BLOB-объектов URI > как json». 

### <a name="troubleshooting-steps"></a>Действия по устранению неполадок

1. Перейдите к плитке входных данных и щелкните ее, чтобы просмотреть предупреждения.

2. На плитке сведений о входных данных отображается набор предупреждений с подробными сведениями о проблеме. Ниже приведен пример предупреждающего сообщения, в котором отображаются раздел, смещение и порядковые номера с данными JSON неправильного формата. 

   ![Предупреждающее сообщение со смещением касательно входных данных](media/stream-analytics-malformed-events/warning-message-with-offset.png)

3. Чтобы получить данные JSON, которые имеют неверный формат, запустите код CheckMalformedEvents.cs. Этот пример доступен в [репозитории примеров GitHub](https://github.com/Azure/azure-stream-analytics/tree/master/Samples/CheckMalformedEventsEH). При помощи этого кода считываются идентификатор раздела и смещение, а затем выводятся данные для этого смещения. 

4. После считывания данных можно проанализировать и исправить формат сериализации.

5. Вы также можете [считывать события из Центра Интернета вещей с помощью обозревателя служебной шины](https://code.msdn.microsoft.com/How-to-read-events-from-an-1641eb1b).

## <a name="delayed-output"></a>Задержанные выходные данные

### <a name="first-output-is-delayed"></a>Первый фрагмент выходных данных задерживается
При запуске задания Stream Analytics считываются входные события, но при определенных обстоятельствах может произойти задержка формирования выходных данных.

Большие значения времени в элементах темпоральных запросов могут приводить к задержке выходных данных. Чтобы сформировать правильные выходные данные за большие периоды времени, задание потоковой передачи начинает считывать данные за самое последнее время (до семи дней назад) для охвата временного окна. В течение этого времени выходные данные не создаются, пока не будут считаны все необработанные входные события. Эта проблема может возникнуть, когда система обновляет задания потоковой передачи, тем самым перезапуская их. Такие обновления обычно происходят один раз каждые несколько месяцев. 

Таким образом, проявляйте осторожность при проектировании запроса Stream Analytics. Если вы используете большое временное окно (более чем несколько часов, до семи дней) для темпоральных элементов в синтаксисе запроса задания, то это может привести к задержке первого фрагмента выходных данных при запуске или перезапуске задания.  

В качестве способа устранения этой задержки можно использовать методы параллелизации запросов (секционирование данных) или добавить дополнительные единицы потоковой передачи, чтобы повысить пропускную способность, пока задание наверстывает упущенное.  Дополнительные сведения см. в статье [Концепции контрольных точек и воспроизведения в Azure Stream Analytics](stream-analytics-concepts-checkpoint-replay.md).

Эти факторы влияют на своевременность генерации первого фрагмента выходных данных:

1. Использование агрегатов данных на основе периодов (оператор группирования GROUP BY по "переворачивающимся", "прыгающим" и "скользящим" окнам).
   - Для агрегатов "переворачивающихся" или "прыгающих" окон результаты создаются в конце оконного временного интервала. 
   - Для "скользящего" окна результаты создаются, когда событие входит в это окно или выходит из него. 
   - Если вы планируете использовать большой размер окна (> 1 часа), то лучше выбрать "прыгающее" или "скользящее" окно, чтобы вы могли чаще видеть выходные данные.

2. Использование темпоральных соединений (JOIN с DATEDIFF).
   - Соответствия генерируются, как только поступают оба экземпляра сопоставляемых событий.
   - Данные без соответствия (LEFT OUTER JOIN) создаются в конце окна DATEDIFF относительно каждого события с левой стороны.

3. Использование темпоральных аналитических функции (ISFIRST, LAST и LAG с LIMIT DURATION).
   - Для аналитических функций выходные данные создаются для каждого события без задержки.

### <a name="output-falls-behind"></a>Выходные данные запаздывают
Если вы обнаружите, что во время обычной работы задания выходные данные задерживаются (и задержка становится больше и больше), то можно выявить первопричины, проанализировав такие факторы:
- регулируется ли подчиненный приемник:
- регулируется ли вышестоящий источник данных;
- потребляет ли логика обработки в запросе много вычислительных ресурсов.

Чтобы просмотреть эти сведения, на портале Azure выберите задание потоковой передачи и щелкните **Схема заданий**. Для каждого набора входных данных есть метрика событий невыполненной работы секции. Если метрика невыполненной работы увеличивается, это сигнализирует об ограниченности ресурсов системы. Это может быть связано с регулированием приемника выходных данных или высокой загрузкой ЦП. Дополнительные сведения об использовании схемы заданий см. в статье [Отладка на основе данных с помощью схемы заданий](stream-analytics-job-diagram-with-metrics.md).

## <a name="handle-duplicate-records-in-azure-sql-database-output"></a>Обработка повторяющихся записей в выходных данных базы данных SQL Azure

При настройке службы "База данных SQL Azure" для выходных данных задания Stream Analytics выполняется массовая вставка записей в целевую таблицу. Обычно Azure Stream Analytics гарантирует [по крайней мере однократную доставку]( https://msdn.microsoft.com/azure/stream-analytics/reference/event-delivery-guarantees-azure-stream-analytics) в приемник выходных данных. Но можно обеспечить и [исключительно однократную доставку]( https://blogs.msdn.microsoft.com/streamanalytics/2017/01/13/how-to-achieve-exactly-once-delivery-for-sql-output/) для выходных данных SQL. Для этого в таблице SQL нужно определить уникальное ограничение. 

Когда в таблицу SQL, в которой настроены уникальные ограничения ключей, вставляются повторяющиеся записи, Azure Stream Analytics удаляет такую запись. Данные разделяются на пакеты, которые рекурсивно вставляются, пока не будет обнаружена повторяющаяся запись. Если задание потоковой передачи имеет значительное число повторяющихся строк, процесс разбиения и вставки должен игнорировать дубликаты по одному, что менее эффективно и занимает много времени. Если в журнале действий в течение последнего часа отображается несколько предупреждающих сообщений о нарушении ключа, вполне вероятно, что обработка выходных данных SQL замедляет выполнение всего задания. 

Чтобы устранить эту проблему, нужно [настроить индекс]( https://docs.microsoft.com/sql/t-sql/statements/create-index-transact-sql), который вызывает нарушение ключа, включив параметр IGNORE_DUP_KEY. Этот параметр позволяет пропускать в SQL повторяющиеся значения при массовой вставке. В таком случае в SQL Azure вместо сообщения об ошибке отображается предупреждающее сообщение. Azure Stream Analytics больше не создают сообщения об ошибке при нарушении первичного ключа.

Если IGNORE_DUP_KEY настраивается для нескольких типов индексов, обратите внимание на следующее:

* IGNORE_DUP_KEY нельзя установить для первичного ключа или уникального ограничения, в котором используется ALTER INDEX. Индекс нужно удалить и создать повторно.  
* Вы можете задать параметр IGNORE_DUP_KEY для уникального индекса при помощи ALTER INDEX. Это ограничение отличается от PRIMARY KEY или UNIQUE и создается с использованием определения CREATE INDEX или INDEX.  
* IGNORE_DUP_KEY не применяется к индексам хранилища столбцов, так как нельзя обеспечить уникальность таких индексов.  

## <a name="next-steps"></a>Дальнейшие действия
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
