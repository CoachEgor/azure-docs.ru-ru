---
title: Потоковые данные в качестве входных данных Azure Stream Analytics
description: Узнайте больше о настройке подключения данных в Azure Stream Analytics. К входным данным относятся поток данных из событий, а также справочные данные.
author: mamccrea
ms.author: mamccrea
ms.reviewer: mamccrea
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 01/17/2020
ms.openlocfilehash: 388f43fec9242f6a4b448483d9486aa4413d2612
ms.sourcegitcommit: a9b1f7d5111cb07e3462973eb607ff1e512bc407
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/22/2020
ms.locfileid: "76314799"
---
# <a name="stream-data-as-input-into-stream-analytics"></a>Потоковые данные в качестве входных данных Stream Analytics

Stream Analytics полностью интегрируется с потоками данных Azure в качестве входных данных трех типов ресурсов.

- [Центры событий Azure](https://azure.microsoft.com/services/event-hubs/)
- [Центр Интернета вещей Azure](https://azure.microsoft.com/services/iot-hub/) 
- [Хранилище BLOB-объектов Azure](https://azure.microsoft.com/services/storage/blobs/) 

Эти ресурсы входных данных могут существовать в той же подписке Azure, что и задание Stream Analytics, или другой подписке.

### <a name="compression"></a>Сжатие

Stream Analytics поддерживает функцию сжатия во всех источниках входных потоковых данных. Поддерживаются следующие типы сжатия: None, GZip и deflate сжатие. Для ссылочных данных сжатие не поддерживается. Если у входных данных формат AVRO, они сжимаются и выполняется их прозрачная обработка. Для сериализации Avro не требуется указывать тип сжатия. 

## <a name="create-edit-or-test-inputs"></a>Создание, изменение или проверка входных данных

Вы можете использовать [портал Azure](stream-analytics-quick-create-portal.md), [Visual Studio](stream-analytics-quick-create-vs.md)и [Visual Studio Code](quick-create-vs-code.md) для добавления и просмотра или изменения существующих входных данных для задания потоковой передачи. Вы также можете проверить входные соединения и [тестовые запросы](stream-analytics-manage-job.md#test-your-query) из примеров данных из портал Azure, [Visual Studio](stream-analytics-vs-tools-local-run.md)и [Visual Studio Code](visual-studio-code-local-run.md). При написании запроса входные данные перечисляются в предложении FROM. Список доступных входных данных можно получить на странице **Запрос** на портале. Чтобы использовать несколько источников входных данных, объедините их с помощью параметра `JOIN` или напишите несколько запросов `SELECT`.


## <a name="stream-data-from-event-hubs"></a>Потоковая передача данных из Центров событий

Центры событий Azure предоставляют высокомасштабируемую службу приема данных о событиях публикации и подписки. Концентратор событий может выполнять собираются миллионы событий в секунду, чтобы можно было обрабатывать и анализировать огромные объемы данных, создаваемых подключенными устройствами и приложениями. Используя Центры событий со службой Stream Analytics, вы получаете комплексное решение для анализа данных в режиме реального времени. Центры событий позволяют передавать события в Azure в режиме реального времени, где задания Stream Analytics также обрабатывают эти события в режиме реального времени. Например, в Центры событий можно отправлять сведения о щелчках, показания датчиков или журналы сетевых событий. Затем можно создать задания Stream Analytics, которые используют Центры событий в качестве входных потоков данных для фильтрации в режиме реального времени, выполнения агрегации и корреляции.

`EventEnqueuedUtcTime` — это метка времени поступления события в концентратор, которая также является меткой времени по умолчанию для событий, поступающих из Центров событий в Stream Analytics. Для обработки данных как потока с помощью метки времени в полезных данных события необходимо использовать ключевое слово [TIMESTAMP BY](https://docs.microsoft.com/stream-analytics-query/timestamp-by-azure-stream-analytics).

### <a name="event-hubs-consumer-groups"></a>Группы потребителей концентраторов событий

Каждый концентратор событий Stream Analytics нужно настроить таким образом, чтобы у него была собственная группа получателей. Если задание содержит самосоединение или несколько источников входных данных, некоторые входные данные могут последовательно считываться несколькими модулями чтения. Эта ситуация влияет на количество модулей чтения в группе получателей. Чтобы не превысить лимит на количество модулей чтения для Центров событий (5 на каждую группу получателей в разделе), рекомендуется назначить группу получателей для каждого задания Stream Analytics. Существует также ограничение в 20 групп потребителей для концентратора событий уровня "Стандартный". Дополнительные сведения см. в разделе об [устранении неполадок входных данных Azure Stream Analytics](stream-analytics-troubleshoot-input.md).

### <a name="create-an-input-from-event-hubs"></a>Создание входных данных из концентраторов событий

В следующей таблице описываются все параметры на странице **Новые входные данные** на портале Azure для передачи потока входных данных из концентратора событий.

| Свойство | Description |
| --- | --- |
| **Псевдоним входных данных** |Понятное имя, используемое в запросах задания для ссылки на эти входные данные. |
| **подписка** | Выберите подписку, в которой существует ресурс концентратора событий. | 
| **Пространство имен концентратора событий** | Пространство имен концентратора событий — это контейнер для набора сущностей обмена сообщениями. При создании нового концентратора событий также создается пространство имен. |
| **Имя концентратора событий** | Имя концентратора событий для использования в качестве источника входных данных. |
| **Имя политики концентратора событий** | Политика общего доступа, которая предоставляет доступ к концентратору событий. Каждой политике общего доступа присваивается имя, а также для нее задаются разрешения и ключи доступа. Этот параметр автоматически заполняется, если только не указан параметр "Указать настройки концентратора событий вручную".|
| **Группа получателей концентратора событий** (рекомендуется) | Для каждого задания Stream Analytics настоятельно рекомендуется использовать отдельную группу получателей. Эта строка указывает группу получателей, принимающих данные из концентратора событий. Если группа получателей не указана, задание Stream Analytics использует группу получателей "$Default".  |
| **Ключ секции** | Если входные данные секционированы по свойству, можно добавить имя этого свойства. Ключи секций необязательны и используются для повышения производительности запроса, если он включает предложение PARTITION BY или GROUP BY для этого свойства. |
| **Формат сериализации событий** | Формат сериализации (JSON, CSV, Avro или [другое (protobuf, XML, запатентованный...)](custom-deserializer.md)) входящего потока данных.  Убедитесь, что формат JSON совпадает со спецификацией и не содержит ведущий "0" в десятичных числах. |
| **Кодирование** | Сейчас UTF-8 — единственный поддерживаемый формат кодировки. |
| **Тип сжатия событий** | Тип сжатия используется для чтения таких входящих потоков данных, как None (по умолчанию), GZip или Deflate. |

При поступлении входных данных из потока данных концентратора событий запрос Stream Analytics может получить доступ к следующим полям метаданных:

| Свойство | Description |
| --- | --- |
| **EventProcessedUtcTime** |Дата и время обработки события службой Stream Analytics. |
| **EventEnqueuedUtcTime** |Дата и время получения события Центрами событий. |
| **PartitionId** |Идентификатор секции для входного адаптера (нумерация идет от нуля). |

Например, используя эти поля, можно писать запросы, как в следующем примере:

```sql
SELECT
    EventProcessedUtcTime,
    EventEnqueuedUtcTime,
    PartitionId
FROM Input
```

> [!NOTE]
> При использовании концентратора событий в качестве конечной точки для маршрутов Центра Интернета вещей вы можете получить доступ к метаданным Центра Интернета вещей с помощью [функции GetMetadataPropertyValue](https://docs.microsoft.com/stream-analytics-query/getmetadatapropertyvalue).
> 

## <a name="stream-data-from-iot-hub"></a>Потоковая передача данных из Центра Интернета вещей

Центр Интернета вещей Azure — это Высокомасштабируемая служба приема событий публикации и подписки, оптимизированная для сценариев Интернета вещей.

По умолчанию метка времени событий, поступающих из Центра Интернета вещей в Stream Analytics, — это метка времени поступления события в концентратор Центра Интернета вещей, то есть `EventEnqueuedUtcTime`. Для обработки данных как потока с помощью метки времени в полезных данных события необходимо использовать ключевое слово [TIMESTAMP BY](https://docs.microsoft.com/stream-analytics-query/timestamp-by-azure-stream-analytics).

### <a name="iot-hub-consumer-groups"></a>Группы потребителей центра Интернета вещей

Каждый Центр Интернета вещей Stream Analytics нужно настроить таким образом, чтобы у него была собственная группа получателей. Если задание включает самосоединение или несколько источников входных данных, некоторые входные данные могут последовательно считываться несколькими модулями чтения. Эта ситуация влияет на количество модулей чтения в группе получателей. Чтобы не превысить лимит на количество модулей чтения для Центра Интернета вещей (5 на каждую группу получателей в разделе), рекомендуется назначить группу получателей для каждого задания Stream Analytics.

### <a name="configure-an-iot-hub-as-a-data-stream-input"></a>Настройка Центра Интернета вещей в качестве входного потока данных

В следующей таблице описываются все параметры на странице **Новые входные данные** на портале Azure при настройке Центра Интернета вещей в качестве потокового входа.

| Свойство | Description |
| --- | --- |
| **Псевдоним входных данных** | Понятное имя, используемое в запросах задания для ссылки на эти входные данные.|
| **подписка** | Выберите подписку, в которой существуют ресурсы Центра Интернета вещей. | 
| **Центр Интернета вещей** | Имя Центра Интернета вещей для использования в качестве источника входных данных. |
| **Конечная точка** | Конечная точка для Центра Интернета вещей.|
| **Имя политики общего доступа** | Политика общего доступа, которая предоставляет доступ к Центру Интернета вещей. Каждой политике общего доступа присваивается имя, а также для нее задаются разрешения и ключи доступа. |
| **Ключ политики общего доступа** | Ключ общего доступа, используемый для авторизации доступа к Центру Интернета вещей.  Этот параметр автоматически заполняется, если только не будет указан вариант ручной настройки параметров Центра Интернета вещей. |
| **Группа потребителей** | Для каждого задания Stream Analytics настоятельно рекомендуется использовать отдельную группу получателей. Группа получателей используется для принимающих данных из Центра Интернета вещей. Stream Analytics использует группу получателей "$Default", если не указано иное.  |
| **Ключ секции** | Если входные данные секционированы по свойству, можно добавить имя этого свойства. Ключи секций необязательны и используются для повышения производительности запроса, если он включает предложение PARTITION BY или GROUP BY для этого свойства. |
| **Формат сериализации событий** | Формат сериализации (JSON, CSV, Avro или [другое (protobuf, XML, запатентованный...)](custom-deserializer.md)) входящего потока данных.  Убедитесь, что формат JSON совпадает со спецификацией и не содержит ведущий "0" в десятичных числах. |
| **Кодирование** | Сейчас UTF-8 — единственный поддерживаемый формат кодировки. |
| **Тип сжатия событий** | Тип сжатия используется для чтения таких входящих потоков данных, как None (по умолчанию), GZip или Deflate. |


При использовании потоковой передачи данных из Центра Интернета вещей запрос Stream Analytics может получить доступ к следующим полям метаданных:

| Свойство | Description |
| --- | --- |
| **EventProcessedUtcTime** | Дата и время обработки события. |
| **EventEnqueuedUtcTime** | Дата и время получения события Центром Интернета вещей. |
| **PartitionId** | Идентификатор секции для входного адаптера (нумерация идет от нуля). |
| **IoTHub.MessageId** | Идентификатор, используемый для корреляции двустороннего обмена данными в Центре Интернета вещей. |
| **IoTHub.CorrelationId** | Идентификатор, используемый в ответах на сообщение и отзывах в Центре Интернета вещей. |
| **IoTHub.ConnectionDeviceId** | Идентификатор проверки подлинности, используемый для отправки этого сообщения. Это значение помещается в сообщения, связанные со службой, Центром Интернета вещей. |
| **IoTHub.ConnectionDeviceGenerationId** | Идентификатор создания устройства, прошедшего проверку подлинности, используемый для отправки этого сообщения. Это значение помещается в сообщения, связанные со службой, Центром Интернета вещей. |
| **IoTHub.EnqueuedTime** | Время, когда Центр Интернета вещей получил сообщение. |


## <a name="stream-data-from-blob-storage"></a>Потоковая передача данных из хранилища BLOB-объектов
Хранилище больших двоичных объектов Azure служит экономичным и масштабируемым решением в сценариях, связанных с хранением больших объемов неструктурированных данных в облаке. Данные в хранилище BLOB-объектов обычно считаются неактивными, но служба Stream Analytics может обрабатывать эти данные как поток данных. 

Обработка журналов — это часто используемый сценарий для обработки входных данных хранилища больших двоичных объектов с помощью Stream Analytics. В этом сценарии файлы данных телеметрии, полученные из системы, необходимо проанализировать и обработать, чтобы извлечь значимые данные.

По умолчанию метка времени событий хранилища больших двоичных объектов в Stream Analytics — это метка времени последнего изменения большого двоичного объекта, то есть `BlobLastModifiedUtcTime`. Если большой двоичный объект передается в учетную запись хранения по адресу 13:00, а задание Azure Stream Analytics запускается с параметром *Now* (13:01), большой двоичный объект не будет выбран, так как время его изменения не превышает период выполнения задания.

Если большой двоичный объект передается в контейнер учетной записи хранения в 13:00, а задание Azure Stream Analytics запускается с использованием *настраиваемого времени* в 13:00 или более ранней версии, большой двоичный объект будет выбран, так как время его изменения попадает в период выполнения задания.

Если Azure Stream Analytics задание *запускается в 13:00* , а большой двоичный объект передается в контейнер учетной записи хранения в 13:01, Azure Stream Analytics выберет большой двоичный объект.

Для обработки данных как потока с помощью метки времени в полезных данных события необходимо использовать ключевое слово [TIMESTAMP BY](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference). Задание Stream Analytics извлекает данные из входных данных хранилища BLOB-объектов Azure каждую секунду, если доступен файл большого двоичного объекта. В случае, если этот файл недоступен, применяется экспоненциально увеличивающаяся задержка с максимальным значением, равным 90 секундам.

Входным данным в формате CSV требуется строка заголовка, определяющая поля для набора данных, а все поля строк заголовков должны быть уникальными.

> [!NOTE]
> Stream Analytics не поддерживает добавление содержимого в существующий файл большого двоичного объекта. Stream Analytics просматривает каждый файл только один раз, и любые изменения, которые произойдут в нем после того, как задание прочитает данные, не обрабатываются. Мы рекомендуем отправлять все данные для файла большого двоичного объекта за один раз, а затем добавлять более новые события в другой новый файл большого двоичного объекта.

Загрузка очень большого количества больших двоичных объектов одновременно может привести к тому, что в редких случаях Stream Analytics пропускать чтение нескольких больших двоичных объектов. Рекомендуется отправлять большие двоичные объекты не менее чем через 2 секунды в хранилище BLOB-объектов. Если этот параметр неприменим, можно использовать концентраторы событий для потоковой передачи больших объемов событий. 

### <a name="configure-blob-storage-as-a-stream-input"></a>Настройка хранилища BLOB-объектов в качестве потокового входа 

В следующей таблице описываются все параметры на странице **Новые входные данные** на портале Azure при настройке хранилища больших двоичных объектов в качестве потокового входа.

| Свойство | Description |
| --- | --- |
| **Псевдоним входных данных** | Понятное имя, используемое в запросах задания для ссылки на эти входные данные. |
| **подписка** | Выберите подписку, в которой существуют ресурсы Центра Интернета вещей. | 
| **Учетная запись хранения** | Имя учетной записи хранения, в которой находятся файлы больших двоичных объектов. |
| **Ключ учетной записи хранения** | Секретный ключ, связанный с учетной записью хранения. Этот параметр автоматически заполняется, если только не будет указан вариант ручной настройки параметров хранилища больших двоичных объектов. |
| **Контейнер** | Контейнер для входных данных большого двоичного объекта. Контейнеры обеспечивают логическую группировку BLOB-объектов, хранящихся в службе BLOB-объектов Microsoft Azure. При передаче большого двоичного объекта в службу хранилища BLOB-объектов для него необходимо указать контейнер. Чтобы создать новый контейнер, вы можете выбрать параметр **Use existing** (Использование имеющихся) контейнеров или **Создать**.|
| **Шаблон пути** (необязательно) | Путь к файлу, используемый для поиска больших двоичных объектов в указанном контейнере. Если требуется считать большие двоичные объекты из корня контейнера, не задавайте шаблон пути. В пути можно указать один или более экземпляров следующих трех переменных: `{date}`, `{time}` или `{partition}`.<br/><br/>Пример 1: `cluster1/logs/{date}/{time}/{partition}`<br/><br/>Пример 2: `cluster1/logs/{date}`<br/><br/>Символ `*` является недопустимым значением для префикса пути. Допустимыми являются только <a HREF="https://msdn.microsoft.com/library/azure/dd135715.aspx">символы больших двоичных объектов Azure</a>. Не включайте имена контейнеров и имена файлов. |
| **Формат даты** (необязательное свойство) | При использовании переменной даты в пути это формат даты, по которому упорядочены файлы. Пример: `YYYY/MM/DD` |
| **Формат времени** (необязательное свойство) |  При использовании переменной времени в пути это формат времени, в котором размещаются файлы. В настоящее время единственным поддерживаемым значением в течение нескольких часов является `HH`. |
| **Ключ секции** | Если входные данные секционированы по свойству, можно добавить имя этого свойства. Ключи секций необязательны и используются для повышения производительности запроса, если он включает предложение PARTITION BY или GROUP BY для этого свойства. |
| **Формат сериализации событий** | Формат сериализации (JSON, CSV, Avro или [другое (protobuf, XML, запатентованный...)](custom-deserializer.md)) входящего потока данных.  Убедитесь, что формат JSON совпадает со спецификацией и не содержит ведущий "0" в десятичных числах. |
| **Кодирование** | В настоящее время единственным поддерживаемым форматом кодирования файлов CSV и JSON является UTF-8. |
| **Сжатие** | Тип сжатия используется для чтения таких входящих потоков данных, как None (по умолчанию), GZip или Deflate. |

При поступлении данных из хранилища больших двоичных объектов запрос Stream Analytics может получить доступ к следующим полям метаданных:

| Свойство | Description |
| --- | --- |
| **BlobName** |Имя входного большого двоичного объекта, от которого поступило событие. |
| **EventProcessedUtcTime** |Дата и время обработки события службой Stream Analytics. |
| **BlobLastModifiedUtcTime** |Дата и время последнего изменения большого двоичного объекта. |
| **PartitionId** |Идентификатор секции для входного адаптера (нумерация идет от нуля). |

Например, используя эти поля, можно писать запросы, как в следующем примере:

```sql
SELECT
    BlobName,
    EventProcessedUtcTime,
    BlobLastModifiedUtcTime
FROM Input
```

## <a name="next-steps"></a>Дальнейшие действия
> [!div class="nextstepaction"]
> [Краткое руководство по созданию задания Stream Analytics с помощью портала Azure](stream-analytics-quick-create-portal.md)

<!--Link references-->
[stream.analytics.developer.guide]: ../stream-analytics-developer-guide.md
[stream.analytics.scale.jobs]: stream-analytics-scale-jobs.md
[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: https://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: https://go.microsoft.com/fwlink/?LinkId=517301
