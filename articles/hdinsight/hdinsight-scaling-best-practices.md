---
title: Масштабирование размеров кластера в Azure HDInsight
description: Масштабируйте кластер Apache Hadoop, чтобы соответствовать вашей рабочей нагрузке в Azure HDInsight
author: ashishthaps
ms.author: ashish
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 02/26/2020
ms.openlocfilehash: 96a72541255ad0059abe5ad280f1728518dbf68c
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "80234734"
---
# <a name="scale-azure-hdinsight-clusters"></a>Масштабируйте кластеры Azure HDInsight

HDInsight обеспечивает гибкость, предоставляя возможность увеличивать и уменьшать масштаб определенного количества рабочих узлов в кластерах. Эта эластичность позволяет сокращать кластер в нерабочее время или в выходные дни и расширять его во время пиковых бизнес-требований.

Если у вас есть периодическая пакетная обработка, кластер HDInsight может быть масштабирован за несколько минут до этой операции, так что ваш кластер имеет достаточную память и мощность процессора. Позже после обработки, когда кластер HDInsight не требует интенсивного использования, можно уменьшить его масштаб для меньшего количества рабочих узлов.

Можно масштабировать кластер вручную, используя один из методов, изложенных ниже, или использовать [параметры автомасштаба,](hdinsight-autoscale-clusters.md) чтобы система автоматически масштабировалась вверх и вниз в ответ на процессор, память и другие метрики.

> [!NOTE]  
> Поддерживаются только кластеры HDInsight версии 3.1.3 или более поздней. Если вы не знаете версию кластера, см. страницу «Свойства».

## <a name="utilities-to-scale-clusters"></a>Утилиты для масштабирования кластеров

Корпорация Майкрософт предоставляет следующие утилиты для масштабирования кластеров:

|Служебная программа | Описание|
|---|---|
|[PowerShell Az](https://docs.microsoft.com/powershell/azure)|[Set-AzHDInsightClusterSize](https://docs.microsoft.com/powershell/module/az.hdinsight/set-azhdinsightclustersize) -ClusterName \<Название кластера \<> -TargetInstanceCount NewSize>|
|[PowerShell AzureRM](https://docs.microsoft.com/powershell/azure/azurerm) |[Set-AzureRmHDInsightClusterSize](https://docs.microsoft.com/powershell/module/azurerm.hdinsight/set-azurermhdinsightclustersize) -ClusterName \<Название кластера \<> -TargetInstanceCount NewSize>|
|[Лазурный CLI](https://docs.microsoft.com/cli/azure/?view=azure-cli-latest)| [az hdinsight переразмерировать](https://docs.microsoft.com/cli/azure/hdinsight?view=azure-cli-latest#az-hdinsight-resize) --ресурс-группа \<Ресурсная группа> --имя \< \<Название кластера> --workernode-count NewSize>|
|[Azure Classic CLI](hdinsight-administer-use-command-line.md)|лазурный кластер hdinsight изменял кластераНаи> \< \<Target Instance Count> |
|[Портал Azure](https://portal.azure.com)|Откройте панель кластера HDInsight, выберите **размер кластера** в левом меню, затем на панели размера кластера, введите число узлов рабочего и выберите Сохранить.|  

![Вариант кластера кластера портала Azure](./media/hdinsight-scaling-best-practices/azure-portal-settings-nodes.png)

С помощью любого из этих методов можно увеличивать или уменьшать масштаб кластера HDInsight за считанные минуты.

> [!IMPORTANT]  
> * Классический CLI Azure унижается и должен использоваться только с классической моделью развертывания. Для всех остальных развертываний используйте [Azure CLI.](https://docs.microsoft.com/cli/azure/?view=azure-cli-latest)  
> * Модуль PowerShell AzureRM унипражен.  Пожалуйста, используйте [модуль Az,](https://docs.microsoft.com/powershell/azure/new-azureps-module-az?view=azps-1.4.0) когда это возможно.

## <a name="impact-of-scaling-operations"></a>Влияние операций масштабирования

При **добавлении** узлов в запущенный кластер HDInsight (масштабирование вверх) любые невыполненные или запущенные задания не будут затронуты. Во время масштабирования можно безопасно передать новые задания. Если операция масштабирования по какой-либо причине не выполняется, сбой будет обработан, чтобы оставить кластер в функциональном состоянии.

При **удалении** узлов (снизу масштабирования) любые невыполненные или выполняемые задания сбой при завершении операции масштабирования. Этот сбой связан с перезапуском некоторых служб в процессе масштабирования. Существует также риск того, что ваш кластер может застрять в безопасном режиме во время ручной операции масштабирования.

Ниже представлены возможности, связанные с изменением количества узлов данных в кластере каждого типа, поддерживаемого в HDInsight:

* Apache Hadoop

    Вы можете легко увеличить количество рабочих узлов в работающем кластере Hadoop. Это не помешает обработке заданий в состоянии ожидания и выполнения. В ходе выполнения операции можно также отправлять новые задания. Сбои операции масштабирования обрабатываются корректно, поэтому кластер всегда пребывает в функциональном состоянии.

    Если уменьшить масштаб кластера Hadoop, сократив количество узлов данных, некоторые службы в нем будут перезапущены. Это приведет к сбою всех выполняющихся и ожидающих заданий при завершении операции масштабирования. Однако после завершения операции вы можете повторно отправить задания.

* Apache HBase

    Вы можете с легкостью добавлять и удалять узлы данных в работающем кластере HBase. Балансировка региональных серверов выполняется автоматически в течение нескольких минут после завершения операции масштабирования. Но их также можно сбалансировать вручную, выполнив вход в головной узел кластера и выполнив следующие команды в окне командной строки:

    ```bash
    pushd %HBASE_HOME%\bin
    hbase shell
    balancer
    ```

    Дополнительные сведения об использовании оболочки HBase см. в статье [Начало работы с примером Apache HBase в HDInsight](hbase/apache-hbase-tutorial-get-started-linux.md).

* Apache Storm

    Вы можете с легкостью добавлять и удалять узлы данных в работающем кластере Storm. Но после успешного завершения операции масштабирования потребуется повторная балансировка топологии.

    Повторную балансировку можно выполнить двумя способами:

  * с помощью веб-интерфейса Storm;
  * с помощью программы командной строки.

    Дополнительные сведения см. в [документации по Apache Storm](https://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html).

    В кластере HDInsight доступен веб-интерфейс Storm.

    ![HDInsight, Storm, масштабирование, перераспределение](./media/hdinsight-scaling-best-practices/hdinsight-portal-scale-cluster-storm-rebalance.png)

    Ниже приведен пример команды CLI для повторной балансировки топологии Storm:

    ```console
    ## Reconfigure the topology "mytopology" to use 5 worker processes,
    ## the spout "blue-spout" to use 3 executors, and
    ## the bolt "yellow-bolt" to use 10 executors
    $ storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10
    ```

## <a name="how-to-safely-scale-down-a-cluster"></a>Как безопасно сократить кластер

### <a name="scale-down-a-cluster-with-running-jobs"></a>Масштабирование кластера с запущенными заданиями

Чтобы избежать сбоя выполняемых заданий во время операции снижения масштаба, вы можете попробовать три вещи:

1. Подождите, пока задания будут завершены, прежде чем масштабировать кластер.
1. Вручную прекратите работу.
1. Повторное представление заданий после завершения операции масштабирования.

Чтобы просмотреть список невыполненных и выполняемых заданий, можно использовать **uI-uI**менеджера ресурсов YARN, следующие следующие действия:

1. На [портале Azure](https://portal.azure.com/)выберите кластер.  Инструкции см. в разделе [Отображение кластеров](./hdinsight-administer-use-portal-linux.md#showClusters). Кластер открывается на новой странице портала.
2. С основного вида перейдите к **кластера приборных панелей** > **Ambari дома**. Введите учетные данные кластера.
3. Из uI Ambari выберите **YARN** в списке услуг в левом меню.  
4. На странице YARN выберите **Быстрые ссылки** и нависните над активным головным узлам, а затем выберите **UI ResourceManager.**

    ![Apache Ambari быстро связывает UI ResourceManager](./media/hdinsight-scaling-best-practices/resource-manager-ui1.png)

Прямой доступ к пользовательскому интерфейсу ResourceManager можно получить, щелкнув ссылку `https://<HDInsightClusterName>.azurehdinsight.net/yarnui/hn/cluster`.

Вы увидите список заданий и их текущее состояние. На скриншоте в настоящее время работает одна работа:

![Приложения пользовательского интерфейса ResourceManager](./media/hdinsight-scaling-best-practices/resourcemanager-ui-applications.png)

Чтобы вручную завершить работу запущенного приложения, из оболочки SSH выполните команду ниже:

```bash
yarn application -kill <application_id>
```

Пример:

```bash
yarn application -kill "application_1499348398273_0003"
```

### <a name="getting-stuck-in-safe-mode"></a>Застрять в безопасном режиме

При уменьшении кластера HDInsight использует интерфейсы управления Apache Ambari для первого вывода из эксплуатации дополнительных узлов рабочего, которые повторяют их блоки HDFS на другие онлайн-узлы. После этого HDInsight безопасно масштабирует кластер вниз. HDFS переходит в безопасный режим во время операции масштабирования, и должен выйти после того, как масштабирование закончено. Однако в некоторых случаях HDFS застревает в безопасном режиме во время операции масштабирования из-за недовоза блока файлов.

По умолчанию HDFS настроен `dfs.replication` с настройкой 1, которая контролирует количество копий каждого файлового блока. Каждая копия блока файлов хранится на другом узлах кластера.

Когда HDFS обнаруживает, что ожидаемое количество копий блоков недоступно, HDFS вступает в безопасный режим, а Ambari генерирует оповещения. Если HDFS вступает в безопасный режим для операции масштабирования, но затем не может выйти из безопасного режима, поскольку необходимое количество узлов не обнаруживается для репликации, кластер может застрять в безопасном режиме.

### <a name="example-errors-when-safe-mode-is-turned-on"></a>Примеры ошибок, когда включен безопасный режим

```output
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/hive/819c215c-6d87-4311-97c8-4f0b9d2adcf0. Name node is in safe mode.
```

```output
org.apache.http.conn.HttpHostConnectException: Connect to active-headnode-name.servername.internal.cloudapp.net:10001 [active-headnode-name.servername. internal.cloudapp.net/1.1.1.1] failed: Connection refused
```

Вы можете изучить журналы узла имени в папке `/var/log/hadoop/hdfs/` примерно в то же время, когда было выполнено масштабирование кластера, чтобы проследить, когда был активирован безопасный режим. Файлам журнала присвоено имя `Hadoop-hdfs-namenode-<active-headnode-name>.*`.

Основной причиной ошибок выше является зависимость Hive от временных файлов в HDFS во время выполнения запросов. Когда HDFS переходит в безопасный режим, Hive не может выполнять запросы, так как не удается произвести запись в HDFS. Временные файлы в HDFS расположены на локальном диске, подключенном к виртуальным машинам с отдельным рабочим узлом, и реплицируются на другие рабочие узлы с минимальным количеством реплик — три.

### <a name="how-to-prevent-hdinsight-from-getting-stuck-in-safe-mode"></a>Как предотвратить застрять в безопасном режиме HDInsight

Есть несколько способов предотвратить зависание HDInsight в безопасном режиме.

* Остановите все задания Hive перед уменьшением масштаба HDInsight. Кроме того, можно запланировать операцию уменьшения масштаба, чтобы избежать конфликта с запущенными заданиями Hive.
* Вручную очистите пустые файлы в каталоге `tmp` Hive в HDFS, а затем приступите к уменьшению масштаба.
* Выполните уменьшение масштаба HDInsight как минимум до трех рабочих узлов. Старайтесь избежать масштабирования до одного рабочего узла.
* При необходимости выполните команду, чтобы отключить безопасный режим.

В разделах ниже описываются эти параметры.

#### <a name="stop-all-hive-jobs"></a>Остановка всех заданий Hive

Остановите все задания Hive перед уменьшением масштаба до одного рабочего узла. Если запланирована рабочая нагрузка, выполните уменьшение масштаба после завершения работы Hive.

Остановка заданий Hive перед масштабированием помогает свести к минимуму количество файлов царапин в папке tmp (если таковые имеется).

#### <a name="manually-clean-up-hives-scratch-files"></a>Очистка пустых файлов Hive вручную

Если при работе Hive остались временные файлы, их можно вручную очистить, а затем выполнить уменьшение масштаба, чтобы избежать активации безопасного режима.

1. Проверьте, какое местоположение используется для временных файлов Hive, посмотрев свойство конфигурации. `hive.exec.scratchdir` Этот параметр `/etc/hive/conf/hive-site.xml`устанавливается в пределах:

    ```xml
    <property>
        <name>hive.exec.scratchdir</name>
        <value>hdfs://mycluster/tmp/hive</value>
    </property>
    ```

1. Остановите службы Hive и убедитесь, что выполнены все задания и запросы.
2. Перечислите содержимое каталога царапин, `hdfs://mycluster/tmp/hive/` найденного выше, чтобы увидеть, содержит ли он какие-либо файлы:

    ```bash
    hadoop fs -ls -R hdfs://mycluster/tmp/hive/hive
    ```

    Ниже приведен пример выходных данных при наличии файлов:

    ```output
    sshuser@scalin:~$ hadoop fs -ls -R hdfs://mycluster/tmp/hive/hive
    drwx------   - hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c
    drwx------   - hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/_tmp_space.db
    -rw-r--r--   3 hive hdfs         27 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/inuse.info
    -rw-r--r--   3 hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/inuse.lck
    drwx------   - hive hdfs          0 2017-07-06 20:30 hdfs://mycluster/tmp/hive/hive/c108f1c2-453e-400f-ac3e-e3a9b0d22699
    -rw-r--r--   3 hive hdfs         26 2017-07-06 20:30 hdfs://mycluster/tmp/hive/hive/c108f1c2-453e-400f-ac3e-e3a9b0d22699/inuse.info
    ```

3. Если эти файлы обработаны Hive, их можно удалить. Просмотрите страницу пользовательского интерфейса Yarn ResourceManager, чтобы убедиться в отсутствии любых запущенных запросов Hive.

    Пример командной строки для удаления файлов из HDFS:

    ```bash
    hadoop fs -rm -r -skipTrash hdfs://mycluster/tmp/hive/
    ```

#### <a name="scale-hdinsight-to-three-or-more-worker-nodes"></a>Масштабируйте HDInsight до трех или более рабочих узлов

Если кластеры часто застревают в безопасном режиме при сокращении до менее чем трех рабочих узлов, а предыдущие этапы не работают, то можно избежать вашего кластера, входящего в безопасный режим, сохраняя по крайней мере три рабочих узла.

Сохранение трех рабочих узлов обходится дороже, чем масштабирование до одного рабочего узла, но это предотвратит застрять кластера в безопасном режиме.

### <a name="scale-hdinsight-down-to-one-worker-node"></a>Масштабируйте HDInsight до одного рабочего узла

Даже когда кластер уменьшен до 1 узла, рабочий узла 0 все равно выживет. Рабочий узлы 0 никогда не могут быть выведены из эксплуатации.

#### <a name="run-the-command-to-leave-safe-mode"></a>Выполнение команды для отключения безопасного режима

Окончательный вариант заключается в выполнении команды безопасного режима отпуска. Если вы знаете, что причина ввода HDFS в безопасный режим из-за недовоспроизводимого файла Hive, вы можете выполнить следующую команду, чтобы выйти из безопасного режима:

```bash
hdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode leave
```

### <a name="scale-down-an-apache-hbase-cluster"></a>Масштабирование кластера Apache HBase

Серверы региона автоматически уравновешиваются в течение нескольких минут после завершения операции масштабирования. Чтобы вручную сбалансировать серверы регионов, выполните следующие действия:

1. Подключитесь к кластеру HDInsight по протоколу SSH. Для получения дополнительной информации [см.](hdinsight-hadoop-linux-use-ssh-unix.md)

2. Запустите оболочку HBase:

    ```bash
    hbase shell
    ```

3. Используйте команду ниже, чтобы вручную распределить нагрузку между региональными серверами:

    ```bash
    balancer
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Автоматическое масштабирование кластеров Azure HDInsight](hdinsight-autoscale-clusters.md)
* [Введение в Azure HDInsight](hadoop/apache-hadoop-introduction.md)
