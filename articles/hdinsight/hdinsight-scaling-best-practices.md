---
title: Масштабирование размеров кластера в Azure HDInsight
description: Гибкое масштабирование кластера Apache Hadoop в соответствии с рабочей нагрузкой в Azure HDInsight
author: ashishthaps
ms.author: ashish
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 06/10/2019
ms.openlocfilehash: aabcf7ac6c7bf14264178831bb3e4f6670d29984
ms.sourcegitcommit: dd69b3cda2d722b7aecce5b9bd3eb9b7fbf9dc0a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/12/2019
ms.locfileid: "70960920"
---
# <a name="scale-azure-hdinsight-clusters"></a>Масштабирование кластеров Azure HDInsight

HDInsight обеспечивает гибкость, предоставляя возможность увеличивать и уменьшать масштаб определенного количества рабочих узлов в кластерах. Эта эластичность позволяет сжимать кластер после часов или выходных дней и увеличивать его во время пиковых бизнес-требований.

Если имеется периодическая Пакетная обработка, кластер HDInsight может быть увеличен до этой операции несколько минут, чтобы кластер имел достаточный объем памяти и ЦП.  Позже после обработки, когда кластер HDInsight не требует интенсивного использования, можно уменьшить его масштаб для меньшего количества рабочих узлов.

Вы можете масштабировать кластер вручную с помощью одного из описанных ниже методов или использовать параметры [автомасштабирования](hdinsight-autoscale-clusters.md) для автоматического увеличения и уменьшения масштаба в ответ на ЦП, память и другие метрики.

> [!NOTE]  
> Поддерживаются только кластеры HDInsight версии 3.1.3 или более поздней. Если вы не знаете версию кластера, см. страницу «Свойства».

## <a name="utilities-to-scale-clusters"></a>Служебные программы для масштабирования кластеров

Корпорация Майкрософт предоставляет следующие служебные программы для масштабирования кластеров:

|Программой | Описание|
|---|---|
|[PowerShell AZ](https://docs.microsoft.com/powershell/azure)|[Set-аздинсигхтклустерсизе](https://docs.microsoft.com/powershell/module/az.hdinsight/set-azhdinsightclustersize) -имя_кластера \<имя кластера >-таржетинстанцекаунт \<newSize >|
|[AzureRM PowerShell](https://docs.microsoft.com/powershell/azure/azurerm) |[Set-азурермхдинсигхтклустерсизе](https://docs.microsoft.com/powershell/module/azurerm.hdinsight/set-azurermhdinsightclustersize) -имя_кластера \<имя кластера >-таржетинстанцекаунт \<newSize >|
|[Интерфейс командной строки Azure](https://docs.microsoft.com/cli/azure/?view=azure-cli-latest)| [AZ hdinsight изменение размера](https://docs.microsoft.com/cli/azure/hdinsight?view=azure-cli-latest#az-hdinsight-resize) -- \<группа ресурсов Группа ресурсов >--Name \<имя кластера >--target-instance-Count \<newSize >|
|[Интерфейс командной строки Azure](hdinsight-administer-use-command-line.md)|размер \<кластера Azure hdinsight имя_кластера > \<число целевых экземпляров > |
|[портал Azure](https://portal.azure.com)|Откройте панель кластера HDInsight, выберите **Размер кластера** в меню слева, затем на панели размер кластера введите число рабочих узлов и нажмите кнопку Сохранить.|  

![Изменить масштаб кластера](./media/hdinsight-scaling-best-practices/scale-cluster-blade1.png)

С помощью любого из этих методов можно увеличивать или уменьшать масштаб кластера HDInsight за считанные минуты.

> [!IMPORTANT]  
> * Классический интерфейс командной строки Aure является устаревшим и должен использоваться только с классической моделью развертывания. Для всех остальных развертываний используйте [Azure CLI](https://docs.microsoft.com/cli/azure/?view=azure-cli-latest).  
> * Модуль PowerShell AzureRM является устаревшим.  При возможности используйте [модуль AZ](https://docs.microsoft.com/powershell/azure/new-azureps-module-az?view=azps-1.4.0) .

## <a name="impact-of-scaling-operations"></a>Влияние операций масштабирования

При **добавлении** узлов в кластер HDInsight (увеличения) все ожидающие или выполняющиеся задания не затрагиваются. Во время масштабирования можно безопасно передать новые задания. Если операция масштабирования по какой-либо причине завершается сбоем, то ошибка будет обработана, чтобы оставить кластер в функциональном состоянии.

Если **Удалить** узлы (уменьшить масштаб), все ожидающие или выполняющиеся задания завершатся ошибкой по завершении операции масштабирования. Эта ошибка вызвана тем, что некоторые службы перезапускаются во время процесса масштабирования. Кроме того, существует риск, что кластер может оставаться в безопасном режиме во время операции масштабирования вручную.

Ниже представлены возможности, связанные с изменением количества узлов данных в кластере каждого типа, поддерживаемого в HDInsight:

* Apache Hadoop

    Вы можете легко увеличить количество рабочих узлов в работающем кластере Hadoop. Это не помешает обработке заданий в состоянии ожидания и выполнения. В ходе выполнения операции можно также отправлять новые задания. Сбои операции масштабирования обрабатываются корректно, поэтому кластер всегда пребывает в функциональном состоянии.

    Если уменьшить масштаб кластера Hadoop, сократив количество узлов данных, некоторые службы в нем будут перезапущены. Это приведет к сбою всех выполняющихся и ожидающих заданий при завершении операции масштабирования. Однако после завершения операции вы можете повторно отправить задания.

* Apache HBase

    Вы можете с легкостью добавлять и удалять узлы данных в работающем кластере HBase. Балансировка региональных серверов выполняется автоматически в течение нескольких минут после завершения операции масштабирования. Но их также можно сбалансировать вручную, выполнив вход в головной узел кластера и выполнив следующие команды в окне командной строки:

    ```bash
    pushd %HBASE_HOME%\bin
    hbase shell
    balancer
    ```

    Дополнительные сведения об использовании оболочки HBase см. в статье [Начало работы с примером Apache HBase в HDInsight](hbase/apache-hbase-tutorial-get-started-linux.md).

* Apache Storm

    Вы можете с легкостью добавлять и удалять узлы данных в работающем кластере Storm. Но после успешного завершения операции масштабирования потребуется повторная балансировка топологии.

    Повторную балансировку можно выполнить двумя способами:

  * с помощью веб-интерфейса Storm;
  * с помощью программы командной строки.

    Дополнительные сведения см. в [документации по Apache Storm](https://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html).

    В кластере HDInsight доступен веб-интерфейс Storm.

    ![HDInsight, Storm, масштабирование, перераспределение](./media/hdinsight-scaling-best-practices/hdinsight-portal-scale-cluster-storm-rebalance.png)

    Ниже приведен пример команды CLI для повторной балансировки топологии Storm:

    ```cli
    ## Reconfigure the topology "mytopology" to use 5 worker processes,
    ## the spout "blue-spout" to use 3 executors, and
    ## the bolt "yellow-bolt" to use 10 executors
    $ storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10
    ```

## <a name="how-to-safely-scale-down-a-cluster"></a>Безопасное масштабирование кластера

### <a name="scale-down-a-cluster-with-running-jobs"></a>Уменьшение масштаба кластера с выполняющимися заданиями

Чтобы избежать сбоя выполняющихся заданий во время операции уменьшения масштаба, можно попробовать выполнить три действия:

1. Дождитесь завершения заданий, прежде чем масштабировать кластер.
1. Завершите задания вручную.
1. Повторно отправьте задания после завершения операции масштабирования.

Чтобы просмотреть список ожидающих и выполняющихся заданий, можно использовать **Пользовательский интерфейс YARN диспетчер ресурсов**, выполнив следующие действия.

1. В [портал Azure](https://portal.azure.com/)выберите свой кластер.  Инструкции см. в разделе [Отображение кластеров](./hdinsight-administer-use-portal-linux.md#showClusters). Кластер открывается на новой странице портала.
2. В главном представлении перейдите к **панели мониторинга** > кластера**Ambari Домашняя страница**. Введите учетные данные кластера.
3. В пользовательском интерфейсе Ambari выберите **YARN** в списке служб в меню слева.  
4. На странице YARN выберите **быстрые ссылки** и наведите указатель мыши на активный головной узел, а затем выберите элемент **Пользовательский интерфейс ResourceManager**.

    ![Пользовательский интерфейс ResourceManager](./media/hdinsight-scaling-best-practices/resource-manager-ui1.png)

Прямой доступ к пользовательскому интерфейсу ResourceManager можно получить, щелкнув ссылку `https://<HDInsightClusterName>.azurehdinsight.net/yarnui/hn/cluster`.

Вы увидите список заданий и их текущее состояние. На снимке экрана в настоящее время выполняется одно задание:

![Приложения пользовательского интерфейса ResourceManager](./media/hdinsight-scaling-best-practices/resourcemanager-ui-applications.png)

Чтобы вручную завершить работу запущенного приложения, из оболочки SSH выполните команду ниже:

```bash
yarn application -kill <application_id>
```

Пример:

```bash
yarn application -kill "application_1499348398273_0003"
```

### <a name="getting-stuck-in-safe-mode"></a>Получение залипания в защищенном режиме

При уменьшении масштаба кластера HDInsight использует интерфейсы управления Apache Ambari, чтобы сначала списать дополнительные рабочие узлы, которые реплицируют их блоки HDFS на другие сетевые рабочие узлы. После этого HDInsight будет безопасно масштабировать кластер. HDFS переходит в защищенный режим во время операции масштабирования и должен быть получен после завершения масштабирования. Однако в некоторых случаях HDFS зависает в защищенном режиме во время операции масштабирования из-за блокирования файла при репликации.

По умолчанию HDFS настроен с `dfs.replication` параметром 3, который определяет, сколько копий каждого блока файлов доступно. Каждая копия блока файла хранится на другом узле кластера.

Когда HDFS обнаруживает, что ожидаемое число блочных копий недоступно, HDFS переходит в защищенный режим, а Ambari создает предупреждения. Если HDFS переходит в защищенный режим для операции масштабирования, но не может выйти из безопасного режима из-за того, что для репликации не обнаружено необходимое число узлов, кластер может зависнуть в защищенном режиме.

### <a name="example-errors-when-safe-mode-is-turned-on"></a>Примеры ошибок, когда включен безопасный режим

```
org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /tmp/hive/hive/819c215c-6d87-4311-97c8-4f0b9d2adcf0. Name node is in safe mode.
```

```
org.apache.http.conn.HttpHostConnectException: Connect to hn0-clustername.servername.internal.cloudapp.net:10001 [hn0-clustername.servername. internal.cloudapp.net/1.1.1.1] failed: Connection refused
```

Вы можете изучить журналы узла имени в папке `/var/log/hadoop/hdfs/` примерно в то же время, когда было выполнено масштабирование кластера, чтобы проследить, когда был активирован безопасный режим. Файлам журнала присвоено имя `Hadoop-hdfs-namenode-hn0-clustername.*`.

Основной причиной ошибок выше является зависимость Hive от временных файлов в HDFS во время выполнения запросов. Когда HDFS переходит в безопасный режим, Hive не может выполнять запросы, так как не удается произвести запись в HDFS. Временные файлы в HDFS расположены на локальном диске, подключенном к виртуальным машинам с отдельным рабочим узлом, и реплицируются на другие рабочие узлы с минимальным количеством реплик — три.

### <a name="how-to-prevent-hdinsight-from-getting-stuck-in-safe-mode"></a>Как предотвратить зависание HDInsight в защищенном режиме

Есть несколько способов предотвратить зависание HDInsight в безопасном режиме.

* Остановите все задания Hive перед уменьшением масштаба HDInsight. Кроме того, можно запланировать операцию уменьшения масштаба, чтобы избежать конфликта с запущенными заданиями Hive.
* Вручную очистите пустые файлы в каталоге `tmp` Hive в HDFS, а затем приступите к уменьшению масштаба.
* Выполните уменьшение масштаба HDInsight как минимум до трех рабочих узлов. Старайтесь избежать масштабирования до одного рабочего узла.
* При необходимости выполните команду, чтобы отключить безопасный режим.

В разделах ниже описываются эти параметры.

#### <a name="stop-all-hive-jobs"></a>Остановка всех заданий Hive

Остановите все задания Hive перед уменьшением масштаба до одного рабочего узла. Если запланирована рабочая нагрузка, выполните уменьшение масштаба после завершения работы Hive.

Остановка заданий Hive перед масштабированием помогает максимально снизить количество временных файлов в папке TMP (если они есть).

#### <a name="manually-clean-up-hives-scratch-files"></a>Очистка пустых файлов Hive вручную

Если при работе Hive остались временные файлы, их можно вручную очистить, а затем выполнить уменьшение масштаба, чтобы избежать активации безопасного режима.

1. Проверьте, какое расположение используется для временных файлов Hive, просмотрев `hive.exec.scratchdir` свойство конфигурации. Этот параметр задается `/etc/hive/conf/hive-site.xml`в:

    ```xml
    <property>
        <name>hive.exec.scratchdir</name>
        <value>hdfs://mycluster/tmp/hive</value>
    </property>
    ```

1. Остановите службы Hive и убедитесь, что выполнены все задания и запросы.
2. Список содержимого вспомогательного каталога, найденного выше, `hdfs://mycluster/tmp/hive/` чтобы узнать, содержит ли он какие либо файлы:

    ```bash
    hadoop fs -ls -R hdfs://mycluster/tmp/hive/hive
    ```

    Ниже приведен пример выходных данных при наличии файлов:

    ```output
    sshuser@hn0-scalin:~$ hadoop fs -ls -R hdfs://mycluster/tmp/hive/hive
    drwx------   - hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c
    drwx------   - hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/_tmp_space.db
    -rw-r--r--   3 hive hdfs         27 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/inuse.info
    -rw-r--r--   3 hive hdfs          0 2017-07-06 13:40 hdfs://mycluster/tmp/hive/hive/4f3f4253-e6d0-42ac-88bc-90f0ea03602c/inuse.lck
    drwx------   - hive hdfs          0 2017-07-06 20:30 hdfs://mycluster/tmp/hive/hive/c108f1c2-453e-400f-ac3e-e3a9b0d22699
    -rw-r--r--   3 hive hdfs         26 2017-07-06 20:30 hdfs://mycluster/tmp/hive/hive/c108f1c2-453e-400f-ac3e-e3a9b0d22699/inuse.info
    ```

3. Если эти файлы обработаны Hive, их можно удалить. Просмотрите страницу пользовательского интерфейса Yarn ResourceManager, чтобы убедиться в отсутствии любых запущенных запросов Hive.

    Пример командной строки для удаления файлов из HDFS:

    ```bash
    hadoop fs -rm -r -skipTrash hdfs://mycluster/tmp/hive/
    ```

#### <a name="scale-hdinsight-to-three-or-more-worker-nodes"></a>Масштабирование HDInsight до трех или более рабочих узлов

Если кластеры постоянно задерживаются в защищенном режиме при уменьшении масштаба до трех рабочих узлов, и предыдущие шаги не будут работать, вы можете избежать того, чтобы кластер перейдет в режим безопасного режима, сохранив по крайней мере три рабочих узла.

Размещение трех рабочих узлов является более дорогостоящим, чем масштабирование до одного рабочего узла, но не позволит кластеру зависнуть в защищенном режиме.

#### <a name="run-the-command-to-leave-safe-mode"></a>Выполнение команды для отключения безопасного режима

Последний вариант — выполнить команду "выйти из безопасного режима". Если известно, что причина, по которой HDFS входит в режим безопасного режима, заключается в наличии файла Hive в разделе-Replication, можно выполнить следующую команду, чтобы выйти из безопасного режима:

```bash
hdfs dfsadmin -D 'fs.default.name=hdfs://mycluster/' -safemode leave
```

### <a name="scale-down-an-apache-hbase-cluster"></a>Уменьшение масштаба кластера Apache HBase

Серверы регионов автоматически распределяются в течение нескольких минут после завершения операции масштабирования. Чтобы вручную сбалансировать серверы регионов, выполните следующие действия.

1. Подключитесь к кластеру HDInsight по протоколу SSH. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

2. Запустите оболочку HBase:

    ```bash
    hbase shell
    ```

3. Используйте команду ниже, чтобы вручную распределить нагрузку между региональными серверами:

    ```bash
    balancer
    ```

## <a name="next-steps"></a>Следующие шаги

* [Автоматическое масштабирование кластеров Azure HDInsight](hdinsight-autoscale-clusters.md)
* [Введение в Azure HDInsight](hadoop/apache-hadoop-introduction.md)
