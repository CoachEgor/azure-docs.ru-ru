---
title: 'Хранилище: Миграция локальных Apache Hadoop в Azure HDInsight'
description: Ознакомьтесь с рекомендациями по использованию хранилища в рамках миграции локальных кластеров Hadoop в Azure HDInsight.
author: hrasheed-msft
ms.reviewer: ashishth
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 09/04/2019
ms.author: hrasheed
ms.openlocfilehash: b22c3c7e7dbbf7a93fff10ded1fbb7bef8fc5900
ms.sourcegitcommit: c22327552d62f88aeaa321189f9b9a631525027c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/04/2019
ms.locfileid: "73494962"
---
# <a name="migrate-on-premises-apache-hadoop-clusters-to-azure-hdinsight"></a>Миграция локальных Apache Hadoop кластеров в Azure HDInsight

В этой статье представлены рекомендации по хранению данных в системах Azure HDInsight. В этом цикле статей приведены рекомендации, применимые при перемещении локальных систем Apache Hadoop в Azure HDInsight.

## <a name="choose-right-storage-system-for-hdinsight-clusters"></a>Выбор правильной системы хранения для кластеров HDInsight

Структура каталогов локальной файловой системы Apache Hadoop (HDFS) может быть воссоздана в службе хранилища Azure или в Azure Data Lake Storage. Затем можно безопасно и без потери пользовательских данных удалять используемые для расчетов кластеры HDInsight. Обе службы могут использоваться и как файловая система по умолчанию, и как дополнительная файловая система для кластера HDInsight. Кластер HDInsight и учетная запись хранения должны размещаться в одном регионе.

### <a name="azure-storage"></a>Хранилище Azure

Кластеры HDInsight могут использовать контейнер больших двоичных объектов в службе хранилища Azure как файловую систему по умолчанию или как дополнительную файловую систему. Учетная запись хранения уровня "Стандартный" поддерживается для использования с кластерами HDInsight. Уровень Premier не поддерживается. Стандартный контейнер больших двоичных объектов хранит сведения о кластере, включая журналы заданий. Совместное использование одного контейнера больших двоичных объектов в качестве файловой системы по умолчанию для нескольких кластеров не поддерживается.

Определенные на этапе создания учетные записи хранения и соответствующие ключи хранятся в файле `%HADOOP_HOME%/conf/core-site.xml` на узлах кластера. Их также можно получить в разделе Custom core site (Пользовательский основной сайт) в конфигурации HDFS в интерфейсе Ambari. Ключ учетной записи хранения зашифрован по умолчанию. Перед тем как передать ключи управляющим программам Hadoop, используется собственный сценарий расшифровки. Задания, включая Hive, MapReduce, потоковую передачу Hadoop и Pig, могут переносить описание учетных записей хранения и метаданные вместе с ними.

Доступна функция георепликации службы хранилища Azure. Хотя это обеспечивает возможность географического восстановления и избыточность данных, переход в расположение геореплицированных данных при отработке отказа заметно сказывается на производительности, что может привести к дополнительным затратам. Поэтому мы рекомендуем взвешенно подходить к выбору георепликации и выбирать ее только в том случае, если ценность данных окупит дополнительные затраты.

Для доступа к данным, хранящимся в службе хранилища Azure, может использоваться один из следующих форматов:

|Формат доступа к данным |Description (Описание) |
|---|---|
|`wasb:///`|хранилище по умолчанию без шифрования обмена данными.|
|`wasbs:///`|Хранилище по умолчанию с шифрованием обмена данными.|
|`wasb://<container-name>@<account-name>.blob.core.windows.net/`|при взаимодействии с учетной записью хранения, кроме используемой по умолчанию. |


Дополнительные сведения о текущих ограничениях в учетных записях хранения Azure см. в статье [Целевые показатели масштабируемости и производительности службы хранилища Azure](../../storage/common/storage-scalability-targets.md). Если предельно достижимых показателей масштабируемости для одной учетной записи хранения недостаточно для работы приложения, то при разработке такого приложения можно настроить его на использование нескольких таких учетных записей и распределить объекты данных между ними.

[Аналитика Службы хранилища](../../storage/storage-analytics.md) предоставляет метрики для всех служб хранения, а на портале Azure можно настроить сбор метрик, которые будут визуализироваться с помощью диаграмм. Можно создать оповещения, чтобы получать уведомления о достижении пороговых значений для метрик ресурсов хранилища.

Служба хранилища Azure теперь предоставляет возможность [обратимого удаления больших двоичных объектов](../../storage/blobs/storage-blob-soft-delete.md). Это упрощает восстановление данных, если они ошибочно изменены или удалены приложением или другим пользователем учетной записи хранения.

Можно создавать [моментальные снимки больших двоичных объектов](https://docs.microsoft.com/rest/api/storageservices/creating-a-snapshot-of-a-blob). Моментальный снимок — это версия большого двоичного объекта только для чтения, сделанная в определенный момент времени, которая обеспечивает способ резервного копирования этого объекта. После создания моментального снимка его можно читать, копировать или удалять, но нельзя изменять.

> [!Note]
> Для более старых версий локальных дистрибутивов Hadoop, у которых нет сертификата wasbs, этот сертификат необходимо импортировать в доверенное хранилище Java.

Для импорта сертификатов в доверенное хранилище Java могут использоваться следующие методы.

Скачайте сертификат SSL большого двоичного объекта Azure в файл:

```bash
echo -n | openssl s_client -connect <storage-account>.blob.core.windows.net:443 | sed -ne '/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p' > Azure_Storage.cer
```

Импортируйте указанный выше файл в доверенное хранилище Java на всех узлах:

```bash
keytool -import -trustcacerts -keystore /path/to/jre/lib/security/cacerts -storepass changeit -noprompt -alias blobtrust -file Azure_Storage.cer
```

Убедитесь, что добавленный сертификат находится в доверенном хранилище:

```bash
keytool -list -v -keystore /path/to/jre/lib/security/cacerts
```

Дополнительные сведения см. в следующих статьях:

- [Использование службы хранилища Azure с кластерами Azure HDInsight](../hdinsight-hadoop-use-blob-storage.md)
- [Целевые показатели масштабируемости и производительности хранилища Azure](../../storage/common/storage-scalability-targets.md)
- [Производительность хранилища Microsoft Azure и контрольный список масштабируемости](../../storage/common/storage-performance-checklist.md)
- [Наблюдение, диагностика и устранение неисправностей хранилища Microsoft Azure](../../storage/common/storage-monitoring-diagnosing-troubleshooting.md)
- [Мониторинг учетной записи хранения на портале Azure](../../storage/common/storage-monitor-storage-account.md)

### <a name="azure-data-lake-storage-gen1"></a>Хранилище Azure Data Lake Storage 1-го поколения

Azure Data Lake Storage реализует модель управления доступом HDFS и POSIX. Она обеспечивает первоклассную интеграцию с AAD для точного контроля доступа. Нет ограничений на размер данных, которые можно хранить, или на способность запускать аналитику с массовым параллелизмом.

Дополнительные сведения см. в следующих статьях:

- [Создание кластеров HDInsight, использующих Azure Data Lake Storage 1-го поколения, с помощью портала Azure](../../data-lake-store/data-lake-store-hdinsight-hadoop-use-portal.md)
- [Использование Data Lake Store с кластерами Azure HDInsight](../hdinsight-hadoop-use-data-lake-store.md)

### <a name="azure-data-lake-storage-gen2"></a>Azure Data Lake Storage 2-го поколения

Azure Data Lake Storage 2-го поколения является последним предложением хранилища. Оно объединяет основные возможности Azure Data Lake Storage первого поколения с конечной точкой файловой системы, совместимой с Hadoop, непосредственно интегрированной в хранилище BLOB-объектов Azure. Это усовершенствование сочетает в себе преимущества масштабирования и экономии хранения объектов с высокой надежностью и производительностью, которые обычно связаны только с локальными файловыми системами.

ADLS 2-го поколения создано на основе  [хранилища BLOB-объектов Azure](../../storage/blobs/storage-blobs-introduction.md) и позволяет работать с данными с использованием как файловой системы, так и парадигм хранения объектов. Это хранилище предоставляет функции  [Azure Data Lake Storage 1-го поколения](../../data-lake-store/index.md), например семантика файловой системы, защита на уровне файлов и масштабирование, а также экономичность, многоуровневость, возможности высокой доступности и аварийного восстановления, большая экосистема средств и пакетов SDK  [хранилища BLOB-объектов Azure](../../storage/blobs/storage-blobs-introduction.md). В Data Lake Storage Gen2 сохранились все качества хранилища объектов, а также появились возможности работы с файловой системой, что позволило оптимизировать рабочие нагрузки аналитики.

Основополагающая функция Data Lake Storage 2-го поколения — это добавление  [иерархических пространств имен](../../storage/data-lake-storage/namespace.md)  в службу хранилища BLOB-объектов, что позволяет упорядочивать объекты и файлы в иерархии каталогов, обеспечивая тем самым удобный доступ к данным. Иерархическая структура позволяет таким операциям, как переименование или удаление каталога, быть отдельными атомарными операциями метаданных в каталоге, а не перечислением и обработкой всех объектов, совместно использующих префикс имени каталога.

Раньше облачная аналитика влияла на производительность, возможности управления и безопасность. Далее приведены основные функции ADLS 2-го поколения.

- **Доступ, совместимый с Hadoop.** Хранилище Azure Data Lake Storage 2-го поколения позволяет получать доступ к данным и управлять ими так же, как и в  [распределенной файловой системе Hadoop (HDFS)](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html). Новый [драйвер ABFS](../../storage/data-lake-storage/abfs-driver.md) доступен во всех средах Apache Hadoop, которые включены в [Azure HDInsight](../index.yml). Этот драйвер позволяет получать доступ к данным в ADLS 2-го поколения.

- **Надмножество разрешений POSIX**. Модель безопасности Data Lake 2-го поколения полностью поддерживает разрешения ACL и POSIX, а также некоторую дополнительную детализацию, относящуюся к Data Lake Storage 2-го поколения. Параметры могут быть настроены через средства администрирования или с помощью платформ, таких как Hive и Spark.

- **Экономичность.** Data Lake Storage Gen2 отличается низкой стоимостью приобретения емкости хранилища и выполнения транзакций. За счет таких встроенных функций, как  [Жизненный цикл хранилища BLOB-объектов Azure](../../storage/common/storage-lifecycle-management-concepts.md), в ходе жизненного цикла данных тарифные ставки максимально снижаются.

- **Поддержка средств, платформ и приложений хранилища BLOB-объектов.** Хранилище Data Lake Storage Gen2 поддерживает большое количество средств, платформ и приложений хранилища BLOB-объектов.

- **Оптимизированный драйвер**. Драйвер файловой системы больших двоичных объектов Azure (ABFS) [оптимизирован специально](../../storage/data-lake-storage/abfs-driver.md) для анализа больших данных. Соответствующие интерфейсы REST API подключены через конечную точку dfs — dfs.core.windows.net.

Для доступа к данным, хранящимся в ADLS 2-го поколения, может использоваться один из следующих форматов:
- `abfs:///`: доступ к хранилищу Data Lake Storage, используемому по умолчанию для кластера.
- `abfs://file_system@account_name.dfs.core.windows.net`: используется при взаимодействии с Data Lake Storage, отличным от используемого по умолчанию.

Дополнительные сведения см. в следующих статьях:

- [Общие сведения о хранилище Azure Data Lake Storage Gen2 (предварительная версия)](../../storage/data-lake-storage/introduction.md)
- [Драйвер файловой системы больших двоичных объектов Azure (ABFS): выделенный драйвер хранилища Azure для Hadoop](../../storage/data-lake-storage/abfs-driver.md)
- [Использование Azure Data Lake Storage Gen2 с кластерами Azure HDInsight](../hdinsight-hadoop-use-data-lake-storage-gen2.md)

## <a name="secure-azure-storage-keys-within-on-premises-hadoop-cluster-configuration"></a>Обеспечение безопасности ключей хранилища Azure в локальной конфигурации кластера Hadoop

Ключи к хранилищу данных Azure, которые добавляются в файлы конфигурации Hadoop, устанавливают соединение между локальной системой HDFS и хранилищем BLOB-объектов Azure. Эти ключи можно защитить, зашифровав их с помощью инфраструктуры поставщика учетных данных Hadoop. Зашифрованные ключи можно надежно хранить и безопасно получать к ним доступ.

**Чтобы подготовить учетные данные:**

```bash
hadoop credential create fs.azure.account.key.account.blob.core.windows.net -value <storage key> -provider jceks://hdfs@headnode.xx.internal.cloudapp.net/path/to/jceks/file
```

**Чтобы добавить указанный выше путь поставщика в файл core-site.xml или в конфигурацию Ambari под настраиваемым основным сайтом:**

```xml
<property>
    <name>hadoop.security.credential.provider.path</name>
        <value>
        jceks://hdfs@headnode.xx.internal.cloudapp.net/path/to/jceks
        </value>
    <description>Path to interrogate for protected credentials.</description>
</property>
```

> [!Note]
> Свойство пути поставщика также можно добавить в командную строку distcp вместо сохранения ключа на уровне кластера в файле core-site.xml следующим образом:

```bash
hadoop distcp -D hadoop.security.credential.provider.path=jceks://hdfs@headnode.xx.internal.cloudapp.net/path/to/jceks /user/user1/ wasb:<//yourcontainer@youraccount.blob.core.windows.net/>user1
```

## <a name="restrict-azure-storage-data-access-using-sas"></a>Ограничение доступа к данным службы хранилища Azure с помощью SAS

HDInsight по умолчанию имеет полный доступ к данным в учетных записях хранения Azure, связанных с кластером. Подписанные URL-адреса (SAS) в контейнере больших двоичных объектов могут использоваться для ограничения доступа к данным, например предоставления пользователям доступа только для чтения.

### <a name="using-the-sas-token-created-with-python"></a>Использование маркера SAS, созданного с помощью Python

1. Откройте файл [SASToken.py](https://github.com/Azure-Samples/hdinsight-dotnet-python-azure-storage-shared-access-signature/blob/master/Python/SASToken.py) и измените следующие значения:

    |Свойство маркера|Description (Описание)|
    |---|---|
    |policy_name|Имя, которое будет использоваться для создаваемой хранимой политики.|
    |storage_account_name|Имя учетной записи хранения.|
    |storage_account_key|Ключ для учетной записи хранения.|
    |storage_container_name|Контейнер в учетной записи хранения, доступ к которому необходимо ограничить.|
    |example_file_path|Путь к файлу, который будет отправляться в контейнер.|

2. Файл SASToken.py поставляется с разрешениями `ContainerPermissions.READ + ContainerPermissions.LIST` и может быть скорректирован с учетом варианта использования.

3. Выполните сценарий следующим образом: `python SASToken.py`

4. После выполнения сценария отобразится маркер SAS следующего вида: `sr=c&si=policyname&sig=dOAi8CXuz5Fm15EjRUu5dHlOzYNtcK3Afp1xqxniEps%3D&sv=2014-02-14`

5. Чтобы ограничить доступ к контейнеру с помощью подписанного URL-адреса, добавьте пользовательскую запись в свойстве Add (Добавить) расширенной пользовательской конфигурации основного сайта Ambari HDFS для кластера.

6. В полях **Key** (Ключ) и **Value** (Значение) укажите следующие значения.

    **Ключ**: `fs.azure.sas.YOURCONTAINER.YOURACCOUNT.blob.core.windows.net` **Значение**: ключ SAS, возвращаемый приложением Python из указанного выше шага 4.

7. Нажмите кнопку **Add** (Добавить), чтобы сохранить этот ключ и значение, а затем кнопку **Save** (Сохранить), чтобы сохранить изменения в конфигурации. При появлении запроса добавьте описание внесенного изменения (например, "Добавление доступа к хранилищу SAS") и нажмите кнопку **Сохранить**.

8. В веб-ИНТЕРФЕЙСе Ambari выберите HDFS из списка слева, а затем в раскрывающемся списке действия службы справа выберите **перезапустить все затронутые** . Когда появится запрос, выберите **Conform Restart All** (Подтвердить перезапуск всех).

9. Повторите эту процедуру для MapReduce2 и YARN.

Существует три важных аспекта, которые нужно помнить при использовании маркеров SAS в Azure.

1. Если маркеры SAS создаются с разрешениями READ + LIST, пользователи, которые обращаются к контейнеру больших двоичных объектов, используя этот маркер SAS, не смогут записывать и удалять данные. Пользователи, которые обращаются к контейнеру больших двоичных объектов, используя этот маркер SAS, и пытаются выполнить операцию записи или удаления, получат сообщение типа `"This request is not authorized to perform this operation"`.

2. Если маркеры SAS создаются с разрешениями `READ + LIST + WRITE` (для ограничения только `DELETE`), команды, подобные `hadoop fs -put`, сначала записывают в файл `\_COPYING\_`, а затем пытаются переименовать файл. Эта операция HDFS сопоставляется с `copy+delete` для WASB. Так как разрешение `DELETE` не было предоставлено, запрос put завершится сбоем. Операция `\_COPYING\_` — это функция Hadoop, предназначенная для обеспечения некоторого контроля параллелизма. В настоящее время нет никакого способа ограничить только операцию DELETE, не затрагивая также операции WRITE.

3. К сожалению, поставщик учетных данных Hadoop и поставщик ключей расшифровки (ShellDecryptionKeyProvider) в настоящее время не работают с маркерами SAS и поэтому не могут быть защищены от видимости.

Дополнительные сведения см. в статье [Использование подписанных URL-адресов хранилища Azure для ограничения доступа к данным в HDInsight](../hdinsight-storage-sharedaccesssignature-permissions.md).

## <a name="use-data-encryption-and-replication"></a>Использование шифрования и репликации данных

Все данные, записываемые в службу хранилища Azure, автоматически шифруются с помощью  [шифрования службы хранилища (SSE)](../../storage/common/storage-service-encryption.md). Данные в учетной записи хранения Azure всегда реплицируются для обеспечения высокой доступности. При создании учетной записи хранения можно выбрать один из следующих вариантов репликации.

- [Локально избыточное хранилище (LRS)](../../storage/common/storage-redundancy-lrs.md)
- [Хранилище, избыточное между зонами (ZRS)](../../storage/common/storage-redundancy-zrs.md)
- [Геоизбыточное хранилище (GRS)](../../storage/common/storage-redundancy-grs.md)
- [Геоизбыточное хранилище с доступом для чтения (RA-GRS)](../../storage/common/storage-redundancy-grs.md#read-access-geo-redundant-storage)

Azure Data Lake Storage предоставляет локально избыточное хранилище (LRS), но необходимо также скопировать критически важные данные в другую учетную запись Data Lake Storage в другом регионе с частотой, соответствующей потребностям плана аварийного восстановления. Существует множество методов копирования данных, включая [ADLCopy](../../data-lake-store/data-lake-store-copy-data-azure-storage-blob.md), DistCp, [Azure PowerShell](../../data-lake-store/data-lake-store-get-started-powershell.md)или [фабрику данных Azure](../../data-factory/connector-azure-data-lake-store.md). Также рекомендуется применять политики доступа для учетной записи Data Lake Storage, чтобы предотвратить случайное удаление.

Дополнительные сведения см. в следующих статьях:

- [Репликация службы хранилища Azure](../../storage/common/storage-redundancy.md)
- [Руководство по аварийному восстановлению данных в Azure Data Lake Storage 1-го поколения](../../data-lake-store/data-lake-store-disaster-recovery-guidance.md)

## <a name="attach-additional-azure-storage-accounts-to-cluster"></a>Подключение дополнительных учетных записей хранения Azure к кластеру

При создании кластера HDInsight в качестве файловой системы по умолчанию выбирается учетная запись службы хранилища Azure или учетная запись Azure Data Lake Storage. Помимо этой учетной записи хранения по умолчанию в процессе создания или после создания кластера можно добавить дополнительные учетные записи хранения из той же или других подписок Azure.

Дополнительную учетную запись хранения можно добавить одним из следующих способов:
- Добавить имя и ключ учетной записи хранения для основного сайта в расширенной пользовательской конфигурации Ambari HDFS и перезапустить службы.
- Использовать [действие сценария](../hdinsight-hadoop-add-storage.md), передав имя и ключ учетной записи хранения.

> [!Note]
> В допустимых случаях ограничения в хранилище Azure можно увеличить с помощью запроса в  [службу поддержки Azure](https://azure.microsoft.com/support/faq/).

Дополнительные сведения см. в следующих статьях:
- [Добавление дополнительных учетных записей хранения в HDInsight](../hdinsight-hadoop-add-storage.md)

## <a name="next-steps"></a>Дальнейшие действия

Прочитайте следующую статью в этом цикле:

- [Migrate on-premises Apache Hadoop clusters to Azure HDInsight - data migration best practices](apache-hadoop-on-premises-migration-best-practices-data-migration.md) (Рекомендации по переносу данных для миграции локальных кластеров Hadoop в Azure HDInsight)
