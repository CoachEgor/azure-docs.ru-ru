---
title: Мигрируйте Azure HDInsight 3.6 Apache Storm в HDInsight 4.0 Apache Spark
description: Различия и миграционный поток для миграции рабочих нагрузок Apache Storm в потоковое воспроизведение или структурированную потоковую передачу Spark.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 01/16/2019
ms.openlocfilehash: 916c54c3739d1164e4e9c1db67aa1f4e0dbd0c6c
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "76157796"
---
# <a name="migrate-azure-hdinsight-36-apache-storm-to-hdinsight-40-apache-spark"></a>Мигрируйте Azure HDInsight 3.6 Apache Storm в HDInsight 4.0 Apache Spark

В этом документе описывается, как мигрировать рабочие нагрузки Apache Storm на HDInsight 3.6 в HDInsight 4.0. HDInsight 4.0 не поддерживает тип кластера Apache Storm, и вам нужно будет перейти на другую платформу потоковых данных. Двумя подходящими вариантами являются потоковая передача Apache Spark и структурированная потоковая передача Spark. В этом документе описаны различия между этими платформами, а также рекомендуется рабочий процесс для миграционных рабочих нагрузок Apache Storm.

## <a name="storm-migration-paths-in-hdinsight"></a>Пути миграции штормов в HDInsight

Если вы хотите перейти от Apache Storm на HDInsight 3.6 у вас есть несколько вариантов:

* Потоковая передача на HDInsight 4.0
* Искра структурированная потоковая передача на HDInsight 4.0
* Azure Stream Analytics

В этом документе содержится руководство по переходу из Apache Storm в потоковое воспроизведение и структурированную потоковую передачу Spark.

> [!div class="mx-imgBorder"]
> ![Путь миграции шторма HDInsight](./media/migrate-storm-to-spark/storm-migration-path.png)

## <a name="comparison-between-apache-storm-and-spark-streaming-spark-structured-streaming"></a>Сравнение между Apache Storm и Spark Streaming, spark Structured Streaming

Apache Storm может обеспечить различные уровни гарантированной обработки сообщений. Например, базовое приложение Storm может гарантировать обработку по крайней мере один раз, а [Trident](https://storm.apache.org/releases/current/Trident-API-Overview.html) может гарантировать точно после обработки. Потоковая передача и структурированная потоковая передача Spark гарантируют, что любое событие ввода обрабатывается один раз, даже если происходит сбой узла. Storm имеет модель, которая обрабатывает каждое отдельное событие, и вы также можете использовать модель Micro Batch с Trident. Spark Streaming и Spark Structured Streaming обеспечивают модель обработки Micro-Batch.

|  |Storm |Потоковая передача Spark | Искра структурированная потоковая передача|
|---|---|---|---|
|**Гарантия обработки событий**|По крайней мере, один раз <br> Ровно один раз (Трайдент) |[Ровно один раз](https://spark.apache.org/docs/latest/streaming-programming-guide.html)|[Ровно один раз](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)|
|**Модель обработки**|В режиме реального времени <br> Микро-пакет (Trident) |Микро-пакет |Микро-пакет |
|**Поддержка времени событий**|[Да](https://storm.apache.org/releases/2.0.0/Windowing.html)|нет|[Да](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)|
|**Языки**|Java и т.д.|Скала, Ява, Питон|Python, R, Скала, Ява, СЗЛ|

### <a name="spark-streaming-vs-spark-structured-streaming"></a>Spark потоковое против Spark структурированной потоковой

Структура потоковой передачи Spark заменяет потоковое воспроизведение (DStreams). Структурированная потоковая передача будет по-прежнему получать усовершенствования и техническое обслуживание, в то время как DStreams будет находиться только в режиме обслуживания. **Примечание: нужны ссылки, чтобы подчеркнуть этот момент.** Структурированная потоковая передача не имеет столько функций, как DStreams для источников и раковин, которые она поддерживает из коробки, поэтому оцените свои требования, чтобы выбрать подходящий вариант обработки потока Spark.

## <a name="streaming-single-event-processing-vs-micro-batch-processing"></a>Потоковая обработка (одно событие) против обработки Micro-Batch

Storm предоставляет модель, которая обрабатывает каждое отдельное событие. Это означает, что все входящие записи будут обработаны, как только они прибудут. Приложениям потоковой передачи Spark необходимо подождать долю секунды, чтобы собрать каждый микропакет событий, прежде чем отправить пакет на обработку. В свою очередь, приложение на основе событий обрабатывает каждое событие сразу же. Задержка при потоковой передаче Spark, как правило, не превышает несколько секунд. Преимущества подхода с использованием микропакетов заключаются в более эффективной обработке данных и более простых статистических вычислениях.

> [!div class="mx-imgBorder"]
> ![потоковая и микро-пакетная обработка](./media/migrate-storm-to-spark/streaming-and-micro-batch-processing.png)

## <a name="storm-architecture-and-components"></a>Архитектура и компоненты шторма

Топологии Storm состоят из нескольких компонентов, которые расположены в виде направленного ациклического графа (DAG). На указанной ниже схеме показаны потоки данных между компонентами. Каждый компонент использует один или несколько потоков данных и может генерировать дополнительные потоки.

|Компонент |Описание |
|---|---|
|Носик|Приводит данные в топологию. Они генерируют один или несколько потоков в топологии.|
|Болт|Потребляет потоки, испускаемые из носиков или других болтов. Элементы bolt могут дополнительно генерировать потоки в топологии. Они также отвечают за запись данных во внешние службы или хранилище, например HDFS, Kafka или HBase.|

> [!div class="mx-imgBorder"]
> ![взаимодействие компонентов шторма](./media/migrate-storm-to-spark/apache-storm-components.png)

Шторм consist of following 3 daemons, которые держат действовать кластершторма.

|Управляющая программа |Описание |
|---|---|
|Nimbus;|Как и в случае с Hadoop JobTracker, он отвечает за распространение кода по всему кластеру и назначение задач машинам и мониторинг сбоев.|
|Zookeeper|Используется для координации кластеров.|
|Supervisor;|Слушает работу, назначенную его машине, и запускает и останавливает рабочие процессы на основе директив от Nimbus. Каждый рабочий процесс выполняет подмножество топологии. Логика приложения пользователя (Spouts и Bolt) работает здесь.|

> [!div class="mx-imgBorder"]
> ![nimbus, зоозащитник, и руководитель daemons](./media/migrate-storm-to-spark/nimbus-zookeeper-supervisor.png)

## <a name="spark-streaming-architecture-and-components"></a>Архитектура и компоненты потоковой передачи spark

Следующие шаги обобщают, как компоненты работают вместе в Spark Streaming (DStreams) и Spark Structured Streaming:

* При запуске потоковой передачи драйвера в исполнителе.
* Исполнитель получает поток из источника потоковых данных.
* Когда исполнитель получает потоки данных, он разбивает поток на блоки и сохраняет их в памяти.
* Блоки данных реплицируются другим исполнителям.
* Затем обработанные данные хранятся в хранилище целевых данных.

> [!div class="mx-imgBorder"]
> ![искры потокового пути к выходу](./media/migrate-storm-to-spark/spark-streaming-to-output.png)

## <a name="spark-streaming-dstream-workflow"></a>Рабочий процесс потоковой передачи искры (DStream)

По окончании каждого интервала пакетов создается новый набор RDD, содержащий все данные из этого интервала. Непрерывные наборы RDD собираются в DStream. Например, если интервал пакетов составляет одну секунду, ваш поток DStream каждую секунду выдает пакет, содержащий один набор RDD со всеми данными, полученными на протяжении этой секунды. При обработке потока DStream событие температуры появляется в одном из этих пакетов. Приложение потоковой передачи Spark обрабатывает пакеты, содержащие события, и в конечном счете работает с данными, хранящимися в каждом наборе RDD.

> [!div class="mx-imgBorder"]
> ![искры потоковой обработки пакетов](./media/migrate-storm-to-spark/spark-streaming-batches.png)

Для получения подробной информации о различных преобразованиях, доступных с spark Streaming, [см.](https://spark.apache.org/docs/latest/streaming-programming-guide.html#transformations-on-dstreams)

## <a name="spark-structured-streaming"></a>Структурированная потоковая передача Spark

Структура потоковой передачи Spark представляет собой поток данных как таблицу, которая не ограничена в глубине. Таблица продолжает расти по мере поступления новых данных. Эта таблица ввода постоянно обрабатывается длительным запросом, и результаты отправляются в таблицу вывода.

В структурированной потоковой передаче данные передаются в систему и сразу же поступают во входную таблицу. Вы можете написать запросы с помощью API кадров и наборов данных для выполнения операций в этой входной таблице.

Выход запроса дает *таблицу результатов,* которая содержит результаты вашего запроса. Можно нарисовать данные из таблицы результатов для внешнего хранилища данных, такой реляционной базы данных.

С помощью интервала триггера задается расписание для обработки данных во входной таблице. По умолчанию интервал триггера равен нулю, поэтому структурированная потоковая передача пытается обрабатывать данные по мере их поступления. На практике это означает, что как только структурированная потоковая передача завершает обработку выполнения предыдущего запроса, она запускает следующую обработку новых полученных данных. Можно настроить запуск триггера с интервалом, что позволит обрабатывать данные потоковой передачи в пакетах на основе времени.

> [!div class="mx-imgBorder"]
> ![обработка данных в структурированной потоковой передаче](./media/migrate-storm-to-spark/structured-streaming-data-processing.png)

> [!div class="mx-imgBorder"]
> ![модель программирования для структурированной потоковой передачи](./media/migrate-storm-to-spark/structured-streaming-model.png)

## <a name="general-migration-flow"></a>Общий миграционный поток

Рекомендуемый миграционный поток от Шторма к Spark предполагает следующую начальную архитектуру:

* Kafka используется в качестве источника потоковых данных
* Kafka и Storm развернуты в одной виртуальной сети
* Данные, обрабатываемые Storm, записываются в раковину данных, такую как Azure Storage или Azure Data Lake Storage Gen2.

    > [!div class="mx-imgBorder"]
    > ![диаграмма предполагаемой текущей среды](./media/migrate-storm-to-spark/presumed-current-environment.png)

Чтобы перенести приложение из Storm в один из aIS потоковой передачи Spark, сделайте следующее:

1. **Развертывание нового кластера.** Развернуть новый кластер HDInsight 4.0 Spark в той же виртуальной сети и развернуть приложение Spark Streaming или Spark Structured Streaming на нем и тщательно протестировать его.

    > [!div class="mx-imgBorder"]
    > ![развертывание новой искры в HDInsight](./media/migrate-storm-to-spark/new-spark-deployment.png)

1. **Прекратите потреблять на старом кластере Storm.** В существующем Storm прекратите употреблять данные из потокового источника данных и ждите, пока данные закончат запись в целевой раковине.

    > [!div class="mx-imgBorder"]
    > ![прекратить потребление на текущем кластере](./media/migrate-storm-to-spark/stop-consuming-current-cluster.png)

1. **Начните потреблять в новом кластере Spark.** Начало потоковой передачи данных из недавно развернутого кластера HDInsight 4.0 Spark. В настоящее время процесс берет на себя потребление от последнего смещения Кафки.

    > [!div class="mx-imgBorder"]
    > ![начать потреблять на новом кластере](./media/migrate-storm-to-spark/start-consuming-new-cluster.png)

1. **Удалите старый кластер по мере необходимости.** После того, как коммутатор будет завершен и работает должным образом, удалите старый кластер HDInsight 3.6 Storm по мере необходимости.

    > [!div class="mx-imgBorder"]
    > ![удалить старые кластеры HDInsight по мере необходимости](./media/migrate-storm-to-spark/remove-old-clusters1.png)

## <a name="next-steps"></a>Дальнейшие действия

Для получения дополнительной информации о Storm, Spark Streaming и Spark Structured Streaming см.

* [Общие сведения о потоковой передаче Apache Spark](../spark/apache-spark-streaming-overview.md)
* [Обзор структурированной потоковой передачи Apache Spark](../spark/apache-spark-structured-streaming-overview.md)