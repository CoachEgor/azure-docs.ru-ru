---
title: Порты, используемые службами Hadoop в HDInsight в Azure
description: В этой статье представлен список портов, используемых службами Apache Hadoop, работающими в Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.custom: hdinsightactive
ms.topic: conceptual
ms.date: 10/15/2019
ms.openlocfilehash: 67cafbb7934381cd4c2936d6e6dfe7fb19d70735
ms.sourcegitcommit: a9b1f7d5111cb07e3462973eb607ff1e512bc407
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/22/2020
ms.locfileid: "76314697"
---
# <a name="ports-used-by-apache-hadoop-services-on-hdinsight"></a>Порты, используемые службами Apache Hadoop в HDInsight

В этом документе представлен список портов, используемых службами Apache Hadoop, работающими в кластерах HDInsight. Кроме того, в статье содержатся сведения о портах, которые используются для подключения к кластеру с помощью протокола SSH.

## <a name="public-ports-vs-non-public-ports"></a>Общедоступные и необщедоступные порты

Кластеры HDInsight под управлением Linux предоставляют только три общедоступных порта для трафика Интернета: 22, 23 и 443. Они используются для безопасного доступа к кластеру с помощью протокола SSH и службам, предоставляемым через защищенный протокол HTTPS.

По сути, HDInsight реализуется несколькими виртуальными машинами Azure (узлами кластера), которые работают в виртуальной сети Azure. Из виртуальной сети вы можете получить доступ к портам, недоступным из Интернета. Например, подключившись к одному из головных узлов по протоколу SSH, вы можете получить прямой доступ к службам, работающим на узлах кластера.

> [!IMPORTANT]  
> Если не указать виртуальную сеть Azure с помощью параметра конфигурации для HDInsight, она будет создана автоматически. Однако вы не можете присоединить другие компьютеры (например, другие виртуальные машины Azure или компьютер разработки клиента) к этой виртуальной сети.

Чтобы присоединить дополнительные компьютеры к виртуальной сети, необходимо сначала создать виртуальную сеть, а затем указать ее при создании кластера HDInsight. Дополнительные сведения см. [в статье Планирование виртуальной сети для HDInsight](hdinsight-plan-virtual-network-deployment.md).

## <a name="public-ports"></a>Общедоступные порты

Все узлы в кластере HDInsight находятся в виртуальной сети Azure, и к ним нельзя получить доступ напрямую из Интернета. Общедоступный шлюз обеспечивает интернет-доступ к приведенным ниже портам. Они общие для всех типов кластеров HDInsight.

| Служба | Port | Протокол | Description |
| --- | --- | --- | --- |
| sshd |22 |SSH |Подключает клиенты к sshd на основном головном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| sshd |22 |SSH |Подключает клиенты к SSHD на граничном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| sshd |23 |SSH |Подключает клиенты к sshd на дополнительном головном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| Ambari |443 |HTTPS |Веб-интерфейс Ambari. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md). |
| Ambari |443 |HTTPS |REST API Ambari. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью REST API Ambari](hdinsight-hadoop-manage-ambari-rest-api.md). |
| WebHCat |443 |HTTPS |REST API HCatalog. См. раздел [Использование MapReduce с фигурой](hadoop/apache-hadoop-use-mapreduce-curl.md) |
| HiveServer2 |443 |ODBC |Подключение к Hive с помощью ODBC. См. статью [Подключение Excel к Hadoop с помощью драйвера Microsoft Hive ODBC](hadoop/apache-hadoop-connect-excel-hive-odbc-driver.md). |
| HiveServer2 |443 |JDBC |Подключение к ApacheHive с помощью JDBC. Дополнительные сведения см. в статье [Отправка запросов в Apache Hive с помощью драйвера JDBC в HDInsight](hadoop/apache-hadoop-connect-hive-jdbc-driver.md). |

Приведенные ниже сведения доступны для определенных типов кластеров.

| Служба | Port | Протокол | Тип кластера | Description |
| --- | --- | --- | --- | --- |
| Stargate |443 |HTTPS |HBase |REST API HBase. Дополнительные сведения см. в статье [Начало работы с примером Apache HBase в HDInsight](hbase/apache-hbase-tutorial-get-started-linux.md). |
| Livy |443 |HTTPS |Spark |Spark REST API. Дополнительные сведения см. в статье [Удаленная отправка заданий Spark в кластер Azure HDInsight с помощью Apache Spark REST API](spark/apache-spark-livy-rest-interface.md) |
| Сервер Thrift Spark |443 |HTTPS |Spark |Сервер Thrift Spark, который используется для отправки запросов Hive. Дополнительные сведения см. в статье [Использование клиента Apache Beeline с Apache Hive](hadoop/apache-hadoop-use-hive-beeline.md). |
| Storm |443 |HTTPS |Storm |Веб-интерфейс Storm. Дополнительные сведения см. в статье [Развертывание и администрирование топологий Apache Storm в Azure HDInsight](storm/apache-storm-deploy-monitor-topology-linux.md) |
| Прокси-сервер Kafka RESTful |443 |HTTPS |Kafka |REST API Kafka. См. статью [взаимодействие с кластерами Apache Kafka в Azure HDInsight с помощью прокси-сервера RESTful](kafka/rest-proxy.md) . |

### <a name="authentication"></a>Проверка подлинности

Все общедоступные службы в Интернете должны проходить проверку подлинности.

| Port | Учетные данные |
| --- | --- |
| 22 или 23 |Учетные данные пользователя SSH, указанные при создании кластера. |
| 443 |Имя для входа (по умолчанию — admin) и пароль, указанные при создании кластера. |

## <a name="non-public-ports"></a>Необщедоступные порты

> [!NOTE]  
> Некоторые службы доступны только в кластерах определенных типов. Например, служба HBase доступна только на кластерах типа HBase.

> [!IMPORTANT]  
> Некоторые службы могут работать только на одном головном узле одновременно. Если вы пытаетесь подключиться к службе на основном головном узле и получаете сообщение об ошибке, повторите попытку, используя вторичный головной узел.

### <a name="ambari"></a>Ambari

| Служба | Узлы | Port | URL-адрес | Протокол |
| --- | --- | --- | --- | --- |
| Веб-интерфейс Ambari | Головные узлы | 8080 | / | HTTP |
| Ambari REST API | Головные узлы | 8080 | /api/v1 | HTTP |

Примеры.

* Ambari REST API: `curl -u admin "http://10.0.0.11:8080/api/v1/clusters"`

### <a name="hdfs-ports"></a>Порты HDFS

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Веб-интерфейс узла имен |Головные узлы |30070 |HTTPS |Пользовательский веб-интерфейс для просмотра состояния. |
| Служба метаданных на узле имен |Головные узлы |8020 |IPC |Метаданные файловой системы |
| Узел данных |Все рабочие узлы |30075 |HTTPS |Веб-интерфейс для просмотра состояния, журналов и т. д. |
| Узел данных |Все рабочие узлы |30010 |&nbsp; |Передача данных |
| Узел данных |Все рабочие узлы |30020 |IPC |Операции с метаданными |
| Дополнительный узел имен |Головные узлы |50090 |HTTP |Контрольная точка для метаданных узла имен |

### <a name="yarn-ports"></a>Порты YARN

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Веб-интерфейс для диспетчера Resource Manager |Головные узлы |8088 |HTTP |Веб-интерфейс для диспетчера Resource Manager |
| Веб-интерфейс для диспетчера Resource Manager |Головные узлы |8090 |HTTPS |Веб-интерфейс для диспетчера Resource Manager |
| Интерфейс администратора для Resource Manager |Головные узлы |8141 |IPC |Для отправки приложений (Hive, Hive Server, Pig и т. д.) |
| Планировщик Resource Manager |Головные узлы |8030 |HTTP |Интерфейс администратора |
| Интерфейс приложения Resource Manager |Головные узлы |8050 |HTTP |Адрес интерфейса диспетчера приложений |
| Диспетчер узлов |Все рабочие узлы |30050 |&nbsp; |Адрес диспетчера контейнеров |
| Веб-интерфейс диспетчера узлов |Все рабочие узлы |30060 |HTTP |Интерфейс диспетчер ресурсов |
| Адрес временной шкалы |Головные узлы |10200 |RPC |Служба RPC службы временной шкалы |
| Веб-интерфейс временной шкалы |Головные узлы |8188 |HTTP |Веб-интерфейс службы временной шкалы |

### <a name="hive-ports"></a>Порты Hive

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| HiveServer2 |Головные узлы |10001 |Thrift |Служба для подключения к Hive (с помощью протокола Thrift или JDBC) |
| Метахранилище Hive |Головные узлы |9083 |Thrift |Служба для подключения к метаданным Hive (с помощью протокола Thrift или JDBC) |

### <a name="webhcat-ports"></a>Порты WebHCat

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Сервер WebHCat |Головные узлы |30111 |HTTP |Веб-API на базе HCatalog и других служб Hadoop |

### <a name="mapreduce-ports"></a>Порты MapReduce

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Журнал заданий |Головные узлы |19888 |HTTP |Веб-интерфейс журнала заданий MapReduce |
| Журнал заданий |Головные узлы |10020 |&nbsp; |Сервер журнала заданий MapReduce |
| Обработчик перемещений |&nbsp; |13562 |&nbsp; |Передача промежуточных выходных данных сопоставления в адрес запрашивающих редукторов |

### <a name="oozie"></a>Oozie,

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Сервер Oozie |Головные узлы |11000 |HTTP |URL-адрес службы Oozie |
| Сервер Oozie |Головные узлы |11001 |HTTP |Порт для администрирования Oozie |

### <a name="ambari-metrics"></a>Метрики Ambari

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Временная шкала (журнал приложения) |Головные узлы |6188 |HTTP |Веб-интерфейс службы временной шкалы |
| Временная шкала (журнал приложения) |Головные узлы |30200 |RPC |Веб-интерфейс службы временной шкалы |

### <a name="hbase-ports"></a>Порты HBase

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| HMaster |Головные узлы |16000 |&nbsp; |&nbsp; |
| Веб-интерфейс информационного сервера HMaster |Головные узлы |16010 |HTTP |Порт для веб-интерфейса на главном узле HBase |
| Региональный сервер |Все рабочие узлы |16020 |&nbsp; |&nbsp; |
| &nbsp; |&nbsp; |2181 |&nbsp; |Порт, используемый клиентами для подключения к ZooKeeper |

### <a name="kafka-ports"></a>Порты Kafka

| Служба | Узлы | Port | Протокол | Description |
| --- | --- | --- | --- | --- |
| Broker |Рабочие узлы |9092 |[Сетевой протокол Kafka](https://kafka.apache.org/protocol.html) |Используется для связи с клиентами |
| &nbsp; |Узлы Zookeeper |2181 |&nbsp; |Порт, используемый клиентами для подключения к ZooKeeper |
| Прокси-сервер RESTFUL | Узлы управления Kafka |9400 |HTTPS |[Спецификация Kafka RESTFUL](https://docs.microsoft.com/rest/api/hdinsight-kafka-rest-proxy/) |

### <a name="spark-ports"></a>Порты Spark

| Служба | Узлы | Port | Протокол | URL-адрес | Description |
| --- | --- | --- | --- | --- | --- |
| Серверы Thrift Spark |Головные узлы |10002 |Thrift | &nbsp; | Служба для подключения к Spark SQL (с помощью протокола Thrift или JDBC) |
| Сервер Livy | Головные узлы | 8998 | HTTP | &nbsp; | Служба для запуска инструкций, заданий и приложений |
| Записная книжка Jupyter | Головные узлы | 8001 | HTTP | &nbsp; | Веб-сайт записных книжек Jupyter |

Примеры.

* Livy: `curl -u admin -G "http://10.0.0.11:8998/"`. В этом примере `10.0.0.11` — IP-адрес головного узла, на котором размещена служба Livy.
