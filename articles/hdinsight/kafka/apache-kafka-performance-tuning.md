---
title: Оптимизация производительности для кластеров Apache Kafka HDInsight
description: Предоставляет обзор методов оптимизации рабочих нагрузок Apache Kafka на Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 12/19/2019
ms.openlocfilehash: 752068af531c4a0ecc832d266f88105c14452ecb
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "75494923"
---
# <a name="performance-optimization-for-apache-kafka-hdinsight-clusters"></a>Оптимизация производительности для кластеров Apache Kafka HDInsight

В этой статье приводятся некоторые предложения по оптимизации производительности рабочих нагрузок Apache Kafka в HDInsight. Основное внимание уделяется корректировке конфигурации производителя и брокера. Существуют различные способы измерения производительности, и оптимизация, которую вы применяете, будет зависеть от ваших бизнес-потребностей.

## <a name="architecture-overview"></a>Обзор архитектуры

Темы Кафки используются для организации записей. Записи создаются производителями, а используются потребителями. Производители отправляют записи брокерам Kafka, которые затем хранят данные. Каждый рабочий узел в кластере HDInsight — это брокер Kafka.

Разделы позволяют распределить записи между брокерами. При считывании записей можно использовать один потребитель на секцию, чтобы обеспечить параллельную обработку данных.

Репликация используется для дублирования разделов между узлами. Это защищает от перебоев в работе узлов (брокеров). Один раздел между группой реплик обозначен как лидер раздела. Трафик производителя направляется в ведущую секцию каждого узла в зависимости от состояния, которым управляет ZooKeeper.

## <a name="identify-your-scenario"></a>Определение своего сценария

Производительность Apache Kafka имеет два основных аспекта – пропускную способность и задержку. Пропускная часть — это максимальная скорость обработки данных. Более высокая пропускная их часть, как правило, лучше. Задержка — это время, необходимое для хранения или извлечения данных. Более низкая задержка, как правило, лучше. Поиск правильного баланса между пропускной стоимостью, задержкой и стоимостью инфраструктуры приложения может оказаться непростой задачей. Требования к производительности, скорее всего, будут соответствовать одной из следующих трех распространенных ситуаций, в зависимости от того, требуется ли высокая пропускная способность, низкая задержка или обе:

* Высокая пропускная ситуация, низкая задержка. Этот сценарий требует как высокой пропускной связи, так и низкой задержки (100 миллисекунд). Примером такого типа приложений является мониторинг доступности услуг.
* Высокая пропускная ситуация, высокая задержка. Этот сценарий требует высокой пропускной связи (1,5 Гбит/с), но может терпеть более высокую задержку (< 250 мс). Примером такого типа приложений является использование телеметрических данных для практически процессов в режиме реального времени, таких как приложения для обнаружения безопасности и вторжения.
* Низкая пропускная ситуация, низкая задержка. Этот сценарий требует низкой задержки (< 10 мс) для обработки в режиме реального времени, но может терпеть более низкую пропускную мощность. Примером такого типа приложений является онлайн-проверка правописания и грамматики.

## <a name="producer-configurations"></a>Конфигурации производителей

В следующих разделах будут освещены некоторые из наиболее важных свойств конфигурации для оптимизации производительности ваших производителей Kafka. Подробное объяснение всех свойств конфигурации [см.](https://kafka.apache.org/documentation/#producerconfigs)

### <a name="batch-size"></a>Размер пакета

Производители Apache Kafka собирают группы сообщений (так называемых пакетов), которые отправляются в качестве единицы для хранения в одном разделе хранения. Размер пакета означает количество байтов, которые должны присутствовать до того, как эта группа будет передана. Увеличение `batch.size` параметра может увеличить пропускную стоимость, так как уменьшает накладные расходы на обработку от запросов сети и обработки. При легкой нагрузке увеличение размера партии может увеличить задержку отправки Kafka, поскольку производитель ждет, когда будет готова партия. При большой нагрузке рекомендуется увеличить размер партии, чтобы улучшить пропускную работу и задержку.

### <a name="producer-required-acknowledgments"></a>Производитель требует подтверждения

Требуемая `acks` конфигурация производителя определяет количество подтверждений, требуемых лидером раздела до того, как запрос на запись будет считаться завершенным. Этот параметр влияет на надежность данных `1`и `-1`он принимает значения `0`, или . Значение `-1` средств, которые необходимо получить от всех реплик до завершения записи, должно быть получено. Установка `acks = -1` обеспечивает более сильные гарантии от потери данных, но это также приводит к более высокой задержке и более низкой пропускной связи. Если требования к заявке требуют `acks = 0` более `acks = 1`высокой пропускной платы, попробуйте установить или . Имейте в виду, что не признавая все реплики может снизить надежность данных.

### <a name="compression"></a>Сжатие

Производитель Kafka может быть настроен для сжатия сообщений перед отправкой их брокерам. Настройка `compression.type` определяет кодек сжатия, который будет использоваться. Поддерживаемые кодеки сжатия являются "gzip", "snappy" и "lz4". Сжатие полезно и должно быть рассмотрено, если есть ограничение на емкость диска.

Среди двух часто используемых кодеков `snappy` `gzip` сжатия, и , `gzip` имеет более высокое соотношение сжатия, что приводит к более низкому использованию диска за счет более высокой нагрузки процессора. Кодек `snappy` обеспечивает меньше сжатия с меньшими накладными расходами процессора. Вы можете решить, какой кодек использовать на основе ограничений маклера или процессора производителя. `gzip`может сжимать данные со `snappy`скоростью в пять раз выше, чем .

Использование сжатия данных увеличит количество записей, которые могут храниться на диске. Это также может увеличить накладные расходы процессора в тех случаях, когда есть несоответствие между форматами сжатия, используемых производителем и брокером. как данные должны быть сжаты перед отправкой, а затем распакованы перед обработкой.

## <a name="broker-settings"></a>Настройки брокера

В следующих разделах будут освещены некоторые из наиболее важных параметров для оптимизации производительности ваших брокеров Kafka. Подробное объяснение всех параметров брокера можно узнать [из документации Apache Kafka о конфигурациях производителей.](https://kafka.apache.org/documentation/#producerconfigs)

### <a name="number-of-disks"></a>Количество дисков

Диски хранения данных имеют ограниченный IOPS (входные/выходные операции в секунду) и прочитаны/записывайте байты в секунду. При создании новых разделов Kafka хранит каждую новую разделна на диске с наименьшим количеством существующих разделов, чтобы сбалансировать их через доступные диски. Несмотря на стратегию хранения данных, при обработке сотен реплик перегородок на каждом диске, Kafka может легко насытить доступную пропускную мощность диска. Компромисс здесь между пропускной стоимостью и стоимостью. Если ваше приложение требует большей пропускной четырбы, создайте кластер с большим количеством управляемых дисков на одного брокера. В настоящее время HDInsight не поддерживает добавление управляемых дисков в запущенный кластер. Для получения дополнительной информации о том, как настроить количество управляемых дисков, [см. Накрешимость для Apache Kafka на HDInsight](apache-kafka-scalability.md). Понимание затрат, относясь к увеличению пространства для хранения узлов в кластере.

### <a name="number-of-topics-and-partitions"></a>Количество тем и разделов

Производители Кафки пишут на темы. Потребители Кафки читают по темам. Тема связана с журналом, который представляет собой структуру данных на диске. Kafka привязав записи от производителя (ы) к концу журнала тем. Тематический журнал состоит из множества разделов, которые распределены по нескольким файлам. Эти файлы, в свою очередь, распределены по нескольким кластерным узлам Kafka. Потребители читают темы Кафки на их каденции и могут выбрать их положение (смещение) в журнале темы.

Каждая разделка Kafka — это файл журнала в системе, и потоки производителя могут записываться в несколько журналов одновременно. Аналогичным образом, поскольку каждый поток потребителя читает сообщения из одного раздела, потребление из нескольких разделов обрабатывается параллельно также.

Увеличение плотности раздела (количество разделов на одного брокера) добавляет накладные расходы, связанные с операциями метаданных и запросом на раздел/ответ между лидером раздела и его последователями. Даже при отсутствии данных, протекающих через, реплики раздела по-прежнему получают данные от лидеров, что приводит к дополнительной обработке для отправки и получения запросов по сети.

Для кластеров Apache Kafka 1.1 и выше в HDInsight мы рекомендуем вам иметь максимум 1000 разделов на одного брокера, включая реплики. Увеличение количества перегородок на одного брокера уменьшает пропускную вылимку, а также может привести к недоступности темы. Для получения дополнительной информации о поддержке раздела Kafka, [см.](https://blogs.apache.org/kafka/entry/apache-kafka-supports-more-partitions) Для получения подробной информации [Apache Kafka: modifying topics](https://kafka.apache.org/documentation/#basic_ops_modify_topic)об изменении тем см.

### <a name="number-of-replicas"></a>Количество реплик

Более высокий коэффициент репликации приводит к дополнительным запросам между лидером раздела и последователями. Следовательно, более высокий коэффициент репликации потребляет больше диска и процессора для обработки дополнительных запросов, увеличивая задержку записи и уменьшая пропускную плату.

Мы рекомендуем использовать репликацию Kafka в Azure HDInsight по крайней мере 3x для Kafka. В большинстве регионов Azure есть три домена неисправностей, но в регионах с двумя доменами неисправности пользователи должны использовать репликацию 4x.

Для получения дополнительной информации о репликации [см.](https://kafka.apache.org/documentation/#replication) [Apache Kafka: increasing replication factor](https://kafka.apache.org/documentation/#basic_ops_increase_replication_factor)

## <a name="next-steps"></a>Дальнейшие действия

* [Processing trillions of events per day with Apache Kafka on Azure](https://azure.microsoft.com/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/) (Ежедневная обработка триллионов событий с помощью Apache Kafka в Azure)
* [Что такое Apache Kafka в HDInsight?](apache-kafka-introduction.md)
