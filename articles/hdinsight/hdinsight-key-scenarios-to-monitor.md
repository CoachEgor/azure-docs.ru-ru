---
title: Мониторинг производительности кластера в Azure HDInsight
description: Как контролировать работоспособность и производительность кластеров Apache Hadoop в Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 03/09/2020
ms.openlocfilehash: 75ac5a7fc352f877573d79a004d8da761c6f1cef
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79082886"
---
# <a name="monitor-cluster-performance-in-azure-hdinsight"></a>Мониторинг производительности кластера в Azure HDInsight

Мониторинг работоспособности и производительности кластера HDInsight важен для обеспечения оптимальной производительности и эффективного использования ресурсов. Мониторинг может также помочь вам обнаружить и устранить ошибки конфигурации кластера и проблемы с пользовательским кодом.

В следующих разделах описывается, как отслеживать и оптимизировать нагрузку на кластеры, очереди Apache Hadoop YARN и обнаруживать проблемы регулирования хранилища.

## <a name="monitor-cluster-load"></a>Мониторинг загрузки кластера

Кластеры Hadoop могут обеспечить наиболее оптимальную производительность, когда нагрузка на кластер равномерно распределена по всем узлам. Это позволяет избежать ограничения задач обработки из-за нехватки ресурсов ОЗУ, ЦП и дисков на отдельных узлах.

Чтобы получить высококачественный взгляд на узлы вашего кластера и их загрузку, восстановитесь на [uI Ambari Web,](hdinsight-hadoop-manage-ambari.md)затем выберите вкладку **Хостов.** Ваши хосты указаны по полностью квалифицированным доменным именам. Состояние каждого узла обозначается цветным индикатором работоспособности.

| Color | Описание |
| --- | --- |
| Красный | Как минимум один ведущий компонент на узле не работает. Наведите указатель мыши, чтобы просмотреть подсказку с перечнем затронутых компонентов. |
| Оранжевый | По крайней мере один вторичный компонент на хостах не работает. Наведите указатель мыши, чтобы просмотреть подсказку с перечнем затронутых компонентов. |
| Желтый | Ambari Server не получал сердцебиение от хозяина более 3 минут. |
| Зеленый | Нормальное рабочее состояние. |

Вы также увидите столбцы с указанием количества ядер и объема ОЗУ для каждого узла, сведений об использовании дисков и средней загрузки.

![Apache Ambari хостов вкладки обзор](./media/hdinsight-key-scenarios-to-monitor/apache-ambari-hosts-tab.png)

Выберите любое имя узла, чтобы подробное изучить компоненты, работающие на этом узле, и их метрики. Метрики отображаются в виде доступной для выбора временной шкалы использования ЦП, загрузки, использование диска, использование памяти, использование сети и числа процессов.

![Apache Ambari хост подробная информация обзор](./media/hdinsight-key-scenarios-to-monitor/apache-ambari-host-details.png)

Подробные сведения о настройке оповещений и просмотре метрик см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

## <a name="yarn-queue-configuration"></a>Конфигурация очереди YARN

На распределенной платформе Hadoop выполняются различные службы. YARN (Yet Another Resource Negotiator, что переводится как "Еще одна система управления ресурсами") координирует эти службы, выделяет ресурсы кластера для обеспечения равномерного распределения нагрузки по кластеру.

YARN разделяет две обязанности JobTracker: управление ресурсами и планирование и мониторинг заданий — между двумя управляющими программами: глобальным приложением Resource Manager и приложением ApplicationMaster для каждого приложения (AM).

Resource Manager является *только планировщиком* и единолично управляет доступными ресурсами для всех конкурирующих приложений. Resource Manager обеспечивает постоянное использование всех ресурсов, оптимизируя различные константы, такие как соглашения об уровне обслуживания, гарантии емкости и т. д. ApplicationMaster согласовывает ресурсы, полученные от Resource Manager, и работает с экземплярами NodeManager для выполнения и отслеживания контейнеров и их потребления ресурсов.

Когда несколько арендаторов имеют общий кластер, возникает конкуренция за ресурсы кластера. CapacityScheduler является подключаемым планировщиком, который упрощает предоставление общего доступа к ресурсам, ставя запросы в очередь. CapacityScheduler также поддерживает *иерархические очереди,* чтобы гарантировать, что ресурсы распределяются между подочередими организации, прежде чем очереди других приложений будут разрешены к использованию свободных ресурсов.

YARN позволяет выделять ресурсы для этих очередей, а также показывает, назначены ли все доступные ресурсы. Чтобы просмотреть сведения об очередях, войдите в пользовательский веб-интерфейс Ambari и в верхнем меню щелкните **YARN Queue Manager** (Диспетчер очередей YARN).

![Менеджер очереди Apache Ambari YARN](./media/hdinsight-key-scenarios-to-monitor/apache-yarn-queue-manager.png)

В левой части страницы "YARN Queue Manager" (Диспетчер очередей YARN) отображается список очередей, а также назначенный каждой из них процент емкости.

![Страница сведений диспетчера очередей YARN](./media/hdinsight-key-scenarios-to-monitor/yarn-queue-manager-details.png)

Чтобы более подробно изучить очереди, на панели мониторинга Ambari из списка слева выберите службу **YARN**. Затем из раскрывающегося меню **Quick Links** (Быстрые ссылки) выберите **Resource Manager UI** (Пользовательский интерфейс Resource Manager) под активным узлом.

![Ссылки на uI-меню менеджера ресурсов](./media/hdinsight-key-scenarios-to-monitor/resource-manager-ui-menu-link.png)

В пользовательском интерфейсе Resource Manager в меню слева выберите **Scheduler** (Планировщик). Список очередей отобразится в разделе *Application Queues* (Очереди приложений). Здесь можно просмотреть емкость, используемую для каждой из очередей, узнать, насколько хорошо задания распределены между ними, и имеются ли задания, которым не хватает ресурсов.

![Меню uI менеджера ресурсов Apache HAdoop](./media/hdinsight-key-scenarios-to-monitor/resource-manager-ui-menu.png)

## <a name="storage-throttling"></a>Регулирование хранилища

Узкое место производительности кластера может возникнуть на уровне хранилища. Этот тип узких мест чаще всего из-за *блокирования* входных /выходных (IO) операций, которые происходят, когда ваши задачи выполнения отправить больше IO, чем служба хранения может обрабатывать. Эта блокировка приводит к образованию очереди запросов на ввод-вывод, ожидающих обработки после завершения обработки текущих операций ввода-вывода. Блоки из-за *регулирования хранилища,* который не является физическим пределом, а скорее ограничение, налагаемое службой хранения соглашением об уровне обслуживания (SLA). Это ограничение гарантирует невозможность монополизации службы каким-ибо одним клиентом. SLA ограничивает количество IOs в секунду (IOPS) для хранения Azure - для деталей, см. [Цели масштабируемости и производительности для стандартных учетных записей хранения.](../storage/common/scalability-targets-standard-account.md)

Если вы используете Azure Storage, для получения информации о проблемах мониторинга хранения, включая регулирование, [см. монитор, диагностику и устранение неполадок ВСУ.](https://docs.microsoft.com/azure/storage/storage-monitoring-diagnosing-troubleshooting)

Если резервным хранилищем кластера является Хранилище озер данных Azure Data (ADLS), то регулирование, скорее всего, из-за ограничений пропускной способности. В данном случае регулирование можно заметить, отслеживая ошибки регулирования в журналах задач. Сведения об использовании ADLS приведены в разделе о регулировании для соответствующей службы в следующих статьях:

* [Рекомендации по настройке производительности для Hive в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-hive.md)
* [Рекомендации по настройке производительности для MapReduce в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-mapreduce.md)
* [Рекомендации по настройке производительности для Storm в HDInsight и Azure Data Lake Storage](../data-lake-store/data-lake-store-performance-tuning-storm.md)

## <a name="troubleshoot-sluggish-node-performance"></a>Устранение неполадок вялой производительности узлов

В некоторых случаях вялость может произойти из-за низкого дискового пространства на кластере. Исследуйте с помощью этих шагов:

1. Используйте [команду ssh](./hdinsight-hadoop-linux-use-ssh-unix.md) для подключения к каждому из узлов.

1. Проверьте использование диска, запустив одну из следующих команд:

    ```bash
    df -h
    du -h --max-depth=1 / | sort -h
    ```

1. Просмотрите вывод и проверьте наличие больших файлов `mnt` в папке или других папках. Как правило, `usercache` `appcache` папки (mnt/resource/hadoop/yarn/local/usercache/hive/appcache/) содержат большие файлы.

1. При наличии больших файлов, либо текущее задание вызывает рост файла, либо неудачное предыдущее задание могло способствовать возникновению этой проблемы. Чтобы проверить, вызвано ли это поведение текущим заданием, запустите следующую команду:

    ```bash
    sudo du -h --max-depth=1 /mnt/resource/hadoop/yarn/local/usercache/hive/appcache/
    ```

1. Если эта команда указывает на определенное задание, можно завершить задание, используя команду, напоминающую следующее:

    ```bash
    yarn application -kill -applicationId <application_id>
    ```

    Заменить `application_id` идентификатор приложения. Если конкретные задания не указаны, перейдите к следующему шагу.

1. После завершения приведенной выше команды или если не указаны конкретные задания, удалите большие файлы, идентифицированные вами, запустив команду, напоминающую следующее:

    ```bash
    rm -rf filecache usercache
    ```

Для получения дополнительной информации о [проблемах](./hadoop/hdinsight-troubleshoot-out-disk-space.md)дискового пространства, см.

> [!NOTE]  
> Если у вас есть большие файлы, которые вы хотите сохранить, но вносят свой вклад в проблему с низким дисковым пространством, необходимо расширить кластер HDInsight и перезапустить службы. После завершения этой процедуры и ожидания в течение нескольких минут, вы заметите, что хранилище освобождается и обычная производительность узла восстанавливается.

## <a name="next-steps"></a>Дальнейшие действия

Перейдите по следующим ссылкам, чтобы получить дополнительные сведения об устранении неполадок и мониторинге кластеров:

* [Сведения об анализе журналов Azure HDInsight в этой статье](hdinsight-debug-jobs.md)
* [Доступ к журналам приложений Apache Hadoop YARN в HDInsight под управлением Linux](hdinsight-hadoop-access-yarn-app-logs-linux.md)
* [Включение дампов кучи для служб Apache Hadoop в HDInsight под управлением Linux](hdinsight-hadoop-collect-debug-heap-dump-linux.md)
