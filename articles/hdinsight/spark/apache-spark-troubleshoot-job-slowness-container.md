---
title: Apache Spark задание выполняется медленно, когда контейнер хранилища Azure содержит много файлов в Azure HDInsight.
description: Apache Spark задание выполняется медленно, когда контейнер хранилища Azure содержит много файлов в Azure HDInsight.
ms.service: hdinsight
ms.topic: troubleshooting
author: hrasheed-msft
ms.author: hrasheed
ms.date: 07/29/2019
ms.openlocfilehash: 78dff1b9d9db4e54ab1a8f7203088753e206c610
ms.sourcegitcommit: 3877b77e7daae26a5b367a5097b19934eb136350
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/30/2019
ms.locfileid: "68641959"
---
# <a name="scenario-apache-spark-job-run-slowly-when-the-azure-storage-container-contains-many-files-in-azure-hdinsight"></a>Сценарий: Apache Spark задание медленно выполняется, если контейнер службы хранилища Azure содержит много файлов в Azure HDInsight

В этой статье описываются действия по устранению неполадок и возможные способы решения проблем при использовании Apache Spark компонентов в кластерах Azure HDInsight.

## <a name="issue"></a>Проблемы

При запуске кластера HDInsight задание Apache Spark, которое выполняет запись в контейнер службы хранилища Azure, замедлит работу при наличии большого количества файлов и вложенных папок. Например, при записи в новый контейнер может потребоваться 20 секунд, а при записи в контейнер с 200 000 деятелей-файлами — 2 минуты.

## <a name="cause"></a>Причина:

Это известная проблема Spark. Медленная работа поступает из `ListBlob` операций и `GetBlobProperties` во время выполнения задания Spark.

Для отслеживания секций Spark должен поддерживать `FileStatusCache` , который содержит сведения о структуре каталогов. С помощью этого кэша Spark может анализировать пути и получать информацию о доступных секциях. Преимущество отслеживания секций заключается в том, что Spark касается только необходимых файлов при чтении данных. Чтобы сохранить эти сведения в актуальном состоянии, при записи новых данных Spark должен вывести список всех файлов в каталоге и обновить этот кэш.

В Spark 1,6 каждый раз при обновлении каталога вы (1) Очистите кэш (2) рекурсивно перечислите все файлы и (3) обновите весь кэш. Это приводит к множеству операций перечисления.

В Spark 2,1 не требуется обновлять кэш после каждой операции записи, Spark проверяет, совпадает ли существующий столбец секционирования с предложенным в текущем запросе записи, поэтому он также приводит к переписи операций в начале каждой операции записи.

В Spark 2,2 при записи данных в режиме добавления эта проблема производительности должна быть исправлена.

## <a name="resolution"></a>Разрешение

При создании секционированного набора данных важно использовать схему секционирования, которая будет ограничивать количество файлов, которые будут перечислены в Spark для обновления `FileStatusCache`.

Для каждого n-го микропакета, где N% 100 = = 0 100 (всего лишь пример), переместите существующие данные в другой каталог, который может быть загружен Spark.

## <a name="next-steps"></a>Следующие шаги

Если вы не видите своего варианта проблемы или вам не удается ее устранить, дополнительные сведения можно получить, посетив один из следующих каналов.

* Получите ответы от экспертов Azure через [службу поддержки сообщества Azure](https://azure.microsoft.com/support/community/).

* Подключайтесь с помощью [@AzureSupport](https://twitter.com/azuresupport) официальной учетной записи Microsoft Azure для улучшения качества работы клиентов, подключив сообщество Azure к нужным ресурсам: ответы, поддержка и эксперты.

* Если вам нужна дополнительная помощь, можно отправить запрос в службу поддержки из [портал Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите пункт **Поддержка** в строке меню или откройте центр **справки и поддержки** . Дополнительные сведения см. [в](https://docs.microsoft.com/azure/azure-supportability/how-to-create-azure-support-request)этой службе. Доступ к управлению подписками и поддержкой выставления счетов включен в вашу подписку Microsoft Azure, а техническая поддержка предоставляется через один из [планов поддержки Azure](https://azure.microsoft.com/support/plans/).
