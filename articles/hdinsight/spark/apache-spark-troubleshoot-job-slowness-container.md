---
title: Apache Spark замедляется, когда хранилище Azure HDInsight имеет много файлов
description: Задание Apache Spark выполняется медленно, когда контейнер хранения Azure содержит много файлов в Azure HDInsight
ms.service: hdinsight
ms.topic: troubleshooting
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.date: 08/21/2019
ms.openlocfilehash: e389c05a6de85287bc86eff510e137f470837e56
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "75894325"
---
# <a name="apache-spark-job-run-slowly-when-the-azure-storage-container-contains-many-files-in-azure-hdinsight"></a>Задание Apache Spark выполняется медленно, если контейнер службы хранилища Azure содержит много файлов в Azure HDInsight

В этой статье описаны шаги устранения неполадок и возможные решения проблем при использовании компонентов Apache Spark в кластерах Azure HDInsight.

## <a name="issue"></a>Проблема

При запуске кластера HDInsight задание Apache Spark, которое записывается в контейнер хранения Azure, становится медленным при наличии большого количества файлов/подпапок. Например, запись в новый контейнер занимает 20 секунд, а около 2 минут — в контейнере с 200k-файлами.

## <a name="cause"></a>Причина

Это известный вопрос Spark. Медлительность исходит `ListBlob` `GetBlobProperties` от и операций во время выполнения работы Spark.

Чтобы отслеживать разделы, Spark должен `FileStatusCache` поддерживать, который содержит информацию о структуре каталога. Используя этот кэш, Spark может разбирать пути и быть в курсе доступных разделов. Преимущество отслеживания разделов заключается в том, что Spark касается только необходимых файлов при чтении данных. Чтобы сохранить эту информацию в актуальном состоянии при написании новых данных, Spark должен перечислить все файлы в каталоге и обновить этот кэш.

В Spark 2.1, в то время как нам не нужно обновлять кэш после каждой записи, Spark проверит, совпадает ли существующая колонка раздела с предлагаемой в текущем запросе на запись, так что это также приведет к операциям листинга в начале каждой записи.

В Spark 2.2 при написании данных в режиме приложения эта проблема производительности должна быть исправлена.

## <a name="resolution"></a>Решение

При создании разделенного набора данных важно использовать схему раздела, которая ограничит количество файлов, которые Spark `FileStatusCache`должен перечислить для обновления .

Для каждой микро-партии N-й, где N % 100 q 0 (100 является лишь примером), переместите существующие данные в другой каталог, который может быть загружен Spark.

## <a name="next-steps"></a>Дальнейшие действия

Если вы не видите своего варианта проблемы или вам не удается ее устранить, дополнительные сведения можно получить, посетив один из следующих каналов.

* Получите ответы от экспертов Azure через [поддержку сообщества Azure.](https://azure.microsoft.com/support/community/)

* Связаться [@AzureSupport](https://twitter.com/azuresupport) с официальным аккаунтом Microsoft Azure для улучшения обслуживания клиентов, подключив сообщество Azure к нужным ресурсам: ответам, поддержке и экспертам.

* Если вам нужна дополнительная помощь, вы можете отправить запрос на поддержку с [портала Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите **поддержку** из бара меню или откройте концентратор **поддержки Справка и.** Для получения более подробной информации, пожалуйста, просмотрите [Как создать запрос поддержки Azure](https://docs.microsoft.com/azure/azure-portal/supportability/how-to-create-azure-support-request). Доступ к управлению подпиской и поддержке выставления счетов включен в подписку Microsoft Azure, а техническая поддержка обеспечивается через один из [планов поддержки Azure.](https://azure.microsoft.com/support/plans/)
