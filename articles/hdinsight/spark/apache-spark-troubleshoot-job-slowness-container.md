---
title: Apache Spark замедляться, когда хранилище Azure HDInsight содержит много файлов
description: Apache Spark задание выполняется медленно, когда контейнер хранилища Azure содержит много файлов в Azure HDInsight.
ms.service: hdinsight
ms.topic: troubleshooting
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.date: 08/21/2019
ms.openlocfilehash: e389c05a6de85287bc86eff510e137f470837e56
ms.sourcegitcommit: 829d951d5c90442a38012daaf77e86046018e5b9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/09/2020
ms.locfileid: "75894325"
---
# <a name="apache-spark-job-run-slowly-when-the-azure-storage-container-contains-many-files-in-azure-hdinsight"></a>Задание Apache Spark выполняется медленно, если контейнер службы хранилища Azure содержит много файлов в Azure HDInsight

В этой статье описываются действия по устранению неполадок и возможные способы исправления проблем, возникающих при использовании компонентов Apache Spark в кластерах Azure HDInsight.

## <a name="issue"></a>Проблема

При запуске кластера HDInsight задание Apache Spark, которое выполняет запись в контейнер службы хранилища Azure, замедлит работу при наличии большого количества файлов и вложенных папок. Например, при записи в новый контейнер может потребоваться 20 секунд, а при записи в контейнер с 200 000 деятелей-файлами — 2 минуты.

## <a name="cause"></a>Причина

Это известная проблема Spark. Медленная работа поступает из `ListBlob` операций и `GetBlobProperties` во время выполнения задания Spark.

Для отслеживания секций Spark должен поддерживать, `FileStatusCache` который содержит сведения о структуре каталогов. С помощью этого кэша Spark может анализировать пути и получать информацию о доступных секциях. Преимущество отслеживания секций заключается в том, что Spark касается только необходимых файлов при чтении данных. Чтобы сохранить эти сведения в актуальном состоянии, при записи новых данных Spark должен вывести список всех файлов в каталоге и обновить этот кэш.

В Spark 2,1 не требуется обновлять кэш после каждой операции записи, Spark проверяет, совпадает ли существующий столбец секционирования с предложенным в текущем запросе записи, поэтому он также приводит к переписи операций в начале каждой операции записи.

В Spark 2,2 при записи данных в режиме добавления эта проблема производительности должна быть исправлена.

## <a name="resolution"></a>Решение

При создании секционированного набора данных важно использовать схему секционирования, которая будет ограничивать количество файлов, которые будут перечислены в Spark для обновления `FileStatusCache` .

Для каждого n-го микропакета, где N %100 = = 0 100 (всего лишь пример), переместите существующие данные в другой каталог, который может быть загружен Spark.

## <a name="next-steps"></a>Дальнейшие действия

Если вы не видите своего варианта проблемы или вам не удается ее устранить, дополнительные сведения можно получить, посетив один из следующих каналов.

* Получите ответы специалистов Azure на [сайте поддержки сообщества пользователей Azure](https://azure.microsoft.com/support/community/).

* Подключитесь к [@AzureSupport](https://twitter.com/azuresupport) — официальной учетной записи Microsoft Azure. Она помогает оптимизировать работу пользователей благодаря возможности доступа к ресурсам сообщества Azure (ответы на вопросы, поддержка и консультации специалистов).

* Если вам нужна дополнительная помощь, отправьте запрос в службу поддержки на [портале Azure](https://portal.azure.com/?#blade/Microsoft_Azure_Support/HelpAndSupportBlade/). Выберите **Поддержка** в строке меню или откройте центр **Справка и поддержка**. Дополнительные сведения см. в статье [Создание запроса на поддержку Azure](https://docs.microsoft.com/azure/azure-portal/supportability/how-to-create-azure-support-request). Доступ к управлению подписками и поддержкой выставления счетов уже включен в вашу подписку Microsoft Azure, а техническая поддержка предоставляется в рамках одного из [планов Службы поддержки Azure](https://azure.microsoft.com/support/plans/).
