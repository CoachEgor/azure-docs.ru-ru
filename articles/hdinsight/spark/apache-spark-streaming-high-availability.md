---
title: Создание высокодоступных заданий потоковой передачи Spark в YARN в Azure HDInsight
description: Как настроить потоковую передачу Spark для сценария с высокой доступностью.
ms.service: hdinsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 01/26/2018
ms.openlocfilehash: 79a36ad39284dc66467ba7c500a363668f78b893
ms.sourcegitcommit: 44a85a2ed288f484cc3cdf71d9b51bc0be64cc33
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2019
ms.locfileid: "64720662"
---
# <a name="create-high-availability-apache-spark-streaming-jobs-with-yarn"></a>Создание в YARN заданий потоковой передачи Apache Spark с высоким уровнем доступности

Потоковая передача [Apache Spark](https://spark.apache.org/) дает возможность реализовывать масштабируемые отказоустойчивые приложения с высокой пропускной способностью для обработки потоков данных. Вы можете подключить приложения потоковой передачи Spark в кластере HDInsight Spark к ряду источников данных, таких как Центры событий Azure, Центр Интернета вещей Azure, [Apache Kafka](https://kafka.apache.org/), [Apache Flume](https://flume.apache.org/), Twitter, [ZeroMQ](http://zeromq.org/), незащищенные сокеты TCP. Можно также отслеживать изменения в файловой системе [Apache Hadoop HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html). Потоковая передача Spark поддерживает отказоустойчивость с гарантией того, что любое указанное событие обрабатывается один раз даже в случае сбоя узла.

Потоковая передача Spark создает долго выполняющиеся задания, в течение которых можно применить преобразования к данным, а затем передать результаты в файловые системы, базы данных, панели мониторинга и консоль. При такой передаче выполняется обработка микропакетов данных — сначала выполняется сбор пакета событий через определенный интервал времени, а затем этот пакет отправляется на обработку и формирование выходных результатов. Интервалы времени для обработки пакета обычно определяются в долях секунды.

![Потоковая передача Spark](./media/apache-spark-streaming-high-availability/spark-streaming.png)

## <a name="dstreams"></a>Потоки DStream

Потоковая передача Spark представляет непрерывный поток данных с использованием *дискретизированного потока* — DStream. Этот поток можно создать из источников входных данных, таких как Центры событий или Kafka, либо путем применения преобразований в другом потоке DStream. При получении события в приложении потоковой передачи Spark оно сохраняется надежным способом, — данные события реплицируются, обеспечивая создание копий на нескольких узлах. Благодаря этому сбой какого-либо узла не приведет к потере события.

Ядро Spark использует *устойчивые распределенные наборы данных* (RDD). Эти наборы данных распределяют данные по нескольким узлам кластера, где каждый узел обычно хранит свои данные в памяти для повышения производительности. Каждый набор данных RDD представляет события, собранные за интервал пакетной обработки. По истечении интервала пакетной обработки потоковая передача Spark формирует новый набор данных RDD со всеми данными, созданными за этот интервал. Этот непрерывный набор RDD собирается в поток DStream. Приложение потоковой передачи Spark обрабатывает данные, хранящиеся в каждом наборе данных RDD в пакете.

![Поток DStream Spark](./media/apache-spark-streaming-high-availability/DStream.png)

## <a name="spark-structured-streaming-jobs"></a>Задания структурированной потоковой передачи Spark

Структурированная потоковая передача Spark была представлена в Spark 2.0 как механизм аналитики для структурированных данных потоковой передачи. В структурированной потоковой передаче Spark используются API механизма пакетной обработки SparkSQL. Как обычная потоковая передача Spark, структурированная потоковая передача выполняет вычисления для непрерывно поступающих микропакетов данных. В структурированной потоковой передаче Spark поток данных представлен в качестве входной таблицы с неограниченным количеством строк. То есть входная таблица продолжает расширяться по мере поступления новых данных. Эта таблица непрерывно обрабатывается с помощью долго выполняющегося запроса, а результаты обработки записываются в выходную таблицу.

![Структурированная потоковая передача Spark](./media/apache-spark-streaming-high-availability/structured-streaming.png)

В структурированной потоковой передаче данные передаются в систему и сразу же поступают во входную таблицу. Вы можете написать запросы для выполнения операций в этой входной таблице. Выходные данные запроса поступают в другую таблицу — таблицу результатов. В таблице результатов содержатся результаты запроса, из которых извлекаются данные для отправки во внешнее хранилище данных, например реляционную базу данных. С помощью *интервала триггера* задается расписание для обработки данных во входной таблице. По умолчанию в структурированной потоковой передаче данные обрабатываются по мере их поступления. Однако можно также настроить триггер для выполнения в течение более длительного интервала, что позволит обрабатывать данные потоковой передачи в пакетах на основе времени. Данные в таблице результатов можно полностью обновлять каждый раз, когда поступают новые данные, благодаря чему таблица будет включать все выходные данные с момента отправки запроса потоковой передачи (*полный режим*) или же содержать только новые данные, поступившие после последней обработки запроса (*режим добавления*).

## <a name="create-fault-tolerant-spark-streaming-jobs"></a>Создание отказоустойчивых заданий потоковой передачи Spark

Чтобы создать высокодоступную среду заданий потоковой передачи Spark, сначала напишите для отдельных заданий код, обеспечивающий их восстановление в случае сбоя. Задания, для которых доступно самостоятельное восстановление, являются отказоустойчивыми.

Наборы данных RDD имеют несколько свойств, которые способствуют высокой доступности и отказоустойчивости заданий потоковой передачи Spark:

* Пакеты входных данных, сохраненные в RDD как поток DStream, автоматически реплицируются в памяти для обеспечения отказоустойчивости.
* Данные, потерянные из-за сбоя рабочего узла, можно восстановить из реплицированных входных данных, сохраненных на разных рабочих узлах, если такие узлы доступны.
* Быстрое восстановление после сбоя может занять не более секунды, так как при восстановлении после сбоев или других ошибок выполняется вычисление в памяти.

### <a name="exactly-once-semantics-with-spark-streaming"></a>Семантика для обработки только один раз в приложении потоковой передачи Spark

Чтобы создать приложение, обрабатывающее каждое событие только один раз, нужно учитывать, как все системные точки отказа перезапускаются после сбоя, а также как избежать потери данных. Семантика обработки только один раз требует, чтобы никакие данные не терялись в какой-либо точке, а обработка сообщений перезапускалась, независимо от того, где произошел сбой. Дополнительные сведения см. в статье [Создание заданий потоковой передачи Spark со строго однократной обработкой событий](apache-spark-streaming-exactly-once.md).

## <a name="spark-streaming-and-apache-hadoop-yarn"></a>Потоковая передача Spark и Apache Hadoop YARN

В HDInsight работа кластера координируется согласователем *Yet Another Resource Negotiator* (YARN). Проектирование заданий потоковой передачи Spark высокого уровня доступности включает методы для потоковой передачи Spark и компонентов YARN.  Ниже приведен пример конфигурации, в которой используется YARN. 

![Архитектура YARN](./media/apache-spark-streaming-high-availability/yarn-arch.png)

В следующих разделах описываются рекомендации по проектированию этой конфигурации.

### <a name="plan-for-failures"></a>Планирование на случай сбоев

Чтобы создать конфигурацию YARN для обеспечения высокого уровня доступности, следует учесть возможные сбои исполнителя или драйвера. Некоторые задания потоковой передачи Spark также имеют требования гарантии в отношении данных, для чего требуется дополнительная конфигурация и настройка. Например, приложение потоковой передачи может включать бизнес-требование, которое заключается в гарантии отсутствия потерь данных, независимо от типа ошибки, произошедшей в системе размещения потоковой передачи или кластере HDInsight.

Если работа **исполнителя** завершается ошибкой, его задачи и получатели автоматически перезапускаются Spark, поэтому изменения конфигурации не требуются.

Однако если происходит сбой **драйвера**, работа его связанных исполнителей также завершается сбоем, что приводит к потере всех полученных блоков и результатов вычислений. Чтобы выполнить восстановление после сбоя драйвера, используйте *создание контрольных точек потока DStream*, как описано в этом [разделе](apache-spark-streaming-exactly-once.md#use-checkpoints-for-drivers). При этом периодически сохраняется *направленный ациклический граф* (DAG) потоков DStream в отказоустойчивое хранилище, например службу хранилища Azure.  Благодаря этому приложение структурированной потоковой передачи Spark может повторно запускать драйвер, работа которого завершилась ошибкой, на основе сведений о контрольной точке.  Повторный запуск такого драйвера приводит к запуску новых исполнителей, а также повторному запуску получателей.

Выполните действия ниже для восстановления драйверов с помощью контрольных точек DStream.

* Настройте автоматический повторный запуск драйвера в YARN с помощью параметра конфигурации `yarn.resourcemanager.am.max-attempts`.
* Настройте каталог контрольных точек в файловой системе, совместимой с HDFS, с помощью `streamingContext.checkpoint(hdfsDirectory)`.
* Реструктурируйте исходный код для выполнения восстановления на основе контрольных точек, например:

    ```scala
        def creatingFunc() : StreamingContext = {
            val context = new StreamingContext(...)
            val lines = KafkaUtils.createStream(...)
            val words = lines.flatMap(...)
            ...
            context.checkpoint(hdfsDir)
        }

        val context = StreamingContext.getOrCreate(hdfsDir, creatingFunc)
        context.start()
    ```

* Настройте восстановление потерянных данных, включив упреждающее протоколирование (WAL) с помощью `sparkConf.set("spark.streaming.receiver.writeAheadLog.enable","true")`, и отключите репликацию в памяти для входящих потоков DStream с помощью `StorageLevel.MEMORY_AND_DISK_SER`.

Подводя итог, скажем, что использование контрольных точек, упреждающего протоколирования (WAL) и надежных получателей позволяет обеспечить восстановление данных "как минимум один раз":

* Одноразовое восстановление данных возможно при условии отсутствия потерь полученных данных и наличия идемпотентных или транзакционных выходных данных.
* Одноразовое восстановление доступно с новым подходом Kafka Direct, где Kafka используется как реплицированный журнал и не используются получатели или упреждающее протоколирование (WAL).

### <a name="typical-concerns-for-high-availability"></a>Высокий уровень доступности и сложности его обеспечения

* Пакетные задания отслеживать проще, чем задания потоковой передачи. Задания потоковой передачи Spark обычно выполняются длительное время, и YARN выполняет статистическую обработку журналов только после завершения задания.  Во время обновления Spark или приложения контрольные точки Spark теряются, поэтому вам нужно очистить каталог контрольных точек во время обновления.

* Настройте такой режим кластера YARN, при котором драйверы запускаются даже в случае сбоя клиента. Чтобы настроить автоматический перезапуск драйверов, выполните команду ниже:

    ```
    spark.yarn.maxAppAttempts = 2
    spark.yarn.am.attemptFailuresValidityInterval=1h
    ```

* У Spark и пользовательского интерфейса потоковой передачи Spark есть настраиваемая система метрик. Вы можете также использовать дополнительные библиотеки, такие как Graphite или Grafana, для загрузки метрик панели мониторинга, например по числу обработанных записей, сборке мусора и использованию памяти для драйвера и исполнителей, общего времени задержки, использованию кластера и т. д. В структурированной потоковой передаче версии 2.1 или выше для сбора дополнительных метрик можно использовать `StreamingQueryListener`.

* Долго выполняющиеся задания необходимо сегментировать.  Когда приложение потоковой передачи Spark отправляется в кластер, необходимо определить очередь YARN, где будет запущено задание. Чтобы отправить долго выполняющиеся задания в отдельные очереди, можно использовать [Планировщик емкости Yarn](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html).

* Корректно завершите работу приложения потоковой передачи. Если известны смещения и все состояние приложения хранится извне, вы можете программным способом остановить приложение потоковой передачи в соответствующем месте. Один из способов — использовать перехватчики потока в Spark, устанавливая флажок внешнего хранилища каждые *n* с. Вы можете также использовать *файл маркера*, который создается в HDFS при запуске приложения и удаляется по завершении его работы. Чтобы выбрать этот вариант, используйте отдельный поток в приложении Spark, вызывающий код, подобный коду ниже:

    ```scala
    streamingContext.stop(stopSparkContext = true, stopGracefully = true)
    // to be able to recover on restart, store all offsets in an external database
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Общие сведения о потоковой передаче Apache Spark](apache-spark-streaming-overview.md)
* [Создание заданий потоковой передачи Apache Spark со строго однократной обработкой событий](apache-spark-streaming-exactly-once.md)
* [Long-running Apache Spark Streaming Jobs on YARN](https://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/) (Долго выполняющиеся задания потоковой передачи Apache Spark в YARN) 
* [Structured Streaming: Fault Tolerant Semantics](https://spark.apache.org/docs/2.1.0/structured-streaming-programming-guide.html#fault-tolerance-semantics) (Структурированная потоковая передача: отказоустойчивая семантика)
* [Discretized Streams: A Fault-Tolerant Model for Scalable Stream Processing](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-259.pdf) (Дискретизированные потоки: отказоустойчивая модель для обработки масштабируемого потока)
