---
title: Высокодоступные задания потоковой передачи Spark в YARN - Azure HDInsight
description: Как настроить потоковую передачу Apache Spark для сценария с высокой доступностью в Azure HDInsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.custom: hdinsightactive
ms.date: 11/29/2019
ms.openlocfilehash: ac51b77e1ffc2b476b0a73dac9b6917552a86ce4
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "74807159"
---
# <a name="create-high-availability-apache-spark-streaming-jobs-with-yarn"></a>Создание в YARN заданий потоковой передачи Apache Spark с высоким уровнем доступности

Потоковая передача [Apache Spark](https://spark.apache.org/) дает возможность реализовывать масштабируемые отказоустойчивые приложения с высокой пропускной способностью для обработки потоков данных. Вы можете подключить приложения Spark Streaming в кластере HDInsight Spark к различным видам источников данных, таким как Azure Event Hubs, Azure IoT Hub, [Apache Kafka,](https://kafka.apache.org/) [Apache Flume,](https://flume.apache.org/)Twitter, [nom ,](http://zeromq.org/)сырые разъемы TCP или мониторинг файловой системы [Apache Hadoop HDFS](https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html) для внесения изменений. Потоковая передача Spark поддерживает отказоустойчивость с гарантией того, что любое указанное событие обрабатывается один раз даже в случае сбоя узла.

Spark Streaming создает длительные задания, в течение которых вы можете применить преобразования к данным, а затем вытолкнуть результаты в файловые системы, базы данных, панели мониторинга и консоль. При такой передаче выполняется обработка микропакетов данных — сначала выполняется сбор пакета событий через определенный интервал времени, а затем этот пакет отправляется на обработку и формирование выходных результатов. Интервалы времени для обработки пакета обычно определяются в долях секунды.

![Потоковая передача Spark](./media/apache-spark-streaming-high-availability/apache-spark-streaming.png)

## <a name="dstreams"></a>Потоки DStream

Потоковая передача Spark представляет непрерывный поток данных с использованием *дискретизированного потока* — DStream. Этот поток можно создать из источников входных данных, таких как Центры событий или Kafka, либо путем применения преобразований в другом потоке DStream. При получении события в приложении потоковой передачи Spark оно сохраняется надежным способом, — данные события реплицируются, обеспечивая создание копий на нескольких узлах. Это гарантирует, что сбой какого-либо одного узла не приведет к потере вашего события.

Ядро Spark использует *устойчивые распределенные наборы данных* (RDD). Эти наборы данных распределяют данные по нескольким узлам кластера, где каждый узел обычно хранит свои данные в памяти для повышения производительности. Каждый набор данных RDD представляет события, собранные за интервал пакетной обработки. По истечении интервала пакетной обработки потоковая передача Spark формирует новый набор данных RDD со всеми данными, созданными за этот интервал. Этот непрерывный набор RDD собирается в поток DStream. Приложение потоковой передачи Spark обрабатывает данные, хранящиеся в каждом наборе данных RDD в пакете.

![Поток DStream Spark](./media/apache-spark-streaming-high-availability/apache-spark-dstream.png)

## <a name="spark-structured-streaming-jobs"></a>Задания структурированной потоковой передачи Spark

Структурированная потоковая передача Spark была представлена в Spark 2.0 как механизм аналитики для структурированных данных потоковой передачи. В структурированной потоковой передаче Spark используются API механизма пакетной обработки SparkSQL. Как и в spark Streaming, Spark Structured Streaming запускает свои вычисления над непрерывно прибывающими микро-пакетами данных. В структурированной потоковой передаче Spark поток данных представлен в качестве входной таблицы с неограниченным количеством строк. То есть входная таблица продолжает расширяться по мере поступления новых данных. Эта таблица непрерывно обрабатывается с помощью долго выполняющегося запроса, а результаты обработки записываются в выходную таблицу.

![Структурированная потоковая передача Spark](./media/apache-spark-streaming-high-availability/structured-streaming.png)

В структурированной потоковой передаче данные передаются в систему и сразу же поступают во входную таблицу. Вы можете написать запросы для выполнения операций в этой входной таблице. Выходные данные запроса поступают в другую таблицу — таблицу результатов. В таблице результатов содержатся результаты запроса, из которых извлекаются данные для отправки во внешнее хранилище данных, например реляционную базу данных. С помощью *интервала триггера* задается расписание для обработки данных во входной таблице. По умолчанию в структурированной потоковой передаче данные обрабатываются по мере их поступления. Однако можно также настроить триггер для выполнения в течение более длительного интервала, что позволит обрабатывать данные потоковой передачи в пакетах на основе времени. Данные в таблице результатов могут обновляться каждый раз, когда подают новые данные, так что они включают все выходные данные с момента начала потокового запроса *(полный режим),* или они могут содержать только новые данные с момента последней обработки запроса *(режим приложения).*

## <a name="create-fault-tolerant-spark-streaming-jobs"></a>Создание отказоустойчивых заданий потоковой передачи Spark

Чтобы создать высокодоступную среду для рабочих мест Spark Streaming, начните с кодирования отдельных заданий для восстановления в случае сбоя. Задания, для которых доступно самостоятельное восстановление, являются отказоустойчивыми.

RDD-сервисы имеют несколько свойств, которые помогают высокодоступным и неисправным Spark Streaming рабочих мест:

* Пакеты входных данных, сохраненные в RDD как поток DStream, автоматически реплицируются в памяти для обеспечения отказоустойчивости.
* Данные, потерянные из-за сбоя работы, могут быть перевычисляться из реплицированных входных данных на разных работниках, при попрочении этих узлов.
* Быстрое восстановление после сбоя может занять не более секунды, так как при восстановлении после сбоев или других ошибок выполняется вычисление в памяти.

### <a name="exactly-once-semantics-with-spark-streaming"></a>Ровно один раз семантика с Spark потокового

Чтобы создать приложение, обрабатывающее каждое событие только один раз, нужно учитывать, как все системные точки отказа перезапускаются после сбоя, а также как избежать потери данных. Ровно после того, как семантика требует, чтобы никакие данные не терялись в любой точке, и что обработка сообщений перезажата, независимо от того, где происходит сбой. Смотрите [Создание Spark потокового задания с точно один раз обработки событий.](apache-spark-streaming-exactly-once.md)

## <a name="spark-streaming-and-apache-hadoop-yarn"></a>Потоковая передача Spark и Apache Hadoop YARN

В HDInsight работа кластера координируется согласователем *Yet Another Resource Negotiator* (YARN). Проектирование заданий потоковой передачи Spark высокого уровня доступности включает методы для потоковой передачи Spark и компонентов YARN.  Ниже приведен пример конфигурации, в которой используется YARN.

![Архитектура YARN](./media/apache-spark-streaming-high-availability/hdi-yarn-architecture.png)

В следующих разделах описываются рекомендации по проектированию этой конфигурации.

### <a name="plan-for-failures"></a>Планирование на случай сбоев

Чтобы создать конфигурацию YARN для обеспечения высокого уровня доступности, следует учесть возможные сбои исполнителя или драйвера. Некоторые задания потоковой передачи Spark также имеют требования гарантии в отношении данных, для чего требуется дополнительная конфигурация и настройка. Например, приложение потоковой передачи может включать бизнес-требование, которое заключается в гарантии отсутствия потерь данных, независимо от типа ошибки, произошедшей в системе размещения потоковой передачи или кластере HDInsight.

Если **исполнитель** выходит из строя, его задачи и приемники перезапускаются Spark автоматически, поэтому изменение конфигурации не требуется.

Однако если происходит сбой **драйвера**, работа его связанных исполнителей также завершается сбоем, что приводит к потере всех полученных блоков и результатов вычислений. Чтобы оправиться от отказа драйвера, используйте *контрольно-пропускную точку DStream,* как описано в [заданиях Create Spark Streaming с точно йежеобработкой событий.](apache-spark-streaming-exactly-once.md#use-checkpoints-for-drivers) При этом периодически сохраняется *направленный ациклический граф* (DAG) потоков DStream в отказоустойчивое хранилище, например службу хранилища Azure.  Благодаря этому приложение структурированной потоковой передачи Spark может повторно запускать драйвер, работа которого завершилась ошибкой, на основе сведений о контрольной точке.  Повторный запуск такого драйвера приводит к запуску новых исполнителей, а также повторному запуску получателей.

Выполните действия ниже для восстановления драйверов с помощью контрольных точек DStream.

* Настройте автоматический повторный запуск драйвера в YARN с помощью параметра конфигурации `yarn.resourcemanager.am.max-attempts`.
* Настройте каталог контрольных точек в файловой системе, совместимой с HDFS, с помощью `streamingContext.checkpoint(hdfsDirectory)`.
* Реструктурируйте исходный код для выполнения восстановления на основе контрольных точек, например:

    ```scala
        def creatingFunc() : StreamingContext = {
            val context = new StreamingContext(...)
            val lines = KafkaUtils.createStream(...)
            val words = lines.flatMap(...)
            ...
            context.checkpoint(hdfsDir)
        }

        val context = StreamingContext.getOrCreate(hdfsDir, creatingFunc)
        context.start()
    ```

* Настройте восстановление потерянных данных, включив упреждающее протоколирование (WAL) с помощью `sparkConf.set("spark.streaming.receiver.writeAheadLog.enable","true")`, и отключите репликацию в памяти для входящих потоков DStream с помощью `StorageLevel.MEMORY_AND_DISK_SER`.

Подводя итоги, используя контрольно-пропускные пункты и надежные приемники WAL, вы сможете обеспечить восстановление данных «по крайней мере один раз»:

* Ровно один раз, до тех пор, пока полученные данные не потеряны и выходы являются либо идемпотентными, либо транзакционными.
* Ровно один раз, с новым подходом Kafka Direct, который использует Kafka как реплицированный журнал, а не с помощью приемников или WALs.

### <a name="typical-concerns-for-high-availability"></a>Высокий уровень доступности и сложности его обеспечения

* Более сложно контролировать рабочие места потоковой передачи, чем пакетные задания. Задания потоковой передачи Spark обычно выполняются длительное время, и YARN выполняет статистическую обработку журналов только после завершения задания.  Во время обновления Spark или приложения контрольные точки Spark теряются, поэтому вам нужно очистить каталог контрольных точек во время обновления.

* Настройте такой режим кластера YARN, при котором драйверы запускаются даже в случае сбоя клиента. Чтобы настроить автоматический перезапуск драйверов, выполните команду ниже:

    ```
    spark.yarn.maxAppAttempts = 2
    spark.yarn.am.attemptFailuresValidityInterval=1h
    ```

* У Spark и пользовательского интерфейса потоковой передачи Spark есть настраиваемая система метрик. Вы также можете использовать дополнительные библиотеки, такие как Graphite/Grafana, для загрузки метрик приборной панели, таких как "обработанные записи num", "использование памяти/GC на драйвере & исполнителей", "полная задержка", "использование кластера" и так далее. В структурированной потоковой передаче версии 2.1 или выше для сбора дополнительных метрик можно использовать `StreamingQueryListener`.

* Долго выполняющиеся задания необходимо сегментировать.  Когда приложение потоковой передачи Spark отправляется в кластер, необходимо определить очередь YARN, где будет запущено задание. Чтобы отправить долго выполняющиеся задания в отдельные очереди, можно использовать [Планировщик емкости Yarn](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html).

* Корректно завершите работу приложения потоковой передачи. Если известны смещения и все состояние приложения хранится извне, вы можете программным способом остановить приложение потоковой передачи в соответствующем месте. Один из способов — использовать перехватчики потока в Spark, устанавливая флажок внешнего хранилища каждые *n* с. Вы можете также использовать *файл маркера*, который создается в HDFS при запуске приложения и удаляется по завершении его работы. Чтобы выбрать этот вариант, используйте отдельный поток в приложении Spark, вызывающий код, подобный коду ниже:

    ```scala
    streamingContext.stop(stopSparkContext = true, stopGracefully = true)
    // to be able to recover on restart, store all offsets in an external database
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Общие сведения о потоковой передаче Apache Spark](apache-spark-streaming-overview.md)
* [Создание заданий потоковой передачи Apache Spark с точно йебликой обработки событий](apache-spark-streaming-exactly-once.md)
* [Long-running Apache Spark Streaming Jobs on YARN](https://mkuthan.github.io/blog/2016/09/30/spark-streaming-on-yarn/) (Долго выполняющиеся задания потоковой передачи Apache Spark в YARN)
* [Structured Streaming: Fault Tolerant Semantics](https://spark.apache.org/docs/2.1.0/structured-streaming-programming-guide.html#fault-tolerance-semantics) (Структурированная потоковая передача: отказоустойчивая семантика)
* [Discretized Streams: A Fault-Tolerant Model for Scalable Stream Processing](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-259.pdf) (Дискретизированные потоки: отказоустойчивая модель для обработки масштабируемого потока)
