---
title: Оптимизация использования памяти в Apache Spark — Azure HDInsight
description: Сведения о том, как оптимизировать использование памяти в Apache Spark на базе Azure HDInsight.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.date: 05/20/2020
ms.custom: contperfq1
ms.openlocfilehash: 056060f8b94747651c78c757150d5e5a5982c7af
ms.sourcegitcommit: afa1411c3fb2084cccc4262860aab4f0b5c994ef
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/23/2020
ms.locfileid: "88757784"
---
# <a name="memory-usage-optimization-for-apache-spark"></a>Оптимизация использования памяти для Apache Spark

В этой статье описано, как оптимизировать управление памятью для кластера Apache Spark, чтобы обеспечить наилучшую производительность в Azure HDInsight.

## <a name="overview"></a>Обзор

Spark работает путем размещения данных в памяти. Поэтому управление ресурсами памяти является ключевым аспектом оптимизации выполнения заданий Spark.  Есть несколько методов, которые можно применить для эффективного использования памяти кластера.

* В рамках стратегии секционирования рекомендуется выбирать небольшие секции данных и учитывать размер данных, типы и распределение.
* Лучше ознакомиться с более новой и эффективной [`Kryo data serialization`](https://github.com/EsotericSoftware/kryo), а не использовать стандартную сериализацию Java.
* Рекомендуется использовать YARN, так как можно разделить `spark-submit` по пакету.
* Отслеживайте и настраивайте параметры конфигурации Spark.

Для справки структура памяти Spark и некоторые основные параметры памяти исполнителя показаны на рисунке ниже.

## <a name="spark-memory-considerations"></a>Рекомендации по использованию памяти Spark

Если вы используете Apache Hadoop YARN, эта платформа управляет объемом памяти, используемой всеми контейнерами на каждом узле Spark.  На схеме ниже показаны ключевые объекты и их связи.

![Управление памятью Spark в YARN](./media/apache-spark-perf/apache-yarn-spark-memory.png)

При получении сообщений о нехватке памяти сделайте следующее:

* Просмотрите операции перемешивания при управлении группами обеспечения доступности баз данных. Ограничьте их путем снижения на стороне сопоставления, выполните предварительное секционирование (или разбиение на группы) исходных данных, увеличьте объем операций перемешивания для отдельных процессов и сократите объем отправляемых данных.
* Выберите `ReduceByKey` с фиксированным объемом памяти, а не `GroupByKey`, который обеспечивает статистические функции, управление окнами и другие возможности, но включает неограниченный объем памяти.
* Выберите `TreeReduce`, который в основном обрабатывает исполнителей или секции, а не `Reduce`, который в основном обрабатывает драйвер.
* Используйте кадры данных, а не объекты устойчивого распределенного набора данных более низкого уровня.
* Создайте типы ComplexTypes, инкапсулирующие действия, такие как "Первые N", различные статистические функции или операции управления окнами.

Дополнительные инструкции по устранению неполадок см. в статье [Исключений OutOfMemoryError для Apache Spark в Azure HDInsight](apache-spark-troubleshoot-outofmemory.md).

## <a name="next-steps"></a>Дальнейшие действия

* [Оптимизация обработки данных для Apache Spark](optimize-cluster-configuration.md)
* [Оптимизация хранения данных для Apache Spark](optimize-data-storage.md)
* [Оптимизация конфигурации кластера для Apache Spark](optimize-cluster-configuration.md)
