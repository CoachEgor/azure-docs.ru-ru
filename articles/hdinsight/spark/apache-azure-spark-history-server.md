---
title: Расширенный сервер журнала Spark для отладки приложений — Azure HDInsight
description: 'Отладка и диагностика приложений Spark с использованием расширенного сервера журнала Spark: Azure HDInsight'
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: jasonh
ms.service: hdinsight
ms.topic: conceptual
ms.custom: hdinsightactive,hdiseo17may2017
ms.date: 11/25/2019
ms.openlocfilehash: 7e9ab0e41086a4c9478f95c5a56754640feeab4e
ms.sourcegitcommit: c31dbf646682c0f9d731f8df8cfd43d36a041f85
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/27/2019
ms.locfileid: "74561831"
---
# <a name="use-extended-apache-spark-history-server-to-debug-and-diagnose-apache-spark-applications"></a>Отладка и диагностика приложений Apache Spark с использованием расширенного сервера журнала Apache Spark

Эта статья содержит рекомендации по использованию расширенного сервера журнала Apache Spark для отладки и диагностики готовых и запущенных приложений Spark. Расширение включает вкладки "данные" и "график" и вкладку "Диагностика". На вкладке **данные** пользователи могут проверить входные и выходные данные задания Spark. На вкладке **Граф** пользователи могут проверить поток данных и воспроизвести граф задания. На вкладке **Диагностика** пользователь может ссылаться на **неравномерное распределение данных**, **отклонение по времени**и **Анализ использования исполнителя**.

## <a name="get-access-to-apache-spark-history-server"></a>Доступ к серверу журнала Apache Spark

Сервер журнала Apache Spark — это пользовательский веб-интерфейс для готовых и запущенных приложений Spark.

### <a name="open-the-apache-spark-history-server-web-ui-from-azure-portal"></a>Открытие пользовательского веб-интерфейса сервера журнала Apache Spark на портале Azure

1. Откройте кластер Spark на [портале Azure](https://portal.azure.com/). Дополнительные сведения см. в разделе [Отображение кластеров](../hdinsight-administer-use-portal-linux.md#showClusters).
2. На **панели мониторинга кластера**выберите **сервер журнала Spark**. При появлении запроса введите учетные данные администратора для кластера Spark.

    ![Запуск сервера журнала Spark на портале](./media/apache-azure-spark-history-server/azure-portal-dashboard-spark-history.png "Сервер журнала Spark")

### <a name="open-the-spark-history-server-web-ui-by-url"></a>Открытие пользовательского веб-интерфейса сервера журнала Spark по URL-адресу

Откройте сервер журнала Spark, перейдя по адресу `https://CLUSTERNAME.azurehdinsight.net/sparkhistory`, где ИМЯ_КЛАСТЕРА — это имя кластера Spark.

Веб-интерфейс сервера журнала Spark может выглядеть следующим образом:

![Сервер журнала HDInsight Spark](./media/apache-azure-spark-history-server/hdinsight-spark-history-server.png)

## <a name="data-tab-in-spark-history-server"></a>Вкладка "Данные" на сервере журнала Spark

Выберите идентификатор задания, а затем в меню инструментов выберите пункт **данные** , чтобы получить представление данных.

+ Проверьте **входные данные**, **выходные данные**и **операции с таблицами** , выбирая вкладки отдельно.

    ![Данные для вкладок приложения Spark](./media/apache-azure-spark-history-server/apache-spark-data-tabs.png)

+ Скопируйте все строки, нажав кнопку **Копировать**.

    ![Данные для копирования приложения Spark](./media/apache-azure-spark-history-server/apache-spark-data-copy.png)

+ Сохраните все данные как CSV-файл, выбрав кнопку **CSV**.

    ![Данные для сохранения приложения Spark](./media/apache-azure-spark-history-server/apache-spark-data-save.png)

+ Выполните поиск, введя ключевые слова в поле **Поиск**. Результат поиска сразу же отобразится.

    ![Данные для поиска приложений Spark](./media/apache-azure-spark-history-server/apache-spark-data-search.png)

+ Выберите заголовок столбца для сортировки таблицы, щелкните знак «плюс», чтобы развернуть строку, чтобы отобразить дополнительные сведения, или щелкните знак «минус», чтобы свернуть строку.

    ![Данные для таблицы приложений Spark](./media/apache-azure-spark-history-server/apache-spark-data-table.png)

+ Загрузить один файл, нажав кнопку **частично загрузить** в правой части, затем выбранный файл будет скачан в локальную папку, если файл больше не существует, откроется новая вкладка, в которой будут показаны сообщения об ошибках.

    ![Данные для строки скачивания приложения Spark](./media/apache-azure-spark-history-server/sparkui-data-download-row.png)

+ Скопируйте полный или относительный путь, выбрав пункт **Копировать полный путь** или **Копировать относительный путь**, которые развертываются из меню загрузки. Для файлов хранилища Azure Data Lake **откройте в обозреватель службы хранилища Azure** запустит обозреватель службы хранилища Azure и перейдите к папке при входе.

    ![Данные для пути копирования приложения Spark](./media/apache-azure-spark-history-server/sparkui-data-copy-path.png)

+ Выберите номер под таблицей для навигации по страницам, если на одной странице слишком много строк.

    ![Страница "данные для приложения Spark"](./media/apache-azure-spark-history-server/apache-spark-data-page.png)

+ Наведите указатель на вопросительный знак рядом с полем данные, чтобы отобразить подсказку, или выберите вопросительный знак для получения дополнительных сведений.

    ![Дополнительные сведения о данных для приложения Spark](./media/apache-azure-spark-history-server/sparkui-data-more-info.png)

+ Отправьте отзыв о проблемах, щелкнув **Provide us feedback** (Оставьте отзыв).

    ![Граф Spark снова предоставляет нам отзыв](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)

## <a name="graph-tab-in-apache-spark-history-server"></a>Вкладка "Граф" на сервере журнала Apache Spark

Выберите идентификатор задания, а затем щелкните **Граф** в меню средств, чтобы получить представление графа задания.

+ Ознакомьтесь с обзором задания на созданном графе задания.

+ По умолчанию отображаются все задания. Их можно отфильтровать по **идентификатору задания**.

    ![Идентификатор задания приложения Spark и графа заданий](./media/apache-azure-spark-history-server/apache-spark-graph-jobid.png)

+ По умолчанию выбрано значение **Выполнение**. Пользователь может проверить поток данных, выбрав **Read/Written** (Прочитано и записано) в раскрывающемся списке **Отображать**.

    ![Отображение приложения Spark и графа заданий](./media/apache-azure-spark-history-server/sparkui-graph-display.png)

    Узел графа отображается цветом, который показывает тепловую карту.

    ![Приложение Spark и тепловой карты графа заданий](./media/apache-azure-spark-history-server/sparkui-graph-heatmap.png)

+ Воспроизводите задание, нажав кнопку **Воспроизведение** и прекращайте работу в любое время, нажав кнопку "Закрыть". Задача отображается в определенном цвете для отображения разных состояний при воспроизведении:

    |Цвет |Описание |
    |---|---|
    |Зеленый|задание успешно выполнено.|
    |Orange|Экземпляры задач, которые завершились ошибкой, но не влияют на окончательный результат задания. Эти задачи дублируют или повторно выполняют экземпляры, которые могут быть успешно выполнены позже.|
    |Синий|задача выполняется.|
    |Белый|задача ожидает выполнения или пропущен этап.|
    |Красный|не удалось выполнить задачу.|

    ![Образец цвета для приложения и задания Spark, выполнение](./media/apache-azure-spark-history-server/sparkui-graph-color-running.png)

    Пропущенный шаг отображается белым цветом.
    Пример цвета диаграммы приложения и задания Spark ![, пропустить](./media/apache-azure-spark-history-server/sparkui-graph-color-skip.png)

    ![Пример цвета для приложения Spark и графа заданий, сбой](./media/apache-azure-spark-history-server/sparkui-graph-color-failed.png)

    > [!NOTE]  
    > Допускается воспроизведение для каждого задания. В незавершенном задании воспроизведение не поддерживается.

+ Прокручивайте колесико мыши, чтобы увеличить или уменьшить граф задания, или нажмите кнопку **Масштабировать по размеру**, чтобы масштабировать по размеру экрана.

    ![Масштабирование приложения Spark и графа заданий в соответствии с](./media/apache-azure-spark-history-server/sparkui-graph-zoom2fit.png)

+ Наведите указатель мыши на узел графа, чтобы увидеть подсказку при наличии невыполненных задач, и щелкните этап, чтобы открыть страницу этапа.

    ![Подсказка для приложения Spark и графа заданий](./media/apache-azure-spark-history-server/sparkui-graph-tooltip.png)

+ На вкладке "Граф" задания на этапах будут отображаться подсказки и маленькие значки при наличии задач, соответствующих условиям ниже:
  + Неравномерное распределение данных: объем считанных данных больше среднего объема считанных данных всех задач на этом этапе в два раза и больше 10 МБ.
  + Неравномерное распределение времени: время выполнения больше среднего времени выполнения всех задач внутри этого этапа в два раза и больше двух минут.

    ![Значок рассогласования для приложения Spark и графа заданий](./media/apache-azure-spark-history-server/sparkui-graph-skew-icon.png)

+ На узле графа задания будут отображаться следующие сведения о каждом этапе:
  + Идентификатор.
  + Имя или описание.
  + Общее количество задач.
  + Чтение данных: сумма размера входных данных и размер данных чтения в случайном порядке.
  + Запись данных: сумма размера выходных данных и размер данных записи в случайном порядке.
  + Время выполнения: время между временем начала первой попытки и временем завершения последней попытки.
  + Количество строк: сумма входных записей, выходных записей, операций чтения и записи в случайном порядке.
  + Ход выполнения.

    > [!NOTE]  
    > По умолчанию на узле графа задания отображаются данные о последней попытке каждого этапа (за исключением времени выполнения этапа), но во время воспроизведения на узле графа отображаются сведения о каждой попытке.

    > [!NOTE]  
    > Для размера данных чтения и записи мы используем 1 МБ = 1000 КБ = 1000 * 1000 байт.

+ Отправьте отзыв о проблемах, выбрав параметр **отправить нам отзыв**.

    ![Отзывы о приложении Spark и графе заданий](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)

## <a name="diagnosis-tab-in-apache-spark-history-server"></a>Вкладка "Диагностика" на сервере журнала Apache Spark

Выберите идентификатор задания, а затем в меню инструментов выберите **Диагностика** , чтобы получить представление диагностики заданий. Вкладка "Диагностика" содержит разделы **неравномерного распределения данных**, **неравномерного распределения времени** и **анализа использования исполнителей**.

+ Проверьте **отклонение данных**, **отклонения времени**и **Использование исполнителя** , выбрав вкладки соответственно.

    ![Повторная вкладка "неравномерное Спаркуи данных диагностики"](./media/apache-azure-spark-history-server/sparkui-diagnosis-tabs.png)

### <a name="data-skew"></a>Неравномерное распределение данных

Выберите вкладку « **неравномерность данных** ». соответствующие отклоненные задачи отображаются на основе указанных параметров.

+ **Укажите параметры** . в первом разделе отображаются параметры, которые используются для обнаружения неравномерного распределения данных. Встроенное правило: чтение данных задачи более трех раз из числа считанных данных задачи, а чтение данных задачи превышает 10 МБ. Если вы хотите определить собственные правила для задач с отклонением, можно использовать собственные параметры. Соответствующим образом будут обновлены разделы **Skewed Stage** (Этап с отклонением) и **Skew Chart** (Диаграмма с отклонением).

+ **Отклоненный этап** . во втором разделе отображаются этапы, имеющие отклоненные задачи, удовлетворяющие заданным выше критериям. Если в одном этапе имеется несколько отклоненных задач, в таблице отклоненные этапы отображается только наиболее наклоненная задача (например, наибольшие данные для смещения данных).

    ![Вкладка "неравномерность данных диагностики спаркуи"](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section2.png)

+ **Skew Chart** (Диаграмма с отклонением). Если в таблице этапов с отклонением выбрана строка, на диаграмме отобразится больше сведений о распределении задач на основе объема считанных данных и времени выполнения. Задачи с отклонением помечены красным, а обычные — синим. В целях оптимизации производительности на диаграмме отображается не более 100 примеров задач. Сведения о задаче отображаются на правой нижней панели.

    ![спаркуиная диаграмма отклонений для этапа 10](./media/apache-azure-spark-history-server/sparkui-diagnosis-dataskew-section3.png)

### <a name="time-skew"></a>Неравномерное распределение времени

На вкладке **Неравномерное распределение времени** отображаются задачи с отклонением на основе времени выполнения задачи.

+ **Укажите параметры** . в первом разделе отображаются параметры, которые используются для определения смещения времени. По умолчанию для определения смещения времени используется критерий: время выполнения задачи больше трех раз среднего времени выполнения, а время выполнения задачи превышает 30 секунд. Параметры можно изменить в соответствии со своими потребностями. На вкладках **Skewed Stage** (Этап с отклонением) и **Skew Chart** (Диаграмма с отклонением) отображается соответствующая информация об этапах и задачах, как и на вкладке **Неравномерное распределение данных** выше.

+ Выберите **отклонение по времени**, после чего отфильтрованный результат отобразится в разделе **отклоненный этап** в соответствии с параметрами, заданными в разделе **Указание параметров**. Выберите один элемент на **отклоненном этапе** , после чего соответствующая диаграмма будет черновиком в section3, а сведения о задаче отобразятся в правой нижней панели.

    ![Секция отклонения времени диагностики спаркуи](./media/apache-azure-spark-history-server/sparkui-diagnosis-timeskew-section2.png)

### <a name="executor-usage-analysis"></a>Анализ использования исполнителей

Диаграмма анализа использования исполнителей визуализирует фактическое распределение исполнителей и состояние выполнения задания Spark.  

+ Выберите **Анализ использования исполнителей**, затем четыре типа кривых об использовании исполнителя являются черновиками, включая **выделенные исполнители**, **выполняющиеся исполнители**, **простаивающие исполнители**и **Максимальное количество экземпляров исполнителя**. Что касается выделенных исполнителей, каждое событие добавления или удаления исполнителя будет увеличивать или уменьшать количество выделенных исполнителей. Для более подробного сравнения ознакомьтесь с представлением временной шкалы на вкладке "Задания".

    ![Вкладка "исполнители диагностики спаркуи"](./media/apache-azure-spark-history-server/sparkui-diagnosis-executors.png)

+ Выберите значок цвета, чтобы выбрать или отменить выбор соответствующего содержимого во всех черновиках.

    ![Выбор диаграммы для диагностики спаркуи](./media/apache-azure-spark-history-server/sparkui-diagnosis-select-chart.png)

## <a name="faq"></a>Вопросы и ответы

### <a name="1-revert-to-community-version"></a>1. вернуться к версии сообщества

Чтобы вернуться к версии для сообщества, сделайте следующее:

1. Откройте кластер в Ambari.
1. Перейдите в раздел **Spark2** > **configs** , > **Custom Spark2 — значения по умолчанию**.
1. Выберите **Добавить свойство...** , добавьте **Spark. UI. расширение. Enabled = false**, сохраните.
1. Это свойство задает значение **false**.
1. Нажмите кнопку **Сохранить**, чтобы сохранить конфигурацию.

    ![Отключение функции Apache Ambari](./media/apache-azure-spark-history-server/apache-spark-turn-off.png)

1. Выберите **Spark2** в левой панели, в разделе Вкладка **Сводка** выберите **сервер журнала Spark2**.

    ![Представление сводки Apache Ambari Spark2](./media/apache-azure-spark-history-server/apache-spark-restart1.png)

1. Перезапустите сервер журнала, выбрав **перезапустить** **сервер журнала Spark2**.

    ![Перезапуск журнала Spark2 Apache Ambari](./media/apache-azure-spark-history-server/apache-spark-restart2.png)  
1. Обновите веб-интерфейс сервера журнала Spark. Он будет возвращен к версии для сообщества.

### <a name="2-upload-history-server-event"></a>2. Отправка события сервера журнала

Если возникла ошибка сервера журнала, выполните шаги, чтобы указать событие.

1. Скачать событие, нажав кнопку **скачать** в веб-интерфейсе сервера журнала.

    ![Скачивание сервера журнала Spark2](./media/apache-azure-spark-history-server/sparkui-download-event.png)

2. Выберите **отправить нам отзыв** на вкладке данные или граф.

    ![Диаграмма Spark предоставляет нам отзыв](./media/apache-azure-spark-history-server/sparkui-graph-feedback.png)

3. Укажите название и описание ошибки, перетащите ZIP-файл в поле редактирования, а затем нажмите кнопку **Submit new issue** (Отправить новую проблему).

    ![Пример проблемы с файлом Apache Spark](./media/apache-azure-spark-history-server/apache-spark-file-issue.png)

### <a name="3-upgrade-jar-file-for-hotfix-scenario"></a>3. обновление JAR-файла для сценария исправления

Если требуется выполнить обновление с применением исправления, используйте приведенный ниже скрипт, который обновит файл spark-enhancement.jar*.

**upgrade_spark_enhancement.sh**:

   ```bash
    #!/usr/bin/env bash

    # Copyright (C) Microsoft Corporation. All rights reserved.

    # Arguments:
    # $1 Enhancement jar path

    if [ "$#" -ne 1 ]; then
        >&2 echo "Please provide the upgrade jar path."
        exit 1
    fi

    install_jar() {
        tmp_jar_path="/tmp/spark-enhancement-hotfix-$( date +%s )"

        if wget -O "$tmp_jar_path" "$2"; then
            for FILE in "$1"/spark-enhancement*.jar
            do
                back_up_path="$FILE.original.$( date +%s )"
                echo "Back up $FILE to $back_up_path"
                mv "$FILE" "$back_up_path"
                echo "Copy the hotfix jar file from $tmp_jar_path   to $FILE"
                cp "$tmp_jar_path" "$FILE"

                "Hotfix done."
                break
            done
        else    
            >&2 echo "Download jar file failed."
            exit 1
        fi
    }

    jars_folder="/usr/hdp/current/spark2-client/jars"
    jar_path=$1

    if ls ${jars_folder}/spark-enhancement*.jar 1>/dev/null 2>&1;   then
        install_jar "$jars_folder" "$jar_path"
    else
        >&2 echo "There is no target jar on this node. Exit with no action."
        exit 0
    fi
   ```

**Использование**:

`upgrade_spark_enhancement.sh https://${jar_path}`

**Пример**:

`upgrade_spark_enhancement.sh https://${account_name}.blob.core.windows.net/packages/jars/spark-enhancement-${version}.jar`

**Использование bash-файла на портале Azure**

1. Запустите [портал Azure](https://ms.portal.azure.com)и выберите кластер.
2. Завершите [действие скрипта](../hdinsight-hadoop-customize-cluster-linux.md) со следующими параметрами:

    |Свойство |Value |
    |---|---|
    |Тип скрипта|- Custom|
    |Name|упградежар|
    |URI bash-скрипта|`https://hdinsighttoolingstorage.blob.core.windows.net/shsscriptactions/upgrade_spark_enhancement.sh`|
    |Типы узлов|Головной, Рабочий|
    |Параметры|`https://${account_name}.blob.core.windows.net/packages/jars/spark-enhancement-${version}.jar`|

     ![Действие "отправить скрипт" портал Azure](./media/apache-azure-spark-history-server/apache-spark-upload1.png)

## <a name="known-issues"></a>Известные проблемы

+ В настоящее время он работает только для кластера Spark 2,3 и 2,4.

+ Входные и выходные данные, использующие RDD, не будут отображаться на вкладке "данные".

## <a name="next-steps"></a>Дальнейшие действия

+ [Управление ресурсами для кластера Apache Spark в HDInsight](apache-spark-resource-manager.md)
+ [Настройка параметров Apache Spark](apache-spark-settings.md)

## <a name="contact-us"></a>Связаться с нами

Если у вас есть отзывы или возникли проблемы при использовании этого средства, отправьте сообщение по адресу ([hdivstool@microsoft.com](mailto:hdivstool@microsoft.com)).
