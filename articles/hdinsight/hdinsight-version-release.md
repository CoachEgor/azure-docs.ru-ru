---
title: Обзор HDInsight 4.0 в Azure
description: Сравнение функций и ограничений HDInsight 3.6 и HDInsight 4.0, а также рекомендации по обновлению.
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: hrasheed
ms.service: hdinsight
ms.topic: conceptual
ms.date: 04/14/2020
ms.openlocfilehash: 466c47492de9c2fc86f309f4cb74df1ff5411dcb
ms.sourcegitcommit: a6d477eb3cb9faebb15ed1bf7334ed0611c72053
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/08/2020
ms.locfileid: "82929304"
---
# <a name="azure-hdinsight-40-overview"></a>Обзор Azure HDInsight 4.0

Azure HDInsight — одна из самых популярных служб среди корпоративных клиентов для Apache Hadoop и Apache Spark. HDInsight 4,0 — это облачное распределение компонентов Apache Hadoop. Эта статья содержит сведения о последнем выпуске Azure HDInsight и инструкции по обновлению.

## <a name="whats-new-in-hdinsight-40"></a>Что нового в HDInsight 4.0?

### <a name="apache-hive-30-and-low-latency-analytical-processing"></a>Apache Hive 3,0 и аналитическая обработка с низкой задержкой

Apache Hive аналитическая обработка с низкой задержкой (LLAP) использует постоянные серверы запросов и кэширование в памяти. Этот процесс позволяет получать результаты быстрого запроса SQL к данным в удаленном облачном хранилище. Hive LLAP использует набор постоянных управляющих программ, выполняющих фрагменты запросов Hive. Выполнение запросов в LLAP аналогично выполнению запросов в Hive без LLAP: рабочие задачи выполняются в управляющих программах LLAP, а не в контейнерах.

Преимущества Hive LLAP:

* Возможность глубокой аналитики SQL без ущерба для производительности и гибкости. Например, сложные объединения, вложенные запросы, функции для работы с окнами, сортировка, пользовательские функции и сложные агрегаты.

* Интерактивные запросы к данным в том же хранилище, в котором выполняется их подготовка, что исключает необходимость перемещать данные из хранилища в другую подсистему для аналитической обработки.

* Кэширование результатов запроса позволяет повторно использовать ранее вычисленные результаты запроса. Этот кэш экономит время и ресурсы, затраченные на выполнение задач кластера, необходимых для запроса.

### <a name="hive-dynamic-materialized-views"></a>Динамические материализованные представления Hive

Hive теперь поддерживает динамические материализованные представления или предварительные вычисления соответствующих сводок. Представления ускоряют обработку запросов в хранилищах данных. Материализованные представления могут храниться в собственном коде в Hive и прозрачно использовать ускорение обработки LLAP.

### <a name="hive-transactional-tables"></a>Транзакционные таблицы Hive

HDI 4,0 включает Apache Hive 3. Для Hive 3 требуется атомарность, согласованность, изоляция и устойчивость для транзакционных таблиц, которые находятся в хранилище Hive. Доступ к совместимым с ACID таблицам и табличным данным и управление ими осуществляет Hive. Данные в таблицах создания, извлечения, обновления и удаления (CRUD) должны быть в формате оптимизированного столбца строк (ORC). Таблицы только для вставки поддерживают все форматы файлов.

* В ACID версии 2 повышена производительность формата хранения и подсистемы выполнения.

* Компонент ACID включен по умолчанию для обеспечения полной поддержки обновления данных.

* Улучшенные возможности ACID дают возможность обновлять и удалять данные на уровне строки.

* Снижение производительности при этом отсутствует.

* Группирование не требуется.

* Служба Spark может считывать и записывать данные в совместимых с ACID таблицах Hive с помощью соединителя хранилища данных Hive.

Узнайте больше об [Apache Hive 3](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/hive-overview/content/hive_whats_new_in_this_release_hive.html).

### <a name="apache-spark"></a>Apache Spark

Apache Spark получает обновляемые таблицы и транзакции ACID с помощью соединителя хранилища данных Hive. Соединитель хранилища данных Hive позволяет зарегистрировать транзакционные таблицы Hive в качестве внешних таблиц в Spark для получения доступа ко всем функциям транзакций. Предыдущие версии поддерживали только оперирование секциями таблиц. Соединитель хранилища Hive также поддерживает потоковые кадры данных.  В ходе этого процесса выполняется потоковая передача операций чтения и записи в таблицы Hive в виде транзакций и потоковой передачи из Spark.

Исполнители Spark могут подключаться непосредственно к управляющим программам Hive LLAP, чтобы извлекать и обновлять данные посредством транзакций, что позволяет Hive сохранить контроль над данными.

Apache Spark в HDInsight 4.0 поддерживает следующие сценарии:

* Обучение моделей машинного обучения с помощью транзакционной таблицы, используемой для создания отчетов.
* Безопасное добавление столбцов из Spark ML в таблицу Hive с помощью транзакций ACID.
* Запуск задания потоковой передачи Spark в канале изменений из таблицы потоковой передачи Hive.
* Создание ORC-файлов непосредственно в задании структурированной потоковой передачи Spark.

Вам больше не нужно беспокоиться о случайной попытке доступа к транзакционным таблицам Hive непосредственно из Spark. Это приводит к непротиворечивым результатам, дублированию данных или повреждению данных. В HDInsight 4.0 таблицы Spark и таблицы Hive хранятся в отдельных хранилищах метаданных. Используйте соединитель хранилища данных Hive, чтобы явно регистрировать транзакционные таблицы Hive как внешние таблицы Spark.

Узнайте больше об [Apache Spark](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/spark-overview/content/analyzing_data_with_apache_spark.html).

### <a name="apache-oozie"></a>Apache Oozie

Apache Oozie 4.3.1 входит в состав HDI 4.0 со следующими изменениями:

* Oozie больше не выполняет действия Hive. Интерфейс командной строки Hive удален и заменен BeeLine.

* Вы можете исключить нежелательные зависимости из общей библиотеки, добавив шаблон исключения в файл **job.properties**.

Узнайте больше об [Apache Oozie](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/release-notes/content/patch_oozie.html).

## <a name="how-to-upgrade-to-hdinsight-40"></a>Как выполнить обновление до HDInsight 4.0

Тщательно протестируйте компоненты перед внедрением последней версии в рабочей среде. Для начала процесса обновления можно использовать HDInsight 4,0. HDInsight 3,6 является параметром по умолчанию для предотвращения случайного мишапс.

Нет поддерживаемого варианта обновления из предыдущих версий HDInsight в HDInsight 4,0. Так как форматы данных хранилище метаданных и BLOB-объектов изменились, 4,0 несовместима с предыдущими версиями. Важно, чтобы новая среда HDInsight 4,0 была отделена от текущей рабочей среды. При развертывании HDInsight 4,0 в текущей среде хранилище метаданных будет безвозвратно обновлен.  

## <a name="limitations"></a>Ограничения

* HDInsight 4,0 не поддерживает MapReduce для Apache Hive. Вместо этого используйте Apache Tez. Узнайте больше об [Apache Tez](https://tez.apache.org/).
* HDInsight 4,0 не поддерживает Apache Storm.
* В HDInsight 4.0 больше не используется представление Hive.
* Интерпретатор оболочки в Apache Zeppelin не поддерживается в кластерах Spark и интерактивных запросов.
* Вы не можете *запретить* использование LLAP в кластере Spark LLAP. LLAP можно только выключить.
* Azure Data Lake Storage 2-го поколения не поддерживает сохранение записных книжек Juypter в кластере Spark.
* Apache Pig работает на Tez по умолчанию, однако его можно изменить на MapReduce.
* Интеграция Spark SQL Ranger для безопасности строк и столбцов устарела
* Spark 2,4 и Kafka 2,1 доступны в HDInsight 4,0, поэтому Spark 2,3 и Kafka 1,1 больше не поддерживаются. Мы рекомендуем использовать Spark 2,4 & Kafka 2,3 и более поздних версий в HDInsight 4,0.


## <a name="next-steps"></a>Дальнейшие действия

* [Документация по Azure HDInsight](index.yml)
* [Заметки о выпуске](hdinsight-release-notes.md)
