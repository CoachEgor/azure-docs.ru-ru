---
title: Обзор HDInsight 4.0 в Azure
description: Сравнение функций и ограничений HDInsight 3.6 и HDInsight 4.0, а также рекомендации по обновлению.
ms.service: hdinsight
author: hrasheed-msft
ms.author: hrasheed
ms.reviewer: hrasheed
ms.topic: conceptual
ms.date: 04/15/2019
ms.openlocfilehash: 74cd6a6919db1c01535fb984d1e8e0d0ad2d5ade
ms.sourcegitcommit: 7c5a2a3068e5330b77f3c6738d6de1e03d3c3b7d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/11/2019
ms.locfileid: "70879325"
---
# <a name="azure-hdinsight-40-overview"></a>Обзор Azure HDInsight 4.0

Azure HDInsight является одной из самых популярных служб среди корпоративных клиентов для аналитики с открытым кодом Apache Hadoop и Apache Spark в Azure. HDInsight 4,0 — это облачное распределение компонентов Apache Hadoop. Эта статья содержит сведения о последнем выпуске Azure HDInsight и инструкции по обновлению.

## <a name="whats-new-in-hdinsight-40"></a>Что нового в HDInsight 4.0?

### <a name="apache-hive-30-and-llap"></a>Apache Hive 3.0 и LLAP

Для аналитической обработки с низкой задержкой (LLAP) Apache Hive используются постоянные серверы запросов и выполняющееся в памяти кэширование. Это ускоряет выполнение SQL-запросов к данным, размещенным в удаленном облачном хранилище. Hive LLAP использует набор постоянных управляющих программ, которые выполняют фрагментов запросов Hive. Выполнение запросов в LLAP аналогично выполнению запросов в Hive без LLAP: рабочие задачи выполняются в управляющих программах LLAP, а не в контейнерах.

Преимущества Hive LLAP:

* Возможность выполнять глубокий анализ SQL, в том числе сложные соединения, вложенные запросы, функции управления окнами, сортировку, определяемые пользователем функции и сложные статистические вычисления, без ущерба для производительности и масштабируемости.

* Интерактивные запросы к данным в том же хранилище, в котором выполняется их подготовка, что исключает необходимость перемещать данные из хранилища в другую подсистему для аналитической обработки.

* Кэширование результатов запросов позволяет многократно использовать результаты ранее вычисленных запросов, что экономит время и ресурсы, затрачиваемые на выполнение задач кластера, необходимых для выполнения запроса.

### <a name="hive-dynamic-materialized-views"></a>Динамические материализованные представления Hive

Hive теперь поддерживает динамические материализованные представления, или предварительное вычисление соответствующих сводок. Эту функцию можно использовать для ускорения обработки запросов в хранилищах данных. Материализованные представления могут храниться в собственном коде в Hive и прозрачно использовать ускорение обработки LLAP.

### <a name="hive-transactional-tables"></a>Транзакционные таблицы Hive

HDI 4.0 включает в себя Apache Hive 3, для которого требуется соответствие требованиям к атомарности, согласованности, изоляции и устойчивости (ACID) для транзакционных таблиц, которые размещены в хранилище данных Hive. Доступ к совместимым с ACID таблицам и табличным данным и управление ими осуществляет Hive. Данные в таблицах, поддерживающих операции создания, извлечения, обновления и удаления (CRUD), должны быть представлены в формате ORC, но таблицы только для вставки поддерживают все форматы файлов.

* В ACID версии 2 повышена производительность формата хранения и подсистемы выполнения. 

* Компонент ACID включен по умолчанию для обеспечения полной поддержки обновления данных.

* Улучшенные возможности ACID дают возможность обновлять и удалять данные на уровне строки.

* Снижение производительности при этом отсутствует.

* Группирование не требуется.

* Служба Spark может считывать и записывать данные в совместимых с ACID таблицах Hive с помощью соединителя хранилища данных Hive.

Узнайте больше об [Apache Hive 3](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/hive-overview/content/hive_whats_new_in_this_release_hive.html).

### <a name="apache-spark"></a>Apache Spark

Apache Spark получает обновляемые таблицы и транзакции ACID с помощью соединителя хранилища данных Hive. Соединитель хранилища данных Hive позволяет зарегистрировать транзакционные таблицы Hive в качестве внешних таблиц в Spark для получения доступа ко всем функциям транзакций. Предыдущие версии поддерживали только оперирование секциями таблиц. Соединитель хранилища данных Hive также поддерживает кадры данных потоковой передачи для потоковой передачи операций чтения и записи в транзакционные таблицы и таблицы потоковой передачи Hive из Spark.

Исполнители Spark могут подключаться непосредственно к управляющим программам Hive LLAP, чтобы извлекать и обновлять данные посредством транзакций, что позволяет Hive сохранить контроль над данными.

Apache Spark в HDInsight 4.0 поддерживает следующие сценарии:

* Обучение моделей машинного обучения с помощью транзакционной таблицы, используемой для создания отчетов.
* Безопасное добавление столбцов из Spark ML в таблицу Hive с помощью транзакций ACID.
* Запуск задания потоковой передачи Spark в канале изменений из таблицы потоковой передачи Hive.
* Создание ORC-файлов непосредственно в задании структурированной потоковой передачи Spark.

Вам больше не нужно беспокоиться о случайных попытках доступа к транзакционным таблицам Hive непосредственно из Spark, которые приводят к несогласованным результатам, возникновению повторяющихся данных или повреждению данных. В HDInsight 4.0 таблицы Spark и таблицы Hive хранятся в отдельных хранилищах метаданных. Используйте соединитель хранилища данных Hive, чтобы явно регистрировать транзакционные таблицы Hive как внешние таблицы Spark.

Узнайте больше об [Apache Spark](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/spark-overview/content/analyzing_data_with_apache_spark.html).


### <a name="apache-oozie"></a>Apache Oozie

Apache Oozie 4.3.1 входит в состав HDI 4.0 со следующими изменениями:

* Oozie больше не выполняет действия Hive. Интерфейс командной строки Hive удален и заменен BeeLine.

* Вы можете исключить нежелательные зависимости из общей библиотеки, добавив шаблон исключения в файл **job.properties**.

Узнайте больше об [Apache Oozie](https://docs.hortonworks.com/HDPDocuments/HDP3/HDP-3.0.0/release-notes/content/patch_oozie.html).

## <a name="how-to-upgrade-to-hdinsight-40"></a>Как выполнить обновление до HDInsight 4.0

Как и для любого выпуска основного номера версии, важно тщательно протестировать компоненты перед внедрением последней версии в рабочей среде. Можно начать процесс обновления до HDInsight 4.0, но во избежание случайных сбоев по умолчанию предлагается HDInsight 3.6.

Поддерживаемый способ обновления более ранних версий HDInsight до HDInsight 4.0 отсутствует. Из-за изменения форматов данных в хранилище метаданных и больших двоичных объектах версия HDInsight 4.0 несовместима с предыдущими версиями. Важно отделить новую среду HDInsight 4.0 от текущей рабочей среды. Если развернуть HDInsight 4.0 в текущей среде, хранилище метаданных будет обновлено, и это невозможно будет отменить.  

## <a name="limitations"></a>Ограничения

* HDInsight 4.0 не поддерживает MapReduce для Apache Hive. Вместо этого используйте Apache Tez. Узнайте больше об [Apache Tez](https://tez.apache.org/).
* HDInsight 4.0 не поддерживает Apache Storm. 
* В HDInsight 4.0 больше не используется представление Hive. 
* Интерпретатор оболочки в Apache Zeppelin не поддерживается в кластерах Spark и Interactive Query.
* Вы не можете *запретить* использование LLAP в кластере Spark LLAP. LLAP можно только выключить.
* Azure Data Lake Storage 2-го поколения не поддерживает сохранение записных книжек Juypter в кластере Spark.

## <a name="next-steps"></a>Следующие шаги

* [Документация по Azure HDInsight](index.yml)
* [Заметки о выпуске](hdinsight-release-notes.md)
