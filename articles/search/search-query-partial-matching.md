---
title: Шаблоны соответствия и специальные символы
titleSuffix: Azure Cognitive Search
description: Используйте подстановочные и префиксные запросы для сопоставления целых или частичных терминов в запросе Azure Когнитивный поиск запроса. Шаблоны с фиксированным соответствием, включающие специальные символы, можно разрешить с помощью полного синтаксиса запросов и пользовательских анализаторов.
manager: nitinme
author: HeidiSteen
ms.author: heidist
ms.service: cognitive-search
ms.topic: conceptual
ms.date: 01/14/2020
ms.openlocfilehash: ec1422d03cce78bdd8206f6687a78b63ddf989dc
ms.sourcegitcommit: 3dc1a23a7570552f0d1cc2ffdfb915ea871e257c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 01/15/2020
ms.locfileid: "75989622"
---
# <a name="match-on-patterns-and-special-characters-dashes"></a>Совпадение с шаблонами и специальными символами (тире)

Для запросов, содержащих специальные символы (`-, *, (, ), /, \, =`) или для шаблонов запросов на основе частичных терминов в рамках более крупного термина, обычно требуется выполнить дополнительные действия по настройке, чтобы убедиться, что индекс содержит ожидаемое содержимое, в правильном формате. 

По умолчанию номер телефона, например `+1 (425) 703-6214`, размечен как `"1"`, `"425"`, `"703"`, `"6214"`. Как можно себе представить, при поиске по `"3-62"`частичные термины, включающие тире, произойдет сбой, так как это содержимое фактически не существует в индексе. 

Если необходимо выполнить поиск по частичным строкам или специальным символам, анализатор по умолчанию можно переопределить с помощью пользовательского анализатора, который работает в более простых правилах разметки, сохраняя все условия, необходимые, если строки запроса содержат части термина или Специального буквы. Выполнив шаг назад, подход выглядит следующим образом:

+ Выбор предопределенного анализатора или определение пользовательского анализатора, создающего нужные выходные данные
+ Назначение анализатора полю
+ Построение индекса и тестирование

В этой статье рассматриваются эти задачи. Описанный здесь подход полезен в других сценариях: в качестве основания для сопоставления шаблонов необходимы полные термины и запросы с подстановочными знаками и регулярными выражениями. 

> [!TIP]
> Оценка аналерс — это итеративный процесс, требующий частых перестроение индекса. Этот шаг можно упростить с помощью POST, интерфейсов API для [создания индекса](https://docs.microsoft.com/rest/api/searchservice/create-index), [удаления индекса](https://docs.microsoft.com/rest/api/searchservice/delete-index),[загрузки документов](https://docs.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents)и [поиска документов](https://docs.microsoft.com/rest/api/searchservice/search-documents). Для документов загрузки текст запроса должен содержать небольшой репрезентативный набор данных, который необходимо протестировать (например, поле с номерами телефонов или кодами продуктов). Используя эти API в той же коллекции POST, можно быстро пройти эти шаги.

## <a name="choosing-an-analyzer"></a>Выбор анализатора

При выборе анализатора, создающего маркеры полного термина, доступны следующие анализаторы:

| Анализатор | Расширения функциональности |
|----------|-----------|
| [keyword](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordAnalyzer.html) | Содержимое всего поля размечено как один термин. |
| [whitespace](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/WhitespaceAnalyzer.html) | Разделяется только на пробелы. Термины, содержащие дефисы или другие символы, рассматриваются как один маркер. |
| [Пользовательский анализатор](index-add-custom-analyzers.md) | такую Создание настраиваемого анализатора позволяет указать как лексему, так и фильтр маркеров. Предыдущие Анализаторы должны использоваться "как есть". Настраиваемый анализатор позволяет выбрать используемые маркеры и фильтры маркеров. <br><br>Рекомендуемым сочетанием является лексема [ключевых слов](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordTokenizer.html) с [фильтром маркеров нижнего регистра](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/LowerCaseFilter.html). Само по себе предопределенный [анализатор ключевых слов](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordAnalyzer.html) не использует строчные буквы в верхнем регистре, что может привести к сбою запросов. Пользовательский анализатор предоставляет механизм для добавления фильтра маркеров нижнего регистра. |

Если вы используете средство тестирования веб-API, например POST, можно добавить [вызов RESTful для анализатора тестов](https://docs.microsoft.com/rest/api/searchservice/test-analyzer) , чтобы проверить выходные данные с маркерами. При наличии существующего индекса и поля, содержащего дефисы или частичные термины, можно испытать различные анализаторы для определенных терминов, чтобы узнать, какие токены будут выдаваться.  

1. Проверьте стандартный анализатор, чтобы увидеть, как термины размечены по умолчанию.

   ```json
   {
   "text": "SVP10-NOR-00",
   "analyzer": "standard"
   }
    ```

1. Оцените ответ, чтобы увидеть, как текст размечен в индексе. Обратите внимание, что каждый термин имеет более низкий регистр и разбивается.

    ```json
    {
        "tokens": [
            {
                "token": "svp10",
                "startOffset": 0,
                "endOffset": 5,
                "position": 0
            },
            {
                "token": "nor",
                "startOffset": 6,
                "endOffset": 9,
                "position": 1
            },
            {
                "token": "00",
                "startOffset": 10,
                "endOffset": 12,
                "position": 2
            }
        ]
    }
    ```
1. Измените запрос для использования `whitespace` или анализатора `keyword`:

    ```json
    {
    "text": "SVP10-NOR-00",
    "analyzer": "keyword"
    }
    ```

1. Теперь ответ состоит из одного маркера в верхнем регистре с тире, сохраненным как часть строки. Если необходимо выполнить поиск по шаблону или частичному термину, механизм запросов теперь имеет базу для поиска соответствия.


    ```json
    {

        "tokens": [
            {
                "token": "SVP10-NOR-00",
                "startOffset": 0,
                "endOffset": 12,
                "position": 0
            }
        ]
    }
    ```
> [!Important]
> Имейте в виду, что средства синтаксического анализа запросов часто имеют более низкие регистры в выражении поиска при построении дерева запросов. Если вы используете анализатор, не имеющий текстовых входных данных в нижнем регистре и не получаете ожидаемые результаты, это может быть причиной. Решением является добавление фильтра маркеров лвовер-Case.

## <a name="analyzer-definitions"></a>Определения анализатора
 
Независимо от того, оцениваете анализаторы или перемещаясь с определенной конфигурацией, необходимо указать анализатор для определения поля и, возможно, настроить сам анализатор, если вы не используете встроенный анализатор. При переключении анализаторов обычно требуется перестроить индекс (удалить, повторно создать и перезагрузить). 

### <a name="use-built-in-analyzers"></a>Использование встроенных анализаторов

Встроенные или стандартные анализаторы можно указать по имени в свойстве `analyzer` определения поля, не требующем дополнительной настройки в индексе. В следующем примере показано, как задать анализатор `whitespace` для поля.

```json
    {
      "name": "phoneNumber",
      "type": "Edm.String",
      "key": false,
      "retrievable": true,
      "searchable": true,
      "analyzer": "whitespace"
    }
```
Дополнительные сведения обо всех доступных встроенных анализаторах см. в разделе [стандартный список анализаторов](https://docs.microsoft.com/azure/search/index-add-custom-analyzers#predefined-analyzers-reference). 

### <a name="use-custom-analyzers"></a>Использование пользовательских анализаторов

Если вы используете [Пользовательский анализатор](index-add-custom-analyzers.md), определите его в индексе с помощью определяемого пользователем сочетания анализатора токенфилтер с возможными параметрами конфигурации. Затем сослаться на определение поля так же, как у встроенного анализатора.

Если цель представляет собой разметку для всего термина, рекомендуется использовать пользовательский анализатор, состоящий из **ключевых слов** и **фильтров маркеров нижнего регистра** .

+ Лексема ключевых слов создает один маркер для всего содержимого поля.
+ Фильтр маркеров нижнего регистра преобразует прописные буквы в строчные. Синтаксические анализаторы запросов обычно имеют прописные буквы в верхнем регистре. Нижний регистр хоможенизес входные данные с помощью лексемных терминов.

В следующем примере показан пользовательский анализатор, который предоставляет маркеры ключевых слов и фильтр маркеров нижнего регистра.

```json
{
"fields": [
  {
  "name": "accountNumber",
  "analyzer":"myCustomAnalyzer",
  "type": "Edm.String",
  "searchable": true,
  "filterable": true,
  "retrievable": true,
  "sortable": false,
  "facetable": false
  }
]

"analyzers": [
  {
  "@odata.type":"#Microsoft.Azure.Search.CustomAnalyzer",
  "name":"myCustomAnalyzer",
  "charFilters":[],
  "tokenizer":"keyword_v2",
  "tokenFilters":["lowercase"]
  }
],
"tokenizers":[],
"charFilters": [],
"tokenFilters": []
```

> [!NOTE]
> Маркер `keyword_v2` и фильтр токенов `lowercase` известны системе и используют их конфигурации по умолчанию, поэтому их можно ссылаться по имени, не определяя их первыми.

## <a name="tips-and-best-practices"></a>Советы и рекомендации

### <a name="tune-query-performance"></a>Настройка производительности запросов

Если вы реализуете рекомендуемую конфигурацию, включающую в себя keyword_v2 лексему и фильтр маркеров более низкого регистра, вы можете заметить снижение производительности запросов из-за обработки дополнительных фильтров маркеров для существующих токенов в индексе. 

В следующем примере добавляется [едженграмтокенфилтер](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.html) , чтобы префикс совпадал быстрее. Дополнительные маркеры создаются в 2-25 символах, содержащих символы: (не только MS, MSF, MSFT, MSFT/, MSFT/S, MSFT/SQ, MSFT/SQL). Как можно себе представить, Дополнительная разметка приводит к увеличению индекса.

```json
{
"fields": [
  {
  "name": "accountNumber",
  "analyzer":"myCustomAnalyzer",
  "type": "Edm.String",
  "searchable": true,
  "filterable": true,
  "retrievable": true,
  "sortable": false,
  "facetable": false
  }
]

"analyzers": [
  {
  "@odata.type":"#Microsoft.Azure.Search.CustomAnalyzer",
  "name":"myCustomAnalyzer",
  "charFilters":[],
  "tokenizer":"keyword_v2",
  "tokenFilters":["lowercase", "my_edgeNGram"]
  }
],
"tokenizers":[],
"charFilters": [],
"tokenFilters": [
  {
  "@odata.type":"#Microsoft.Azure.Search.EdgeNGramTokenFilterV2",
  "name":"my_edgeNGram",
  "minGram": 2,
  "maxGram": 25,
  "side": "front"
  }
]
```

### <a name="use-different-analyzers-for-indexing-and-query-processing"></a>Использование различных анализаторов для индексирования и обработки запросов

Анализаторы вызываются во время индексирования и во время выполнения запроса. Обычно используется один и тот же анализатор, но для каждой рабочей нагрузки можно настроить пользовательские анализаторы. Переопределения анализатора указываются в [определении индекса](https://docs.microsoft.com/rest/api/searchservice/create-index) в `analyzers` разделе, а затем указываются на определенные поля. 

Если пользовательский анализ требуется только во время индексирования, можно применить пользовательский анализатор для просто индексирования и продолжить использование стандартного анализатора Lucene (или другого анализатора) для запросов.

Чтобы задать анализ для конкретной роли, можно задать свойства для каждого поля, задав `indexAnalyzer` и `searchAnalyzer` вместо свойства `analyzer` по умолчанию.

```json
"name": "featureCode",
"indexAnalyzer":"my_customanalyzer",
"searchAnalyzer":"standard",
```

### <a name="duplicate-fields-for-different-scenarios"></a>Дублирование полей для различных сценариев

Другой вариант использует назначение анализатора для каждого поля, чтобы оптимизировать для различных сценариев. В частности, можно определить "Феатурекоде" и "Феатурекодережекс" для поддержки обычного полнотекстового поиска в первом и расширенного сопоставления шаблонов во втором.

```json
{
  "name": "featureCode",
  "type": "Edm.String",
  "retrievable": true,
  "searchable": true,
  "analyzer": null
},
{
  "name": "featureCodeRegex",
  "type": "Edm.String",
  "retrievable": true,
  "searchable": true,
  "analyzer": "my_customanalyzer"
},
```

## <a name="next-steps"></a>Дальнейшие действия

В этой статье объясняется, как анализаторы вносят проблемы в запросы и решают проблемы запросов. В качестве следующего шага подробнее рассмотрим анализатор влияния на индексирование и обработку запросов. В частности, рассмотрите возможность использования API анализа текста для возврата выходных данных с маркерами, чтобы вы могли точно увидеть, что создает анализатор для вашего индекса.

+ [Языковые анализаторы](search-language-support.md)
+ [Анализаторы для обработки текста в Azure Когнитивный поиск](search-analyzers.md)
+ [API анализа текста (ОСТАВШАЯся)](https://docs.microsoft.com/rest/api/searchservice/test-analyzer)
+ [Как работает полнотекстовый поиск (Архитектура запросов)](search-lucene-query-architecture.md)