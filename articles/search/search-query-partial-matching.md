---
title: Частичные термины, шаблоны и специальные символы
titleSuffix: Azure Cognitive Search
description: Используйте подстановочные знаки, регулярные выражения и префиксные запросы для сопоставления целых или частичных терминов в запросе Azure Когнитивный поиск запроса. Шаблоны с фиксированным соответствием, включающие специальные символы, можно разрешить с помощью полного синтаксиса запросов и пользовательских анализаторов.
manager: nitinme
author: HeidiSteen
ms.author: heidist
ms.service: cognitive-search
ms.topic: conceptual
ms.date: 04/09/2020
ms.openlocfilehash: 5a05f2973ac17460250fb3e80eb7bc0da9849940
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "81262882"
---
# <a name="partial-term-search-and-patterns-with-special-characters-wildcard-regex-patterns"></a>Частичный Поиск терминов и шаблоны со специальными символами (шаблон, регулярное выражение, шаблоны)

*Частичный Поиск терминов* относится к запросам, состоящим из фрагментов терминов, где вместо целого термина может быть только начало, середина или окончание срока (иногда они называются запросами префикса, инфиксные или суффикса). *Шаблон* может сочетать фрагменты, часто с специальными символами, такими как дефисы или косые черты, которые являются частью строки запроса. В число типичных вариантов использования входят запросы для частей номера телефона, URL-адреса, кодов людей или продуктов или составных слов.

Частичный и шаблонный Поиск могут быть проблематичными, если в индексе нет терминов в ожидаемом формате. На [этапе лексического анализа](search-lucene-query-architecture.md#stage-2-lexical-analysis) индексирования (при условии использования стандартного анализатора по умолчанию) специальные символы отбрасываются, составные и составные строки разбиваются, и удаляются пробелы. Все это может привести к сбою запросов шаблонов, если совпадений не найдено. Например, номер телефона, `+1 (425) 703-6214` например (с маркером `"1"`, `"425"`, `"703"`, `"6214"`), `"3-62"` не будет отображаться в запросе, поскольку это содержимое фактически не существует в индексе. 

Решение заключается в вызове анализатора, который сохраняет полную строку, включая пробелы и специальные символы, если это необходимо, чтобы можно было сопоставляться с частичными терминами и шаблонами. Создание дополнительного поля для неизменной строки и использование анализатора, который сохраняет содержимое, является основанием решения.

> [!TIP]
> Знакомы с API-интерфейсами почтовых и других функций? [Скачайте коллекцию примеров запросов](https://github.com/Azure-Samples/azure-search-postman-samples/tree/master/full-syntax-examples) , чтобы запросить частичные термины и специальные символы, описанные в этой статье.

## <a name="what-is-partial-search-in-azure-cognitive-search"></a>Что такое частичный Поиск в Azure Когнитивный поиск

В Azure Когнитивный поиск частичный Поиск и шаблон доступны в следующих формах:

+ [Поиск префиксов](query-simple-syntax.md#prefix-search), например `search=cap*`, сопоставление для кап'на Набережнаяного ИНН или ГАКК капитала. Для поиска префиксов можно использовать простой синтаксис запросов или полный синтаксис запроса Lucene.

+ [Поиск](query-lucene-syntax.md#bkmk_wildcard) по шаблону или [регулярные выражения](query-lucene-syntax.md#bkmk_regex) , которые выполняют поиск шаблона или частей внедренной строки. Для использования подстановочных знаков и регулярных выражений необходим полный синтаксис Lucene. Запросы суффиксов и индексов формируются как регулярное выражение.

  Ниже приведены некоторые примеры частичного поиска терминов. Для запроса суффикса с учетом слова "буквенно-цифровой" можно использовать поиск с подстановочными знаками (`search=/.*numeric.*/`) для поиска совпадения. Для частичного термина, включающего внутренние символы, такие как фрагмент URL-адреса, может потребоваться добавить управляющие символы. В JSON обратная косая `/` черта преобразуется в обратную косую черту `\`. Таким образом, `search=/.*microsoft.com\/azure\/.*/` является синтаксисом фрагмента URL-адреса «Microsoft.com/Azure/».

Как уже отмечалось, все вышеперечисленное требует, чтобы индекс содержал строки в формате, пригодного в соответствие шаблону, который не предоставляется стандартным анализатором. Выполнив действия, описанные в этой статье, можно убедиться в наличии необходимого содержимого для поддержки этих сценариев.

## <a name="solving-partialpattern-search-problems"></a>Решение проблем с частичным поиском или недоступностью шаблонов

Если необходимо выполнить поиск по фрагментам или шаблонам или специальным символам, можно переопределить анализатор по умолчанию с помощью пользовательского анализатора, работающего в более простых правилах разметки, оставив всю строку. Выполнив шаг назад, подход выглядит следующим образом:

+ Определите поле для хранения неизменной версии строки (при условии, что требуется анализируемый и неанализируемый текст)
+ Выбор предопределенного анализатора или определение пользовательского анализатора для вывода необработанной неповрежденной строки
+ Назначение настраиваемого анализатора полю
+ Сборка и тестирование индекса

> [!TIP]
> Оценка анализаторов — это итеративный процесс, требующий частых перестроение индекса. Этот шаг можно упростить с помощью POST, интерфейсов API для [создания индекса](https://docs.microsoft.com/rest/api/searchservice/create-index), [удаления индекса](https://docs.microsoft.com/rest/api/searchservice/delete-index),[загрузки документов](https://docs.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents)и [поиска документов](https://docs.microsoft.com/rest/api/searchservice/search-documents). Для документов загрузки текст запроса должен содержать небольшой репрезентативный набор данных, который необходимо протестировать (например, поле с номерами телефонов или кодами продуктов). Используя эти API в той же коллекции POST, можно быстро пройти эти шаги.

## <a name="duplicate-fields-for-different-scenarios"></a>Дублирование полей для различных сценариев

Анализаторы назначаются для каждого поля, что означает возможность создания полей в индексе для оптимизации различных сценариев. В частности, можно определить "Феатурекоде" и "Феатурекодережекс" для поддержки обычного полнотекстового поиска в первом и расширенного сопоставления шаблонов во втором.

```json
{
  "name": "featureCode",
  "type": "Edm.String",
  "retrievable": true,
  "searchable": true,
  "analyzer": null
},
{
  "name": "featureCodeRegex",
  "type": "Edm.String",
  "retrievable": true,
  "searchable": true,
  "analyzer": "my_custom_analyzer"
},
```

## <a name="choose-an-analyzer"></a>Выбор анализатора

При выборе анализатора, создающего маркеры полного термина, доступны следующие анализаторы:

| Анализатор | Расширения функциональности |
|----------|-----------|
| [Анализаторы языка](index-add-language-analyzers.md) | Сохраняет дефисы в составных словах, строках, гласных фрагментах и формах глаголов. Если шаблоны запросов содержат тире, может быть достаточно использования анализатора языка. |
| [This](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordAnalyzer.html) | Содержимое всего поля размечено как один термин. |
| [Бель](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/WhitespaceAnalyzer.html) | Разделяется только на пробелы. Термины, содержащие дефисы или другие символы, рассматриваются как один маркер. |
| [Пользовательский анализатор](index-add-custom-analyzers.md) | такую Создание настраиваемого анализатора позволяет указать как лексему, так и фильтр маркеров. Предыдущие Анализаторы должны использоваться "как есть". Настраиваемый анализатор позволяет выбрать используемые маркеры и фильтры маркеров. <br><br>Рекомендуемым сочетанием является лексема [ключевых слов](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordTokenizer.html) с [фильтром маркеров нижнего регистра](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/LowerCaseFilter.html). Само по себе предопределенный [анализатор ключевых слов](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/core/KeywordAnalyzer.html) не использует строчные буквы в верхнем регистре, что может привести к сбою запросов. Пользовательский анализатор предоставляет механизм для добавления фильтра маркеров нижнего регистра. |

Если вы используете средство тестирования веб-API, например POST, можно добавить [вызов RESTful для анализатора тестов](https://docs.microsoft.com/rest/api/searchservice/test-analyzer) , чтобы проверить выходные данные с маркерами.

Для работы необходим имеющийся индекс. При наличии существующего индекса и поля, содержащего дефисы или частичные термины, можно испытать различные анализаторы для определенных терминов, чтобы узнать, какие токены будут выдаваться.  

1. Проверьте стандартный анализатор, чтобы увидеть, как термины размечены по умолчанию.

   ```json
   {
   "text": "SVP10-NOR-00",
   "analyzer": "standard"
   }
    ```

1. Оцените ответ, чтобы увидеть, как текст размечен в индексе. Обратите внимание, что каждый термин имеет более низкий регистр и разбивается.

    ```json
    {
        "tokens": [
            {
                "token": "svp10",
                "startOffset": 0,
                "endOffset": 5,
                "position": 0
            },
            {
                "token": "nor",
                "startOffset": 6,
                "endOffset": 9,
                "position": 1
            },
            {
                "token": "00",
                "startOffset": 10,
                "endOffset": 12,
                "position": 2
            }
        ]
    }
    ```
1. Измените запрос для использования анализатора `whitespace` или `keyword` :

    ```json
    {
    "text": "SVP10-NOR-00",
    "analyzer": "keyword"
    }
    ```

1. Теперь ответ состоит из одного маркера в верхнем регистре с тире, сохраненным как часть строки. Если необходимо выполнить поиск по шаблону или частичному термину, механизм запросов теперь имеет базу для поиска соответствия.


    ```json
    {

        "tokens": [
            {
                "token": "SVP10-NOR-00",
                "startOffset": 0,
                "endOffset": 12,
                "position": 0
            }
        ]
    }
    ```
> [!Important]
> Имейте в виду, что средства синтаксического анализа запросов часто имеют более низкие регистры в выражении поиска при построении дерева запросов. Если вы используете анализатор, не имеющий текстовых входных данных в нижнем регистре и не получаете ожидаемые результаты, это может быть причиной. Решение заключается в добавлении фильтра маркеров нижнего регистра, как описано в разделе "использование пользовательских анализаторов" ниже.

## <a name="configure-an-analyzer"></a>Настройка анализатора
 
Независимо от того, оцениваете анализаторы или перемещаясь с определенной конфигурацией, необходимо указать анализатор для определения поля и, возможно, настроить сам анализатор, если вы не используете встроенный анализатор. При переключении анализаторов обычно требуется перестроить индекс (удалить, повторно создать и перезагрузить). 

### <a name="use-built-in-analyzers"></a>Использование встроенных анализаторов

Встроенные или стандартные анализаторы могут быть заданы по имени в `analyzer` свойстве определения поля, при этом в индексе не требуется дополнительная настройка. В следующем примере показано, как задать `whitespace` анализатор для поля. 

Другие сценарии и дополнительные сведения о других встроенных анализаторах см. в разделе [стандартный список анализаторов](https://docs.microsoft.com/azure/search/index-add-custom-analyzers#predefined-analyzers-reference). 

```json
    {
      "name": "phoneNumber",
      "type": "Edm.String",
      "key": false,
      "retrievable": true,
      "searchable": true,
      "analyzer": "whitespace"
    }
```

### <a name="use-custom-analyzers"></a>Использование пользовательских анализаторов

Если вы используете [Пользовательский анализатор](index-add-custom-analyzers.md), определите его в индексе с помощью определяемого пользователем сочетания анализатора лексемы, фильтра маркеров с возможными параметрами конфигурации. Затем сослаться на определение поля так же, как у встроенного анализатора.

Если цель представляет собой разметку для всего термина, рекомендуется использовать пользовательский анализатор, состоящий из **ключевых слов** и **фильтров маркеров нижнего регистра** .

+ Лексема ключевых слов создает один маркер для всего содержимого поля.
+ Фильтр маркеров нижнего регистра преобразует прописные буквы в строчные. Синтаксические анализаторы запросов обычно имеют прописные буквы в верхнем регистре. В нижнем регистре хоможенизес входные данные с помощью лексемных терминов.

В следующем примере показан пользовательский анализатор, который предоставляет маркеры ключевых слов и фильтр маркеров нижнего регистра.

```json
{
"fields": [
  {
  "name": "accountNumber",
  "analyzer":"myCustomAnalyzer",
  "type": "Edm.String",
  "searchable": true,
  "filterable": true,
  "retrievable": true,
  "sortable": false,
  "facetable": false
  }
],

"analyzers": [
  {
  "@odata.type":"#Microsoft.Azure.Search.CustomAnalyzer",
  "name":"myCustomAnalyzer",
  "charFilters":[],
  "tokenizer":"keyword_v2",
  "tokenFilters":["lowercase"]
  }
],
"tokenizers":[],
"charFilters": [],
"tokenFilters": []
```

> [!NOTE]
> `keyword_v2` Лексема и `lowercase` фильтр маркеров известны системой и используют их конфигурации по умолчанию, поэтому их можно ссылаться по имени, не определяя их первыми.

## <a name="build-and-test"></a>Сборка и тестирование

Определив индекс с анализаторами и определениями полей, которые поддерживают ваш сценарий, загрузите документы с репрезентативными строками, чтобы можно было тестировать частичные строковые запросы. 

В предыдущих разделах была объяснена логика. В этом разделе описывается каждый API, который следует вызывать при тестировании решения. Как отмечалось ранее, при использовании интерактивного средства веб-тестирования, такого как POST, можно быстро выполнять эти задачи.

+ [Удалить индекс](https://docs.microsoft.com/rest/api/searchservice/delete-index) удаляет существующий индекс с тем же именем, чтобы его можно было повторно создать.

+ [Создать индекс](https://docs.microsoft.com/rest/api/searchservice/create-index) создает структуру индекса в службе поиска, включая определения и поля анализатора с указанием анализатора.

+ [Загрузка документов](https://docs.microsoft.com/rest/api/searchservice/addupdate-or-delete-documents) импортирует документы, имеющие ту же структуру, что и индекс, а также содержимое, доступное для поиска. После выполнения этого шага индекс будет готов к выполнению запроса или тесту.

+ [Анализатор тестов](https://docs.microsoft.com/rest/api/searchservice/test-analyzer) появился в окне [Выбор анализатора](#choose-an-analyzer). Протестируйте некоторые строки в индексе с помощью различных анализаторов, чтобы понять, как будут размечены условия.

+ В [документах поиска](https://docs.microsoft.com/rest/api/searchservice/search-documents) объясняется, как создать запрос запроса, используя [простой синтаксис](query-simple-syntax.md) или [полный синтаксис Lucene](query-lucene-syntax.md) для подстановочных знаков и регулярных выражений.

  Для запросов с частичными терминами, таких как запрос "3-6214" для поиска совпадения в "+ 1 (425) 703-6214", можно использовать простой синтаксис: `search=3-6214&queryType=simple`.

  Для запросов инфиксные и суффиксов, таких как запрос "num" или "numeric" для поиска совпадений на "буквенно-цифровые", используйте полный синтаксис Lucene и регулярное выражение:`search=/.*num.*/&queryType=full`

## <a name="tips-and-best-practices"></a>Советы и рекомендации

### <a name="tune-query-performance"></a>Настройка производительности запросов

Если вы реализуете рекомендуемую конфигурацию, включающую в себя keyword_v2 лексему и фильтр маркеров более низкого регистра, вы можете заметить снижение производительности запросов из-за обработки дополнительных фильтров маркеров для существующих токенов в индексе. 

В следующем примере добавляется [едженграмтокенфилтер](https://lucene.apache.org/core/6_6_1/analyzers-common/org/apache/lucene/analysis/ngram/EdgeNGramTokenizer.html) , чтобы префикс совпадал быстрее. Дополнительные маркеры создаются в 2-25 символах, содержащих символы: (не только MS, MSF, MSFT, MSFT/, MSFT/S, MSFT/SQ, MSFT/SQL). Как можно себе представить, Дополнительная разметка приводит к увеличению индекса.

```json
{
"fields": [
  {
  "name": "accountNumber",
  "analyzer":"myCustomAnalyzer",
  "type": "Edm.String",
  "searchable": true,
  "filterable": true,
  "retrievable": true,
  "sortable": false,
  "facetable": false
  }
],

"analyzers": [
  {
  "@odata.type":"#Microsoft.Azure.Search.CustomAnalyzer",
  "name":"myCustomAnalyzer",
  "charFilters":[],
  "tokenizer":"keyword_v2",
  "tokenFilters":["lowercase", "my_edgeNGram"]
  }
],
"tokenizers":[],
"charFilters": [],
"tokenFilters": [
  {
  "@odata.type":"#Microsoft.Azure.Search.EdgeNGramTokenFilterV2",
  "name":"my_edgeNGram",
  "minGram": 2,
  "maxGram": 25,
  "side": "front"
  }
]
```

### <a name="use-different-analyzers-for-indexing-and-query-processing"></a>Использование различных анализаторов для индексирования и обработки запросов

Анализаторы вызываются во время индексирования и во время выполнения запроса. Обычно используется один и тот же анализатор, но для каждой рабочей нагрузки можно настроить пользовательские анализаторы. Переопределения анализатора указываются в [определении индекса](https://docs.microsoft.com/rest/api/searchservice/create-index) в `analyzers` разделе, а затем указываются на определенные поля. 

Если пользовательский анализ требуется только во время индексирования, можно применить пользовательский анализатор для просто индексирования и продолжить использование стандартного анализатора Lucene (или другого анализатора) для запросов.

Чтобы задать анализ для конкретной роли, можно задать свойства для каждого из них, задав `indexAnalyzer` свойство и `searchAnalyzer` вместо свойства по умолчанию. `analyzer`

```json
"name": "featureCode",
"indexAnalyzer":"my_customanalyzer",
"searchAnalyzer":"standard",
```

## <a name="next-steps"></a>Дальнейшие шаги

В этой статье объясняется, как анализаторы вносят проблемы в запросы и решают проблемы запросов. В качестве следующего шага подробнее рассмотрим анализатор влияния на индексирование и обработку запросов. В частности, рассмотрите возможность использования API анализа текста для возврата выходных данных с маркерами, чтобы вы могли точно увидеть, что создает анализатор для вашего индекса.

+ [Языковые анализаторы](search-language-support.md)
+ [Анализаторы для обработки текста в Azure Когнитивный поиск](search-analyzers.md)
+ [API анализа текста (ОСТАВШАЯся)](https://docs.microsoft.com/rest/api/searchservice/test-analyzer)
+ [Как работает полнотекстовый поиск (Архитектура запросов)](search-lucene-query-architecture.md)