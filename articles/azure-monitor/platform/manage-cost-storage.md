---
title: Управление использованием и затратами для Azure Log Analytics | Документация Майкрософт
description: Узнайте, как изменить ценовой план, а также управлять объемом данных и политикой хранения для рабочей области Log Analytics в Azure.
services: log-analytics
documentationcenter: log-analytics
author: mgoedtel
manager: carmonm
editor: ''
ms.assetid: ''
ms.service: log-analytics
ms.workload: na
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 03/29/2018
ms.author: magoedte
ms.subservice: ''
ms.openlocfilehash: a2f90c52823664df5fdc71c55220cc660c2f68e3
ms.sourcegitcommit: 3102f886aa962842303c8753fe8fa5324a52834a
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/23/2019
ms.locfileid: "60782896"
---
# <a name="manage-usage-and-costs-for-log-analytics-in-azure-monitor"></a>Управление потреблением и затраты для Log Analytics в Azure Monitor

> [!NOTE]
> В этой статье описывается, как контролировать затраты в Log Analytics путем установки срока хранения данных.  Дополнительные сведения приведены в статьях ниже.
> - В статье [Анализ использования данных в службе Log Analytics](manage-cost-storage.md) описано, как анализировать и оповещать об использовании данных.
> - В статье [Мониторинг использования и ожидаемых затрат](usage-estimated-costs.md) описано, как можно просмотреть сведения об использовании и оценить затраты по нескольким функциям мониторинга Azure для разных моделей ценообразования. Там также описано, как можно изменить модель ценообразования.

Предназначен для масштабирования и поддержки сбора, индексирования и хранения больших объемов данных в день из любого источника в вашей организации или развернутых в Azure log Analytics в Azure Monitor.  Хотя это может быть определяющим фактором для вашей организации, в конечном счете основной является экономическая эффективность. Поэтому важно понять, что стоимость рабочей области Log Analytics зависит не только от объема собранных данных, но также от выбранного плана и от того, как долго будут храниться данные из ваших подключенных источников.  

В этой статье мы рассмотрим, как можно в упреждающем режиме отслеживать увеличение объема хранимых данных и определять ограничения для контроля этих связанных затрат. 

Стоимость данных может быть значительной в зависимости от следующих факторов: 

- объем данных, создаваемых и попадающих в рабочую область; 
    - число включенных решений по управлению;
    - число отслеживаемых систем;
    - тип данных, собираемых из каждого отслеживаемого ресурса; 
- выбранная продолжительность хранения данных. 

## <a name="understand-your-workspaces-usage-and-estimated-cost"></a>Понимание использования и ожидаемых затрат для рабочей области
В Log Analytics легко разобраться с расчетной стоимостью на основе последних шаблонов использования.  Вы можете просматривать и анализировать использование данных с помощью раздела **Использование и ожидаемые затраты в Log Analytics**. Здесь вы узнаете, какой объем данных был собран каждым решением, какой объем данных сохраняется, и получите оценку затрат на основании объема полученных данных и дополнительных объемов хранения сверх включенных в тариф.

![Использование и ожидаемые затраты](media/manage-cost-storage/usage-estimated-cost-dashboard-01.png)

Чтобы подробнее изучить данные, щелкните значок в верхней правой части любой диаграммы на странице **Использование и ожидаемые затраты**. Теперь вы можете доработать этот запрос, чтобы получить дополнительные сведения о потреблении.  

![Представление журналов](media/manage-cost-storage/logs.png)

На странице **Использование и оценка затрат** можно просмотреть сведения о томах данных за месяц. Сюда входят все данные, полученные и сохраненные в рабочей области Log Analytics.  Щелкните **Сведения об использовании** в верхней части страницы, чтобы просмотреть панель управления со сведениями о тенденциях объема данных по источникам, компьютерам и предложениям. Чтобы просмотреть и установить ежедневное ограничение или изменить срок хранения, щелкните **Управление объемом данных**.
 
Оплата за использование Log Analytics добавляется в счет Azure. Дополнительную информацию о счете за подписку на Azure можно просмотреть в разделе выставления счетов портала Azure или на [Портале управления счетами и подписками Azure](https://account.windowsazure.com/Subscriptions).  

## <a name="daily-cap"></a>Ежедневное ограничение
Вы можете настроить ежедневное ограничение и ограничить ежедневный прием данных для своей рабочей области, но будьте осторожны, так как ваша цель не должна превышать дневной лимит.  В противном случае в этот момент вы потеряете данные за оставшуюся часть дня, что может повлиять на доступность в рабочей области служб и решений Azure, функциональные возможности которых зависят от актуальных данных.  В результате вы не сможете наблюдать за условиями работоспособности ресурсов, поддерживающих ИТ-службы, и получать соответствующие уведомления.  Ежедневное ограничение выступает в качестве способа управления неожиданным увеличением объема данных, собираемых из управляемых ресурсов. Оно помогает не превышать предел сбора данных. Кроме того, его можно использовать для ограничения незапланированных платежей за рабочую область.  

По достижении ежедневного ограничения сбор платных типов данных прекращается до конца дня. В верхней части страницы для выбранной рабочей области Log Analytics появится предупреждающий баннер и событие операции будет отправлено в таблицу *Операция* в категории **LogManagement**. Сбор данных возобновится по наступлении времени сброса, определенного в разделе *Daily limit will be set at* (Ежедневное ограничение будет установлено в). Рекомендуем определить правило генерации оповещений на основе этого события операции, настроенного для уведомления о достижении ежедневного ограничения по сбору данных. 

### <a name="identify-what-daily-data-limit-to-define"></a>Определение ежедневного ограничения по сбору данных 
Сведения о тенденциях приема данных и определении ежедневного ограничения для объема см. в статье [Анализ использования данных в службе Log Analytics](usage-estimated-costs.md). Их необходимо тщательно рассмотреть, так как вы не сможете контролировать свои ресурсы после достижения предела. 

### <a name="manage-the-maximum-daily-data-volume"></a>Управление максимальным ежедневным объемом данных 
В следующих шагах показано, как настроить ограничения для управления объемом данных, которые Log Analytics будет принимать в день.  

1. В рабочей области на панели слева выберите пункт **Usage and estimated costs** (Использование и ожидаемые затраты).
2. В верхней части страницы **Usage and estimated costs** (Использование и ожидаемые затраты) для выбранной рабочей области щелкните **Управление объемом данных**. 
3. По умолчанию для ежедневного ограничения установлено значение **Выкл**. Щелкните **Вкл.**, чтобы включить его, а затем настройте лимит для объема данных (ГБ/день).<br><br> ![Настройка ограничения сбора данных в Log Analytics](media/manage-cost-storage/set-daily-volume-cap-01.png)

### <a name="alert-when-daily-cap-reached"></a>Оповещение при достижении ежедневного ограничения
Когда достигнуто ограничение сбора данных, на портале Azure отображается соответствующее сообщение. Однако, возможно, вы управляете операционными проблемами, требующими немедленного внимания, иным образом.  Чтобы получать оповещение, вы можете создать новое правило генерации оповещений в Azure Monitor.  Дополнительные сведения см. в статье [Создание и просмотр оповещений, а также управление ими с помощью Azure Monitor — интерфейс оповещений (предварительная версия)](alerts-metric.md).      

Перед началом работы просмотрите рекомендуемые настройки для оповещения:

* Цель: выбор ресурса Log Analytics.
* Критерии: 
   * "Название сигнала" — "Поиск по пользовательским журналам";
   * "Поисковый запрос" — Operation | where Detail has 'OverQuota'
   * "На основе" — Количество результатов
   * "Условие" — Больше
   * "Пороговое значение" — 0
   * "Период" — 5 (минут);
   * "Частота" — 5 (минут);
* "Имя правила генерации оповещений" — "Достигнут ежедневный предел сбора данных";
* "Уровень серьезности" — "Предупреждение (серьезность 1)"

Как только будет определено оповещение и достигнут предел, активируется предупреждение и будет выполнен ответ, определенный в группе действий. Ваша команда может получать сообщение по электронной почте и текстовое сообщение, могут быть автоматизированы действия с помощью веб-перехватчиков, модулей Runbook службы автоматизации или же выполнена [интеграция с внешним решением ITSM](itsmc-overview.md#create-itsm-work-items-from-azure-alerts). 

## <a name="change-the-data-retention-period"></a>Изменение срока хранения данных 
В следующих шагах описана настройка периода хранения данных журнала в рабочей области.
 
1. В рабочей области на панели слева выберите пункт **Usage and estimated costs** (Использование и ожидаемые затраты).
2. В верхней части страницы **Usage and estimated costs** (Использование и ожидаемые затраты) щелкните **Управление объемом данных**.
5. В области воспользуйтесь ползунком, чтобы увеличить или уменьшить количество дней, а затем нажмите кнопку **ОК**.  Если вы используете уровень *Бесплатный*, то вы не сможете изменить срок хранения данных. Необходимо перейти на платный уровень, чтобы управлять этим параметром.<br><br> ![Изменение параметра хранения данных рабочей области](media/manage-cost-storage/manage-cost-change-retention-01.png)

## <a name="legacy-pricing-tiers"></a>Устаревшие ценовые категории

Клиенты, которые подписали Соглашение Enterprise до 1 июля 2018 года или которые уже создали в подписке рабочую область Log Analytics, по-прежнему имеют доступ к плану *Бесплатный*. Если подписка не связана с имеющимся Соглашением Enterprise, при создании рабочей области в новой подписке после 2 апреля 2018 года уровень *Бесплатный* недоступен.  Если вы используете уровень *Бесплатный*, данные хранятся в течение 7 дней.  Для устаревших уровней *Автономный* или *На узел*, а также для текущей единой ценовой категории за 2018 г. доступны собранные данные за последний 31 день. При использовании уровня *Бесплатный* у вас будет ежедневное ограничение в 500 МБ. Если вы обнаружите, что постоянно превышаете допустимые объемы, то сможете изменить рабочую область и выбрать другой план, чтобы собирать данные свыше этого ограничения. 

> [!NOTE]
> Чтобы использовать права, полученные при покупке подписки OMS E1, OMS E2 или настройки OMS для System Center, выберите ценовой уровень Log Analytics *за узле*.

## <a name="changing-pricing-tier"></a>Изменение ценовой категории.

Если ваша рабочая область Log Analytics имеет доступ к устаревшим уровням ценообразования, для переключения между устаревшими уровнями ценообразования выполните следующее.

1. На портале Azure в области подписок Log Analytics выберите рабочую область.

2. На панели рабочей области в разделе **Общие** щелкните **Ценовая категория**.  

3. В разделе **Ценовая категория** выберите ценовую категорию и щелкните **Выбрать**.  
    ![Выбранный ценовой план](media/manage-cost-storage/workspace-pricing-tier-info.png)

Если вы хотите переместить свое рабочее пространство в текущий ценовой уровень, необходимо изменить ценовую модель мониторинга подписки в Azure Monitor, что изменит ценовой уровень всех рабочих пространств в этой подписке. Дополнительные сведения см. в этой [статье](usage-estimated-costs.md#moving-to-the-new-pricing-model).


> [!NOTE]
> Дополнительные сведения о [Настройка ценовой категории с помощью ARM](template-workspace-configuration.md#create-a-log-analytics-workspace) и как обеспечить успешное развертывание ARM независимо от того, ли подписки в устаревших или новой модели ценообразования. 


## <a name="troubleshooting-why-log-analytics-is-no-longer-collecting-data"></a>Почему Log Analytics больше не собирает данные
Если вы используете устаревшую бесплатную ценовую категорию и отправили больше 500 МБ данных за день, сбор данных останавливается до конца дня. Достижение ежедневного ограничения является распространенной причиной, по которой Log Analytics прекращает сбор данных или по которой данные отсутствуют.  Log Analytics создает событие типа "Операция", когда сбор данных начинается и останавливается. Выполните следующий запрос в поле поиска, чтобы проверить, достигнут ли лимит и отсутствуют ли данные: 

`Operation | where OperationCategory == 'Data Collection Status'`

При остановке сбора данных параметр OperationStatus принимает значение Warning. При начале сбора данных параметр OperationStatus принимает значение Succeeded. В следующей таблице описаны причины, по которым сбор данных останавливается, и приведены рекомендуемые действия, чтобы его возобновить:  

|Причина прекращения сбора| Решение| 
|-----------------------|---------|
|Достигнут ежедневный предел устаревшей бесплатной ценовой категории. |Дождитесь следующего дня для автоматического перезапуска сбора или перейдите на платную ценовую категорию.|
|Достигнуто ежедневное ограничение рабочей области.|Дождитесь автоматического перезапуска сбора или увеличьте предел ежедневного объема собираемых данных, как описано в разделе управления максимальным ежедневным объемом данных. Время сброса ежедневного ограничения отображается на странице **Управление объемом данных**. |
|Подписка Azure находится в состоянии "Приостановлено" по причине:<br> Период бесплатной пробной версии завершен<br> Истек срок действия Azure Pass<br> Достигнут лимит ежемесячной суммы расходов (например, на подписку MSDN или Visual Studio)|Измените подписку на платную<br> Удалите ограничение или подождите, пока оно сбросится|

Чтобы получать оповещение об остановке сбора данных, выполните шаги, описанные в разделе *Создание ограничения ежедневного сбора данных*. Выполните шаги, описанные в действиях добавления, чтобы настроить сообщения электронной почты, веб-перехватчик или действие Runbook для правила генерации оповещений. 

## <a name="troubleshooting-why-usage-is-higher-than-expected"></a>Превышенный объем данных: причины и устранение
Превышенное использование вызывается одной (или двумя) причинами:
- превышено число узлов, отправляющих данные в службу Log Analytics.
- отправлен превышенный объем данных в службу Log Analytics;

Далее разделах Разработка

## <a name="understanding-nodes-sending-data"></a>Основные сведения об узлах, отправка данных

Чтобы узнать, сколько компьютеров (узлов) отправили данные каждый день за последний месяц, выполните следующий запрос:

`Heartbeat | where TimeGenerated > startofday(ago(31d))
| summarize dcount(Computer) by bin(TimeGenerated, 1d)    
| render timechart`

Чтобы получить список компьютеров, отправляющих **счет за типы данных** (некоторые типы данных бесплатные), используйте свойство [_IsBillable](log-standard-properties.md#_isbillable).

`union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| where computerName != ""
| summarize TotalVolumeBytes=sum(_BilledSize) by computerName`

Используйте эти запросы `union withsource = tt *` только в случае необходимости, так как сканирование по типам данных требует больших затрат на выполнение. Следующий запрос заменяет старый способ запроса на получение сведений для компьютера с типом данных об использовании.  

Это может быть расширен для возврата количества компьютеров в час, которые отправляют выставлен счет типы данных (то есть, как Log Analytics подсчитывает оплачиваемых узлов для прежних версий каждого узла Ценовая категория):

`union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| where computerName != ""
| summarize dcount(computerName) by bin(TimeGenerated, 1h) | sort by TimeGenerated asc`

## <a name="understanding-ingested-data-volume"></a>Основные сведения о принимаемых данных тома 

На странице **Использование и ожидаемые затраты** есть диаграмма *Data ingestion per solution* (Прием данных по решениям), которая позволяет отобразить объем отправленных данных в целом и для каждого решения отдельно. Это позволяет выявить некоторые тенденции, например оценить изменения общего объема используемых данных (или по определенному решению). Для создания этой диаграммы применяется такой запрос:

`Usage | where TimeGenerated > startofday(ago(31d))| where IsBillable == true
| summarize TotalVolumeGB = sum(Quantity) / 1024 by bin(TimeGenerated, 1d), Solution| render barchart`

Обратите внимание, что предложение "where IsBillable = true" отсеивает выбранные типы данных из определенных решений, для которых не взимается плата за прием данных. 

Вы можете изучить данные еще подробнее, чтобы найти тенденции для определенных типов данных, например для данных из журналов IIS:

`Usage | where TimeGenerated > startofday(ago(31d))| where IsBillable == true
| where DataType == "W3CIISLog"
| summarize TotalVolumeGB = sum(Quantity) / 1024 by bin(TimeGenerated, 1d), Solution| render barchart`

### <a name="data-volume-by-computer"></a>Том данных по компьютерам

Для просмотра **размер** оплачиваемых событий, обрабатываемых на каждом компьютере, используйте `_BilledSize` свойство ([_billedsize.md # свойства журнала стандарта](learn more)) который предоставляет размер в байтах:

```
union withsource = tt * 
| where _IsBillable == true 
| summarize Bytes=sum(_BilledSize) by  Computer | sort by Bytes nulls last
```

`_IsBillable` Свойство указывает, будет ли данные, полученные взиматься плата ([_isbillable # log-standard-properties.md](Learn more).)

Чтобы узнать **количество** полученных событий для каждого компьютера, выполните такой запрос:

`union withsource = tt *
| summarize count() by Computer | sort by count_ nulls last`

Чтобы узнать количество полученных оплачиваемых событий для каждого компьютера, выполните такой запрос: 

`union withsource = tt * 
| where _IsBillable == true 
| summarize count() by Computer  | sort by count_ nulls last`

Чтобы счетчики оплачиваемых типов данных отправляли данные на конкретный компьютер, выполните такой запрос:

```
union withsource = tt *
| where Computer == "computer name"
| where _IsBillable == true 
| summarize count() by tt | sort by count_ nulls last
```

### <a name="data-volume-by-azure-resource-resource-group-or-subscription"></a>Объем данных в зависимости от ресурсов Azure, группу ресурсов или подписку

Для данных из узлов, размещенных в Azure можно получить **размер** оплачиваемых событий, которые принимаются __на каждом компьютере__, использовать `_ResourceId` свойство, которое предоставляет полный путь к ресурсу ([ log-standard-properties.md #_resourceid](learn more)):

```
union withsource = tt * 
| where _IsBillable == true 
| summarize Bytes=sum(_BilledSize) by _ResourceId | sort by Bytes nulls last
```

Для данных из узлов, размещенных в Azure можно получить **размер** оплачиваемых событий, которые принимаются __каждой подписки Azure__, синтаксический анализ `_ResourceId` свойство как:

```
union withsource = tt * 
| where _IsBillable == true 
| parse tolower(_ResourceId) with "/subscriptions/" subscriptionId "/resourcegroups/" 
    resourceGroup "/providers/" provider "/" resourceType "/" resourceName   
| summarize Bytes=sum(_BilledSize) by subscriptionId | sort by Bytes nulls last
```

Изменение `subscriptionId` для `resourceGroup` покажет том оплачиваемые данные, полученные по Azure resouurce группы. 


> [!NOTE]
> Некоторые поля с типом данных Usage (Потребление) уже устарели и данные в них не заполняются, хотя они пока сохраняются в схеме. Например, сюда относятся поля **Computer** и ряд данных о приеме данных (**TotalBatches**, **BatchesWithinSla**, **BatchesOutsideSla**, **BatchesCapped** и **AverageProcessingTimeMs**).

### <a name="querying-for-common-data-types"></a>Запросы для общих типов данных

Чтобы получить более подробную информацию об источнике данных по определенному типу данных, воспользуйтесь приведенными ниже примерами запросов.

+ Решение по **безопасности**
  - `SecurityEvent | summarize AggregatedValue = count() by EventID`
+ Решение для **управления журналами**
  - `Usage | where Solution == "LogManagement" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | summarize AggregatedValue = count() by DataType`
+ Тип данных **Perf**
  - `Perf | summarize AggregatedValue = count() by CounterPath`
  - `Perf | summarize AggregatedValue = count() by CounterName`
+ Тип данных **Event**
  - `Event | summarize AggregatedValue = count() by EventID`
  - `Event | summarize AggregatedValue = count() by EventLog, EventLevelName`
+ Тип данных **Syslog**
  - `Syslog | summarize AggregatedValue = count() by Facility, SeverityLevel`
  - `Syslog | summarize AggregatedValue = count() by ProcessName`
+ Тип данных **AzureDiagnostics**
  - `AzureDiagnostics | summarize AggregatedValue = count() by ResourceProvider, ResourceId`

### <a name="tips-for-reducing-data-volume"></a>Советы по снижению объемов данных

Вот несколько рекомендаций, которые помогут снизить объем собираемых журналов.

| Источник превышенного объема данных | Как сократить объем данных |
| -------------------------- | ------------------------- |
| События безопасности            | Выберите [события со стандартным или минимальным уровнем безопасности](https://docs.microsoft.com/azure/security-center/security-center-enable-data-collection#data-collection-tier). <br> Измените политику аудита безопасности таким образом, чтобы собирать только необходимые события. В частности проверьте необходимость сбора следующих событий: <br> - [аудит платформы фильтрации](https://technet.microsoft.com/library/dd772749(WS.10).aspx); <br> - [аудит реестра](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd941614(v%3dws.10));<br> - [аудит файловой системы](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd772661(v%3dws.10));<br> - [аудит объектов ядра](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd941615(v%3dws.10));<br> - [аудит работы с дескрипторами](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd772626(v%3dws.10));<br> — аудит съемных носителей. |
| Счетчики производительности       | Измените [конфигурацию счетчика производительности](data-sources-performance-counters.md), чтобы <br> уменьшить частоту сбора или <br> сократить число счетчиков производительности. |
| Журналы событий                 | Измените [конфигурацию журнала событий](data-sources-windows-events.md), чтобы <br> сократить число собранных журналов событий или <br> выполнять сбор только необходимых уровней событий. Например, не выполняйте сбор событий уровня *сведений*. |
| syslog                     | Измените [конфигурацию системного журнала](data-sources-syslog.md), чтобы <br> сократить число собранных объектов или <br> выполнять сбор только необходимых уровней событий. Например, не выполняйте сбор событий уровня *сведений* и *отладки*. |
| AzureDiagnostics           | Измените коллекцию журнала ресурсов, чтобы: <br> Уменьшить число ресурсов, отправляющих журналы в Log Analytics. <br> Выполнять сбор только необходимых журналов. |
| Данные решений с компьютеров, которым не требуется решение | Используйте [нацеливание решений](../insights/solution-targeting.md), чтобы выполнять сбор данных только в нужных группах компьютеров. |

### <a name="getting-security-and-automation-node-counts"></a>Получение счетчиков узел безопасности и автоматизации 

Если вы используете ценовую категорию "За узел (OMS)", плата взимается в зависимости от количества используемых узлов и решений. Количество узлов для предложения "Аналитика", для которых выставляются счета, отображается в таблице на странице **Использование и предполагаемые затраты**.  

Чтобы просмотреть количество отдельных узлов безопасности, выполните такой запрос:

`union
(
    Heartbeat
    | where (Solutions has 'security' or Solutions has 'antimalware' or Solutions has 'securitycenter')
    | project Computer
),
(
    ProtectionStatus
    | where Computer !in~
    (
        (
            Heartbeat
            | project Computer
        )
    )
    | project Computer
)
| distinct Computer
| project lowComputer = tolower(Computer)
| distinct lowComputer
| count`

Чтобы просмотреть количество отдельных узлов службы автоматизации, выполните такой запрос:

```
 ConfigurationData 
 | where (ConfigDataType == "WindowsServices" or ConfigDataType == "Software" or ConfigDataType =="Daemons") 
 | extend lowComputer = tolower(Computer) | summarize by lowComputer 
 | join (
     Heartbeat 
       | where SCAgentChannel == "Direct"
       | extend lowComputer = tolower(Computer) | summarize by lowComputer, ComputerEnvironment
 ) on lowComputer
 | summarize count() by ComputerEnvironment | sort by ComputerEnvironment asc
```

## <a name="create-an-alert-when-data-collection-is-higher-than-expected"></a>Создание оповещения для превышенного объема сбора данных

В этом разделе описывается создание оповещения для следующих случаев:
- объем данных превышает заданный объем;
- объем данных превысит заданный объем.

Служба "Оповещения Azure" поддерживает [оповещения журналов](alerts-unified-log.md), использующие поисковые запросы. 

Следующий запрос содержит результат, когда за сутки собрано более 100 ГБ данных:

`union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize DataGB = sum((Quantity / 1024)) by Type | where DataGB > 100`

Следующий запрос использует простую формулу для прогноза, что в течение 24 часов будет отправлено более 100 ГБ данных: 

`union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize EstimatedGB = sum(((Quantity * 8) / 1024)) by Type | where EstimatedGB > 100`

Чтобы создать оповещения для различных объемов данных, измените значение "100" в запросах на число ГБ, для которых вы хотите создать оповещения.

Выполните действия, описанные в разделе о [создании оповещений журналов](alerts-metric.md), чтобы получать уведомления при превышении ожидаемого объема собираемых данных.

При создании оповещения для первого запроса, когда имеется объем данных, превышающий 100 ГБ в сутки, задайте параметрам следующие значения:  

- Для параметра **Определение условия оповещения** укажите свою рабочую область Log Analytics в качестве целевого ресурса.
- Для **критериев оповещения** укажите следующее:
   - для **названия сигнала** выберите значение **Пользовательский поиск по журналам**;
   - **поисковому запросу** — `union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize DataGB = sum((Quantity / 1024)) by Type | where DataGB > 100`;
   - **логика оповещений** должна быть **основана на** *числе результатов*, а значение **условия** должно быть *больше* **порогового значения** *0*;
   - укажите **период времени** *1440* минут, а для **частоты оповещений** задайте каждые *60* минут, так как данные об использовании обновляются раз в час.
- В разделе **Определение сведений об оповещении** задайте такие значения:
   - **имени** — *объем данных, превышающий 100 ГБ в сутки*;
   - **серьезности** — *предупреждение*;

Укажите существующую или создайте новую [группу действий](action-groups.md), чтобы получать соответствующее уведомление, когда оповещение журнала соответствует заданным критериям.

При создании оповещения для второго запроса, когда спрогнозировано, что суточный объем данных превысит 100 ГБ, задайте параметрам следующие значения:

- Для параметра **Определение условия оповещения** укажите свою рабочую область Log Analytics в качестве целевого ресурса.
- Для **критериев оповещения** укажите следующее:
   - для **названия сигнала** выберите значение **Пользовательский поиск по журналам**;
   - **поисковому запросу** — `union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize EstimatedGB = sum(((Quantity * 8) / 1024)) by Type | where EstimatedGB > 100`;
   - **логика оповещений** должна быть **основана на** *числе результатов*, а значение **условия** должно быть *больше* **порогового значения** *0*;
   - укажите **период времени** *180* минут, а для **частоты оповещений** задайте каждые *60* минут, так как данные об использовании обновляются один раз в час.
- В разделе **Определение сведений об оповещении** задайте такие значения:
   - **имени** — *объем данных, превышающий 100 ГБ в сутки*;
   - **серьезности** — *предупреждение*;

Укажите существующую или создайте новую [группу действий](action-groups.md), чтобы получать соответствующее уведомление, когда оповещение журнала соответствует заданным критериям.

Когда вы получите оповещение, выполните действия, описанные в следующем разделе, чтобы определить причину использования превышенного объема данных.

## <a name="next-steps"></a>Дальнейшие действия
* Ознакомьтесь со статьей [Поиск данных по журналам](../log-query/log-query-overview.md), чтобы узнать, как использовать язык поиска. Вы можете использовать поисковые запросы, чтобы выполнить дополнительный анализ данных об использовании.
* Выполните действия, описанные в разделе о [создании оповещений журналов](alerts-metric.md), чтобы получать уведомления при выполнении условий поиска.
* Используйте [нацеливание решений](../insights/solution-targeting.md), чтобы выполнять сбор данных только в нужных группах компьютеров.
* Сведения о настройке эффективной политики сбора событий см. в статье [Сбор данных в Центре безопасности Azure](../../security-center/security-center-enable-data-collection.md).
* Измените [конфигурацию счетчика производительности](data-sources-performance-counters.md).
* Сведения об изменении параметров сбора событий см. в статье [Источники данных для журнала событий Windows в Log Analytics](data-sources-windows-events.md).
* Сведения об изменении конфигурации системного журнала см. в статье [Источники данных для журнала событий Windows в Log Analytics](data-sources-syslog.md).


