---
title: Управление использованием и затратами для журналов Azure Monitor | Документация Майкрософт
description: Узнайте, как изменить тарифный план и управлять объемом данных и политикой хранения для рабочей области Log Analytics в Azure Monitor.
services: azure-monitor
documentationcenter: azure-monitor
author: mgoedtel
manager: carmonm
editor: ''
ms.assetid: ''
ms.service: azure-monitor
ms.workload: na
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 10/01/2019
ms.author: magoedte
ms.subservice: ''
ms.openlocfilehash: 5b6ec913226f44a47bfa5c734e0c20ef3a87ca67
ms.sourcegitcommit: 1d0b37e2e32aad35cc012ba36200389e65b75c21
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/15/2019
ms.locfileid: "72329426"
---
# <a name="manage-usage-and-costs-with-azure-monitor-logs"></a>Управление использованием и затратами с помощью журналов Azure Monitor

> [!NOTE]
> В этой статье описывается, как оценить и контролировать затраты на Azure Monitor журналов. В связанной статье, [мониторинге использования и оценочных затратах](https://docs.microsoft.com/azure/azure-monitor/platform/usage-estimated-costs) описывается просмотр использования и оценка затрат в нескольких функциях мониторинга Azure для различных моделей ценообразования.

Журналы Azure Monitor предназначены для масштабирования и поддержки сбора, индексирования и хранения больших объемов данных в день из любого источника в вашей организации или развертывания в Azure.  Хотя это может быть определяющим фактором для вашей организации, в конечном счете основной является экономическая эффективность. Для этого важно понимать, что стоимость Log Analytics рабочей области не базируется только на объеме собираемых данных, он также зависит от выбранного плана и от того, сколько времени выбрано для хранения данных, созданных из подключенных источников.  

В этой статье мы рассмотрим, как можно заранее отслеживать принятые объемы данных и рост объема хранилища, а также определять ограничения для управления этими затратами. 

## <a name="pricing-model"></a>Модель ценообразования

Цены по умолчанию для Log Analytics — это модель с **оплатой по мере** использования, основанная на объеме данных, принимаемых и необязательно для более длительного хранения данных. Объем данных измеряется как размер данных, которые будут храниться. Каждая Рабочая область Log Analytics оплачивается как отдельная служба и участвует в выставлении счетов за подписку Azure. Объем приема данных может быть значительным в зависимости от следующих факторов. 

  - Число включенных решений по управлению и их конфигурация (например, 
  - Число отслеживаемых виртуальных машин
  - Тип данных, собираемых с каждой отслеживаемой виртуальной машины 
  
Помимо модели с оплатой по мере использования, мы предоставили **резервирования емкости** для log Analytics, которые позволяют сэкономить на 25% по сравнению с ценой оплаты по мере использования. Цены резервирования емкости позволяют приобрести резервирование, начиная с 100 ГБ в день. При использовании выше уровня резервирования будет взиматься плата по тарифу по мере использования. [Узнайте больше](https://azure.microsoft.com/pricing/details/monitor/) о ценах на log Analytics с оплатой по мере использования и резервированием мощностей. 

Обратите внимание, что некоторые решения, такие как [Центр безопасности Azure](https://azure.microsoft.com/pricing/details/security-center/) и метка [Azure](https://azure.microsoft.com/pricing/details/azure-sentinel/), имеют собственную модель ценообразования. 

## <a name="estimating-the-costs-to-manage-your-environment"></a>Оценка затрат на управление средой 

Если вы еще не используете журналы Azure Monitor, можно использовать [Калькулятор цен Azure Monitor](https://azure.microsoft.com/pricing/calculator/?service=monitor) , чтобы оценить стоимость использования log Analytics. Начните с ввода в поле поиска «Azure Monitor» и щелчком на полученном Azure Monitor плитке. Прокрутите страницу вниз до Azure Monitor и выберите Log Analytics в раскрывающемся списке тип.  Здесь можно ввести количество виртуальных машин и ГБ данных, которые вы собираетесь получать из каждой виртуальной машины. Месяц с типЦиалли 1 до 3 ГБ данных принимается от типичной виртуальной машины Azure. Если вы уже вырабатываете журналы Azure Monitor, вы можете использовать статистику данных из собственной среды. Ниже приведены сведения о том, как определить [количество отслеживаемых виртуальных машин](https://docs.microsoft.com/azure/azure-monitor/platform/manage-cost-storage#understanding-nodes-sending-data) и объем данных, принимаемых [рабочей областью](https://docs.microsoft.com/azure/azure-monitor/platform/manage-cost-storage#understanding-ingested-data-volume). 

## <a name="understand-your-usage-and-estimate-costs"></a>Сведения об использовании и оценке затрат

Если вы используете Azure Monitor журналов, то легко понять, что именно в них могут основываться на последних шаблонах использования. Для этого используйте **log Analytics использования и предполагаемые затраты** для просмотра и анализа использования данных. Здесь вы узнаете, какой объем данных был собран каждым решением, какой объем данных сохраняется, и получите оценку затрат на основании объема полученных данных и дополнительных объемов хранения сверх включенных в тариф.

![Использование и ожидаемые затраты](media/manage-cost-storage/usage-estimated-cost-dashboard-01.png)

Чтобы подробнее изучить данные, щелкните значок в верхней правой части любой диаграммы на странице **Использование и ожидаемые затраты**. Теперь вы можете доработать этот запрос, чтобы получить дополнительные сведения о потреблении.  

![Представление журналов](media/manage-cost-storage/logs.png)

На странице **Использование и оценка затрат** можно просмотреть сведения о томах данных за месяц. Сюда входят все данные, полученные и сохраненные в рабочей области Log Analytics.  Щелкните **сведения об использовании** в верхней части страницы, чтобы просмотреть панель мониторинга использования с информацией о тенденциях объема данных по источникам, компьютерам и предложениям. Чтобы просмотреть и установить ежедневное ограничение или изменить срок хранения, щелкните **Управление объемом данных**.
 
Оплата за использование Log Analytics добавляется в счет Azure. Дополнительную информацию о счете за подписку на Azure можно просмотреть в разделе выставления счетов портала Azure или на [Портале управления счетами и подписками Azure](https://account.windowsazure.com/Subscriptions).  

## <a name="viewing-log-analytics-usage-on-your-azure-bill"></a>Просмотр Log Analytics использования в счете Azure 

Azure предоставляет большое количество полезных функций в центре [управления затратами Azure и центра выставления счетов](https://docs.microsoft.com/azure/cost-management/quick-acm-cost-analysis?toc=/azure/billing/TOC.json) . Например, функция "анализ затрат" позволяет просматривать расходы на ресурсы Azure. Добавление фильтра по типу ресурса (в Microsoft. operationalinsights/Workspace для Log Analytics) позволит вам относить затраты.

Чтобы получить дополнительные сведения об использовании, скачайте сведения [об использовании с портала Azure](https://docs.microsoft.com/azure/billing/billing-download-azure-invoice-daily-usage-date#download-usage-in-azure-portal). В скачанной электронной таблице вы можете просмотреть сведения об использовании каждого ресурса Azure (например, Log Analytics рабочей области) в день. В этой таблице Excel использование рабочих областей Log Analytics можно найти с помощью первой фильтрации в столбце "Категория счетчиков", чтобы отобразить "аналитика и аналитика" (используется некоторыми устаревшими ценовыми категориями) и "Log Analytics", а затем добавить фильтр для экземпляра ID "столбец" содержит рабочую область ". Использование отображается в столбце "потребленное количество", а единица для каждой записи отображается в столбце "единица измерения".  Дополнительные сведения помогут вам [разобраться с Microsoft Azureным счетом](https://docs.microsoft.com/azure/billing/billing-understand-your-bill). 

## <a name="manage-your-maximum-daily-data-volume"></a>Управление максимальным дневным объемом данных

Вы можете настроить ежедневное ограничение и ограничить ежедневный прием данных для своей рабочей области, но будьте осторожны, так как ваша цель не должна превышать дневной лимит.  В противном случае в этот момент вы потеряете данные за оставшуюся часть дня, что может повлиять на доступность в рабочей области служб и решений Azure, функциональные возможности которых зависят от актуальных данных.  В результате вы не сможете наблюдать за условиями работоспособности ресурсов, поддерживающих ИТ-службы, и получать соответствующие уведомления.  Ежедневное ограничение предназначено для использования в качестве способа управления непредвиденным увеличением объема данных из управляемых ресурсов, а также за пределами вашего ограничения или за ограничение незапланированных затрат для рабочей области.  

По достижении ежедневного ограничения сбор платных типов данных прекращается до конца дня. В верхней части страницы для выбранной рабочей области Log Analytics появится предупреждающий баннер и событие операции будет отправлено в таблицу *Операция* в категории **LogManagement**. Сбор данных возобновится по наступлении времени сброса, определенного в разделе *Daily limit will be set at* (Ежедневное ограничение будет установлено в). Рекомендуем определить правило генерации оповещений на основе этого события операции, настроенного для уведомления о достижении ежедневного ограничения по сбору данных. 

> [!NOTE]
> Ежедневное ограничение не останавливает сбор данных из центра безопасности Azure, за исключением рабочих областей, в которых был установлен центр безопасности Azure до 19 июня 2017 г. 

### <a name="identify-what-daily-data-limit-to-define"></a>Определение ежедневного ограничения по сбору данных

Сведения о тенденциях приема данных и определении ежедневного ограничения для объема см. в статье [Анализ использования данных в службе Log Analytics](usage-estimated-costs.md). Их необходимо тщательно рассмотреть, так как вы не сможете контролировать свои ресурсы после достижения предела. 

### <a name="set-the-daily-cap"></a>Установка ежедневного ограничения

Ниже описано, как настроить ограничение на Управление объемом данных, которые Log Analytics рабочей области в день.  

1. В рабочей области на панели слева выберите пункт **Usage and estimated costs** (Использование и ожидаемые затраты).
2. В верхней части страницы **Usage and estimated costs** (Использование и ожидаемые затраты) для выбранной рабочей области щелкните **Управление объемом данных**. 
3. По умолчанию для ежедневного ограничения установлено значение **Выкл**. Щелкните **Вкл.** , чтобы включить его, а затем настройте лимит для объема данных (ГБ/день).

    ![Log Analytics настроить ограничение данных](media/manage-cost-storage/set-daily-volume-cap-01.png)

### <a name="alert-when-daily-cap-reached"></a>Оповещать при достижении ежедневного ограничения

Когда достигнуто ограничение сбора данных, на портале Azure отображается соответствующее сообщение. Однако, возможно, вы управляете операционными проблемами, требующими немедленного внимания, иным образом.  Чтобы получать оповещение, вы можете создать новое правило генерации оповещений в Azure Monitor.  Дополнительные сведения см. в статье [Создание и Просмотр оповещений и управление ими](alerts-metric.md).

Перед началом работы просмотрите рекомендуемые настройки для оповещения:

- Цель: выберите рабочую область Log Analytics.
- Критерии: 
   - Название сигнала: "Пользовательский поиск по журналам".
   - Поисковый запрос: Operation | где в Detail указано OverQuota.
   - Основа: число результатов.
   - Условие: "больше чем".
   - Пороговое значение: 0.
   - Период: 5 (в минутах).
   - Периодичность: 5 (в минутах).
- Название правила генерации оповещений: "Достигнуто ежедневное ограничение сбора данных".
- Серьезность: предупреждение (серьезность 1).

Как только будет определено оповещение и достигнут предел, активируется предупреждение и будет выполнен ответ, определенный в группе действий. Ваша команда может получать сообщение по электронной почте и текстовое сообщение, могут быть автоматизированы действия с помощью веб-перехватчиков, модулей Runbook службы автоматизации или же выполнена [интеграция с внешним решением ITSM](itsmc-overview.md#create-itsm-work-items-from-azure-alerts). 

## <a name="change-the-data-retention-period"></a>Изменение срока хранения данных

В следующих шагах описана настройка периода хранения данных журнала в рабочей области.

### <a name="default-retention"></a>Хранение по умолчанию

Чтобы задать срок хранения по умолчанию для рабочей области, 
 
1. На портале Azure в рабочей области выберите **использование и оценочные затраты** в левой области.
2. В верхней части страницы **Usage and estimated costs** (Использование и ожидаемые затраты) щелкните **Управление объемом данных**.
3. В области воспользуйтесь ползунком, чтобы увеличить или уменьшить количество дней, а затем нажмите кнопку **ОК**.  Если вы используете уровень *Бесплатный*, то вы не сможете изменить срок хранения данных. Необходимо перейти на платный уровень, чтобы управлять этим параметром.

    ![Изменение параметра хранения данных рабочей области](media/manage-cost-storage/manage-cost-change-retention-01.png)
    
Сохранение также можно задать с помощью [Azure Resource Manager](https://docs.microsoft.com/azure/azure-monitor/platform/template-workspace-configuration#configure-a-log-analytics-workspace) с помощью параметра `retentionInDays`. Кроме того, если задать срок хранения данных 30 дней, можно немедленно запустить немедленную очистку старых данных с помощью параметра `immediatePurgeDataOn30Days`, который может быть полезен для сценариев, связанных с соответствием. Эта функция доступна только через Azure Resource Manager. 

Два типа данных--`Usage` и `AzureActivity`--по умолчанию сохраняются в течение 90 дней, а плата за этот период хранения 90 не взимается. Эти типы данных также предоставляются бесплатно из расходов на прием данных. 

### <a name="retention-by-data-type"></a>Хранение по типу данных

Можно также указать различные параметры хранения для отдельных типов данных. Каждый тип данных является подресурсом рабочей области. Например, таблицу SecurityEvent можно устранить в [Azure Resource Manager](https://docs.microsoft.com/azure/azure-resource-manager/resource-group-overview) как:

```
/subscriptions/00000000-0000-0000-0000-00000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.OperationalInsights/workspaces/MyWorkspaceName/Tables/SecurityEvent
```

Обратите внимание, что тип данных (таблица) учитывает регистр.  Чтобы получить текущие параметры хранения для типа данных определенного типа данных (в этом примере это SecurityEvent), используйте следующую команду:

```JSON
    GET /subscriptions/00000000-0000-0000-0000-00000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.OperationalInsights/workspaces/MyWorkspaceName/Tables/SecurityEvent?api-version=2017-04-26-preview
```

Чтобы получить текущие параметры хранения для типа данных для всех типов данных в рабочей области, просто исключите конкретный тип данных, например:

```JSON
    GET /subscriptions/00000000-0000-0000-0000-00000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.OperationalInsights/workspaces/MyWorkspaceName/Tables?api-version=2017-04-26-preview
```

Чтобы задать срок хранения определенного типа данных (в этом примере — SecurityEvent) до 730 дней, выполните

```JSON
    PUT /subscriptions/00000000-0000-0000-0000-00000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.OperationalInsights/workspaces/MyWorkspaceName/Tables/SecurityEvent?api-version=2017-04-26-preview
    {
        "properties": 
        {
            "retentionInDays": 730
        }
    }
```

Типы данных `Usage` и `AzureActivity` не могут быть заданы с помощью настраиваемого хранения. Они будут принимать максимум времени хранения рабочей области по умолчанию или 90 дней. 

Отличным инструментом для прямого подключения к Azure Resource Manager, чтобы задать хранение по типу данных, является инструмент OSS [ARMclient](https://github.com/projectkudu/ARMClient).  Дополнительные сведения о ARMclient см. в статьях по [Дэвид эббо](http://blog.davidebbo.com/2015/01/azure-resource-manager-client.html) и [Даниэль бовбес](https://blog.bowbyes.co.nz/2016/11/02/using-armclient-to-directly-access-azure-arm-rest-apis-and-list-arm-policy-details/).  Вот примере, использующий ARMClient, который устанавливает данные SecurityEvent в 730 день:

```
armclient PUT /subscriptions/00000000-0000-0000-0000-00000000000/resourceGroups/MyResourceGroupName/providers/Microsoft.OperationalInsights/workspaces/MyWorkspaceName/Tables/SecurityEvent?api-version=2017-04-26-preview "{properties: {retentionInDays: 730}}"
```

> [!NOTE]
> Задание хранения для отдельных типов данных можно использовать для снижения затрат на хранение данных.  Для данных, собираемых начиная с октября 2019 (когда эта функция была выпущена), уменьшение срока хранения для некоторых типов данных может снизить стоимость хранения с течением времени.  Для данных, собранных ранее, установка более низкого срока хранения для отдельного типа не повлияет на стоимость хранения.  

## <a name="legacy-pricing-tiers"></a>Устаревшие ценовые категории

Подписки, у которых в ней есть Log Analytics Рабочая область или Application Insights ресурс до 2 апреля 2018, или они связаны с Соглашение Enterprise, который был запущен до 1 февраля 2019, будет по-прежнему иметь доступ для использования устаревших ценовых категорий: **Free**, **Автономный (за ГБ)** и **на узел (OMS)** .  Для рабочих областей в ценовой категории "бесплатный" будет использоваться ограничение ежедневного приема данных в 500 МБ (за исключением типов данных безопасности, собранных центром безопасности Azure), а срок хранения данных ограничен 7 днями. Ценовая категория "бесплатный" предназначена только для ознакомительных целей. Для рабочих областей в ценовых категориях автономная или на уровне узла предусмотрено Настраиваемое пользователем хранение до 2 лет. 

Рабочие области, созданные до апреля 2016, также могут получить доступ к исходным ценовым категориям " **стандартный** " и " **премиум** " с фиксированным сроком хранения данных 30 и 365 дней соответственно. Новые рабочие области нельзя создавать в ценовых категориях " **стандартный** " или " **премиум** ". Если Рабочая область перемещается из этих уровней, она не может быть перемещена обратно. 

Дополнительные сведения об ограничениях ценовых категорий доступны [здесь](https://docs.microsoft.com/azure/azure-subscription-service-limits#log-analytics-workspaces).

> [!NOTE]
> Чтобы использовать права, полученные при покупке подписки OMS E1, OMS E2 или настройки OMS для System Center, выберите ценовой уровень Log Analytics *за узле*.


## <a name="changing-pricing-tier"></a>Изменение ценовой категории.

Если ваша рабочая область Log Analytics имеет доступ к устаревшим уровням ценообразования, для переключения между устаревшими уровнями ценообразования выполните следующее.

1. На портале Azure в области подписок Log Analytics выберите рабочую область.

2. На панели рабочей области в разделе **Общие** щелкните **Ценовая категория**.  

3. В разделе **Ценовая категория** выберите ценовую категорию и щелкните **Выбрать**.  
    ![Выбранный ценовой план](media/manage-cost-storage/workspace-pricing-tier-info.png)

[Ценовую категорию](https://docs.microsoft.com/azure/azure-monitor/platform/template-workspace-configuration#configure-a-log-analytics-workspace) можно также задать с помощью Azure Resource Manager с помощью параметра `sku` (`pricingTier` в шаблоне ARM). 

## <a name="troubleshooting-why-log-analytics-is-no-longer-collecting-data"></a>Почему Log Analytics больше не собирает данные

Если вы используете устаревшую бесплатную ценовую категорию и отправили больше 500 МБ данных за день, сбор данных останавливается до конца дня. Достижение ежедневного ограничения является распространенной причиной, по которой Log Analytics прекращает сбор данных или по которой данные отсутствуют.  Log Analytics создает событие типа "Операция", когда сбор данных начинается и останавливается. Выполните следующий запрос в поле поиска, чтобы проверить, достигнут ли лимит и отсутствуют ли данные: 

```kusto
Operation | where OperationCategory == 'Data Collection Status'
```

При остановке сбора данных значение operationstatus является **предупреждением**. При запуске сбора данных значение operationstatus будет **успешной**. В следующей таблице описаны причины, по которым сбор данных останавливается, и приведены рекомендуемые действия, чтобы его возобновить:  

|Причина прекращения сбора| Решение| 
|-----------------------|---------|
|Достигнут ежедневный предел устаревшей бесплатной ценовой категории. |Дождитесь следующего дня для автоматического перезапуска сбора или перейдите на платную ценовую категорию.|
|Достигнуто ежедневное ограничение рабочей области.|Дождитесь автоматического перезапуска сбора или увеличьте предел ежедневного объема собираемых данных, как описано в разделе управления максимальным ежедневным объемом данных. Время сброса ежедневного ограничения отображается на странице **Управление объемом данных**. |
|Подписка Azure находится в состоянии "Приостановлено" по причине:<br> Период бесплатной пробной версии завершен<br> Истек срок действия Azure Pass<br> Достигнут лимит ежемесячной суммы расходов (например, на подписку MSDN или Visual Studio)|Измените подписку на платную<br> Удалите ограничение или подождите, пока оно сбросится|

Чтобы получать уведомления о прекращении сбора данных, выполните действия, описанные в разделе *Создание оповещения ежедневного ограничения данных* для уведомления о прекращении сбора данных. Выполните действия, описанные в разделе [Создание группы действий](action-groups.md) для настройки электронной почты, веб-перехватчика или действия Runbook для правила генерации оповещений. 

## <a name="troubleshooting-why-usage-is-higher-than-expected"></a>Превышенный объем данных: причины и устранение

Превышенное использование вызывается одной (или двумя) причинами:
- Больше узлов, чем ожидалось, отправка данных в Log Analytics рабочую область
- Больше данных, чем ожидалось, отправляется в Log Analytics рабочую область

## <a name="understanding-nodes-sending-data"></a>Общие сведения об узлах, отправляющих данные

Чтобы понять количество компьютеров, передающих пакеты пульса каждый день в прошлом месяце, используйте

```kusto
Heartbeat | where TimeGenerated > startofday(ago(31d))
| summarize dcount(Computer) by bin(TimeGenerated, 1d)    
| render timechart
```

Чтобы получить список компьютеров, которые будут оплачиваться как узлы, если Рабочая область находится в ценовой категории "устаревшие на узел", найдите узлы, отправляющие **типы данных с оплатой** (некоторые типы данных свободны). Для этого используйте [свойство](log-standard-properties.md#_isbillable) `_IsBillable` и используйте крайнее левое поле полного доменного имени. В результате будет возвращен список компьютеров с данными о счетах:

```kusto
union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| where computerName != ""
| summarize TotalVolumeBytes=sum(_BilledSize) by computerName
```

Число наблюдаемых оплачиваемых узлов можно оценить следующим образом: 

```kusto
union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| where computerName != ""
| billableNodes=dcount(computerName)
```

> [!NOTE]
> Используйте эти запросы `union withsource = tt *` только в случае необходимости, так как сканирование по типам данных требует больших затрат на выполнение. Этот запрос заменяет старый способ запроса информации на компьютере с типом данных использования.  

Более точное вычисление того, что будет оплачиваться, — получение количества компьютеров в час, отправляющих типы данных с оплатой. (Для рабочих областей в ценовой категории "устаревший на узел" Log Analytics вычисляет количество узлов, которые должны оплачиваться на почасовой основе.) 

```kusto
union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| where computerName != ""
| summarize billableNodes=dcount(computerName) by bin(TimeGenerated, 1h) | sort by TimeGenerated asc
```

## <a name="understanding-ingested-data-volume"></a>Основные сведения о принимаемом томе данных

На странице **Использование и ожидаемые затраты** есть диаграмма *Data ingestion per solution* (Прием данных по решениям), которая позволяет отобразить объем отправленных данных в целом и для каждого решения отдельно. Это позволяет выявить некоторые тенденции, например оценить изменения общего объема используемых данных (или по определенному решению). Для создания этой диаграммы применяется такой запрос:

```kusto
Usage | where TimeGenerated > startofday(ago(31d))| where IsBillable == true
| summarize TotalVolumeGB = sum(Quantity) / 1024 by bin(TimeGenerated, 1d), Solution| render barchart
```

Обратите внимание, что предложение "where IsBillable = true" отсеивает выбранные типы данных из определенных решений, для которых не взимается плата за прием данных. 

Вы можете изучить данные еще подробнее, чтобы найти тенденции для определенных типов данных, например для данных из журналов IIS:

```kusto
Usage | where TimeGenerated > startofday(ago(31d))| where IsBillable == true
| where DataType == "W3CIISLog"
| summarize TotalVolumeGB = sum(Quantity) / 1024 by bin(TimeGenerated, 1d), Solution| render barchart
```

### <a name="data-volume-by-computer"></a>Объем данных по компьютерам

Чтобы просмотреть **Размер** оплачиваемых событий, принимаемых на компьютер, используйте [свойство](log-standard-properties.md#_billedsize)`_BilledSize`, которое предоставляет размер в байтах:

```kusto
union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| summarize Bytes=sum(_BilledSize) by  computerName | sort by Bytes nulls last
```

[Свойство](log-standard-properties.md#_isbillable) `_IsBillable` указывает, будут ли полученные данные взиматься за плату.

Чтобы просмотреть число **оплачиваемых** событий, принимаемых на компьютер, используйте 

```kusto
union withsource = tt * 
| where _IsBillable == true 
| extend computerName = tolower(tostring(split(Computer, '.')[0]))
| summarize eventCount=count() by computerName  | sort by count_ nulls last
```

Чтобы счетчики оплачиваемых типов данных отправляли данные на конкретный компьютер, выполните такой запрос:

```kusto
union withsource = tt *
| where Computer == "computer name"
| where _IsBillable == true 
| summarize count() by tt | sort by count_ nulls last
```

### <a name="data-volume-by-azure-resource-resource-group-or-subscription"></a>Объем данных по ресурсам, группам ресурсов или подпискам Azure

Для данных из узлов, размещенных в Azure, можно получить **Размер** оплачиваемых событий, принимаемых __на компьютер__, используя [свойство](log-standard-properties.md#_resourceid)_ResourceId, которое предоставляет полный путь к ресурсу:

```kusto
union withsource = tt * 
| where _IsBillable == true 
| summarize Bytes=sum(_BilledSize) by _ResourceId | sort by Bytes nulls last
```

Для данных из узлов, размещенных в Azure, можно получить **Размер** оплачиваемых событий, принимаемых __для каждой подписки Azure__, проанализируйте свойство `_ResourceId` следующим образом:

```kusto
union withsource = tt * 
| where _IsBillable == true 
| parse tolower(_ResourceId) with "/subscriptions/" subscriptionId "/resourcegroups/" 
    resourceGroup "/providers/" provider "/" resourceType "/" resourceName   
| summarize Bytes=sum(_BilledSize) by subscriptionId | sort by Bytes nulls last
```

При изменении `subscriptionId` на `resourceGroup` будет показан объем оплачиваемых полученных данных в группе ресурсов Azure. 


> [!NOTE]
> Некоторые поля с типом данных Usage (Потребление) уже устарели и данные в них не заполняются, хотя они пока сохраняются в схеме. Например, сюда относятся поля **Computer** и ряд данных о приеме данных (**TotalBatches**, **BatchesWithinSla**, **BatchesOutsideSla**, **BatchesCapped** и **AverageProcessingTimeMs**).

### <a name="querying-for-common-data-types"></a>Запросы к общим типам данных

Чтобы получить более подробную информацию об источнике данных по определенному типу данных, воспользуйтесь приведенными ниже примерами запросов.

+ Решение по **безопасности**
  - `SecurityEvent | summarize AggregatedValue = count() by EventID`
+ Решение для **управления журналами**
  - `Usage | where Solution == "LogManagement" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | summarize AggregatedValue = count() by DataType`
+ Тип данных **Perf**
  - `Perf | summarize AggregatedValue = count() by CounterPath`
  - `Perf | summarize AggregatedValue = count() by CounterName`
+ Тип данных **Event**
  - `Event | summarize AggregatedValue = count() by EventID`
  - `Event | summarize AggregatedValue = count() by EventLog, EventLevelName`
+ Тип данных **Syslog**
  - `Syslog | summarize AggregatedValue = count() by Facility, SeverityLevel`
  - `Syslog | summarize AggregatedValue = count() by ProcessName`
+ Тип данных **AzureDiagnostics**
  - `AzureDiagnostics | summarize AggregatedValue = count() by ResourceProvider, ResourceId`

### <a name="tips-for-reducing-data-volume"></a>Советы по снижению объемов данных

Вот несколько рекомендаций, которые помогут снизить объем собираемых журналов.

| Источник превышенного объема данных | Как сократить объем данных |
| -------------------------- | ------------------------- |
| События безопасности            | Выберите [события со стандартным или минимальным уровнем безопасности](https://docs.microsoft.com/azure/security-center/security-center-enable-data-collection#data-collection-tier). <br> Измените политику аудита безопасности таким образом, чтобы собирать только необходимые события. В частности проверьте необходимость сбора следующих событий: <br> - [аудит платформы фильтрации](https://technet.microsoft.com/library/dd772749(WS.10).aspx); <br> - [аудит реестра](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd941614(v%3dws.10));<br> - [аудит файловой системы](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd772661(v%3dws.10));<br> - [аудит объектов ядра](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd941615(v%3dws.10));<br> - [аудит работы с дескрипторами](https://docs.microsoft.com/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd772626(v%3dws.10));<br> — аудит съемных носителей. |
| Счетчики производительности       | Измените [конфигурацию счетчика производительности](data-sources-performance-counters.md), чтобы <br> уменьшить частоту сбора или <br> сократить число счетчиков производительности. |
| Журналы событий                 | Измените [конфигурацию журнала событий](data-sources-windows-events.md), чтобы <br> сократить число собранных журналов событий или <br> выполнять сбор только необходимых уровней событий. Например, не выполняйте сбор событий уровня *сведений*. |
| Системный журнал                     | Измените [конфигурацию системного журнала](data-sources-syslog.md), чтобы <br> сократить число собранных объектов или <br> выполнять сбор только необходимых уровней событий. Например, не выполняйте сбор событий уровня *сведений* и *отладки*. |
| AzureDiagnostics           | Измените коллекцию журнала ресурсов, чтобы: <br> Уменьшить число ресурсов, отправляющих журналы в Log Analytics. <br> Выполнять сбор только необходимых журналов. |
| Данные решений с компьютеров, которым не требуется решение | Используйте [нацеливание решений](../insights/solution-targeting.md), чтобы выполнять сбор данных только в нужных группах компьютеров. |

### <a name="getting-security-and-automation-node-counts"></a>Получение количества узлов по обеспечению безопасности и автоматизации

Если вы используете ценовую категорию "За узел (OMS)", плата взимается в зависимости от количества используемых узлов и решений. Количество узлов для предложения "Аналитика", для которых выставляются счета, отображается в таблице на странице **Использование и предполагаемые затраты**.  

Чтобы просмотреть количество отдельных узлов безопасности, выполните такой запрос:

```kusto
union
(
    Heartbeat
    | where (Solutions has 'security' or Solutions has 'antimalware' or Solutions has 'securitycenter')
    | project Computer
),
(
    ProtectionStatus
    | where Computer !in~
    (
        (
            Heartbeat
            | project Computer
        )
    )
    | project Computer
)
| distinct Computer
| project lowComputer = tolower(Computer)
| distinct lowComputer
| count
```

Чтобы просмотреть количество отдельных узлов службы автоматизации, выполните такой запрос:

```kusto
 ConfigurationData 
 | where (ConfigDataType == "WindowsServices" or ConfigDataType == "Software" or ConfigDataType =="Daemons") 
 | extend lowComputer = tolower(Computer) | summarize by lowComputer 
 | join (
     Heartbeat 
       | where SCAgentChannel == "Direct"
       | extend lowComputer = tolower(Computer) | summarize by lowComputer, ComputerEnvironment
 ) on lowComputer
 | summarize count() by ComputerEnvironment | sort by ComputerEnvironment asc
```

## <a name="create-an-alert-when-data-collection-is-high"></a>Создавать оповещение при высоком уровне сбора данных

В этом разделе описывается создание оповещения для следующих случаев:
- объем данных превышает заданный объем;
- объем данных превысит заданный объем.

Служба "Оповещения Azure" поддерживает [оповещения журналов](alerts-unified-log.md), использующие поисковые запросы. 

Следующий запрос содержит результат, когда за сутки собрано более 100 ГБ данных:

```kusto
union withsource = $table Usage 
| where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true 
| extend Type = $table | summarize DataGB = sum((Quantity / 1024)) by Type 
| where DataGB > 100
```

Следующий запрос использует простую формулу для прогноза, что в течение 24 часов будет отправлено более 100 ГБ данных: 

```kusto
union withsource = $table Usage 
| where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true 
| extend Type = $table 
| summarize EstimatedGB = sum(((Quantity * 8) / 1024)) by Type 
| where EstimatedGB > 100
```

Чтобы создать оповещения для различных объемов данных, измените значение "100" в запросах на число ГБ, для которых вы хотите создать оповещения.

Выполните действия, описанные в разделе о [создании оповещений журналов](alerts-metric.md), чтобы получать уведомления при превышении ожидаемого объема собираемых данных.

При создании оповещения для первого запроса, когда имеется объем данных, превышающий 100 ГБ в сутки, задайте параметрам следующие значения:  

- Для параметра **Определение условия оповещения** укажите вашу рабочую область Log Analytics в качестве целевого ресурса.
- Для **критериев оповещения** укажите следующее:
   - для **названия сигнала** выберите значение **Пользовательский поиск по журналам**;
   - **поисковому запросу** — `union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize DataGB = sum((Quantity / 1024)) by Type | where DataGB > 100`;
   - **логика оповещений** должна быть **основана на** *числе результатов*, а значение **условия** должно быть *больше* **порогового значения** *0*;
   - укажите **период времени** *1440* минут, а для **частоты оповещений** задайте каждые *60* минут, так как данные об использовании обновляются раз в час.
- В разделе **Определение сведений об оповещении** задайте такие значения:
   - **имени** — *объем данных, превышающий 100 ГБ в сутки*;
   - **серьезности** — *предупреждение*;

Укажите существующую или создайте новую [группу действий](action-groups.md), чтобы получать соответствующее уведомление, когда оповещение журнала соответствует заданным критериям.

При создании оповещения для второго запроса, когда спрогнозировано, что суточный объем данных превысит 100 ГБ, задайте параметрам следующие значения:

- Для параметра **Определение условия оповещения** укажите вашу рабочую область Log Analytics в качестве целевого ресурса.
- Для **критериев оповещения** укажите следующее:
   - для **названия сигнала** выберите значение **Пользовательский поиск по журналам**;
   - **поисковому запросу** — `union withsource = $table Usage | where QuantityUnit == "MBytes" and iff(isnotnull(toint(IsBillable)), IsBillable == true, IsBillable == "true") == true | extend Type = $table | summarize EstimatedGB = sum(((Quantity * 8) / 1024)) by Type | where EstimatedGB > 100`;
   - **логика оповещений** должна быть **основана на** *числе результатов*, а значение **условия** должно быть *больше* **порогового значения** *0*;
   - укажите **период времени** *180* минут, а для **частоты оповещений** задайте каждые *60* минут, так как данные об использовании обновляются один раз в час.
- В разделе **Определение сведений об оповещении** задайте такие значения:
   - **имени** — *объем данных, превышающий 100 ГБ в сутки*;
   - **серьезности** — *предупреждение*;

Укажите существующую или создайте новую [группу действий](action-groups.md), чтобы получать соответствующее уведомление, когда оповещение журнала соответствует заданным критериям.

Когда вы получите оповещение, выполните действия, описанные в следующем разделе, чтобы определить причину использования превышенного объема данных.

## <a name="data-transfer-charges-using-log-analytics"></a>Плата за передачу данных с помощью Log Analytics

Отправка данных в Log Analytics может повлечь за собой плату за пропускную способность данных. Как описано на [странице цен на пропускную способность Azure](https://azure.microsoft.com/pricing/details/bandwidth/), передача данных между службами Azure, расположенными в двух регионах, наследуется в качестве исходящих данных по нормальной ставке. Передача входящих данных предоставляется бесплатно. Однако эта плата очень мала (несколько%) по сравнению с затратами на Log Analytics приема данных. Следовательно, управление затратами на Log Analytics должно сосредоточиться на принятом объеме данных, и мы предлагаем рекомендации, которые помогут понять [это.](https://docs.microsoft.com/azure/azure-monitor/platform/manage-cost-storage#understanding-ingested-data-volume)   

## <a name="limits-summary"></a>Сводная таблица ограничений

Существует несколько дополнительных ограничений Log Analytics, некоторые из которых зависят от ценовой категории Log Analytics. Эти данные описаны [здесь](https://docs.microsoft.com/azure/azure-subscription-service-limits#log-analytics-workspaces).


## <a name="next-steps"></a>Дальнейшие действия

- Сведения об использовании языка поиска см. [в статье Поиск по журналам в Azure Monitor журналах](../log-query/log-query-overview.md) . Вы можете использовать поисковые запросы, чтобы выполнить дополнительный анализ данных об использовании.
- Выполните действия, описанные в разделе о [создании оповещений журналов](alerts-metric.md), чтобы получать уведомления при выполнении условий поиска.
- Используйте [нацеливание решений](../insights/solution-targeting.md), чтобы выполнять сбор данных только в нужных группах компьютеров.
- Сведения о настройке эффективной политики сбора событий см. в статье [Сбор данных в Центре безопасности Azure](../../security-center/security-center-enable-data-collection.md).
- Измените [конфигурацию счетчика производительности](data-sources-performance-counters.md).
- Сведения об изменении параметров сбора событий см. в статье [Источники данных для журнала событий Windows в Log Analytics](data-sources-windows-events.md).
- Сведения об изменении конфигурации системного журнала см. в статье [Источники данных для журнала событий Windows в Log Analytics](data-sources-syslog.md).