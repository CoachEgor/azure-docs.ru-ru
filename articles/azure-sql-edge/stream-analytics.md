---
title: Использование заданий Azure Stream Analytics для пограничных устройств в SQL Azure для пограничных вычислений (предварительная версия)
description: Сведения об использовании заданий Stream Analytics в SQL Azure для пограничных вычислений (предварительная версия)
keywords: SQL для пограничных вычислений, Stream Analytics
services: sql-edge
ms.service: sql-edge
ms.topic: conceptual
author: SQLSourabh
ms.author: sourabha
ms.reviewer: sstein
ms.date: 05/19/2020
ms.openlocfilehash: 7c15312b48e7118517894d8ffd4807e4892e03a3
ms.sourcegitcommit: f1132db5c8ad5a0f2193d751e341e1cd31989854
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/31/2020
ms.locfileid: "84233143"
---
# <a name="using-azure-stream-analytics-jobs-with-sql-edge"></a>Использование заданий Azure Stream Analytics в SQL для пограничных вычислений

SQL Azure для пограничных вычислений (предварительная версия) — это оптимизированное ядро реляционной СУБД, предназначенное для развертываний в Интернете вещей и на пограничных устройствах. Оно основано на последних версиях ядра СУБД Microsoft SQL Server, которые предоставляют ведущие в отрасли возможности повышения уровня производительности и безопасности, а также обработки запросов. Наряду с передовыми возможностями управления реляционными базами данных, которые предоставляются в SQL Server, SQL Azure для пограничных вычислений предоставляет встроенные функции аналитики в реальном времени и сложной обработки событий.

Azure SQL для пограничных вычислений включает собственную реализацию среды выполнения Stream Analytics. Эта реализация позволяет создавать задания Azure Stream Analytics для пограничных устройств и развертывать их как задания потоковой передачи в SQL для пограничных вычислений. Задания Azure Stream Analytics можно развернуть в SQL для пограничных вычислений с помощью аргумента ASAJobInfo, который предоставляется через параметр `module twin's desired properties` в модуле SQL для пограничных вычислений.

```json
{
    "properties.desired":
    {
        "SqlPackage": "<Optional_DACPAC_ZIP_SAS_URL>",
        "ASAJobInfo": "<Optional_ASA_Job_ZIP_SAS_URL>"
    }
}
```

|Поле | Описание |
|------|-------------|
| SqlPackage | Универсальный код ресурса (URI) хранилища BLOB-объектов Azure для ZIP-файла, который содержит пакет DAC для Базы данных SQL.
| ASAJobInfo | Универсальный код ресурса (URI) хранилища BLOB-объектов Azure для задания Azure Stream Analytics для пограничных устройств.

## <a name="create-an-azure-stream-analytics-edge-job"></a>Создание задания Azure Stream Analytics для пограничных устройств

1. Перейдите на портал Azure.

2. Создайте новое задание **Azure Stream Analytics на IoT Edge**. Выберите среду размещения, ориентированную на **пограничные устройства**.

3. Определите входы и выходы для задания Azure Stream Analytics. Каждый выход SQL, который вы здесь указываете, привязывается к одной таблице в базе данных. Если вам нужно передавать данные в несколько таблиц, нужно будет создать несколько выходов для Базы данных SQL. Вы можете настроить выходы SQL, указывающие на разные базы данных.

    **Вход.** Выберите EdgeHub в качестве входа для задания пограничных вычислений и укажите сведения о ресурсе.

    **Выход**. Выберите Базу данных SQL в качестве выхода. Щелкните **Ввести параметры базы данных SQL вручную**. Укажите сведения для настройки базы данных и таблицы.

    |Поле      | Описание |
    |---------------|-------------|
    |Псевдоним выходных данных | Имя псевдонима для выхода.|
    |База данных | Имя базы данных SQL. Здесь должно быть допустимое имя базы данных, реально существующей в экземпляре SQL для пограничных вычислений.|
    |Имя сервера | Имя (или IP-адрес) и номер порта для экземпляра SQL. Для развертывания SQL для пограничных вычислений можно указать в качестве имени сервера значение **tcp:.,1433**.|
    |Имя пользователя | Учетная запись входа в SQL, которая предоставляет права на чтение и запись данных в базе данных, которую вы указали ранее.|
    |Пароль | Пароль для учетной записи входа SQL, которую вы указали ранее.|
    |Таблица | Имя таблицы, которая будет служить выходом для задания потоковой передачи.|
    |Наследование секционирования| Позволяет наследовать схему секционирования от предыдущего шага запроса или входа. Если этот параметр включен, повышается скорость для заданий записи в таблицу на диске с топологией полной параллельной обработки.|
    |Размер пакета| Максимальное число записей, отправляемых с каждой транзакцией массовой вставки.|

    Ниже приведен пример конфигурации входов и выходов.

    ```txt
        Input:
            Input from EdgeHub
            Input alias: input
            Event serialization format: JSON
            Encoding: UTF-8
            Event compression type: None

        Output:
            Output alias: output
            Database:  MeasurementsDB
            Server name: tcp:.,1433
            Username: sa
            Password: <Password>
            Table: TemperatureMeasurements
            Inherit Partitioning: Merge all input partitions into a single writer
            Max batch count: 10000
    ```

    > [!NOTE]
    > Дополнительные сведения о выходном адаптере SQL для Azure Stream Analytics см. в статье [Вывод данных Azure Stream Analytics в Базу данных SQL Azure](../stream-analytics/stream-analytics-sql-output-perf.md).

4. Определите запрос с заданием ASA для пограничных вычислений. Этот запрос должен использовать ранее определенные псевдонимы входов и выходов в качестве имен входных и выходных данных. Дополнительные сведения см. в статье [Справочник по языку запросов Stream Analytics](https://docs.microsoft.com/stream-analytics-query/stream-analytics-query-language-reference).

5. Настройте параметры учетной записи хранения для задания пограничных вычислений. Эта учетная запись хранения используется в качестве целевого объекта публикации для задания пограничных вычислений.

6. В разделе **Настройка** выберите **Опубликовать**. Затем нажмите кнопку **Опубликовать**. Сохраните URI SAS, чтобы использовать его с модулем SQL для пограничных вычислений.

## <a name="deploy-azure-stream-analytics-edge-job-to-sql-edge"></a>Развертывание задания Azure Stream Analytics в SQL для пограничных вычислений

Чтобы развернуть задание потоковой передачи в модуле SQL для пограничных вычислений, обновите конфигурацию модуля SQL для пограничных вычислений, включив в нее URI SAS этого задания потоковой передачи, полученный на предыдущем шаге. Чтобы обновить модуль SQL для пограничных вычислений, сделайте следующее:

1. Перейдите к нужному развертыванию Центра Интернета вещей на портале Azure.

2. В левой области щелкните **IoT Edge**.

3. На странице **IoT Edge** найдите и выберите IoT Edge, где развернут модуль SQL для пограничных вычислений.

4. На странице **Устройство IoT Edge** выберите **Set Module** (Настройка модуля).

5. На странице **Выбор модулей** выберите **Настроить** для нужного модуля SQL для пограничных вычислений.

6. На панели **Пользовательские модули IoT Edge** выберите **Установить требуемые свойства двойника модуля**. Измените требуемые свойства, указав значение универсального кода ресурса (URI) для параметра `ASAJobInfo`, как показано в следующем примере.

    > [!NOTE]
    > URI подписанного URL-адреса в приведенном ниже коде JSON используется только для примера. Замените этот универсальный код ресурса (URI) фактическим значением для вашего развертывания.

    ```json
        {
            "properties.desired":
            {
                "ASAJobInfo": "<<<SAS URL For the published ASA Edge Job>>>>"
            }
        }
    ```

7. Щелкните **Сохранить**.

8. На странице **Выбор модулей** нажмите кнопку **Далее**.

9. На странице **Выбор модулей** нажмите кнопку **Далее**. Затем щелкните элемент **Отправить**.

10. Когда обновление модуля завершится, файл задания Stream Analytics будет скачан, распакован и развернут в экземпляре SQL для пограничных вычислений.

## <a name="next-steps"></a>Дальнейшие действия

- [Развертывание SQL Azure для пограничных вычислений с помощью портала Azure](deploy-portal.md)

- [Потоковая передача данных](stream-data.md)

- [Машинное обучение и ИИ с применением ONNX в SQL для пограничных вычислений (предварительная версия)](onnx-overview.md)
