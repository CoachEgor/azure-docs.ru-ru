---
title: Основные концепции Kubernetes — служба Azure Kubernetes (AKS)
description: Сведения о компонентах Kubernetes для базового кластера и рабочей нагрузки и из связях с функциями службы Azure Kubernetes (AKS)
services: container-service
author: mlearned
ms.service: container-service
ms.topic: conceptual
ms.date: 06/03/2019
ms.author: mlearned
ms.openlocfilehash: 3792eed170d3e3e1cdd267c0c88d2d2d6c520733
ms.sourcegitcommit: 2d9a9079dd0a701b4bbe7289e8126a167cfcb450
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/29/2019
ms.locfileid: "71672812"
---
# <a name="kubernetes-core-concepts-for-azure-kubernetes-service-aks"></a>Ключевые концепции Kubernetes для службы Azure Kubernetes (AKS)

По мере того как разработка приложений перемещается в сторону подхода на основе контейнера, важно управлять ресурсами и контролировать их. Kubernetes сейчас является ведущей платформой надежного планирования рабочих нагрузок для отказоустойчивых приложений. Служба Azure Kubernetes (AKS) — это управляемая среда Kubernetes, упрощающая развертывание приложений на основе контейнеров и управление ими.

В этой статье рассматриваются основные компоненты инфраструктуры Kubernetes, такие как *главный кластер*, *узлы* и *пулы узлов*. Кроме того, здесь дается представление о ресурсах рабочих нагрузок, таких как модули *pod*, *развертывания* и *наборы*, а также о возможности группировать ресурсы в *пространства имен*.

## <a name="what-is-kubernetes"></a>Что такое Kubernetes?

Платформа Kubernetes, которая сейчас очень быстро развивается, предназначена для управления контейнерными приложениями и связанными с ними компонентами сети и хранилища. Основное внимание в ней уделяется рабочим нагрузкам приложений, а не базовым компонентам инфраструктуры. В Kubernetes реализуется декларативный подход к развертываниям, подкрепленный продуманным набором API-интерфейсов для операций управления.

Вы можете создавать и запускать переносимые версии современных приложений на базе микрослужб, использующие возможности Kubernetes по оркестрации и управлению доступностью для поддерживаемых компонентов приложения. Kubernetes поддерживает приложения без отслеживания состояния и с отслеживанием состояния, что очень удобно при адаптации приложений на базе микрослужб.

Kubernetes как открытая платформа позволяет создавать приложения на любом языке программирования, для любой операционной системы, с применением любых библиотек и служб сообщений. С Kubernetes можно интегрировать любые средства непрерывной интеграции и непрерывной поставки (CI/CD) для планирования и развертывания выпусков.

Служба Azure Kubernetes (AKS) предоставляет управляемую службу Kubernetes, которая упрощает выполнение важнейших задач развертывания и управления, в том числе координацию обновлений. Главными узлами кластера AKS управляет платформа Azure, а вы оплачиваете работу только тех узлов AKS, где фактически выполняется ваше приложение. AKS построен на основе модуля Azure Kubernetes Service Engine с открытым исходным кодом ([AKS-Engine][aks-engine]).

## <a name="kubernetes-cluster-architecture"></a>Архитектура кластера Kubernetes

Кластер Kubernetes разделяется на два компонента:

- *главные узлы* кластера предоставляют базовые службы Kubernetes и оркестрируют рабочие нагрузки приложения;
- *узлы* непосредственно выполняют рабочие нагрузки приложения.

![Главные и рядовые узлы кластера Kubernetes](media/concepts-clusters-workloads/cluster-master-and-nodes.png)

## <a name="cluster-master"></a>Главный узел

При создании кластера AKS автоматически создается и настраивается главный узел кластера. Главный узел предоставляется в формате управляемых ресурсов Azure и не привязан к пользователю. На главный кластер кластера не взимается плата, а только узлы, входящие в кластер AKS.

В главном узле размещены следующие основные компоненты Kubernetes:

- *kube-apiserver* — сервер API-интерфейсов, который предоставляет базовые API-интерфейсы Kubernetes. Этот компонент поддерживает взаимодействие со средствами управления, например с `kubectl` или панелью мониторинга Kubernetes.
- *etcd* — поддерживает состояния кластера Kubernetes и конфигурации. В Kubernetes поддерживается хранилище ключей *etcd* с высоким уровнем доступности.
- *kube-scheduler* — при создании или масштабировании приложения этот планировщик принимает решения о том, какие узлы могут выполнять рабочую нагрузку, и запускает их.
- *kube-controller-manager* — диспетчер контроллеров управляет работой нескольких небольших контроллеров, которые выполняют такие действия, как репликация модулей pod и обработка операций узлов.

AKS предоставляет главный узел кластера с одним клиентом, в котором выполняются выделенный сервер API-интерфейсов, планировщик и т. д. Вы только задаете количество и размер узлов, а платформа Azure организует защищенный обмен данными между главными и рядовыми узлами кластера. Взаимодействие с главным узлом кластера происходит через API Kubernetes, например `kubectl` или панель мониторинга Kubernetes.

Этот управляемый главный кластер означает, что вам не нужно настраивать такие компоненты, как хранилище *etcd* высокой доступности, но это также означает, что доступ к хозяину кластера напрямую невозможен. Обновления Kubernetes оркестрируются через Azure CLI или портал Azure. Первыми обновляются главные узлы кластера, а затем рядовые узлы. Для устранения возникших неполадок вы можете изучить журналы главного узла кластера с помощью журналов Azure Monitor.

Если необходимо настроить главный кластер в конкретном случае или требуется прямой доступ к ним, можно развернуть собственный кластер Kubernetes с помощью [AKS Engine][aks-engine].

Соответствующие рекомендации см. в статье рекомендации [по обеспечению безопасности и обновления кластера в AKS][operator-best-practices-cluster-security].

## <a name="nodes-and-node-pools"></a>Узлы и пулы узлов

Чтобы запускать приложения и вспомогательные службы, вам нужен *узел* Kubernetes. Кластер AKS содержит один или несколько узлов. Они представляют собой виртуальные машины Azure, которые выполняют компоненты узла Kubernetes и среду выполнения контейнера.

- Агент Kubernetes `kubelet` обрабатывает запросы оркестрации, поступающие от главного узла кластера, и распределяет работу по выполнению назначенных контейнеров.
- Поддержка виртуальных сетей обеспечивается прокси-сервером *kube-proxy*, который выполняется в каждом узле. Этот прокси-сервер перенаправляет сетевой трафик и управляет IP-адресами для служб и модулей pod.
- *Среда выполнения контейнера* — это компонент, поддерживающий выполнение контейнерных приложений и их взаимодействие с дополнительными ресурсами, такими как виртуальная сеть и хранилище. В AKS в качестве среды выполнения контейнера используется значок Кита.

![Виртуальная машина Azure и вспомогательные ресурсы для узла Kubernetes](media/concepts-clusters-workloads/aks-node-resource-interactions.png)

Размер виртуальной Машины Azure для узлов определяет количество ядер ЦП, объем памяти, а также тип и размер хранилища (высокопроизводительные твердотельные накопители или обычные жесткие диски), которые будут доступны. Если вы ожидаете, что приложениям потребуется большой объем ресурсов ЦП и (или) памяти и (или) высокая производительность хранилища, учтите это при выборе размера узла. Вы также можете масштабировать количество узлов в кластере AKS в соответствии с текущими потребностями.

В AKS образ виртуальной машины для узлов в кластере в настоящее время основан на Ubuntu Linux или Windows Server 2019. Когда вы создаете кластер AKS или масштабируете количество узлов, платформа Azure создает и настраивает необходимое количество виртуальных машин. Ручная настройка не выполняется. Узлы агентов выставляются как стандартные виртуальные машины, поэтому все скидки на используемом вами размере виртуальной машины (включая [резервирование Azure][reservation-discounts]) применяются автоматически.

Если необходимо использовать другую ОС узла, среду выполнения контейнера или включить пользовательские пакеты, можно развернуть собственный кластер Kubernetes с помощью [AKS Engine][aks-engine]. Компоненты и параметры конфигурации становятся доступными для вышестоящего обработчика `aks-engine` раньше, чем начинается официальная поддержка в кластерах AKS. Например, если вы хотите использовать среду выполнения контейнеров, отличную от значок Кита, можно использовать `aks-engine` для настройки и развертывания кластера Kubernetes, который соответствует текущим потребностям.

### <a name="resource-reservations"></a>Резервирование ресурсов

Ресурсы узла используются AKS для обеспечения работы узла в составе кластера. Это может создать дискрепенци между общим ресурсом вашего узла и ресурсами аллокатабле при использовании в AKS. Это важно отметить при задании запросов и ограничений для развернутых пользователем модулей Pod.

Чтобы найти ресурсы аллокатабле узла, выполните следующие действия.
```kubectl
kubectl describe node [NODE_NAME]

```

Для поддержания производительности и функциональности узла ресурсы зарезервированы на каждом узле AKS. По мере роста размера узла в ресурсах резервирование ресурсов растет из-за большего количества пользователей, развернутых в модулях, которым требуется управление.

>[!NOTE]
> Использование таких надстроек, как OMS, будет использовать дополнительные ресурсы узла.

- Зарезервированный **ЦП зависит** от типа узла и конфигурации кластера, что может привести к меньшему аллокатабле ЦП из-за выполнения дополнительных функций

| Ядра ЦП на узле | 1 | 2 | 4 | 8 | 16 | 32|64|
|---|---|---|---|---|---|---|---|
|KUBE — зарезервировано (миллиардах)|60|100|140|180|260|420|740|

- **Память** — резервирование памяти следует за прогрессивной скоростью
  - 25% от первых 4 ГБ памяти
  - 20% следующих 4 ГБ памяти (до 8 ГБ)
  - 10% от следующих 8 ГБ памяти (до 16 ГБ)
  - 6% следующих 112 ГБ памяти (до 128 ГБ)
  - 2% любой памяти выше 128 ГБ

Такое резервирование приводит к тому, что приложениям предоставляется меньше ресурсов ЦП и памяти, чем содержит сам узел. Если возникнут ограничения на ресурсы, связанные с количеством запущенных приложений, такое резервирование гарантирует доступность ЦП и памяти для основных компонентов Kubernetes. Невозможно изменить резервирование ресурса.

Для функционирования базовой ОС узла также требуется некоторое количество ресурсов ЦП и памяти.

Соответствующие рекомендации см. в разделе рекомендации [по основным функциям планировщика в AKS][operator-best-practices-scheduler].

### <a name="node-pools"></a>Пулы узлов

Узлы с одинаковой конфигурацией группируются в *пулы узлов*. Кластер Kubernetes содержит один или несколько пулов узлов. При создании кластера AKS вы указываете начальное количество и размер узлов, которые составляют *пул узлов по умолчанию*. В пуле узлов по умолчанию в AKS содержатся базовые виртуальные машины, на которых выполняются узлы агентов. В настоящее время доступна предварительная версия поддержки нескольких пулов узлов в AKS.

> [!NOTE]
> Чтобы обеспечить надежное функционирование кластера, необходимо запустить по крайней мере 2 узла в пуле узлов по умолчанию.

Когда вы масштабируете или обновляете кластер AKS, выбранные действия применяются именно к пулу узлов по умолчанию. Можно также масштабировать или обновлять конкретный пул узлов. При операциях обновления все запущенные контейнеры поочередно переносятся в другие узлы в том же пуле узлов, пока все узлы не будут успешно обновлены.

Дополнительные сведения об использовании нескольких пулов узлов в AKS см. в статье [Создание пулов нескольких узлов для кластера в AKS и управление ими][use-multiple-node-pools].

### <a name="node-selectors"></a>Селекторы узлов

В кластере AKS, содержащем несколько пулов узлов, может потребоваться сообщить планировщику Kubernetes, какой пул узлов использовать для данного ресурса. Например, контроллеры входящих данных не должны выполняться на узлах Windows Server (в настоящее время они находятся в предварительной версии в AKS). С помощью селекторов узлов можно определить различные параметры, такие как ОС узла, чтобы контролировать, где следует планировать модуль.

В следующем примере экземпляр NGINX планируется на узле Linux с помощью средства выбора узла *"Beta.kubernetes.IO/OS": Linux*:

```yaml
kind: Pod
apiVersion: v1
metadata:
  name: nginx
spec:
  containers:
    - name: myfrontend
      image: nginx:1.15.12
  nodeSelector:
    "beta.kubernetes.io/os": linux
```

Дополнительные сведения о том, как управлять расположением модулей Pod, см. в разделе рекомендации [по использованию расширенных функций планировщика в AKS][operator-best-practices-advanced-scheduler].

## <a name="pods"></a>Модули pod

Для запуска экземпляров приложения Kubernetes использует *модули pod*. Каждый pod соответствует одному экземпляру приложения. Обычно с каждым контейнером сопоставляется ровно один pod, но в некоторых сложных сценариях pod может содержать несколько контейнеров. Такие pod с несколькими контейнерами назначаются одному узлу и позволяют контейнерам совместно использовать связанные с ними ресурсы.

При создании pod вы можете определить *ограничения ресурсов*, чтобы запрашивать определенный объем ресурсов ЦП или памяти. В этом случае планировщик Kubernetes будет стараться распределить pod в узел, содержащий достаточное (запрошенное) количество ресурсов. Вы также можете указать максимальное ограничение на используемые ресурсы, чтобы pod не потреблял слишком много вычислительных ресурсов базового узла. Мы рекомендуем включать ограничения ресурсов для всех pod, чтобы планировщик Kubernetes лучше понимал, какие ресурсы потребуются для работы и какие можно использовать.

Дополнительные сведения см. в разделе жизненный цикл [Kubernetes pods][kubernetes-pods] и [Kubernetes pod lifecycle][kubernetes-pod-lifecycle].

Pod представляет собой логический ресурс, а контейнеры выполняют фактические рабочие нагрузки. Модули pod — это временные одноразовые ресурсы. Отдельное планирование pod лишает вас некоторых возможностей Kubernetes, повышающих уровень доступности и избыточность. Лучше всего доверить развертывание pod и управление ими *контроллерам* Kubernetes, например контроллеру развертывания.

## <a name="deployments-and-yaml-manifests"></a>Развертывания и манифесты YAML

*Развертывание* обозначает один или несколько идентичных модулей pod под управлением контроллера развертывания Kubernetes. Развертывание определяет количество создаваемых *реплик* (pod), а планировщик Kubernetes следит за тем, чтобы при возникновении проблем с pod или узлами своевременно создавались дополнительные модули pod в работоспособных узлах.

Вы можете обновить развертывание, изменяя конфигурацию pod, используемого образа контейнера или хранилища данных. Контроллер развертывания будет освобождать и останавливать некоторое число реплик, а также создавать новые реплики с новым определением развертывания. Этот процесс продолжается, пока не будут обновлены все реплики в развертывании.

Для большинства приложений без отслеживания состояний следует использовать именно такую модель развертывания в AKS, а не распределять отдельные модули pod. Kubernetes может отслеживать работоспособность и состояние развертывания, поддерживая выполнение в кластере необходимого числа реплик. Если запланировать отдельные модули, то модули не перезапускаются при возникновении проблемы и не перепланируются на работоспособные узлы, если на их текущем узле возникла проблема.

Если приложению важно иметь минимальный доступный набор экземпляров, поддерживающий свободу в принятии решений, процесс обновления не должен нарушать такую возможность. *Бюджеты неработоспособности pod* позволяют определить, сколько реплик в развертывании допустимо одновременно отключать на период обновления или изменения узлов. Например, для развертывания с *5-ю* репликами вы можете указать минимальное ограничение в *4* модуля pod, чтобы в любой момент можно было удалять или переназначать только одну реплику. Как и с ограничениями ресурсов для pod, мы рекомендуем всегда указывать бюджет неработоспособности pod для приложений, для которых требуется постоянное присутствие минимального числа реплик.

Развертывания обычно создаются и управляются с помощью `kubectl create` или `kubectl apply`. Чтобы создать развертывание, определите файл манифеста в формате YAML. В следующем примере создается базовое развертывание веб-сервера NGINX. Для этого развертывания настроено создание *3-х* реплик и открытый порт *80* для контейнера. Также определены требуемые и максимальные объемы ресурсов ЦП и памяти.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.2
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 250m
            memory: 64Mi
          limits:
            cpu: 500m
            memory: 256Mi
```

Чтобы создать более сложные приложения, можно включить в манифест в формате YAML дополнительные службы, например подсистемы балансировки нагрузки.

Дополнительные сведения см. в разделе [Kubernetes deployments][kubernetes-deployments].

### <a name="package-management-with-helm"></a>Управление пакетами с помощью Helm

Распространенным подходом к управлению приложениями в Kubernetes является [Helm][helm]. Вы можете создавать новые или использовать существующие общедоступные *диаграммы* Helm, которые содержат упакованную версию кода приложения и YAML-манифесты Kubernetes для развертывания ресурсов. Эти диаграммы Helm могут храниться локально или часто в удаленном репозитории, например в [реестре контейнеров Azure Helm][acr-helm]в репозитории диаграммы.

Чтобы использовать Helm, в кластере Kubernetes устанавливается серверный компонент *Tiller*. Tiller управляет установкой диаграмм в пределах кластера. Сам клиент Helm устанавливается локально на компьютере или может использоваться в [Azure Cloud Shell][azure-cloud-shell]. С помощью клиента вы можете найти или создать диаграммы Helm, а затем установить их в кластере Kubernetes.

![Helm включает клиентский компонент и компонент Tiller на стороне сервера, который создает ресурсы внутри кластера Kubernetes.](media/concepts-clusters-workloads/use-helm.png)

Дополнительные сведения см. [в статье Установка приложений с помощью Helm в службе Kubernetes Azure (AKS)][aks-helm].

## <a name="statefulsets-and-daemonsets"></a>StatefulSet и DaemonSet

Контроллер развертывания использует планировщик Kubernetes для выполнения указанного количества реплик в любом доступном узле с достаточными ресурсами. Такой подход к использованию развертываний часто обоснован для приложений без отслеживания состояния, но непригоден для приложений, которым нужно поддержание постоянных имен или хранилищ. Для приложений, реплика которых должна существовать в каждом узле или в определенном наборе узлов в кластере, контроллер развертывания не отслеживает распределение реплик между узлами.

В работе с такими приложениями вам помогут два ресурса Kubernetes:

- наборы *StatefulSet*, которые поддерживают состояние приложений за пределами жизненного цикла отдельных модулей pod, например для хранилища;
- наборы *Daemonset*, которые обеспечивают запуск экземпляров на каждом узле с самых ранних этапов начальной загрузки Kubernetes.

### <a name="statefulsets"></a>Наборы StatefulSet

Современные приложения часто работают без отслеживания состояния, но если отслеживание состояния будет обязательным, например для приложений с компонентами баз данных, вы можете применить наборы *StatefulSet*. Наборы StatefulSet действуют так же, как развертывание одного или нескольких идентичных модулей pod и управление ими. Для реплик, включенных в StatefulSet, соблюдаются мягкие и последовательные процессы развертывания, масштабирования, обновления и прерывания. Если используется StatefulSet, то при перемещении реплик сохраняются конвенции об именовании, сетевые имена и состояния хранилищ.

Вам достаточно определить приложение в формате YAML с помощью `kind: StatefulSet`, и контроллер StatefulSet возьмет на себя развертывание требуемых реплик, а также управление ими. Данные сохраняются в постоянном хранилище, предоставленном в Управляемых дисках Azure или в службе файлов Azure. При использовании StatefulSet базовое постоянное хранилище сохраняется даже после удаления StatefulSet.

Дополнительные сведения см. в разделе [Kubernetes статефулсетс][kubernetes-statefulsets].

Включенные в StatefulSet реплики назначаются и выполняются в любом доступном узле кластера AKS. Если вам нужно гарантировать, что на каждом узле выполняется по меньшей мере один модуль pod из набора, правильнее использовать наборы DaemonSet.

### <a name="daemonsets"></a>Наборы DaemonSet

Для некоторых задач сбора журналов и (или) мониторинга, возможно, потребуется выполнять определенный модуль pod во всех узлах или в определенном наборе узлов. Объект *DaemonSet* также предназначен для развертывания одного или нескольких идентичных модулей pod, но, в отличие от предыдущего, контроллер DaemonSet гарантирует выполнение экземпляра pod на каждом из указанных узлов.

Контроллер DaemonSet может распределять модули pod в узлы в самом начале процесса загрузки кластера, еще до запуска стандартного планировщика Kubernetes. Эта возможность гарантирует, что модули pod из набора DaemonSet будут запущены раньше, чем модули pod из основного развертывания или набора StatefulSet.

DaemonSet, как и StatefulSet, включается в определение YAML с помощью `kind: DaemonSet`.

Дополнительные сведения см. в разделе [Kubernetes daemonset][kubernetes-daemonset].

> [!NOTE]
> Если используется [надстройка виртуальных узлов](virtual-nodes-cli.md#enable-virtual-nodes-addon), daemonset не будет создавать модули Pod на виртуальном узле.

## <a name="namespaces"></a>Пространства имен

Ресурсы Kubernetes, такие как модули pod и развертывания, логически группируются в *пространства имен*. Такая группировка позволяет логически разделить кластер AKS и ограничить права на создание, просмотр ресурсов и управление ими. Например, вы можете создать отдельные пространства имен для разных бизнес-подразделений. Пользователи смогут взаимодействовать только с ресурсами из назначенных им пространств имен.

![Пространства имен Kubernetes для логического разделения ресурсов и приложений](media/concepts-clusters-workloads/namespaces.png)

Когда вы создаете кластер AKS, вам доступны следующие пространства имен:

- *default* (по умолчанию) — в этом пространстве имен по умолчанию создаются модули pod и развертывания, для которых не указано пространство имен. В небольших средах вполне допустимо развертывать все приложения в пространстве имен по умолчанию, не создавая дополнительные логические разделы. Если при любом взаимодействии с API Kubernetes, например через `kubectl get pods`, не указано конкретное пространство имен, всегда используется пространство имен по умолчанию.
- *kube-system* — в этом пространстве имен содержатся основные ресурсы, такие как DNS, прокси-сервер и другие сетевые компоненты, а также панели мониторинга Kubernetes. Обычно вам не нужно развертывать приложения в этом пространстве имен.
- *kube-public* — это пространство имен обычно не используется. Оно позволяет сделать ресурс видимым в пределах всего кластера и доступным для просмотра всем пользователям.

Дополнительные сведения см. в разделе [пространства имен Kubernetes][kubernetes-namespaces].

## <a name="next-steps"></a>Следующие шаги

Из этой статьи вы узнали об основных компонентах Kubernetes и о том, как они применяются к кластерах AKS. Дополнительные сведения о ключевых концепциях Kubernetes и AKS вы получите в следующих статьях:

- [Доступ и идентификация Kubernetes/AKS][aks-concepts-identity]
- [Безопасность Kubernetes и AKS][aks-concepts-security]
- [Виртуальные сети Kubernetes/AKS][aks-concepts-network]
- [Хранилище Kubernetes/AKS][aks-concepts-storage]
- [Масштабирование Kubernetes/AKS][aks-concepts-scale]

<!-- EXTERNAL LINKS -->
[aks-engine]: https://github.com/Azure/aks-engine
[kubernetes-pods]: https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/
[kubernetes-pod-lifecycle]: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/
[kubernetes-deployments]: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
[kubernetes-statefulsets]: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
[kubernetes-daemonset]: https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/
[kubernetes-namespaces]: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
[helm]: https://helm.sh/
[azure-cloud-shell]: https://shell.azure.com

<!-- INTERNAL LINKS -->
[aks-concepts-identity]: concepts-identity.md
[aks-concepts-security]: concepts-security.md
[aks-concepts-scale]: concepts-scale.md
[aks-concepts-storage]: concepts-storage.md
[aks-concepts-network]: concepts-network.md
[acr-helm]: ../container-registry/container-registry-helm-repos.md
[aks-helm]: kubernetes-helm.md
[operator-best-practices-cluster-security]: operator-best-practices-cluster-security.md
[operator-best-practices-scheduler]: operator-best-practices-scheduler.md
[use-multiple-node-pools]: use-multiple-node-pools.md
[operator-best-practices-advanced-scheduler]: operator-best-practices-advanced-scheduler.md
[reservation-discounts]: ../billing/billing-save-compute-costs-reservations.md