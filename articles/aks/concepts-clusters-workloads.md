---
title: Основные концепции Kubernetes — служба Azure Kubernetes (AKS)
description: Сведения о компонентах Kubernetes для базового кластера и рабочей нагрузки и из связях с функциями службы Azure Kubernetes (AKS)
services: container-service
author: mlearned
ms.service: container-service
ms.topic: conceptual
ms.date: 06/03/2019
ms.author: mlearned
ms.openlocfilehash: 5f387310e737982b824d0ac9662822d9a74f39e9
ms.sourcegitcommit: 6a42dd4b746f3e6de69f7ad0107cc7ad654e39ae
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/07/2019
ms.locfileid: "67616016"
---
# <a name="kubernetes-core-concepts-for-azure-kubernetes-service-aks"></a>Ключевые концепции Kubernetes для службы Azure Kubernetes (AKS)

При перемещении разработки приложений на основе контейнера, важно потребность в координации и управления ресурсами. Kubernetes сейчас является ведущей платформой надежного планирования рабочих нагрузок для отказоустойчивых приложений. Служба Azure Kubernetes (AKS) — это управляемая среда Kubernetes, упрощающая развертывание приложений на основе контейнеров и управление ими.

В этой статье рассматриваются основные компоненты инфраструктуры Kubernetes, такие как *главный кластер*, *узлы* и *пулы узлов*. Кроме того, здесь дается представление о ресурсах рабочих нагрузок, таких как модули *pod*, *развертывания* и *наборы*, а также о возможности группировать ресурсы в *пространства имен*.

## <a name="what-is-kubernetes"></a>Что такое Kubernetes?

Платформа Kubernetes, которая сейчас очень быстро развивается, предназначена для управления контейнерными приложениями и связанными с ними компонентами сети и хранилища. Основное внимание в ней уделяется рабочим нагрузкам приложений, а не базовым компонентам инфраструктуры. В Kubernetes реализуется декларативный подход к развертываниям, подкрепленный продуманным набором API-интерфейсов для операций управления.

Вы можете создавать и запускать переносимые версии современных приложений на базе микрослужб, использующие возможности Kubernetes по оркестрации и управлению доступностью для поддерживаемых компонентов приложения. Kubernetes поддерживает приложения без отслеживания состояния и с отслеживанием состояния, что очень удобно при адаптации приложений на базе микрослужб.

Kubernetes как открытая платформа позволяет создавать приложения на любом языке программирования, для любой операционной системы, с применением любых библиотек и служб сообщений. С Kubernetes можно интегрировать любые средства непрерывной интеграции и непрерывной поставки (CI/CD) для планирования и развертывания выпусков.

Служба Azure Kubernetes (AKS) предоставляет управляемую службу Kubernetes, которая упрощает выполнение важнейших задач развертывания и управления, в том числе координацию обновлений. Главными узлами кластера AKS управляет платформа Azure, а вы оплачиваете работу только тех узлов AKS, где фактически выполняется ваше приложение. AKS построена на основе ядро открытым кодом Azure Kubernetes Service ([aks-engine][aks-engine]).

## <a name="kubernetes-cluster-architecture"></a>Архитектура кластера Kubernetes

Кластер Kubernetes разделяется на два компонента:

- *главные узлы* кластера предоставляют базовые службы Kubernetes и оркестрируют рабочие нагрузки приложения;
- *узлы* непосредственно выполняют рабочие нагрузки приложения.

![Главные и рядовые узлы кластера Kubernetes](media/concepts-clusters-workloads/cluster-master-and-nodes.png)

## <a name="cluster-master"></a>Главный узел

При создании кластера AKS автоматически создается и настраивается главный узел кластера. Главный узел предоставляется в формате управляемых ресурсов Azure и не привязан к пользователю. Нет никаких затрат для главного узла кластера, только узлы, которые являются частью кластера AKS.

В главном узле размещены следующие основные компоненты Kubernetes:

- *kube-apiserver* — сервер API-интерфейсов, который предоставляет базовые API-интерфейсы Kubernetes. Этот компонент поддерживает взаимодействие со средствами управления, например с `kubectl` или панелью мониторинга Kubernetes.
- *etcd* — поддерживает состояния кластера Kubernetes и конфигурации. В Kubernetes поддерживается хранилище ключей *etcd* с высоким уровнем доступности.
- *kube-scheduler* — при создании или масштабировании приложения этот планировщик принимает решения о том, какие узлы могут выполнять рабочую нагрузку, и запускает их.
- *kube-controller-manager* — диспетчер контроллеров управляет работой нескольких небольших контроллеров, которые выполняют такие действия, как репликация модулей pod и обработка операций узлов.

AKS предоставляет главный узел кластера с одним клиентом, в котором выполняются выделенный сервер API-интерфейсов, планировщик и т. д. Вы только задаете количество и размер узлов, а платформа Azure организует защищенный обмен данными между главными и рядовыми узлами кластера. Взаимодействие с главным узлом кластера происходит через API Kubernetes, например `kubectl` или панель мониторинга Kubernetes.

Этот образец управляемого кластера означает, что не нужно настроить компоненты, такие как высокой доступности *etcd* хранилище, но он также означает, что вы нет доступа к хозяину кластера непосредственно. Обновления Kubernetes оркестрируются через Azure CLI или портал Azure. Первыми обновляются главные узлы кластера, а затем рядовые узлы. Для устранения возникших неполадок вы можете изучить журналы главного узла кластера с помощью журналов Azure Monitor.

Если вам нужно настроить главного кластера определенным образом или требуется прямой доступ к ним, вы можете развернуть собственный кластер Kubernetes с помощью [aks-engine][aks-engine].

Связанные практические рекомендации, см. в разделе [советы и рекомендации для обеспечения безопасности кластера и обновления в AKS][operator-best-practices-cluster-security].

## <a name="nodes-and-node-pools"></a>Узлы и пулы узлов

Чтобы запускать приложения и вспомогательные службы, вам нужен *узел* Kubernetes. Кластер AKS содержит один или несколько узлов. Они представляют собой виртуальные машины Azure, которые выполняют компоненты узла Kubernetes и среду выполнения контейнера.

- Агент Kubernetes `kubelet` обрабатывает запросы оркестрации, поступающие от главного узла кластера, и распределяет работу по выполнению назначенных контейнеров.
- Поддержка виртуальных сетей обеспечивается прокси-сервером *kube-proxy*, который выполняется в каждом узле. Этот прокси-сервер перенаправляет сетевой трафик и управляет IP-адресами для служб и модулей pod.
- *Среда выполнения контейнера* — это компонент, поддерживающий выполнение контейнерных приложений и их взаимодействие с дополнительными ресурсами, такими как виртуальная сеть и хранилище. В AKS Кита используется в качестве среды выполнения контейнера.

![Виртуальная машина Azure и вспомогательные ресурсы для узла Kubernetes](media/concepts-clusters-workloads/aks-node-resource-interactions.png)

Размер виртуальной Машины Azure для узлов определяет количество ядер ЦП, объем памяти, а также тип и размер хранилища (высокопроизводительные твердотельные накопители или обычные жесткие диски), которые будут доступны. Если вы ожидаете, что приложениям потребуется большой объем ресурсов ЦП и (или) памяти и (или) высокая производительность хранилища, учтите это при выборе размера узла. Вы также можете масштабировать количество узлов в кластере AKS в соответствии с текущими потребностями.

В AKS образ виртуальной Машины для узлов кластера в данный момент основана на Ubuntu Linux или Windows Server 2019. Когда вы создаете кластер AKS или масштабируете количество узлов, платформа Azure создает и настраивает необходимое количество виртуальных машин. Нет никакой дополнительной настройки можно выполнить. Узлы агентов оплачиваются как стандартные виртуальные машины, поэтому все скидки на размер виртуальной Машины вы используете (включая [Azure резервирования][reservation-discounts]) применяются автоматически.

Если вам нужно использовать другой операционной системы, контейнер среды выполнения, или включить пользовательские пакеты, можно развернуть собственный кластер Kubernetes с помощью [aks-engine][aks-engine]. Компоненты и параметры конфигурации становятся доступными для вышестоящего обработчика `aks-engine` раньше, чем начинается официальная поддержка в кластерах AKS. Например, если вы хотите использовать среду выполнения контейнера Кроме Кита, можно использовать `aks-engine` для настройки и развертывания кластера Kubernetes, подходящие для потребностей текущей.

### <a name="resource-reservations"></a>Резервирование ресурсов

Вам не придется отдельно управлять на каждом узле основными компонентами Kubernetes, такими как *kubelet*, *kube-proxy* и *kube-dns*, но они все же потребляют некоторую часть доступных вычислительных ресурсов. Чтобы поддерживать производительность и работоспособность узла, на каждом узле резервируются следующие вычислительные ресурсы:

- **ЦП** — 60 мс;
- **память** — 20 %, но не более 4 ГиБ.

Такое резервирование приводит к тому, что приложениям предоставляется меньше ресурсов ЦП и памяти, чем содержит сам узел. Если возникнут ограничения на ресурсы, связанные с количеством запущенных приложений, такое резервирование гарантирует доступность ЦП и памяти для основных компонентов Kubernetes. Невозможно изменить резервирования ресурсов.

Пример:

- Узел размером **Standard DS2 v2** содержит 2 виртуальных ЦП и 7 ГиБ памяти.
    - 20 % от 7 Гиб памяти составляет 1,4 ГиБ.
    - На этом узле будет доступно *7 – 1,4 = 5,6 ГиБ* памяти.
    
- Узел размером **Standard E4s v3** содержит 4 виртуальных ЦП и 32 ГиБ памяти.
    - 20 % от 32 Гиб памяти составляет 6,4 Гиб, но AKS резервирует не более 4 ГиБ.
    - На этом узле будет доступно *32–4=28 ГиБ* памяти.
    
Для функционирования базовой ОС узла также требуется некоторое количество ресурсов ЦП и памяти.

Связанные практические рекомендации, см. в разделе [советы и рекомендации для возможности основные планировщика в AKS][operator-best-practices-scheduler].

### <a name="node-pools"></a>Пулы узлов

Узлы с одинаковой конфигурацией группируются в *пулы узлов*. Кластер Kubernetes содержит один или несколько пулов узлов. При создании кластера AKS вы указываете начальное количество и размер узлов, которые составляют *пул узлов по умолчанию*. В пуле узлов по умолчанию в AKS содержатся базовые виртуальные машины, на которых выполняются узлы агентов. Поддержка нескольких пула узла в настоящее время доступна Предварительная версия в AKS.

Когда вы масштабируете или обновляете кластер AKS, выбранные действия применяются именно к пулу узлов по умолчанию. Также можно масштабировать или обновить пуле определенного узла. При операциях обновления все запущенные контейнеры поочередно переносятся в другие узлы в том же пуле узлов, пока все узлы не будут успешно обновлены.

Дополнительные сведения об использовании нескольких пулов узлов в AKS, см. в разделе [создать и управлять несколькими пулы узлов в кластере AKS][use-multiple-node-pools].

### <a name="node-selectors"></a>Селекторы узла

В кластере AKS, который содержит несколько пулов узлов может потребоваться определить планировщик Kubernetes, какой узел пул использовать для данного ресурса. Например входящие контроллеры не должны выполняться на узлах Windows Server (сейчас в предварительной версии в AKS). Узел селекторы позволяют определить различные параметры, например узел операционной системы, к элементу управления, где следует планировать pod.

Следующий пример планирует экземпляр NGINX на узле Linux с помощью селектора узел *«beta.kubernetes.io/os»: linux*:

```yaml
kind: Pod
apiVersion: v1
metadata:
  name: nginx
spec:
  containers:
    - name: myfrontend
      image: nginx:1.15.12
  nodeSelector:
    "beta.kubernetes.io/os": linux
```

Дополнительные сведения о том, как элемент управления, где планируются модулей см. в разделе [советы и рекомендации для возможности расширенной планировщика в AKS][operator-best-practices-advanced-scheduler].

## <a name="pods"></a>Модули pod

Для запуска экземпляров приложения Kubernetes использует *модули pod*. Каждый pod соответствует одному экземпляру приложения. Обычно с каждым контейнером сопоставляется ровно один pod, но в некоторых сложных сценариях pod может содержать несколько контейнеров. Такие pod с несколькими контейнерами назначаются одному узлу и позволяют контейнерам совместно использовать связанные с ними ресурсы.

При создании pod вы можете определить *ограничения ресурсов*, чтобы запрашивать определенный объем ресурсов ЦП или памяти. В этом случае планировщик Kubernetes будет стараться распределить pod в узел, содержащий достаточное (запрошенное) количество ресурсов. Вы также можете указать максимальное ограничение на используемые ресурсы, чтобы pod не потреблял слишком много вычислительных ресурсов базового узла. Мы рекомендуем включать ограничения ресурсов для всех pod, чтобы планировщик Kubernetes лучше понимал, какие ресурсы потребуются для работы и какие можно использовать.

Дополнительные сведения см. в разделе [модули Kubernetes][kubernetes-pods] and [Kubernetes pod lifecycle][kubernetes-pod-lifecycle].

Pod представляет собой логический ресурс, а контейнеры выполняют фактические рабочие нагрузки. Модули pod — это временные одноразовые ресурсы. Отдельное планирование pod лишает вас некоторых возможностей Kubernetes, повышающих уровень доступности и избыточность. Лучше всего доверить развертывание pod и управление ими *контроллерам* Kubernetes, например контроллеру развертывания.

## <a name="deployments-and-yaml-manifests"></a>Развертывания и манифесты YAML

*Развертывание* обозначает один или несколько идентичных модулей pod под управлением контроллера развертывания Kubernetes. Развертывание определяет количество создаваемых *реплик* (pod), а планировщик Kubernetes следит за тем, чтобы при возникновении проблем с pod или узлами своевременно создавались дополнительные модули pod в работоспособных узлах.

Вы можете обновить развертывание, изменяя конфигурацию pod, используемого образа контейнера или хранилища данных. Контроллер развертывания будет освобождать и останавливать некоторое число реплик, а также создавать новые реплики с новым определением развертывания. Этот процесс продолжается, пока не будут обновлены все реплики в развертывании.

Для большинства приложений без отслеживания состояний следует использовать именно такую модель развертывания в AKS, а не распределять отдельные модули pod. Kubernetes может отслеживать работоспособность и состояние развертывания, поддерживая выполнение в кластере необходимого числа реплик. При планировании только отдельных модулей, модулей POD не перезагружается, если они возникнут проблемы и не перепланировано на работоспособные узлы, если возникают неполадки в их текущего узла.

Если приложению важно иметь минимальный доступный набор экземпляров, поддерживающий свободу в принятии решений, процесс обновления не должен нарушать такую возможность. *Бюджеты неработоспособности pod* позволяют определить, сколько реплик в развертывании допустимо одновременно отключать на период обновления или изменения узлов. Например, для развертывания с *5-ю* репликами вы можете указать минимальное ограничение в *4* модуля pod, чтобы в любой момент можно было удалять или переназначать только одну реплику. Как и с ограничениями ресурсов для pod, мы рекомендуем всегда указывать бюджет неработоспособности pod для приложений, для которых требуется постоянное присутствие минимального числа реплик.

Развертывания обычно создаются и управляются с помощью `kubectl create` или `kubectl apply`. Чтобы создать развертывание, определите файл манифеста в формате YAML. В следующем примере создается базовое развертывание веб-сервера NGINX. Для этого развертывания настроено создание *3-х* реплик и открытый порт *80* для контейнера. Также определены требуемые и максимальные объемы ресурсов ЦП и памяти.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.2
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 250m
            memory: 64Mi
          limits:
            cpu: 500m
            memory: 256Mi
```

Чтобы создать более сложные приложения, можно включить в манифест в формате YAML дополнительные службы, например подсистемы балансировки нагрузки.

Дополнительные сведения см. в разделе [развертывания Kubernetes][kubernetes-deployments].

### <a name="package-management-with-helm"></a>Управление пакетами с помощью Helm

Распространенный подход к управлению приложениями в Kubernetes — с [Helm][helm]. Вы можете создавать новые или использовать существующие общедоступные *диаграммы* Helm, которые содержат упакованную версию кода приложения и YAML-манифесты Kubernetes для развертывания ресурсов. Эти диаграммы Helm могут храниться локально или часто в удаленном репозитории, например [репозитория диаграмма Helm реестра контейнеров Azure][acr-helm].

Чтобы использовать Helm, в кластере Kubernetes устанавливается серверный компонент *Tiller*. Tiller управляет установкой диаграмм в пределах кластера. Сам клиент Helm установлен локально на компьютере, или можно использовать в [Azure Cloud Shell][azure-cloud-shell]. С помощью клиента вы можете найти или создать диаграммы Helm, а затем установить их в кластере Kubernetes.

![Helm включает клиентский компонент и компонент Tiller на стороне сервера, который создает ресурсы внутри кластера Kubernetes.](media/concepts-clusters-workloads/use-helm.png)

Дополнительные сведения см. в разделе [устанавливать приложения с помощью Helm в службе Azure Kubernetes (AKS)][aks-helm].

## <a name="statefulsets-and-daemonsets"></a>StatefulSet и DaemonSet

Контроллер развертывания использует планировщик Kubernetes для выполнения указанного количества реплик в любом доступном узле с достаточными ресурсами. Такой подход к использованию развертываний часто обоснован для приложений без отслеживания состояния, но непригоден для приложений, которым нужно поддержание постоянных имен или хранилищ. Для приложений, реплика которых должна существовать в каждом узле или в определенном наборе узлов в кластере, контроллер развертывания не отслеживает распределение реплик между узлами.

В работе с такими приложениями вам помогут два ресурса Kubernetes:

- наборы *StatefulSet*, которые поддерживают состояние приложений за пределами жизненного цикла отдельных модулей pod, например для хранилища;
- наборы *Daemonset*, которые обеспечивают запуск экземпляров на каждом узле с самых ранних этапов начальной загрузки Kubernetes.

### <a name="statefulsets"></a>Наборы StatefulSet

Современные приложения часто работают без отслеживания состояния, но если отслеживание состояния будет обязательным, например для приложений с компонентами баз данных, вы можете применить наборы *StatefulSet*. Наборы StatefulSet действуют так же, как развертывание одного или нескольких идентичных модулей pod и управление ими. Для реплик, включенных в StatefulSet, соблюдаются мягкие и последовательные процессы развертывания, масштабирования, обновления и прерывания. Если используется StatefulSet, то при перемещении реплик сохраняются конвенции об именовании, сетевые имена и состояния хранилищ.

Вам достаточно определить приложение в формате YAML с помощью `kind: StatefulSet`, и контроллер StatefulSet возьмет на себя развертывание требуемых реплик, а также управление ими. Данные сохраняются в постоянном хранилище, предоставленном в Управляемых дисках Azure или в службе файлов Azure. При использовании StatefulSet базовое постоянное хранилище сохраняется даже после удаления StatefulSet.

Дополнительные сведения см. в разделе [Kubernetes StatefulSets][kubernetes-statefulsets].

Включенные в StatefulSet реплики назначаются и выполняются в любом доступном узле кластера AKS. Если вам нужно гарантировать, что на каждом узле выполняется по меньшей мере один модуль pod из набора, правильнее использовать наборы DaemonSet.

### <a name="daemonsets"></a>Наборы DaemonSet

Для некоторых задач сбора журналов и (или) мониторинга, возможно, потребуется выполнять определенный модуль pod во всех узлах или в определенном наборе узлов. Объект *DaemonSet* также предназначен для развертывания одного или нескольких идентичных модулей pod, но, в отличие от предыдущего, контроллер DaemonSet гарантирует выполнение экземпляра pod на каждом из указанных узлов.

Контроллер DaemonSet может распределять модули pod в узлы в самом начале процесса загрузки кластера, еще до запуска стандартного планировщика Kubernetes. Эта возможность гарантирует, что модули pod из набора DaemonSet будут запущены раньше, чем модули pod из основного развертывания или набора StatefulSet.

DaemonSet, как и StatefulSet, включается в определение YAML с помощью `kind: DaemonSet`.

Дополнительные сведения см. в разделе [наборы Daemonset Kubernetes][kubernetes-daemonset].

> [!NOTE]
> При использовании [надстройки виртуальные узлы](virtual-nodes-cli.md#enable-virtual-nodes-addon), наборы Daemonset не создаст модулей на виртуальный узел.

## <a name="namespaces"></a>Пространства имен

Ресурсы Kubernetes, такие как модули pod и развертывания, логически группируются в *пространства имен*. Такая группировка позволяет логически разделить кластер AKS и ограничить права на создание, просмотр ресурсов и управление ими. Например, вы можете создать отдельные пространства имен для разных бизнес-подразделений. Пользователи смогут взаимодействовать только с ресурсами из назначенных им пространств имен.

![Пространства имен Kubernetes для логического разделения ресурсов и приложений](media/concepts-clusters-workloads/namespaces.png)

Когда вы создаете кластер AKS, вам доступны следующие пространства имен:

- *default* (по умолчанию) — в этом пространстве имен по умолчанию создаются модули pod и развертывания, для которых не указано пространство имен. В небольших средах вполне допустимо развертывать все приложения в пространстве имен по умолчанию, не создавая дополнительные логические разделы. Если при любом взаимодействии с API Kubernetes, например через `kubectl get pods`, не указано конкретное пространство имен, всегда используется пространство имен по умолчанию.
- *kube-system* — в этом пространстве имен содержатся основные ресурсы, такие как DNS, прокси-сервер и другие сетевые компоненты, а также панели мониторинга Kubernetes. Обычно вам не нужно развертывать приложения в этом пространстве имен.
- *kube-public* — это пространство имен обычно не используется. Оно позволяет сделать ресурс видимым в пределах всего кластера и доступным для просмотра всем пользователям.

Дополнительные сведения см. в разделе [пространств имен Kubernetes][kubernetes-namespaces].

## <a name="next-steps"></a>Следующие шаги

Из этой статьи вы узнали об основных компонентах Kubernetes и о том, как они применяются к кластерах AKS. Дополнительные сведения о ключевых концепциях Kubernetes и AKS вы получите в следующих статьях:

- [Kubernetes и AKS доступа и удостоверений][aks-concepts-identity]
- [Kubernetes / AKS безопасности][aks-concepts-security]
- [Kubernetes / AKS виртуальных сетей][aks-concepts-network]
- [Kubernetes / AKS хранилища][aks-concepts-storage]
- [Kubernetes / масштабирование AKS][aks-concepts-scale]

<!-- EXTERNAL LINKS -->
[aks-engine]: https://github.com/Azure/aks-engine
[kubernetes-pods]: https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/
[kubernetes-pod-lifecycle]: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/
[kubernetes-deployments]: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/
[kubernetes-statefulsets]: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
[kubernetes-daemonset]: https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/
[kubernetes-namespaces]: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
[helm]: https://helm.sh/
[azure-cloud-shell]: https://shell.azure.com

<!-- INTERNAL LINKS -->
[aks-concepts-identity]: concepts-identity.md
[aks-concepts-security]: concepts-security.md
[aks-concepts-scale]: concepts-scale.md
[aks-concepts-storage]: concepts-storage.md
[aks-concepts-network]: concepts-network.md
[acr-helm]: ../container-registry/container-registry-helm-repos.md
[aks-helm]: kubernetes-helm.md
[operator-best-practices-cluster-security]: operator-best-practices-cluster-security.md
[operator-best-practices-scheduler]: operator-best-practices-scheduler.md
[use-multiple-node-pools]: use-multiple-node-pools.md
[operator-best-practices-advanced-scheduler]: operator-best-practices-advanced-scheduler.md
[reservation-discounts]: ../billing/billing-save-compute-costs-reservations.md