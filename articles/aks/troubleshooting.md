---
title: Устранение распространенных проблем со Службой Azure Kubernetes
description: Узнайте, как устранить распространенные проблемы при использовании Службы Azure Kubernetes (AKS).
services: container-service
author: sauryadas
ms.service: container-service
ms.topic: troubleshooting
ms.date: 08/13/2018
ms.author: saudas
ms.openlocfilehash: 00fadd8a98ec4f58783ed8b407e2621a7c107149
ms.sourcegitcommit: 040abc24f031ac9d4d44dbdd832e5d99b34a8c61
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/16/2019
ms.locfileid: "69533521"
---
# <a name="aks-troubleshooting"></a>Устранение неполадок с AKS

При создании кластеров Azure Kubernetes Service (AKS) или управлении ими иногда вы можете сталкиваться с проблемами. В этой статье описаны некоторые распространенные проблемы и действия по устранению неполадок.

## <a name="in-general-where-do-i-find-information-about-debugging-kubernetes-problems"></a>Где найти общие сведения об отладке проблем Kubernetes?

[Вот официальное руководство по устранению неполадок с кластерами Kubernetes](https://kubernetes.io/docs/tasks/debug-application-cluster/troubleshooting/).
[Это руководство по устранению неполадок](https://github.com/feiskyer/kubernetes-handbook/blob/master/en/troubleshooting/index.md) модулей pod, узлов, кластеров и т. д., опубликованное инженером Майкрософт.

## <a name="im-getting-a-quota-exceeded-error-during-creation-or-upgrade-what-should-i-do"></a>Я получаю ошибку превышения квоты во время создания или обновления. Что делать? 

Вам необходимо [запросить ядра](https://docs.microsoft.com/azure/azure-supportability/resource-manager-core-quotas-request).

## <a name="what-is-the-maximum-pods-per-node-setting-for-aks"></a>Каково максимальное число модулей pod на узел, установленное для AKS?

Если вы развертываете кластер AKS на портале Azure, максимальное число модулей pod на узел по умолчанию составляет 30.
Если вы развертываете кластер AKS в Azure CLI, максимальное число модулей pod на узел по умолчанию составляет 110. Убедитесь, что используется последняя версия Azure CLI. Этот параметр по умолчанию можно изменить с помощью флага `–-max-pods` в команде `az aks create`.

## <a name="im-getting-an-insufficientsubnetsize-error-while-deploying-an-aks-cluster-with-advanced-networking-what-should-i-do"></a>Я получаю ошибку insufficientSubnetSize при развертывании кластера AKS с использованием расширенного сетевого взаимодействия. Что делать?

Если используется Azure CNI (расширенная сеть), AKS предварительно выделяет IP-адреса на основе настроенного максимального числа pod для каждого узла. В кластере AKS может быть любое число узлов в диапазоне от 1 до 110. На основе настроенного максимального числа модулей pod для каждого узла, размер подсети должен быть больше "произведения количества узлов и максимального числа модулей pod на узел". Следующее основное выражение описывает:

Размер подсети > количество узлов в кластере (с учетом требований к масштабированию в будущем) * максимальное число модулей pod на узел.

Дополнительные сведения см. в разделе [Планирование назначения IP-адресов для кластера](configure-azure-cni.md#plan-ip-addressing-for-your-cluster).

## <a name="my-pod-is-stuck-in-crashloopbackoff-mode-what-should-i-do"></a>Мой модуль pod завис в режиме CrashLoopBackOff. Что делать?

Модуль pod может зависнуть в этом режиме по различным причинам. Вы можете просмотреть:

* сведения о самом модуле pod с помощью команды `kubectl describe pod <pod-name>`;
* сведения в журналах с помощью команды `kubectl log <pod-name>`.

Дополнительные сведения об устранении неполадок модуля pod см. в статье об [отладке приложений](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-application/#debugging-pods).

## <a name="im-trying-to-enable-rbac-on-an-existing-cluster-how-can-i-do-that"></a>Я пытаюсь включить RBAC в существующем кластере. Как это сделать?

К сожалению, включение RBAC в существующих кластерах в настоящее время не поддерживается. Необходимо явно создать кластеры. Если вы используете CLI, RBAC включается по умолчанию. Если вы используете портал AKS, в рабочем процессе создания будет доступен переключатель для включения RBAC.

## <a name="i-created-a-cluster-with-rbac-enabled-by-using-either-the-azure-cli-with-defaults-or-the-azure-portal-and-now-i-see-many-warnings-on-the-kubernetes-dashboard-the-dashboard-used-to-work-without-any-warnings-what-should-i-do"></a>Кластер создан с поддержкой RBAC помощью Azure CLI со значениями по умолчанию или на портале Azure, при этом на панели мониторинга Kubernetes появились многочисленные предупреждения. Ранее на панели мониторинга не возникало никаких предупреждений. Что делать?

Причина отображения предупреждений на панели мониторинга заключается в том, что теперь в кластере включена функция RBAC, в которой доступ к этой панели отключен по умолчанию. В целом этот подход является рекомендуемым, так как раскрытие панели мониторинга по умолчанию для всех пользователей кластера может привести к угрозам безопасности. Если вы по-прежнему хотите включить панель мониторинга, следуйте указаниям в этом [блоге](https://pascalnaber.wordpress.com/2018/06/17/access-dashboard-on-aks-with-rbac-enabled/).

## <a name="i-cant-connect-to-the-dashboard-what-should-i-do"></a>Мне не удается подключиться к панели мониторинга. Что делать?

Самый простой способ получить доступ к службе за пределами кластера — запустить `kubectl proxy`, который будет запрашивать ваш локальный порт 8001 для подключения к серверу API Kubernetes. После этого сервер API может установить прокси-подключение к вашей службе: `http://localhost:8001/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/#!/node?namespace=default`.

Если вы не видите панель мониторинга Kubernetes, проверьте, запущен ли модуль pod `kube-proxy` в пространстве имен `kube-system`. Если модуль pod находится в нерабочем состоянии, удалите его, и он перезапустится.

## <a name="i-cant-get-logs-by-using-kubectl-logs-or-i-cant-connect-to-the-api-server-im-getting-error-from-server-error-dialing-backend-dial-tcp-what-should-i-do"></a>Мне не удается получить журналы kubectl, или подключение к серверу API завершается сбоем. Я получаю сообщение об ошибке "сервер: ошибка при вызове внутреннего сервера: вызов TCP...". Что делать?

Убедитесь, что группа безопасности сети по умолчанию не изменена и что порт 22 и 9000 открыты для подключения к серверу API. Проверьте, выполняется `tunnelfront` ли модуль Pod в пространстве имен *KUBE-System* с помощью `kubectl get pods --namespace kube-system` команды. Если он не запущен, принудительно удалите его, и он перезапустится.

## <a name="im-trying-to-upgrade-or-scale-and-am-getting-a-message-changing-property-imagereference-is-not-allowed-error-how-do-i-fix-this-problem"></a>При попытке обновления или масштабирования я получаю подобное сообщение: Changing property 'imageReference' is not allowed (Не разрешено изменять свойство imageReference). Как устранить эту проблему?

Возможно, вы получаете эту ошибку, потому что изменили теги в узлах агента внутри кластера AKS. Изменение и удаление тегов и других свойств ресурсов в группе ресурсов MC_* может привести к непредвиденным результатам. Изменение ресурсов в группе MC_* в кластере AKS нарушает цель уровня обслуживания (SLO).

## <a name="im-receiving-errors-that-my-cluster-is-in-failed-state-and-upgrading-or-scaling-will-not-work-until-it-is-fixed"></a>Я получаю ошибки, когда кластер находится в состоянии сбоя, и обновление или масштабирование не будут работать, пока оно не будет исправлено

*Эта помощь направляется из https://aka.ms/aks-cluster-failed*

Эта ошибка возникает, когда кластеры перейдет в состояние сбоя по нескольким причинам. Выполните следующие действия, чтобы устранить сбой кластера перед повторным выполнением ранее выполненной операции.

1. Пока кластер не окажется `failed` в состоянии, `upgrade` и `scale` операции не будут выполнены. Ниже приведены общие основные проблемы и способы их устранения.
    * Масштабирование с недостаточной **квотой Compute (CRP)** . Чтобы устранить эту проблему, сначала выполните масштабирование кластера до стабильного состояния цели в пределах квоты. Затем выполните следующие [действия, чтобы запросить увеличение квоты вычислений,](../azure-supportability/resource-manager-core-quotas-request.md) прежде чем пытаться увеличить масштаб после превышения квоты на начальные значения.
    * Масштабирование кластера с расширенными сетевыми возможностями и недостаточными **сетевыми ресурсами**. Чтобы устранить эту проблему, сначала выполните масштабирование кластера до стабильного состояния цели в пределах квоты. Затем выполните следующие [действия, чтобы запросить увеличение квоты ресурсов](../azure-resource-manager/resource-manager-quota-errors.md#solution) перед попыткой увеличения масштаба после превышения квоты на начальные значения.
2. После устранения проблемы с обновлением кластер должен находиться в состоянии "успешно". После проверки состояния "успех" повторите исходную операцию.

## <a name="im-receiving-errors-when-trying-to-upgrade-or-scale-that-state-my-cluster-is-being-currently-being-upgraded-or-has-failed-upgrade"></a>Возникли ошибки при попытке обновления или масштабирования состояния, в котором выполняется обновление кластера или произошел сбой обновления

*Эта помощь направляется из https://aka.ms/aks-pending-upgrade*

Операции обновления и масштабирования в кластере с одним пулом узлов или кластером с [несколькими пулами узлов](use-multiple-node-pools.md) являются взаимоисключающими. Нельзя одновременно обновлять и масштабировать кластер или пул узлов. Вместо этого каждый тип операции должен быть завершен в целевом ресурсе до следующего запроса к этому же ресурсу. В результате операции ограничены при выполнении активных операций обновления или масштабирования, а также при последующей попытке сбоя. 

Для диагностики выполнения `az aks show -g myResourceGroup -n myAKSCluster -o table` проблемы, чтобы получить подробные сведения о состоянии кластера. В зависимости от результата:

* Если кластер активно обновляется, дождитесь завершения операции. В случае успеха повторите операцию, которая была выполнена ранее.
* Если произошел сбой обновления кластера, выполните действия, описанные в предыдущем разделе.

## <a name="can-i-move-my-cluster-to-a-different-subscription-or-my-subscription-with-my-cluster-to-a-new-tenant"></a>Можно ли переместить кластер в другую подписку или подписку с кластером в новый клиент?

Если вы переместили кластер AKS в другую подписку или подписку на другой клиент, кластер потеряет функциональные возможности из-за потери назначений ролей и прав субъектов служб. **AKS не поддерживает перемещение кластеров между подписками или клиентами** из-за этого ограничения.

## <a name="im-receiving-errors-trying-to-use-features-that-require-virtual-machine-scale-sets"></a>При попытке использования функций, требующих масштабируемых наборов виртуальных машин, возникают ошибки

*Эта помощь по устранению неполадок направляется от aka.ms/aks-vmss-enablement*

Могут возникать ошибки, указывающие, что кластер AKS не находится в масштабируемом наборе виртуальных машин, как показано в следующем примере:

**Для Ажентпул "ажентпул" задано автоматическое масштабирование "включено", но оно отсутствует в масштабируемых наборах виртуальных машин**

Чтобы использовать такие функции, как Автомасштабирование кластера или пулы с несколькими узлами, необходимо создать кластеры AKS, использующие масштабируемые наборы виртуальных машин. Ошибки возвращаются при попытке использовать функции, которые зависят от масштабируемых наборов виртуальных машин, и вы используете обычный кластер AKS, не являющийся масштабируемым набором виртуальных машин. Сейчас поддержка масштабируемого набора виртуальных машин доступна в предварительной версии в AKS.

*Перед началом* действий в соответствующем документе выполните действия из соответствующего документа, чтобы правильно зарегистрироваться в предварительной версии компонента масштабируемого набора виртуальных машин и создать кластер AKS.

* [Использование автомасштабирования кластера](cluster-autoscaler.md)
* [Создание и использование пулов с несколькими узлами](use-multiple-node-pools.md)
 
## <a name="what-naming-restrictions-are-enforced-for-aks-resources-and-parameters"></a>Какие ограничения именования применяются к AKS ресурсам и параметрам?

*Эта помощь по устранению неполадок направляется от aka.ms/aks-naming-rules*

Ограничения именования реализуются как платформой Azure, так и AKS. Если имя или параметр ресурса нарушает одно из этих ограничений, возвращается сообщение об ошибке, предлагающее указать другие входные данные. Применяются следующие общие рекомендации по именованию.

* Имя группы ресурсов AKS *MC_* объединяет имя группы ресурсов и имя ресурса. Автоматически созданный синтаксис `MC_resourceGroupName_resourceName_AzureRegion` должен быть не длиннее 80 символов. При необходимости Сократите длину имени группы ресурсов или имени кластера AKS.
* *DnsPrefix* должен начинаться и заканчиваться буквенно-цифровыми значениями. Допустимые символы включают буквенно-цифровые значения и дефисы (–). *DnsPrefix* не может содержать специальные символы, такие как точка (.).

## <a name="im-receiving-errors-when-trying-to-create-update-scale-delete-or-upgrade-cluster-that-operation-is-not-allowed-as-another-operation-is-in-progress"></a>При попытке создать, обновить, масштабировать, удалить или обновить кластер возникают ошибки. Эта операция запрещена, так как выполняется другая операция.

*Эта помощь по устранению неполадок направляется от aka.ms/aks-pending-operation*

Операции с кластером ограничены, если предыдущая операция все еще выполняется. Чтобы получить подробные сведения о состоянии кластера, используйте `az aks show -g myResourceGroup -n myAKSCluster -o table` команду. При необходимости используйте собственную группу ресурсов и имя кластера AKS.

На основе выходных данных состояния кластера:

* Если кластер находится в состоянии подготовки, отличном от " *успешно* " или " *сбой*", дождитесь завершения операции (обновление, обновление, создание, масштабирование,*Удаление*или миграция). После завершения предыдущей операции повторите последнюю операцию с кластером.

* Если в кластере произошел сбой обновления, выполните действия, описанные в разделе " [ошибки", когда кластер находится в состоянии сбоя, а обновление или масштабирование не будет работать до исправления](#im-receiving-errors-that-my-cluster-is-in-failed-state-and-upgrading-or-scaling-will-not-work-until-it-is-fixed).
