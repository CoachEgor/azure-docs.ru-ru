---
title: Перенос сотен терабайт данных в Azure Cosmos DB
description: Этот документ описывает, как можно перенести 100 терабайт данных в Космос DB
author: bharathsreenivas
ms.service: cosmos-db
ms.subservice: cosmosdb-sql
ms.topic: conceptual
ms.date: 10/23/2019
ms.author: bharathb
ms.openlocfilehash: 69b400eb7838c986ac6f275da58c7457179ebea6
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "72880204"
---
# <a name="migrate-hundreds-of-terabytes-of-data-into-azure-cosmos-db"></a>Перенос сотен терабайт данных в Azure Cosmos DB 

Azure Cosmos DB может хранить терабайты данных. Вы можете выполнить крупномасштабную миграцию данных, чтобы переместить рабочую нагрузку в Azure Cosmos DB. В этой статье описаны проблемы, связанные с крупномасштабным перемещением данных в Azure Cosmos DB, а также представлено средство, которое помогает устранять проблемы и переносить данные в Azure Cosmos DB. В этом примере клиент использовал API SQL Cosmos DB.  

Перед переносом всей рабочей нагрузки в DB Azure Cosmos можно перенести подмножество данных для проверки некоторых аспектов, таких как выбор ключа раздела, производительность запроса и моделирование данных. После проверки подтверждения концепции можно переместить всю рабочую нагрузку в Azure Cosmos DB.  

## <a name="tools-for-data-migration"></a>Инструменты для миграции данных 

Стратегии миграции Azure Cosmos DB в настоящее время различаются в зависимости от выбора API и размера данных. Для переноса меньших наборов данных — для проверки моделирования данных, производительности запроса, выбора ключа раздела и т.д. — можно выбрать [инструмент миграции данных](import-data.md) или [разъем Azure Cosmos DB.](../data-factory/connector-azure-cosmos-db.md) Если вы знакомы с Spark, вы также можете использовать [разъем Azure Cosmos DB Spark](spark-connector.md) для переноса данных.

## <a name="challenges-for-large-scale-migrations"></a>Проблемы для крупномасштабных миграций 

Существующие инструменты для переноса данных в Azure Cosmos DB имеют некоторые ограничения, которые становятся особенно очевидными в больших масштабах:

 * **Ограниченные возможности масштабирования**: Для того, чтобы как можно быстрее перенести терабайты данных в Azure Cosmos DB и эффективно потреблять всю прокладку данных, клиенты миграции должны иметь возможность масштабироваться бесконечно.  

* **Отсутствие отслеживания хода и проверки:** Важно отслеживать прогресс миграции и иметь контрольные указания при миграции больших наборов данных. В противном случае любая ошибка, возниканизаемая во время миграции, остановит миграцию, и вы должны начать процесс с нуля. Было бы непродуктивно перезапустить весь процесс миграции, когда 99% из него уже завершено.  

* **Отсутствие мертвой очереди букв**: В больших наборах данных в некоторых случаях могут возникнуть проблемы с частями исходных данных. Кроме того, могут возникнуть временные проблемы с клиентом или сетью. Ни один из этих случаев не должен привести к сбою всей миграции. Несмотря на то, что большинство инструментов миграции имеют надежные возможности повторная попытка, которые защищают от периодических проблем, этого не всегда достаточно. Например, если размер исходных данных превышает 0,01% исходных данных, это приведет к сбою записи документа в Azure Cosmos DB. В идеале инструменту миграции полезно упорствовать в этих «неудачных» документах в другую мертвую очередь букв, которая может быть обработана после миграции. 

Многие из этих ограничений исправляются для таких инструментов, как фабрика данных Azure, службы миграции данных Azure. 

## <a name="custom-tool-with-bulk-executor-library"></a>Пользовательский инструмент с библиотекой исполнителей сыпучих 

Проблемы, описанные в вышеуказанном разделе, могут быть решены с помощью пользовательского инструмента, который может быть легко масштабируется в нескольких экземплярах и устойчив к временным сбоям. Кроме того, пользовательский инструмент может приостановить и возобновить миграцию на различных контрольно-пропускных пунктах. Azure Cosmos DB уже предоставляет [библиотеку исполнителей с объемом,](https://docs.microsoft.com/azure/cosmos-db/bulk-executor-overview) которая включает в себя некоторые из этих функций. Например, библиотека исполнителей с объемом уже имеет функциональность для обработки временных ошибок и может масштабировать потоки в одном узло, чтобы потреблять около 500 K RUs на узла. Библиотека-исполнитель навалом также разрезает набор исходных данных на микро-пакеты, которые управляются независимо как форма контрольно-пропускного пункта.  

Пользовательский инструмент использует библиотеку исполнителей навалом и поддерживает масштабирование в несколько клиентов и отслеживание ошибок в процессе приема. Чтобы использовать этот инструмент, исходные данные должны быть разделены на отдельные файлы в Хранилище озер данных Azure (ADLS), чтобы различные работники миграции могли забрать каждый файл и проглотать их в Azure Cosmos DB. Пользовательский инструмент использует отдельную коллекцию, которая хранит метаданные о ходе миграции для каждого отдельного исходного файла в ADLS и отслеживает любые ошибки, связанные с ними.  

Следующее изображение описывает процесс миграции с помощью этого пользовательского инструмента. Инструмент работает на наборе виртуальных машин, и каждая виртуальная машина запрашивает сбор отслеживания в Azure Cosmos DB, чтобы приобрести в аренду один из разделов исходных данных. Как только это будет сделано, раздел исходных данных считывается инструментом и попадает в Azure Cosmos DB с помощью библиотеки исполнителей. Далее, сбор отслеживания обновляется для записи хода приема данных и любых обнаруженных ошибок. После обработки раздела данных инструмент пытается запросить следующий доступный раздел источника. Он продолжает обрабатывать следующий раздел источника до тех пор, пока все данные не будут перенесены. Исходный код инструмента доступен [здесь](https://github.com/Azure-Samples/azure-cosmosdb-bulkingestion).  

 
![Настройка инструмента миграции](./media/migrate-cosmosdb-data/migrationsetup.png)
 

 

Коллекция отслеживания содержит документы, указанные в следующем примере. Такие документы по одному для каждого раздела будут в исходных данных.  Каждый документ содержит метаданные для раздела исходных данных, такие как его местоположение, статус миграции и ошибки (если таковые имеются):  

```json
{ 
  "owner": "25812@bulkimporttest07", 
  "jsonStoreEntityImportResponse": { 
    "numberOfDocumentsReceived": 446688, 
    "isError": false, 
    "totalRequestUnitsConsumed": 3950252.2800000003, 
    "errorInfo": [], 
    "totalTimeTakenInSeconds": 188, 
    "numberOfDocumentsImported": 446688 
  }, 
  "storeType": "AZURE_BLOB", 
  "name": "sourceDataPartition", 
  "location": "sourceDataPartitionLocation", 
  "id": "sourceDataPartitionId", 
  "isInProgress": false, 
  "operation": "unpartitioned-writes", 
  "createDate": { 
    "seconds": 1561667225, 
    "nanos": 146000000 
  }, 
  "completeDate": { 
    "seconds": 1561667515, 
    "nanos": 180000000 
  }, 
  "isComplete": true 
} 
```
 

## <a name="prerequisites-for-data-migration"></a>Предпосылки для миграции данных 

Перед началом миграции данных необходимо учитывать несколько предпосылок:  

#### <a name="estimate-the-data-size"></a>Оцените размер данных:  

Размер исходных данных может не сопоставить размер данных в Azure Cosmos DB. Несколько выборочных документов из источника могут быть вставлены для проверки размера их данных в Azure Cosmos DB. В зависимости от размера выборки документа можно оценить общий размер данных в Azure Cosmos DB после миграции. 

Например, если каждый документ после миграции в Azure Cosmos DB составляет около 1 кБ, а в исходном наборе данных около 60 миллиардов, это будет означать, что предполагаемый размер в Azure Cosmos DB будет близок к 60 ТБ. 

 

#### <a name="pre-create-containers-with-enough-rus"></a>Предварительное создание контейнеров с достаточным количеством RUs: 

Хотя Azure Cosmos DB автоматически масштабирует хранение, не рекомендуется начинать с наименьшего размера контейнера. Меньшие контейнеры имеют более низкую пропускную готовность, что означает, что для завершения миграции потребуется гораздо больше времени. Вместо этого полезно создать контейнеры с окончательным размером данных (как предполагалось на предыдущем этапе) и убедиться, что рабочая нагрузка по миграции полностью потребляет просрлизм.  

На предыдущем этапе. поскольку, по оценкам, размер данных составляет около 60 ТБ, для размещения всего набора данных требуется контейнер объемом не менее 2,4 Млн РУ.  

 

#### <a name="estimate-the-migration-speed"></a>Оцените скорость миграции: 

Если предположить, что миграционная рабочая нагрузка может потреблять всю подготовленную пропускную выливку, подготовленная во всем будет обеспечивать оценку скорости миграции. Продолжая предыдущий пример, для записи документа с 1 кВ для учетной записи Azure Cosmos DB S'L API требуется 5 R.  2,4 миллиона RUs позволит передавать 480 000 документов в секунду (или 480 МБ/с). Это означает, что полная миграция 60 ТБ займет 125 000 секунд или около 34 часов.  

В случае, если вы хотите, чтобы миграция была завершена в течение дня, необходимо увеличить просрлизм до 5 миллионов rUs. 

 

#### <a name="turn-off-the-indexing"></a>Выключите индексацию:  

Поскольку миграция должна быть завершена как можно скорее, желательно свести к минимуму время и RUs, затраченные на создание индексов для каждого из погонянных документов.  Azure Cosmos DB автоматически индексирует все свойства, стоит свести к минимуму индексацию до выбранных нескольких терминов или полностью отключить ее для переноса. Вы можете отключить политику индексирования контейнера, изменив индексную Mode на ни один, как показано ниже:  

 
```
  { 
        "indexingMode": "none" 
  } 
```
 

После завершения миграции можно обновить индексирование.  

## <a name="migration-process"></a>Процесс миграции 

После завершения предпосылок можно перенести данные следующими шагами:  

1. Сначала импортируйте данные из источника в Хранилище Azure Blob. Чтобы увеличить скорость миграции, полезно проводить параллель между различными разделами источника. Перед началом миграции набор исходных данных должен быть разделен на файлы размером около 200 МБ.   

2. Объем библиотеки исполнителей может масштабироваться, потребляя 500 000 RUs в одном клиенте VM. Поскольку доступная пропускная связь составляет 5 миллионов rUs, 10 UBuntu 16.04 VMs (Standard_D32_v3) должны быть подготовлены в том же регионе, где находится ваша база данных Azure Cosmos. Эти вм-файлы должны быть подготовл с помощью инструмента миграции и файла настроек.  

3. Запустите ступень очереди на одной из виртуальных машин клиента. Этот шаг создает коллекцию отслеживания, которая сканирует контейнер ADLS и создает документ отслеживания хода для каждого из файлов раздела набора исходных данных.  

4. Затем запустите шаг импорта на всех клиентских VMs. Каждый из клиентов может взять на себя ответственность за раздел источника и глотать свои данные в Azure Cosmos DB. Как только он завершен и его статус будет обновлен в коллекции отслеживания, клиенты могут запросить следующий доступный раздел исходного кода в коллекции отслеживания.  

5. Этот процесс продолжается до тех пор, пока не будет просачен весь набор исходных перегородок. После обработки всех исходных разделов инструмент должен быть повторен в режиме коррекции ошибок в одном и том же сборе отслеживания. Этот шаг необходим для определения исходных разделов, которые должны быть переработаны из-за ошибок.  

6. Некоторые из этих ошибок могут быть вызваны неверными документами в исходных данных. Они должны быть идентифицированы и исправлены. Далее следует повторно запустить шаг импорта на неисправных разделах, чтобы перевернуть их. 

После завершения миграции можно проверить, что количество документов в DB Azure Cosmos совпадает с подсчетом документов в исходной базе данных. В этом примере общий размер в Azure Cosmos DB составил 65 терабайт. После миграции, индексация может быть выборочно включена, и RUs может быть снижен до уровня, требуемого для работы рабочей нагрузки.

## <a name="contact-the-azure-cosmos-db-team"></a>Свяжитесь с командой Azure Cosmos DB
Хотя вы можете следовать этому руководству, чтобы успешно перенести большие наборы данных в Azure Cosmos DB, для крупномасштабных миграций рекомендуется обратиться к группе продуктов Azure Cosmos DB для проверки моделирования данных и общего обзора архитектуры. Основываясь на наборе данных и рабочей нагрузке, команда разработчиков может также предложить другие оптимизации производительности и затрат, которые могут быть применимы к вам. Чтобы связаться с командой Azure Cosmos DB для получения помощи в крупномасштабных миграциях, можно открыть билет поддержки в соответствии с типом проблемы "Общее консультирование" и подтипом проблемы "Большие (ТБ) "

![Тема поддержки миграции](./media/migrate-cosmosdb-data/supporttopic.png)


## <a name="next-steps"></a>Дальнейшие действия

* Узнайте больше, опробовав пример приложений, потребляющих библиотеку исполнителей навалом в [.NET](bulk-executor-dot-net.md) и [Java.](bulk-executor-java.md) 
* Библиотека-исполнитель навалом интегрирована в разъем Cosmos DB Spark, чтобы узнать больше, [см.](spark-connector.md)  
* Свяжитесь с группой продуктов Azure Cosmos DB, открыв билет поддержки в соответствии с типом проблемы "Общее консультирование" и подтипом проблемы "Большие (ТБ) " для получения дополнительной помощи при крупномасштабных миграциях. 
