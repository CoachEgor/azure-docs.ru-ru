---
title: Используйте управление API Azure с помощью микрослужб, развернутых в службе Azure Kubernetes (ru) Документы Майкрософт
description: В этой статье описаны варианты развертывания Управления API с помощью AKS
services: api-management
documentationcenter: ''
author: miaojiang
manager: cfowler
editor: ''
ms.service: api-management
ms.workload: mobile
ms.tgt_pltfrm: na
ms.topic: article
ms.date: 12/14/2019
ms.author: apimpm
ms.openlocfilehash: 1d6773b4daac256234c33bf50fb3736d585ac505
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "75481000"
---
# <a name="use-azure-api-management-with-microservices-deployed-in-azure-kubernetes-service"></a>Используйте управление API Azure с микрослужбами, развернутыми в службе Azure Kubernetes

Микросервисы идеально подходят для создания AA. С помощью [службы Azure Kubernetes](https://azure.microsoft.com/services/kubernetes-service/) Service (AKS) можно быстро развернуть и управлять [архитектурой на основе микрослужб](https://docs.microsoft.com/azure/architecture/guide/architecture-styles/microservices) в облаке. Затем можно использовать [Azure API Management](https://aka.ms/apimrocks) (API Management) для публикации микрослужб в качестве API для внутреннего и внешнего потребления. В этой статье описаны варианты развертывания Управления API с помощью AKS. Он предполагает базовые знания о компаниях Kubernetes, API Management и сети Azure. 

## <a name="background"></a>Историческая справка

При публикации микрослужб в качестве AA для потребления может быть сложно управлять связью между микрослужбами и клиентами, которые их потребляют. Существует множество проблем, связанных с перекрестной резкостью, таких как аутентификация, авторизация, регулирование, кэширование, преобразование и мониторинг. Эти проблемы являются действительными независимо от того, подвергаются ли микрослужбы внутренним или внешним клиентам. 

Шаблон [API Gateway](https://docs.microsoft.com/dotnet/architecture/microservices/architect-microservice-container-applications/direct-client-to-microservice-communication-versus-the-api-gateway-pattern) устраняет эти проблемы. Шлюз API служит входной дверью для микрослужб, отсоединяет клиентов от микрослужб, добавляет дополнительный уровень безопасности и снижает сложность ваших микрослужб, снимая бремя обработки проблем, связанных с перекрестной резки. 

[Управление API Azure API](https://aka.ms/apimrocks) — это решение под ключ для решения потребностей шлюза API. Вы можете быстро создать согласованный и современный шлюз для микрослужб и опубликовать их в виде AI. В качестве решения для управления API с полным жизненным циклом он также предоставляет дополнительные возможности, включая портал разработчиков самообслуживания для обнаружения API, управления жизненным циклом API и аналитики API.

При совместной использовании AKS и API Management предоставляют платформу для развертывания, публикации, обеспечения безопасности, мониторинга и управления API на основе микрослужб. В этой статье мы пройдем несколько вариантов развертывания AKS совместно с API Management. 

## <a name="kubernetes-services-and-apis"></a>Услуги и AA Ubernetes

В кластере Kubernetes контейнеры размещаются в [стручках,](https://kubernetes.io/docs/concepts/workloads/pods/pod/)которые являются эфемерными и имеют жизненный цикл. При смерти рабочего узла стручки, работающие на уде, теряются. Таким образом, IP-адрес Pod может измениться в любое время. Мы не можем полагаться на него, чтобы общаться с стручка. 

Чтобы решить эту проблему, Kubernetes представил концепцию [услуг](https://kubernetes.io/docs/concepts/services-networking/service/). Служба Kubernetes — это слой абстракции, который определяет логическую группу стручков и обеспечивает внешнее воздействие трафика, балансировку нагрузки и обнаружение сервиса для этих стручков. 

Когда мы готовы публиковать наши микросервисы в качестве API через API Management, нам нужно подумать о том, как сопоставить наши услуги в Kubernetes с API в aPI Management. Нет установленных правил. Это зависит от того, как вы разработали и разделить ваши бизнес-возможности или домены в микрослужбы в начале. Например, если стручки службы несут ответственность за все операции на данном ресурсе (например, Customer), служба может быть отображана в одном API. Если операции на ресурсе разделены на несколько микрослужб (например, GetOrder, PlaceOrder), то несколько служб могут быть логически агрегированы в один aPI в управлении API (см. рис. 1). 

Отображение также может развиваться. Поскольку API Management создает фасад перед микрослужбами, это позволяет нам рефакторингировать и правильного размера наших микрослужб с течением времени. 

![Карта услуг для AA](./media/api-management-aks/service-api-mapping.png)

## <a name="deploy-api-management-in-front-of-aks"></a>Развертывание управления API перед AKS

Существует несколько вариантов развертывания Управления API перед кластером AKS. 

В то время как кластер AKS всегда развертывается в виртуальной сети (VNet), экземпляр Управления API не требуется для развертывания в VNet. Если API Management не находится в кластере VNet, кластер AKS должен публиковать общедоступные конечные точки для подключения API Management. В этом случае необходимо обеспечить связь между API Management и AKS. Другими словами, мы должны обеспечить доступ к кластеру только через API Management. Давайте рассмотрим варианты. 

### <a name="option-1-expose-services-publicly"></a>Вариант 1: Услуги по публичному воздействию

Службы в кластере AKS могут быть публично раскрыты с помощью [типов служб](https://docs.microsoft.com/azure/aks/concepts-network) NodePort, LoadBalancer или ExternalName. В этом случае услуги доступны непосредственно из публичного интернета. После развертывания API Management перед кластером мы должны обеспечить, чтобы весь входящий трафик проходил через API Management, применяя аутентификацию в микросервисах. Например, API Management может включать токен доступа в каждый запрос, сделанный в кластер. Каждая микрослужба несет ответственность за проверку токена перед обработкой запроса. 


Это может быть самым простым вариантом развертывания API Management перед AKS, особенно если в микрослужбах уже реализована логика проверки подлинности. 

![Публикация услуг напрямую](./media/api-management-aks/direct.png)

Преимущества.
* Легкая конфигурация на стороне управления API, поскольку она не должна быть введена в кластер VNet
* Нет изменений со стороны AKS, если службы уже открыты, а логика проверки подлинности уже существует в микрослужбах

Недостатки.
* Потенциальный риск для безопасности из-за публичной видимости конечных точек Службы
* Нет точки с одним входом для входящего кластерного трафика
* Усложняет микрослужбы с дубликатом логики аутентификации

### <a name="option-2-install-an-ingress-controller"></a>Вариант 2: Установка контроллера входа

Хотя вариант 1 может быть проще, он имеет заметные недостатки, как упоминалось выше. Если экземпляр Управления API не находится в кластере VNet, взаимная проверка подлинности TLS (mTLS) является надежным способом обеспечения безопасности трафика и доверия в обоих направлениях между экземпляром Управления API и кластером AKS. 

Взаимная аутентификация TLS [поддерживается aPI](https://docs.microsoft.com/azure/api-management/api-management-howto-mutual-certificates) Management и может быть включена в Kubernetes путем [установки контроллера Ingress (рис.](https://docs.microsoft.com/azure/aks/ingress-own-tls) 3). В результате аутентификация будет выполняться в ingress Controller, что упрощает микрослужбы. Кроме того, можно добавить IP-адреса API Management в разрешенный список Ingress, чтобы убедиться, что только API Management имеет доступ к кластеру.  

 
![Публикация через контроллер входа](./media/api-management-aks/ingress-controller.png)


Преимущества.
* Легкая конфигурация на стороне Управления API, поскольку она не нуждается в впрыскиваемых в кластер VNet и mTLS является родной поддержкой
* Централизирует защиту входящего кластерного трафика на слое Ingress Controller
* Снижает риск безопасности за счет минимизации общедоступных конечных точек кластера

Недостатки.
* Увеличивает сложность конфигурации кластера за счет дополнительной работы по установке, настройке и обслуживанию контроллера Ingress и управления сертификатами, используемыми для mTLS
* Риск для безопасности из-за публичной видимости конечной точки Ingress Controller (ы)


При публикации API в Управлении API использование ключей подписки является самым простым способом защитить доступ к этим интерфейсам API. Разработчики, которым требуется использовать опубликованные API, должны включать действительный ключ подписки в HTTP-запросах при выполнении вызовов к этим API. Иначе все вызовы немедленно игнорируются шлюзом Управления API. Они не передаются в серверные службы.

Чтобы получить ключ подписки для доступа к API, нужна подписка. Подписка по сути является именованным контейнером для пары ключей подписки. Разработчики, которым требуется доступ к опубликованным API, могут получить подписки. Им не требуется согласие издателей API. Издатели API могут самостоятельно создавать подписки напрямую для пользователей API.

### <a name="option-3-deploy-apim-inside-the-cluster-vnet"></a>Вариант 3: Развертывание APIM внутри кластера VNet

В некоторых случаях клиенты с нормативными ограничениями или строгими требованиями безопасности могут найти нежизнеспособные решения по вариантам 1 и 2 из-за публично открытых конечных точек. В других странах кластер AKS и приложения, потребляющие микрослужбы, могут находиться в пределах одного и того же VNet, поэтому нет причин публично разоблачать кластер, так как весь трафик API останется в VNet. В этих сценариях можно развернуть управление API в кластере VNet. [Уровень API Management Premium](https://aka.ms/apimpricing) поддерживает развертывание VNet. 

Существует два способа [развертывания Управления API в VNet](https://docs.microsoft.com/azure/api-management/api-management-using-with-vnet) - внешний и внутренний. 

Если потребители API не проживают в кластере VNet, следует использовать внешний режим (рис. 4). В этом режиме шлюз Управления API вводится в кластер VNet, но доступен из общедоступного интернета через внешний балансера нагрузки. Это помогает полностью скрыть кластер, позволяя внешним клиентам потреблять микрослужбы. Кроме того, можно использовать сетевые возможности Azure, такие как Network Security Groups (NSG), для ограничения сетевого трафика.

![Внешний режим VNet](./media/api-management-aks/vnet-external.png)

Если все потребители API находятся в кластере VNet, то можно использовать внутренний режим (рис. 5). В этом режиме шлюз Управления API вводится в кластер VNET и доступен только из этого VNet через внутренний балансеер нагрузки. Нет никакого способа добраться до шлюза Управления API или кластера AKS из публичного интернета. 

![Внутренний режим VNet](./media/api-management-aks/vnet-internal.png)

 В обоих случаях кластер AKS не является общедоступным. По сравнению с вариантом 2, Ingress Controller может не быть необходимым. В зависимости от сценария и конфигурации, проверка подлинности может по-прежнему потребоваться между Управлением API и вашими микрослужбами. Например, если сетка службы принята, она всегда требует взаимной аутентификации TLS. 

Преимущества.
* Наиболее безопасный вариант, поскольку кластер AKS не имеет общедоступной конечной точки
* Упрощает конфигурацию кластера, так как она не имеет общедоступной конечной точки
* Возможность скрыть как API Management, так и AKS внутри VNet с помощью внутреннего режима
* Возможность управления сетевым трафиком с помощью сетевых возможностей Azure, таких как группы сетевой безопасности (NSG)

Недостатки.
* Увеличивает сложность развертывания и настройки управления API для работы внутри VNet

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте больше о [концепциях Сети для приложений в AKS](https://docs.microsoft.com/azure/aks/concepts-network)
* Узнайте больше о [том, как использовать управление API с виртуальными сетями](https://docs.microsoft.com/azure/api-management/api-management-using-with-vnet)





