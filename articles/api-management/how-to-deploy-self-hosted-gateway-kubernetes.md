---
title: Развертывание самостоятельно размещенного шлюза в Kubernetes | Документация Майкрософт
description: Узнайте, как развернуть компонент шлюза с самостоятельным размещением в службе управления API Azure в Kubernetes
services: api-management
author: vladvino
manager: gwallace
ms.service: api-management
ms.workload: mobile
ms.topic: article
ms.author: apimpm
ms.date: 04/23/2020
ms.openlocfilehash: 7802614540bd5e553fbf1d7a0884ffa2f7433c37
ms.sourcegitcommit: 67bddb15f90fb7e845ca739d16ad568cbc368c06
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "82205109"
---
# <a name="deploy-self-hosted-gateway-to-kubernetes"></a>Развертывание самостоятельно размещенного шлюза в Kubernetes

В этой статье описаны действия по развертыванию компонента самостоятельно размещенного шлюза службы управления API Azure в кластере Kubernetes.

## <a name="prerequisites"></a>Предварительные условия

- Выполните следующие действия в кратком руководстве по [созданию экземпляра службы управления API Azure](get-started-create-service-instance.md) .
- Создайте кластер Kubernetes.
> [!TIP]
> [Кластеры с одним узлом](https://kubernetes.io/docs/setup/#learning-environment) хорошо работают в целях разработки и оценки. Используйте [сертифицированные Kubernetes](https://kubernetes.io/partners/#conformance) кластеры с несколькими узлами в локальной среде или в облаке для рабочих нагрузок.
- [Подготавливает ресурс шлюза с самостоятельным размещением в экземпляре управления API](api-management-howto-provision-self-hosted-gateway.md).

## <a name="deploy-to-kubernetes"></a>Развертывание в Kubernetes

1. Выберите **шлюзы** в разделе **развертывание и инфраструктура**.
2. Выберите ресурс самостоятельно размещенного шлюза, который планируется развернуть.
3. Выберите **развертывание**.
4. Обратите внимание, что маркер доступа в текстовом поле **маркера** был создан автоматически при использовании значений **срока действия** по умолчанию и **секретного ключа** . При необходимости выберите нужные значения в одном или обоих элементах управления для создания нового маркера.
5. В разделе **скрипты развертывания**выберите вкладку **Kubernetes** .
6. Щелкните ссылку **<имя шлюза>. yml** и скачайте файл YAML.
7. Щелкните значок **Копировать** в правом нижнем углу текстового поля **развернуть** , чтобы сохранить `kubectl` команды в буфер обмена.
8. Вставка команд в окно терминала (или команда). Первая команда создает секрет Kubernetes, содержащий маркер доступа, созданный на шаге 4. Вторая команда применяет файл конфигурации, скачанный на шаге 6, в кластер Kubernetes и ждет, что файл находится в текущем каталоге.
9. Выполните команды, чтобы создать необходимые объекты Kubernetes в [пространстве имен по умолчанию](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) и запустить самостоятельно размещенные шлюзы из [образа контейнера](https://aka.ms/apim/sputnik/dhub) , скачанного из реестра контейнеров Майкрософт.
10. Выполните команду, показанную ниже, чтобы проверить, было ли развертывание выполнено. Обратите внимание, что для создания объектов и инициализации модулей может потребоваться немного времени.
```console
kubectl get deployments
NAME             READY   UP-TO-DATE   AVAILABLE   AGE
<gateway-name>   1/1     1            1           18s
```
11. Выполните команду, показанную ниже, чтобы проверить, успешно ли создана служба. Обратите внимание, что IP-адреса и порты службы будут отличаться.
```console
kubectl get services
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
<gateway-name>   LoadBalancer   10.99.236.168   <pending>     80:31620/TCP,443:30456/TCP   9m1s
```
12. Вернитесь к портал Azure и выберите **Обзор**.
13. **Состояние** , показывающее зеленый значок галочки, за которым следует число узлов, соответствующее количеству реплик, указанных в файле YAML, подтверждает, что развернутые автономные модули шлюзов успешно взаимодействуют со службой управления API и имеют обычный "Пульс".

![состояние шлюза](media/how-to-deploy-self-hosted-gateway-kubernetes/status.png)

> [!TIP]
> Выполните <code>kubectl logs deployment/<gateway-name></code> команду, чтобы просмотреть журналы из случайно выбранного модуля Pod, если имеется более одного.
> Выполните <code>kubectl logs -h</code> для полного набора параметров команды, например для просмотра журналов конкретного Pod или контейнера.

## <a name="production-deployment-considerations"></a>Вопросы развертывания в рабочей среде

### <a name="access-token"></a>Маркер доступа
Без действительного шлюза для самостоятельного размещения маркера доступа не удается получить доступ и скачать конфигурацию из конечной точки данных конфигурации связанной службы управления API. Маркер доступа может быть допустимым не более 30 дней. Его необходимо создать повторно, а кластер с свежим маркером — вручную или с помощью автоматизации до истечения срока действия. При автоматизации обновления маркеров используйте эту [операцию](https://docs.microsoft.com/rest/api/apimanagement/2019-12-01/gateway/generatetoken) API управления для создания нового маркера. Перейдите по этой [ссылке](https://kubernetes.io/docs/concepts/configuration/secret) , чтобы получить сведения об управлении секретами Kubernetes.

### <a name="namespace"></a>Пространство имен
[Пространства имен](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) Kubernetes помогают разделить один кластер между несколькими командами, проектами или приложениями. Пространства имен предоставляют область для ресурсов и имен и могут быть связаны с квотами ресурсов и политиками управления доступом.
Команды, предоставляемые в портал Azure создавать самостоятельно размещенные ресурсы шлюзов в пространстве имен **по умолчанию** , которое создается автоматически, существует в каждом кластере и не может быть удалено.
Рассмотрите возможность [создания и развертывания](https://kubernetesbyexample.com/ns/) самостоятельно размещенного шлюза в отдельном пространстве имен в рабочей среде.

### <a name="number-of-replicas"></a>Количество реплик
Минимальное число реплик, подходящих в рабочей среде, равно двум.

По умолчанию самостоятельно размещенный шлюз развертывается с помощью [стратегии](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy)развертывания **роллингупдате** . Просмотрите значения по умолчанию и рассмотрите возможность явного задания полей [**максунаваилабле**](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#max-unavailable) и [**макссурже**](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#max-surge) , особенно при использовании счетчика высокой реплики.

### <a name="container-resources"></a>Ресурсы контейнера
По умолчанию файл YAML, указанный в портал Azure, не указывает запросы ресурсов контейнера.

Невозможно надежно предсказать и рекомендовать объем ресурсов ЦП и памяти для каждого контейнера, а также количество реплик, необходимых для поддержки конкретной рабочей нагрузки из-за многих факторов, например:

- Конкретное оборудование, на котором работает кластер
- Присутствие и тип виртуализации
- Число и скорость параллельных подключений клиентов
- Частота запросов
- Тип и количество настроенных политик
- Размер полезных данных и, если полезная нагрузка буферизована или потоковая передача
- Задержка серверной службы

Рекомендуется задать для запроса ресурса 2 ядра и 2 гиб в качестве отправной точки, выполнить нагрузочный тест и увеличить или уменьшить масштаб или уменьшение или в зависимости от результатов.

### <a name="container-image-tag"></a>Тег образа контейнера
В файле YAML, указанном в портал Azure, используется **последний** тег, который всегда ссылается на последнюю версию образа контейнера автономного шлюза.

Рекомендуется использовать тег определенной версии в рабочей среде во избежание непреднамеренного обновления до более новой версии.

Чтобы просмотреть полный список доступных тегов, перейдите по этой [ссылке](https://mcr.microsoft.com/v2/azure-api-management/gateway/tags/list) .

### <a name="dns-policy"></a>Политика DNS
Разрешение DNS-имен играет важную роль в разрешении на самостоятельно размещении шлюза для подключения к зависимостям в Azure и диспетчеризации вызовов API к серверным службам.

Файл YAML, указанный в портал Azure, применяет политику [**клустерфирст**](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy) по умолчанию, которая приводит к тому, что запросы разрешения имен, не разрешенные DNS-сервером кластера, перенаправляются на вышестоящий DNS-сервер, наследуемый от узла.

Перейдите по этой [ссылке](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service) , чтобы узнать о разрешении имен в Kubernetes и рассмотрите возможность настройки [политики DNS](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy) или[конфигурации системы NS](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-config) в соответствии с настройками.

### <a name="configuration-backup"></a>Резервная копия конфигурации
Перейдите по этой [ссылке](self-hosted-gateway-overview.md#connectivity-to-azure) , чтобы узнать о поведении собственного шлюза при наличии временного сбоя подключения к Azure.
Настройте локальный том хранилища для контейнера саморазмещенного шлюза, чтобы он мог сохранить резервную копию последней скачанной конфигурации, и, если подключение не работает, используйте его после перезагрузки. Путь подключения тома должен иметь <code>/apim/config</code>значение. Пример вы можете найти [здесь](https://github.com/Azure/api-management-self-hosted-gateway/blob/master/examples/self-hosted-gateway-with-configuration-backup.yaml).
Чтобы узнать о хранилище в Kubernetes, перейдите по этой [ссылке](https://kubernetes.io/docs/concepts/storage/volumes/).

### <a name="local-logs-and-metrics"></a>Локальные журналы и метрики
Самостоятельно размещенный шлюз отправляет данные телеметрии в [Azure Monitor](api-management-howto-use-azure-monitor.md) и [Azure Application Insights](api-management-howto-app-insights.md) на параметры конфигурации в связанной службе управления API.
Когда [Подключение к Azure](self-hosted-gateway-overview.md#connectivity-to-azure) временно теряется, поток телеметрии в Azure прерывается и данные теряются в течение сбоя.
Рассмотрите возможность [настройки локального мониторинга](how-to-configure-local-metrics-logs.md) , чтобы обеспечить возможность наблюдения за трафиком API и предотвращения потери данных телеметрии во время простоя подключения Azure.

## <a name="next-steps"></a>Дальнейшие шаги

* Дополнительные сведения о самостоятельно размещенном шлюзе см. в статье [Обзор самостоятельного размещения шлюза в службе управления API Azure](self-hosted-gateway-overview.md) .