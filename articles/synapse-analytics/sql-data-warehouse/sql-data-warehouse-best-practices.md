---
title: Рекомендации для пула Synapse S'L в Azure Synapse Analytics (ранее S'L DW)
description: Рекомендации и рекомендации по разработке решений для пула S'L в Azure Synapse Analytics (ранее S'L DW).
services: synapse-analytics
author: mlee3gsd
manager: craigg
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 11/04/2019
ms.author: martinle
ms.reviewer: igorstan
ms.openlocfilehash: 0a2a49546a31f6d767b5e89348dc6b703278d877
ms.sourcegitcommit: d597800237783fc384875123ba47aab5671ceb88
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/03/2020
ms.locfileid: "80633633"
---
# <a name="best-practices-for-synapse-sql-pool-in-azure-synapse-analytics-formerly-sql-dw"></a>Рекомендации для пула Synapse S'L в Azure Synapse Analytics (ранее S'L DW)

Данная статья представляет собой набор рекомендаций, которые помогут вам достичь оптимальной производительности в результате развертывания [пула S'L.](sql-data-warehouse-overview-what-is.md)  Цель этой статьи состоит в том, чтобы дать вам некоторые основные рекомендации и выделить важные области внимания.  

## <a name="reduce-cost-with-pause-and-scale"></a>Снижение расходов за счет приостановки и масштабирования ресурсов

Дополнительные сведения о сокращении затрат при помощи приостановки и масштабирования см. в статье об [управлении вычислительными ресурсами](sql-data-warehouse-manage-compute-overview.md).

## <a name="maintain-statistics"></a>Обеспечение статистики

Пул спомощьи может быть настроен для автоматического обнаружения и создания статистики по столбцам.  Планы запросов, созданные оптимизатором, хороши только так же хорошо, как и доступная статистика.  

Мы рекомендуем включить AUTO_CREATE_STATISTICS для баз данных и обновлять статистику ежедневно или после каждой загрузки, чтобы гарантировать, что статистика столбцов, используемых в ваших запросах, всегда актуальна.

Если вы обнаружите, что обновление всех статистических данных занимает слишком много времени, вы можете попытаться быть более избирательными в отношении того, какие столбцы нуждаются в частых обновлениях статистики. Например, можно ежедневно обновлять столбцы дат, в которые добавляются новые значения.

> [!TIP]
> Наибольшую выгоду вы получите, обновив статистику по столбикам, участвующим в соединениях, столбцам, используемым в оговорке WHERE, и столбцам, найденным в GROUP BY.

Смотрите также [Управление таблицей статистики](sql-data-warehouse-tables-statistics.md), [CREATE STATISTICS](https://msdn.microsoft.com/library/ms188038.aspx), и ОБНОВЛЕНИЕ [STATISTICS](https://msdn.microsoft.com/library/ms187348.aspx).

## <a name="use-dmvs-to-monitor-and-optimize-your-queries"></a>Использование динамических административных представлений для отслеживания и оптимизации запросов

В пуле S'L есть несколько DMV, которые могут быть использованы для мониторинга выполнения запросов.  Монитор вашей рабочей нагрузки с помощью dMVs статьи детали пошаговые инструкции о том, как смотреть на детали выполнения запроса.  

Чтобы быстро определить запросы в динамических административных представлениях, используйте в запросах параметр LABEL.

Смотрите также [Контролировать свою рабочую нагрузку с помощью DMVs](sql-data-warehouse-manage-monitor.md), [LABEL](sql-data-warehouse-develop-label.md), [OPTION](https://msdn.microsoft.com/library/ms190322.aspx), [sys.dm_exec_sessions]( https://msdn.microsoft.com/library/ms176013.aspx), [sys.dm_pdw_exec_requests](https://msdn.microsoft.com/library/mt203887.aspx), [sys.dm_pdw_request_steps](https://msdn.microsoft.com/library/mt203913.aspx), [sys.dm_pdw_sql_requests,](https://msdn.microsoft.com/library/mt203889.aspx) [sys.dm_pdw_dms_workers,](https://msdn.microsoft.com/library/mt203878.aspx) [DBCC PDW_SHOWEXECUTIONPLAN,](https://msdn.microsoft.com/library/mt204017.aspx)и [sys.dm_pdw_waits](https://msdn.microsoft.com/library/mt203893.aspx).

## <a name="tune-query-performance-with-new-product-enhancements"></a>Настройка производительности запроса с помощью новых усовершенствований продукта

- [Performance tuning with materialized views](performance-tuning-materialized-views.md) (Настройка производительности с помощью материализованных представлений)
- [Performance tuning with result set caching](performance-tuning-ordered-cci.md) (Настройка производительности с помощью упорядоченного кластеризованного индекса columnstore)
- [Performance tuning with result set caching](performance-tuning-result-set-caching.md) (Настройка производительности путем кэширования результирующего набора)

## <a name="group-insert-statements-into-batches"></a>Объединение инструкций INSERT в группы

Одноразовая нагрузка на небольшой стол с выпиской INSERT или даже периодическая перезагрузка поиска может `INSERT INTO MyLookup VALUES (1, 'Type 1')`хорошо работать для ваших нужд с таким заявлением, как.  

Однако для загрузки тысяч или миллионов строк на протяжении дня одноэлементных инструкций INSERT может быть недостаточно.  Вместо них можно создать процессы, которые будут записывать инструкции INSERT в файл и периодически загружать его.

Смотрите также [INSERT](https://msdn.microsoft.com/library/ms174335.aspx).

## <a name="use-polybase-to-load-and-export-data-quickly"></a>Быстрая загрузка и экспорт данных с помощью PolyBase

Пул спомощьи в пуле поддержки загрузки и экспорта данных с помощью нескольких инструментов, включая Azure Data Factory, PolyBase и BCP.  При работе с данными небольшого объема, что не требует высокой производительности, можно использовать любой инструмент.  Однако для загрузки или экспорта данных большого объема, что требует высокой производительности, лучше всего использовать PolyBase.  

PolyBase предназначен для использования архитектуры MPP (Massively Parallel Processing) и будет загружать и экспортировать величину данных быстрее, чем любой другой инструмент.  Загрузку данных с помощью PolyBase можно выполнить, используя команды CTAS или INSERT INTO.  

> [!TIP]
> Команда CTAS позволяет свести к минимуму нагрузку ведения журнала транзакций и быстрее всего выполнить загрузку данных.

Фабрика данных Azure также поддерживает нагрузки PolyBase и способна достичь производительности, сопоставимой с CTAS.  PolyBase поддерживает различные форматы файлов, включая формат GZIP.  
  
> [!NOTE]
> Чтобы максимизировать пропускную стоимость при использовании текстовых файлов gzip, разбейте файлы на 60 или более файлов, чтобы максимизировать параллелизм вашей нагрузки.  Кроме того, для повышения общей пропускной способности можно загружать данные одновременно.

Смотрите также [данные о загрузке,](design-elt-data-loading.md)Руководство по использованию [шаблонов и стратегий загрузки пула](https://blogs.msdn.microsoft.com/sqlcat/20../../) [PolyBase,](guidance-for-loading-data.md)S'L, [Загрузка данных с Azure Data Factory,]( ../../data-factory/load-azure-sql-data-warehouse.md) [Перемещение данных с Azure Data Factory](../../data-factory/transform-data-using-machine-learning.md), ( ,https://msdn.microsoft.com/library/dn935026.aspx)и Создание [таблицы по выбору (CTAS).](sql-data-warehouse-develop-ctas.md)

## <a name="load-then-query-external-tables"></a>Загрузка внешних таблиц и отправка запросов к ним

Технология Polybase (т. н. внешние таблицы), возможно, является самым быстрым способом загрузки данных, но она не оптимальна с точки зрения запросов. Таблицы Polybase в настоящее время поддерживают только файлы Azure blob и хранилище Azure Data Lake. Эти файлы не обслуживаются какими-либо вычислительными ресурсами.  

В результате пул S'L не может разгрузить эту работу и поэтому должен прочитать весь файл, загрузив его в tempdb для чтения данных.  Таким образом, если будет отправлено несколько запросов к этим данным, то лучше один раз загрузить их в локальную таблицу и предоставить ее для выполнения запросов.

Смотрите также [Руководство по использованию PolyBase](guidance-for-loading-data.md).

## <a name="hash-distribute-large-tables"></a>Хэш-распределение больших таблиц

По умолчанию таблицы распределяются по методу циклического перебора.  Это позволяет упростить процесс создания таблиц, так как пользователям не нужно принимать решение о типе распределения.  Таблицы с распределением по методу циклического перебора могут вполне годиться для некоторых рабочих нагрузок, но в большинстве случаев намного эффективнее использовать столбец распределения.  

Наглядно это превосходство можно увидеть при объединении больших таблиц фактов.  

Например, во время выполнения запроса на объединение таблицы Orders, распределенной по идентификатору order_id, с таблицей Transactions, распределенной по тому же идентификатору, этот запрос превращается в запрос к серверу, что исключает выполнение операций перемещения данных.  Чем меньше в запросе действий, тем быстрее он выполняется.  Скорость выполнения запроса также зависит от объема перемещаемых данных.  

> [!TIP]
> При загрузке распределенной таблицы входящие данные не должны быть отсортированы по ключу распределения, так как это замедлит процесс загрузки.  

Более подробную информацию о том, как выбор столбца распределения может повысить производительность, а также о том, как определить распределенную таблицу, можно узнать в пункте с оговоркой CREATE TABLE.

Смотрите также [Обзор таблицы](sql-data-warehouse-tables-overview.md), [Распределение таблицы](sql-data-warehouse-tables-distribute.md), [Выбор распределения таблицы](https://blogs.msdn.microsoft.com/sqlcat/20../../choosing-hash-distributed-table-vs-round-robin-distributed-table-in-azure-sql-dw-service/), [CREATE TABLE](https://msdn.microsoft.com/library/mt203953.aspx), CREATE TABLE [AS SELECT.](https://msdn.microsoft.com/library/mt204041.aspx)

## <a name="do-not-over-partition"></a>Недопущение избыточного секционирования

В то время как данные раздела могут быть эффективными для поддержания ваших данных путем переключения разделов или оптимизации сканирования с помощью исключения раздела, наличие слишком большого количества разделов может замедлить ваши запросы.  Часто стратегия раздела с высокой гранулированностью, которая может хорошо работать на сервере S'L, может не хорошо работать в пуле S'L.  

Слишком большое количество секций снижает эффективность кластеризованных индексов Columnstore, если в секции содержится менее миллиона строк.  Имейте в виду, что за кулисами пул пула S'L перерезает ваши данные для вас в 60 баз данных, так что если вы создаете таблицу с 100 разделами, это фактически приводит к 6000 разделов.  

Все рабочие нагрузки отличаются, поэтому рекомендуется поэкспериментировать с секционированием, чтобы выбрать наиболее подходящее количество секций для вашей рабочей нагрузки.  В хранилище данных SQL можно использовать меньшее количество секций, чем в SQL Server.  Например, попробуйте использовать еженедельные или ежемесячные секции вместо ежедневных.

Смотрите также [раздел таблицы](sql-data-warehouse-tables-partition.md).

## <a name="minimize-transaction-sizes"></a>Уменьшение размера транзакций

Инструкции INSERT, UPDATE и DELETE выполняются в транзакциях. В случае сбоя их необходимо откатить.  Чтобы сократить время выполнения отката, необходимо по возможности уменьшить размеры транзакций.  Это можно сделать, разделив инструкции INSERT, UPDATE и DELETE на части.  

Например, если у вас есть INSERT, который, по возможности, займет 1 час, разбейте INSERT на четыре части, каждая из которых будет проходить за 15 минут.  Для снижения риска отката можно использовать специальные случаи минимальной регистрации, такие как CTAS, TRUNCATE, DROP TABLE или INSERT.  

Устранить откаты также можно, используя для управления данными только операции с метаданными (например, переключение секций).  Например, вместо того, чтобы выполнить заявление DELETE, чтобы удалить все строки в таблице, где order_date был в октябре 2001 года, можно ежемесячно переключать данные, а затем выключать раздел с данными для пустого раздела из другой таблицы (см. примеры [ALTER TABLE).](https://msdn.microsoft.com/library/ms190273.aspx)  

Для неразделенных таблиц рассмотрите возможность использования CTAS для записи данных, которые вы хотите сохранить в таблице, а не с помощью DELETE.  Если CTAS занимает столько же времени, это гораздо безопаснее работать, поскольку она имеет минимальный журнал записи транзакций и может быть отменена быстро, если это необходимо.

Смотрите также [Понимание транзакций](sql-data-warehouse-develop-transactions.md), [Оптимизация транзакций](sql-data-warehouse-develop-best-practices-transactions.md), [Раздел таблицы](sql-data-warehouse-tables-partition.md), [TRUNCATE TABLE](https://msdn.microsoft.com/library/ms177570.aspx), ALTER [TABLE](https://msdn.microsoft.com/library/ms190273.aspx), и [Создать таблицу как выбрать (CTAS)](sql-data-warehouse-develop-ctas.md).

## <a name="reduce-query-result-sizes"></a>Уменьшение размеров результатов запроса

Этот шаг помогает избежать проблем со стороны клиента, вызванных большим результатом запроса.  Можно отсеять запрос, чтобы уменьшить количество возвращенных строк. Некоторые инструменты генерации запросов позволяют добавлять синтаксис "Top N" к каждому запросу.  Вы также можете CETAS результат запроса к временной таблице, а затем использовать экспорт PolyBase для обработки низшия.

## <a name="use-the-smallest-possible-column-size"></a>Использование минимального размера столбца

При определении DDL использование наименьшего типа данных, который будет поддерживать ваши данные, улучшит производительность запроса.  Этот подход особенно важен для столбцов CHAR и VARCHAR.  

Если самое длинное значение в столбце состоит из 25 знаков, столбец необходимо определить как VARCHAR(25).  Не рекомендуется использовать по умолчанию длинные значения столбцов.  Кроме того, по возможности определяйте столбцы как VARCHAR, а не NVARCHAR.

Смотрите также обзор [таблицы, типы данных таблицы,](sql-data-warehouse-tables-data-types.md) [CREATE TABLE](https://msdn.microsoft.com/library/mt203953.aspx). [Table overview](sql-data-warehouse-tables-overview.md)

## <a name="use-temporary-heap-tables-for-transient-data"></a>Использование временных таблиц без кластеризованных индексов для хранения временных данных

При временной посадке данных, вы можете обнаружить, что с помощью таблицы кучи сделает общий процесс быстрее.  Если вы загружаете данные только для промежуточного хранения перед их последующими преобразованиями, загрузка таблицы в таблицу кучи будет происходить значительно быстрее по сравнению с загрузкой данных в кластеризованную таблицу columnstore.  

Кроме того, загрузка данных во временную таблицу выполняется гораздо быстрее, чем загрузка таблицы в постоянное хранилище.  Временные таблицы начинаются с "К" и доступны только по созданной сессии, поэтому они могут работать только в ограниченных сценариях.

Таблицы без кластеризованных индексов определены в предложении WITH инструкции CREATE TABLE.  При использовании временной таблицы рекомендуется создавать в ней статистику.

Смотрите также [Временные таблицы](sql-data-warehouse-tables-temporary.md), [CREATE TABLE](https://msdn.microsoft.com/library/mt203953.aspx), [CREATE TABLE AS SELECT](https://msdn.microsoft.com/library/mt204041.aspx).

## <a name="optimize-clustered-columnstore-tables"></a>Оптимизация таблиц с кластеризованными индексами columnstore

Кластерные индексы столбцов являются одним из наиболее эффективных способов хранения данных в пуле S'L.  По умолчанию таблицы в пуле S'L создаются как кластерный columnStore.  Качество кластеризованного сегмента Columnstore существенно влияет на эффективность выполнения запросов в таблицах с кластеризованными индексами Columnstore.  

Если во время записи строк в таблицы Columnstore возникает нехватка памяти, качество сегмента Columnstore может ухудшиться.  Качество сегмента можно изменить по числу строк в сжатой группе строк.  О [причинах плохого качества индекса columnstore](sql-data-warehouse-tables-index.md#causes-of-poor-columnstore-index-quality) в статье [«Индексы таблицы»](sql-data-warehouse-tables-index.md) можно ознакомиться с инструкциями по обнаружению и улучшению качества сегмента для кластерных таблиц столбцов.  

Поскольку высококачественные сегменты магазинов столбцов важны, рекомендуется использовать идентифицировать пользователей, которые относятся к среднему или крупному классу ресурсов, для загрузки данных. Использование [единиц использования хранилища данных](what-is-a-data-warehouse-unit-dwu-cdwu.md) меньшего размера требует присвоения пользователю загрузки класса ресурсов большего размера.

Поскольку таблицы столбцов обычно не будут перемещать данные в сегмент сжатого столбцов до тех пор, пока на стол не будет более 1 миллиона строк, и каждый бильярдный стол S'L не будет разделен на 60 таблиц, как правило, таблицы столбцов не принесут пользу запросу, если только в таблице не будет более 60 миллионов строк.  Поэтому нецелесообразно применять к таблицам Columnstore запросы до тех пор, пока количество строк в таблице не превысит 60 миллионов.  Для таблицы с количеством строк менее 60 миллионов бессмысленно использовать индекс Columnstore, хотя он и не повлияет на производительность.  

Более того, чтобы воспользоваться преимуществами кластеризованного индекса Columnstore при секционировании данных, каждая секция должна состоять из миллиона строк.  Если таблица имеет 100 разделов, то она должна иметь по крайней мере 6 миллиардов строк, чтобы воспользоваться кластерными столбиками магазина (60 дистрибутивов *100 разделов* 1 миллион строк).  

Если таблица не содержит такого количества строк, рекомендуется уменьшить количество секций или использовать таблицу без кластеризованных индексов.  Чтобы получить более высокую производительность, возможно, вместо кластеризованной таблицы стоит использовать таблицу без кластеризованных индексов, содержащую вторичные индексы.

> [!TIP]
> Если выбрать только необходимые столбцы, запросы к таблице ColumnStore будут выполняться быстрее.  

Ознакомьтесь также со статьями [Индексирование таблиц в хранилище данных SQL](sql-data-warehouse-tables-index.md), [Руководство по индексам columnstore](https://msdn.microsoft.com/library/gg492088.aspx) и разделом с описанием [повторной сборки индексов columnstore](sql-data-warehouse-tables-index.md#rebuilding-indexes-to-improve-segment-quality).

## <a name="use-larger-resource-class-to-improve-query-performance"></a>Использование класса ресурсов большого размера для повышения производительности запросов

В пуле S'L используются группы ресурсов в качестве способа распределения памяти для запросов.  Из коробки, все пользователи назначаются к небольшому классу ресурсов, который предоставляет 100 МБ памяти в распределении.  В хранилище данных SQL содержится 60 распределений, на каждое из которых выделяется как минимум 100 МБ памяти. Поэтому в целом для системы выделяется 6000 МБ памяти (около 6 ГБ).  

На выполнение некоторых запросов (например, на объединение таблиц с кластеризованными индексами Columnstore или добавления в них данных) требуется больше памяти.  Некоторые запросы, такие как чистое сканирование, не принесут никакой пользы.  Однако использование больших классов ресурсов снижает параллелизм, поэтому необходимо учитывать это влияние, прежде чем переходить всех пользователей в большой класс ресурсов.

Смотрите также [классы ресурсов для управления рабочей нагрузкой.](resource-classes-for-workload-management.md)

## <a name="use-smaller-resource-class-to-increase-concurrency"></a>Использование класса ресурсов небольшого размера для увеличения параллелизма

Если вы заметили, что запросы пользователей, кажется, имеют длительную задержку, это может быть, что ваши пользователи работают в больших классах ресурсов и потребляют много слотов параллелизма, вызывая другие запросы в очереди.  Чтобы посмотреть очередь выполнения пользовательских запросов, выполните команду `SELECT * FROM sys.dm_pdw_waits`, которая позволяет просмотреть возвращенные строки.

Смотрите также [классы ресурсов для управления рабочей нагрузкой,](resource-classes-for-workload-management.md) [sys.dm_pdw_waits](https://msdn.microsoft.com/library/mt203893.aspx).

## <a name="other-resources"></a>Другие ресурсы

Дополнительные сведения о распространенных проблемах и решениях см. в статье [Устранение неполадок хранилища данных SQL Azure](sql-data-warehouse-troubleshoot.md).

Если вы не нашли то, что искали в этой статье, попробуйте использовать «Поиск документов» в левой части этой страницы для поиска всех документов Azure Synapse.  [Форум Azure Synapse](https://social.msdn.microsoft.com/Forums/sqlserver/home?forum=AzureSQLDataWarehouse) — это место для размещения вопросов другим пользователям и группе продуктов Azure Synapse. Мы регулярно просматриваем этот форум и следим за тем, чтобы другие пользователи или наши специалисты ответили на интересующие вас вопросы.  

Если вы предпочитаете задавать свои вопросы по переполнению стеков, у нас также есть [Форум перелива стек Azure Synapse.](https://stackoverflow.com/questions/tagged/azure-sqldw)

Пожалуйста, используйте страницу [обратной связи Azure Synapse](https://feedback.azure.com/forums/307516-sql-data-warehouse) для запросов функций.  Ваши отзывы и голоса за отзывы, оставленные другими пользователями, помогут нам определить, какие улучшения функций наиболее приоритетные.
