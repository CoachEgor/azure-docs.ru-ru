---
title: Рекомендации по разработке
description: Рекомендации и рекомендации, которые следует учитывать при разработке решений для пула SQL синапсе.
services: synapse-analytics
author: XiaoyuMSFT
manager: craigg
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 09/04/2018
ms.author: xiaoyul
ms.reviewer: igorstan
ms.custom: seo-lt-2019
ms.openlocfilehash: 9c4f08b143ab4a0d3e780f68f8d5ab823d4eae12
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "80745366"
---
# <a name="development-best-practices-for-synapse-sql-pool"></a>Рекомендации по разработке для пула SQL синапсе

В этой статье приводятся рекомендации и рекомендации по разработке решения для работы с пулом SQL.

## <a name="tune-query-performance-with-new-product-enhancements"></a>Настройка производительности запросов с помощью новых усовершенствований продукта

- [Performance tuning with materialized views](performance-tuning-materialized-views.md) (Настройка производительности с помощью материализованных представлений)
- [Performance tuning with result set caching](performance-tuning-ordered-cci.md) (Настройка производительности с помощью упорядоченного кластеризованного индекса columnstore)
- [Performance tuning with result set caching](performance-tuning-result-set-caching.md) (Настройка производительности путем кэширования результирующего набора)

## <a name="reduce-cost-with-pause-and-scale"></a>Снижение расходов за счет приостановки и масштабирования ресурсов

Дополнительные сведения об уменьшении затрат путем приостановки и масштабирования см. в статье [Управление вычислениями](sql-data-warehouse-manage-compute-overview.md) .

## <a name="maintain-statistics"></a>Обеспечение статистики

Пул SQL можно настроить для автоматического обнаружения и создания статистики по столбцам.  Планы запросов, созданные оптимизатором, так же хороши, как и доступные статистические данные.  

Рекомендуется включить AUTO_CREATE_STATISTICS для баз данных и обновлять статистику ежедневно или после каждой нагрузки, чтобы гарантировать, что статистика по столбцам, используемых в запросах, всегда будет актуальной.

Если вы обнаружите, что обновление всей статистики занимает слишком много времени, может возникнуть необходимость более избирательно выбирать столбцы, для которых требуется часто обновлять статистику. Например, можно ежедневно обновлять столбцы дат, в которые добавляются новые значения.

> [!TIP]
> Вы получите наибольшее преимущество, используя обновленную статистику по столбцам, участвующим в соединении, столбцам, используемым в предложении WHERE, и столбцам, найденным в поле GROUP BY.

См. также раздел [Управление статистикой таблицы](sql-data-warehouse-tables-statistics.md), [Создание статистики](sql-data-warehouse-tables-statistics.md)и [Обновление статистики](sql-data-warehouse-tables-statistics.md#update-statistics).

## <a name="hash-distribute-large-tables"></a>Хэш-распределение больших таблиц

По умолчанию таблицы распределяются по методу циклического перебора.  Такая схема позволяет пользователям легко приступить к созданию таблиц без необходимости выбирать способ распространения их таблиц.  

Таблицы с распределением по методу циклического перебора могут вполне годиться для некоторых рабочих нагрузок, но в большинстве случаев намного эффективнее использовать столбец распределения.  Наглядно это превосходство можно увидеть при объединении больших таблиц фактов.  

Например, во время выполнения запроса на объединение таблицы Orders, распределенной по идентификатору order_id, с таблицей Transactions, распределенной по тому же идентификатору, этот запрос превращается в запрос к серверу, что исключает выполнение операций перемещения данных.  Чем меньше в запросе действий, тем быстрее он выполняется.  Скорость выполнения запроса также зависит от объема перемещаемых данных.  

При загрузке распределенной таблицы входящие данные не должны быть отсортированы по ключу распределения, так как это замедлит процесс загрузки.  В следующих статьях приводятся дополнительные сведения о повышении производительности за счет выбора столбца распределения и определения распределенной таблицы в предложении WITH инструкции CREATE TABLEs.

См. также [Обзор таблиц](sql-data-warehouse-tables-overview.md), [распределение таблиц](sql-data-warehouse-tables-distribute.md), [Выбор распределения ТАБЛИЦ](https://blogs.msdn.microsoft.com/sqlcat/20../../choosing-hash-distributed-table-vs-round-robin-distributed-table-in-azure-sql-dw-service/), [CREATE TABLE](sql-data-warehouse-tables-overview.md)и [CREATE TABLE как SELECT](sql-data-warehouse-develop-ctas.md) .

## <a name="do-not-over-partition"></a>Недопущение избыточного секционирования

В то время как секционирование данных может быть эффективным для поддержания данных посредством переключения секций или оптимизации проверок с помощью исключения секций, наличие слишком большого количества секций может замедлить выполнение запросов.  

Зачастую стратегия секционирования с высокой степенью детализации, которая хорошо работает на SQL Server, может плохо работать в пуле SQL.  Слишком большое количество секций снижает эффективность кластеризованных индексов Columnstore, если в секции содержится менее миллиона строк.  

Помните, что в фоновом режиме пул SQL разделяет данные на базы данных 60, поэтому при создании таблицы с 100 секций это приводит к 6000 секций.  Все рабочие нагрузки отличаются, поэтому рекомендуется поэкспериментировать с секционированием, чтобы выбрать наиболее подходящее количество секций для вашей рабочей нагрузки.  

> [!TIP]
> Рекомендуется использовать более низкую степень детализации, чем та, которая могла бы работать в SQL Server.  Например, попробуйте использовать еженедельные или ежемесячные секции вместо ежедневных.

См. также [секционирование таблиц](sql-data-warehouse-tables-partition.md).

## <a name="minimize-transaction-sizes"></a>Уменьшение размера транзакций

Инструкции INSERT, UPDATE и DELETE выполняются в транзакциях. В случае сбоя их необходимо откатить.  Чтобы сократить время выполнения отката, необходимо по возможности уменьшить размеры транзакций.  Это можно сделать, разделив инструкции INSERT, UPDATE и DELETE на части.  

Например, если имеется вставка, которая, по возможности, займет 1 час, разбейте вставку на четыре части, которые будут выполняться в течение 15 минут.  Для снижения риска отката используйте специальные случаи минимального протоколирования, такие как CTAS, УСЕЧЕНИЕ, удаление таблицы или Вставка в пустые таблицы.  

Устранить откаты также можно, используя для управления данными только операции с метаданными (например, переключение секций).  Например, вместо выполнения инструкции DELETE для удаления всех строк в таблице, упорядоченной по идентификатору order_date (октябрь 2001 г.), данные можно секционировать ежемесячно, а потом переключить секцию с данными на пустую секцию из другой таблицы (см. примеры использования инструкции ALTER TABLE).  

Для несекционированных таблиц рекомендуется использовать CTAS для записи данных, которые необходимо сохранить в таблице, а не использовать DELETE.  Если CTAS занимает то же время, это намного безопасная работа, так как она имеет минимальное протоколирование транзакций и при необходимости может быть отменена.

См. также раздел [Основные сведения о транзакциях](sql-data-warehouse-develop-transactions.md), [Оптимизация транзакций](sql-data-warehouse-develop-best-practices-transactions.md), [секционирование ТАБЛИЦ](sql-data-warehouse-tables-partition.md), [TRUNCATE TABLE](/sql/t-sql/statements/truncate-table-transact-sql?toc=/azure/synapse-analytics/sql-data-warehouse/toc.json&bc=/azure/synapse-analytics/sql-data-warehouse/breadcrumb/toc.json&view=azure-sqldw-latest), [ALTER TABLE](/sql/t-sql/statements/alter-table-transact-sql?toc=/azure/synapse-analytics/sql-data-warehouse/toc.json&bc=/azure/synapse-analytics/sql-data-warehouse/breadcrumb/toc.json&view=azure-sqldw-latest), а [также создание таблицы как SELECT (CTAS)](sql-data-warehouse-develop-ctas.md).

## <a name="use-the-smallest-possible-column-size"></a>Использование минимального размера столбца

При определении DDL с использованием наименьшего типа данных, который будет поддерживать ваши данные, повышает производительность запросов.  Этот подход особенно важен для столбцов CHAR и VARCHAR.  

Если самое длинное значение в столбце состоит из 25 знаков, столбец необходимо определить как VARCHAR(25).  Не рекомендуется использовать по умолчанию длинные значения столбцов.  Кроме того, по возможности определяйте столбцы как VARCHAR, а не NVARCHAR.

См. также [Общие сведения о таблице](sql-data-warehouse-tables-overview.md), [табличные типы данных](sql-data-warehouse-tables-data-types.md)и [CREATE TABLE](sql-data-warehouse-tables-overview.md).

## <a name="optimize-clustered-columnstore-tables"></a>Оптимизация таблиц с кластеризованными индексами columnstore

Кластеризованные индексы columnstore — это один из наиболее эффективных способов хранения данных в пуле SQL.  По умолчанию таблицы в пуле SQL создаются как кластеризованный ColumnStore.  

> [!NOTE]
> Чтобы обеспечить оптимальную производительность запросов к таблицам columnstore, важно иметь хорошее качество сегмента.  

Если во время записи строк в таблицы Columnstore возникает нехватка памяти, качество сегмента Columnstore может ухудшиться.  Качество сегмента можно изменить по числу строк в сжатой группе строк.  

Пошаговые инструкции по обнаружению и улучшению качества сегментов для кластеризованных таблиц columnstore см. в статьях [причины низкого качества индексов columnstore](sql-data-warehouse-tables-index.md#causes-of-poor-columnstore-index-quality) в статье [индексы таблиц](sql-data-warehouse-tables-index.md) .  

Так как высококачественные сегменты columnstore важны, рекомендуется использовать идентификаторы пользователей, которые находятся в классе ресурсов среднего или большого размера для загрузки данных. Использование [единиц использования хранилища данных](what-is-a-data-warehouse-unit-dwu-cdwu.md) меньшего размера требует присвоения пользователю загрузки класса ресурсов большего размера.

Так как таблицы columnstore обычно не отправляют данные в сжатый сегмент columnstore до тех пор, пока в таблице не будет более 1 000 000 строк, а каждая таблица пула SQL секционирована на 60 таблиц, в целом таблицы columnstore не смогут получить запрос, если только таблица не содержит более 60 000 000 строк.  

Для таблицы, которая содержит менее 60 000 000 строк, может не иметь смысла использовать индекс columnstore.  Для таблицы с количеством строк менее 60 миллионов бессмысленно использовать индекс Columnstore, хотя он и не повлияет на производительность.  

Более того, чтобы воспользоваться преимуществами кластеризованного индекса Columnstore при секционировании данных, каждая секция должна состоять из миллиона строк.  Если таблица содержит 100 секций, то для получения преимуществ из хранилища кластеризованных столбцов требуется по крайней мере 6 000 000 000 строк (60 распределений *100 секции* 1 000 000 строки).  

Если таблица не содержит такого количества строк, рекомендуется уменьшить количество секций или использовать таблицу без кластеризованных индексов.  Чтобы получить более высокую производительность, возможно, вместо кластеризованной таблицы стоит использовать таблицу без кластеризованных индексов, содержащую вторичные индексы.

> [!TIP]
> Если выбрать только необходимые столбцы, запросы к таблице ColumnStore будут выполняться быстрее.  

См. также инструкции по [индексам таблиц](sql-data-warehouse-tables-index.md), [индексам columnstore](/sql/relational-databases/indexes/columnstore-indexes-overview?toc=/azure/synapse-analytics/sql-data-warehouse/toc.json&bc=/azure/synapse-analytics/sql-data-warehouse/breadcrumb/toc.json&view=azure-sqldw-latest)и [перестроению индексов columnstore](sql-data-warehouse-tables-index.md#rebuilding-indexes-to-improve-segment-quality).

## <a name="next-steps"></a>Дальнейшие шаги

Если вы не нашли то, что ищете в этой статье, воспользуйтесь командой "Поиск документов" в левой части этой страницы, чтобы найти все документы Azure синапсе.  

[Форум Azure синапсе](https://social.msdn.microsoft.com/Forums/sqlserver/home?forum=AzureSQLDataWarehouse) — это место для отправки вопросов другим пользователям и группе продуктов Azure синапсе.  Мы регулярно просматриваем этот форум и следим за тем, чтобы другие пользователи или наши специалисты ответили на интересующие вас вопросы.  

Вопросы также можно задавать на [форуме по хранилищу данных SQL Azure на сайте Stack Overflow](https://stackoverflow.com/questions/tagged/azure-sqldw).

Используйте страницу [обратной связи Azure синапсе](https://feedback.azure.com/forums/307516-sql-data-warehouse) для выполнения запросов к функциям.  Ваши отзывы и голоса за отзывы, оставленные другими пользователями, помогут нам определить, какие улучшения функций наиболее приоритетные.
