---
title: Руководство по Начало работы с Azure Synapse Analytics
description: В этом руководстве изложены основные этапы настройки и использования Azure Synapse Analytics.
services: synapse-analytics
author: saveenr
ms.author: saveenr
manager: julieMSFT
ms.reviewer: jrasnick
ms.service: synapse-analytics
ms.topic: tutorial
ms.date: 05/19/2020
ms.openlocfilehash: daa8b594b06203c7de9a9b462be469dd71ed2e49
ms.sourcegitcommit: 6571e34e609785e82751f0b34f6237686470c1f3
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/15/2020
ms.locfileid: "84791866"
---
# <a name="get-started-with-azure-synapse-analytics"></a>Начало работы с Azure Synapse Analytics

В этом руководстве рассматриваются основные шаги по настройке и использованию Azure Synapse Analytics.

## <a name="prepare-a-storage-account"></a>Подготовка учетной записи хранения

1. Откройте [портал Azure](https://portal.azure.com).
1. Создайте учетную запись хранения со следующими параметрами:

    |Вкладка|Параметр | Рекомендуемое значение | Описание |
    |---|---|---|---|
    |Основы|**Имя учетной записи хранения**| Можно выбрать любое имя.|В этом документе он будет называться **contosolake**.|
    |Основы|**Account kind** (Тип учетной записи)|Для этого свойства нужно задать значение **StorageV2**.||
    |Основы|**Расположение**|Выберите любое расположение.| Рекомендуем располагать рабочую область Azure Synapse Analytics и учетную запись Azure Data Lake Storage Gen2 в одном регионе.|
    |Дополнительно|**Data Lake Storage 2-го поколения**|**Enabled**| Azure Synapse работает только с учетными записями хранения, в которых этот параметр включен.|
    |||||

1. После создания учетной записи хранения выберите команду **Управление доступом (IAM)** на левой панели. Затем назначьте следующие роли или убедитесь, что они уже назначены:
    1. Назначьте себе роль **Владелец**.
    1. Назначьте себе роль **Владелец данных BLOB-объектов хранилища**.
1. В области навигации слева выберите **Контейнеры** и создайте контейнер.
1. Вы можете присвоить контейнеру любое имя. В этом документе мы назовем контейнер **users**.
1. Примите значение по умолчанию **Общедоступный уровень доступа**, а затем выберите команду **Создать**.

На следующем этапе вам нужно будет сделать эту учетную запись хранения основной в настройках рабочей области Azure Synapse и включить сохранение ее данных в контейнере. В рабочей области данные хранятся в таблицах Apache Spark. Журналы приложений Spark хранятся в папке с именем **/synapse/workspacename**.

## <a name="create-a-synapse-workspace"></a>Создание рабочей области Synapse

1. Откройте [Портал Azure](https://portal.azure.com) и в поле поиска вверху выполните поиск по слову **Synapse**.
1. В поисковых результатах в разделе **Службы** выберите **Azure Synapse Analytics (workspaces preview)** (Azure Synapse Analytics (предварительная версия рабочих областей)).
1. Выберите команду **Добавить** и создайте рабочую область со следующими параметрами:

    |Вкладка|Параметр | Рекомендуемое значение | Описание |
    |---|---|---|---|
    |Основы|**Имя рабочей области**|Можно присвоить любое имя.| В этом документе мы будем использовать **myworkspace**.|
    |Основы|**Регион**|Совпадает с регионом учетной записи хранения.|

1. В разделе **Select Data Lake Storage Gen 2** (Выбрать Data Lake Storage Gen 2) выберите учетную запись и контейнер, созданные ранее.
1. Выберите команду **Просмотреть и создать** > **Создать**. Рабочая область будет готова через несколько минут.

## <a name="verify-access-to-the-storage-account"></a>Подтвердите доступ к учетной записи хранения

Управляемые удостоверения для рабочей области Azure Synapse могут уже иметь доступ к учетной записи хранения. Чтобы удостовериться, выполните следующие действия:

1. Откройте [портал Azure](https://portal.azure.com) и основную учетную запись хранения, выбранную для вашей рабочей области.
1. На левой панели выберите **Управление доступом (IAM)** .
1. Назначьте следующие роли или убедитесь, что они уже назначены. Мы используем одно и то же имя для удостоверения рабочей области и имени рабочей области.
    1. Для роли **Участник для данных BLOB-объектов хранилища** в учетной записи хранения назначьте **myworkspace** как удостоверение рабочей области.
    1. Назначьте **myworkspace** как имя рабочей области.

1. Щелкните **Сохранить**.

## <a name="open-synapse-studio"></a>Открытие Synapse Studio

После создания рабочей области Azure Synapse можно открыть Synapse Studio двумя способами:

* Откройте рабочую область Synapse на [портале Azure](https://portal.azure.com). В верхней области раздела **Обзор** выберите **Запуск Synapse Studio**.
* Перейдите на https://web.azuresynapse.net и войдите в рабочую область.

## <a name="create-a-sql-pool"></a>Создание пула SQL

1. В Synapse Studio в области навигации слева выберите **Управление** > **Пулы SQL**.
1. Выберите команду **Создать** и введите следующие параметры:

    |Параметр | Рекомендуемое значение | 
    |---|---|---|
    |**Имя пула SQL**| **SQLDB1**|
    |**Уровень производительности**|**DW100C**|
    |||

1. Выберите команду **Просмотреть и создать** > **Создать**. Пул SQL будет готов через несколько минут. Ваш пул SQL связан с базой данных пула SQL, также называемой **SQLDB1**.

Пул SQL использует платные ресурсы, пока он активен. Позже пул можно будет приостановить, чтобы снизить затраты.

## <a name="create-an-apache-spark-pool"></a>Создание пула Apache Spark

1. В окне Synapse Studio слева выберите **Управление** > **Пулы Apache Spark**.
1. Выберите команду **Создать** и введите следующие параметры:

    |Параметр | Рекомендуемое значение | 
    |---|---|---|
    |**Имя пула Apache Spark**|**Spark1**
    |**Размер узла**| **Малый**|
    |**Количество узлов**| Задайте для минимума и максимума значение 3.|

1. Выберите команду **Просмотреть и создать** > **Создать**. Ваш пул Apache Spark будет готов через несколько секунд.

> [!NOTE]
> Несмотря на свое имя, пул Apache Spark не является пулом SQL. Это лишь базовые метаданные, которые используются для информирования рабочей области Azure Synapse о том, как взаимодействовать со Spark.

Из-за того, что это метаданные, пулы Spark нельзя запустить или остановить.

При выполнении действий со Spark в Azure Synapse необходимо указать используемый пул Spark. Пул сообщает Azure Synapse, сколько ресурсов Spark использовать. Вы платите только за те ресурсы, которые используете. При активной отмене использования пула ресурсы автоматически истекают и перераспределяются.

> [!NOTE]
> Базы данных Spark создаются независимо от пулов Spark. В рабочей области всегда есть база данных Spark которая называется **по умолчанию**. Можно создать дополнительные базы данных Spark.

## <a name="the-sql-on-demand-pool"></a>Пул SQL по запросу

Каждая рабочая область поставляется с предварительно созданным пулом, который называется **SQL по требованию**. Этот пул невозможно удалить. Пул SQL по запросу позволяет работать с SQL без необходимости создавать пул Synapse SQL в Azure Synapse или заниматься его управлением.

В отличие от других типов пулов, выставление счетов за использование SQL по запросу зависит от объема данных, просканированных для выполнения запроса, а не от количества ресурсов, используемых для выполнения запроса.

* SQL по запросу имеет собственные базы данных SQL по требованию, которые существуют независимо от любого пула SQL по требованию.
* Рабочая область всегда имеет ровно один пул SQL по запросу с именем **SQL по требованию**.

## <a name="load-the-nyc-taxi-sample-data-into-the-sqldb1-database"></a>Загрузите образец данных нью-йоркского такси в базу данных SQLDB1

1. В Synapse Studio в самом верхнем синем меню выберите **?** .
1. Выберите **Начало работы** > **Центр начала работы**.
1. В карточке, помеченной как **Query sample data** (Образец данных запроса), выберите пул SQL с именем **SQLDB1**.
1. Выберите **Данные запроса**. Кратко отобразится уведомление "Загрузка демонстрационных данных". В верхней части Synapse Studio появится светло-синяя строка состояния, показывающая, что данные загружаются в SQLDB1.
1. Когда строка состояния станет зеленой, закройте ее.

## <a name="explore-the-nyc-taxi-data-in-the-sql-pool"></a>Изучите данные нью-йоркского такси в пуле SQL

1. В Synapse Studio перейдите в центр **Данные**.
1. Перейдите в раздел **SQLDB1** > **Таблицы**. Вы увидите, что несколько таблиц загружены.
1. Щелкните правой кнопкой мыши таблицу **dbo.Trip** и выберите команду **Создать скрипт SQL** > **Выбрать первые 100 строк**.
1. Подождите, пока новый скрипт SQL будет создан и запущен.
1. Обратите внимание, что в верхней части скрипта SQL для параметра **Подключиться к** автоматически задано значение пула SQL, именуемого **SQLDB1**.
1. Замените текст скрипта SQL этим кодом и запустите его.

    ```sql
    SELECT PassengerCount,
          SUM(TripDistanceMiles) as SumTripDistance,
          AVG(TripDistanceMiles) as AvgTripDistance
    FROM  dbo.Trip
    WHERE TripDistanceMiles > 0 AND PassengerCount > 0
    GROUP BY PassengerCount
    ORDER BY PassengerCount
    ```

    Этот запрос показывает, как общее время поездки и среднее расстояние поездки связаны с количеством пассажиров.
1. В окне результатов скрипта SQL измените представление с **Обзор** на **График**, чтобы увидеть визуализацию результатов в виде графика.

## <a name="load-the-nyc-taxi-data-into-the-spark-nyctaxi-database"></a>Загрузка данных нью-йоркского такси в базу данных Spark "nyctaxi"

В таблице есть данные, доступные в **SQLDB1**. Загрузите их в базу данных Spark с именем **nyctaxi**.

1. В Synapse Studio перейдите в центр **Разработка**.
1. Выберите **+**  > **Записная книжка**.
1. В верхней части записной книжки задайте для параметра **Присоединить к** значение **Spark1**.
1. Выберите **Добавить код**, для того, чтобы добавить ячейку кода записной книжки, и вставьте следующий текст:

    ```scala
    %%spark
    spark.sql("CREATE DATABASE IF NOT EXISTS nyctaxi")
    val df = spark.read.sqlanalytics("SQLDB1.dbo.Trip") 
    df.write.mode("overwrite").saveAsTable("nyctaxi.trip")
    ```

1. Перейдите в центр **Данные**, щелкните правой кнопкой мыши **Базы данных** и потом выберите **Обновить**. Вы должны видеть такие базы данных:

    - **SQLDB1** (пул SQL)
    - **nyctaxi** (Spark)

## <a name="analyze-the-nyc-taxi-data-using-spark-and-notebooks"></a>Анализ данных нью-йоркского такси с помощью Spark и записных книжек

1. Вернитесь к своей записной книжке.
1. Создайте новую ячейку кода и введите следующий текст. Потом запустите ячейку, чтобы показать данные про нью-йоркское такси, которые мы загрузили в базу данных Spark **nyctaxi**.

   ```py
   %%pyspark
   df = spark.sql("SELECT * FROM nyctaxi.trip") 
   display(df)
   ```

1. Выполните следующий код, чтобы провести тот же анализ, который был сделан ранее с помощью пула SQL **SQLDB1**. Этот код сохраняет результаты анализа в таблицу с именем **nyctaxi.passengercountstats** и визуализирует результаты.

   ```py
   %%pyspark
   df = spark.sql("""
      SELECT PassengerCount,
          SUM(TripDistanceMiles) as SumTripDistance,
          AVG(TripDistanceMiles) as AvgTripDistance
      FROM nyctaxi.trip
      WHERE TripDistanceMiles > 0 AND PassengerCount > 0
      GROUP BY PassengerCount
      ORDER BY PassengerCount
   """) 
   display(df)
   df.write.saveAsTable("nyctaxi.passengercountstats")
   ```

1. В результатах ячейки выберите пункт **Диаграмма**, чтобы просмотреть визуализацию данных.

## <a name="customize-data-visualization-with-spark-and-notebooks"></a>Настройка данных визуализации с помощью Spark и записных книжек

Вы можете управлять отображением диаграмм используя записные книжки. Ниже приведен простой пример кода. Он использует популярные библиотеки **matplotlib** и **seaborn**. Код отображает такой же вид графика, что и запросы SQL, которые мы выполняли ранее.

```py
%%pyspark
import matplotlib.pyplot
import seaborn

seaborn.set(style = "whitegrid")
df = spark.sql("SELECT * FROM nyctaxi.passengercountstats")
df = df.toPandas()
seaborn.lineplot(x="PassengerCount", y="SumTripDistance" , data = df)
seaborn.lineplot(x="PassengerCount", y="AvgTripDistance" , data = df)
matplotlib.pyplot.show()
```

## <a name="load-data-from-a-spark-table-into-a-sql-pool-table"></a>Загрузка данных из таблицы Spark в таблицу пула SQL

Ранее мы скопировали данные из таблицы пула SQL **SQLDB1. dbo.Trip** в таблицу Spark **nyctaxi.trip**. Затем, используя Spark, данные были агрегированы в таблицу Spark **nyctaxi.passengercountstats**. Теперь скопируйте данные из **nyctaxi.passengercountstats** в таблицу пула SQL с именем **SQLDB1.dbo.PassengerCountStats**.

Запустите следующую ячейку в записной книжке. Сводная таблица Spark копируется обратно в таблицу пула SQL.

```scala
%%spark
val df = spark.sql("SELECT * FROM nyctaxi.passengercountstats")
df.write.sqlanalytics("SQLDB1.dbo.PassengerCountStats", Constants.INTERNAL )
```

## <a name="analyze-nyc-taxi-data-in-spark-databases-using-sql-on-demand"></a>Анализируйте данные нью-йоркского такси в базах данных Spark с помощью SQL по запросу

Таблицы в базах данных Spark автоматически будут видимы и данные в них могут быть доступны для SQL по запросу.

1. В Synapse Studio перейдите в центр **Разработка** и создайте новый скрипт SQL.
1. Установите для параметра **Подключиться к** значение **SQL on-demand**.
1. Вставьте в скрипт следующий текст и выполните скрип.

    ```sql
    SELECT *
    FROM nyctaxi.dbo.passengercountstats
    ```

    > [!NOTE]
    > При первом выполнении запроса, использующего SQL по запросу, SQL по запросу потребуется примерно 10 секунд на сбор ресурсов SQL, необходимых для выполнения запросов. Следующие запросы будут выполняться гораздо быстрее.
  
## <a name="orchestrate-activities-with-pipelines"></a>Оркестрация действий с помощью конвейеров

В Azure Synapse можно управлять множеством задач.

1. В Synapse Studio перейдите в центр **Оркестрация**.
1. Выберите **+**  > **Конвейер**, чтобы создать новый конвейер.
1. Перейдите в центр **Разработка** и найдите созданную ранее записную книжку.
1. Перетащите эту записную книжку в конвейер.
1. В конвейере выберите **Добавить триггер** > **Создать или изменить**.
1. В окне **Выбор триггера** выберите **Создать**, а затем для **повторения** задайте ежечасный запуск триггера.
1. Щелкните **ОК**.
1. Выберите **Опубликовать все**. Конвейер запускается каждый час.
1. Чтобы конвейер выполнился сейчас, не дожидаясь следующего часа, выберите **Добавить триггер** > **Создать или изменить**.

## <a name="work-with-data-in-a-storage-account"></a>Работайте с данными в учетной записи хранилища

До сих пор были рассмотрены ситуации, когда данные находятся в базах данных в рабочей области. Теперь мы покажем, как работать с файлами в учетных записях хранения. В этом сценарии мы будем использовать основную учетную запись хранения для рабочей области и контейнера, которые мы указали при создании рабочей области.

* Имя учетной записи хранения: **contosolake**
* Имя контейнера в учетной записи хранения: **пользователи**

### <a name="create-csv-and-parquet-files-in-your-storage-account"></a>Создание файлов CSV и Parquet в учетной записи хранения

Выполните приведенный ниже код в записной книжке. Он создает CSV-файл и Parquet-файл в учетной записи хранения.

```py
%%pyspark
df = spark.sql("SELECT * FROM nyctaxi.passengercountstats")
df = df.repartition(1) # This ensure we'll get a single file during write()
df.write.mode("overwrite").csv("/NYCTaxi/PassengerCountStats.csv")
df.write.mode("overwrite").parquet("/NYCTaxi/PassengerCountStats.parquet")
```

### <a name="analyze-data-in-a-storage-account"></a>Анализируйте данные в учетной записи хранения

1. В Synapse Studio перейдите в центр **Данные**, а затем выберите команду **Связанный**.
1. Перейдите в раздел **Учетные записи хранения** > **myworkspace (Primary — contosolake)** .
1. Выберите **пользователи (Основной)"** . Вы увидите папку **NYCTaxi**. Внутри вы увидите две папки **PassengerCountStats.csv** и **PassengerCountStats.parquet**.
1. Откройте папку**PassengerCountStats.parquet**. Внутри вы увидите файл parquet с именем вида *part-00000-2638e00c-0790-496b-a523-578da9a15019-c000.snappy.parquet*.
1. Щелкните правой кнопкой мыши **.parquet**, а затем выберите пункт **Создать записную книжку**. Он создает записную книжку с ячейкой следующего вида:

    ```py
    %%pyspark
    data_path = spark.read.load('abfss://users@contosolake.dfs.core.windows.net/NYCTaxi/PassengerCountStats.parquet/part-00000-1f251a58-d8ac-4972-9215-8d528d490690-c000.snappy.parquet', format='parquet')
    data_path.show(100)
    ```

1. Запустите эту ячейку.
1. Щелкните правой кнопкой мыши файл Parquet и выберите команду **Новый скрипт SQL** > **Выбрать первые 100 строк**. Он создает скрипт SQL таким образом:

    ```sql
    SELECT TOP 100 *
    FROM OPENROWSET(
        BULK 'https://contosolake.dfs.core.windows.net/users/NYCTaxi/PassengerCountStats.parquet/part-00000-1f251a58-d8ac-4972-9215-8d528d490690-c000.snappy.parquet',
        FORMAT='PARQUET'
    ) AS [r];
    ```

     В скрипте для поля **Присоединить к** будет установлено значение **SQL on-demand**.

1. Выполните скрипт.

## <a name="visualize-data-with-power-bi"></a>Визуализация данных с помощью Power BI

Из данных нью-йоркского такси мы создали агрегированные наборы данных в двух таблицах:
- **nyctaxi.passengercountstats**
- **SQLDB1.dbo.PassengerCountStats**

Рабочую область Power BI можно связать с рабочей областью Azure Synapse. Это позволяет легко получать данные в рабочую область Power BI. Вы можете изменить отчеты Power BI непосредственно в рабочей области Azure Synapse.

### <a name="create-a-power-bi-workspace"></a>Создание рабочей области Power BI

1. Войдите на портал [powerbi.microsoft.com](https://powerbi.microsoft.com/).
1. Создайте новую рабочую область Power BI с именем **NYCTaxiWorkspace1**.

### <a name="link-your-azure-synapse-workspace-to-your-new-power-bi-workspace"></a>Связывание рабочей области Azure Synapse с новой рабочей областью Power BI

1. В Synapse Studio последовательно выберите команду **Управление** > **Cвязанные службы**.
1. Выберите команду **Создать** > **Подключиться к Power BI**, и задайте следующие поля:

    |Параметр | Рекомендуемое значение | 
    |---|---|
    |**имя**;|**NYCTaxiWorkspace1**|
    |**Имя рабочей области**|**NYCTaxiWorkspace1**|

1. Нажмите кнопку **создания**.

### <a name="create-a-power-bi-dataset-that-uses-data-in-your-azure-synapse-workspace"></a>Создание набора данных Power BI, использующего данные в рабочей области Azure Synapse

1. В Synapse Studio перейдите в **Разработка** > **Power BI**.
1. Перейдите в раздел **NYCTaxiWorkspace1** > **Наборы данных Power BI** и выберите **Новый набор данных Power BI**.
1. Наведите указатель мыши на базу данных **SQLDB1** и выберите **Download .pbids file** (Загрузить файл .pbids).
1. Откройте загруженный файл **.pbids**. Рабочий стол Power BI открывает и автоматически подключается к **SQLDB1** в рабочей области Azure Synapse.
1. Если откроется диалоговое окно с именем **База данных SQL Server**:
    1. Выберите **Учетная запись Майкрософт**.
    1. Выберите **Войти** и войдите в свою учетную запись.
    1. Выберите **Подключиться**.
1. После того как откроется диалоговое окно **Навигатор**, проверьте таблицу **PassengerCountStats** и выберите команду **Загрузить**.
1. После того как откроется диалоговое окно **Параметры подключения**, выберите команду **DirectQuery** > **ОК**.
1. Нажмите кнопку **Отчет** слева.
1. Добавьте в отчет **График**.
    1. Перетащите столбец **PassengerCount** в **Визуализации** > **Ось**.
    1. Перетащите столбцы **SumTripDistance** и **AvgTripDistance** в **Визуализации** > **Значения**.
1. На вкладке **Главная** нажмите кнопку **Опубликовать**.
1. Выберите **Сохранить**, чтобы сохранить изменения.
1. Выберите имя файла **PassengerAnalysis.pbix**, а затем выберите команду **Сохранить**.
1. В окне **Выбор назначения** выберите **NYCTaxiWorkspace1**, а затем щелкните **Выбрать**.
1. Дождитесь завершения публикации.

### <a name="configure-authentication-for-your-dataset"></a>Настройка проверки подлинности для набора данных

1. Откройте [powerbi.microsoft.com](https://powerbi.microsoft.com/) и выполните **Вход**.
1. В левой части в разделе **Рабочие области** выберите рабочую область **NYCTaxiWorkspace1**.
1. В этой рабочей области выберите набор данных с именем **Анализ пассажиров** и отчет с именем **Анализ пассажиров**.
1. Наведите указатель мыши на набор данных **PassengerAnalysis**, нажмите кнопку с многоточием (...), а затем выберите команду **Параметры**.
1. В разделе **Учетные данные источника данных** задайте для параметра **Метод аутентификации** значение **OAuth2** и выберите **Вход**.

### <a name="edit-a-report-in-synapse-studio"></a>Изменение отчета в Synapse Studio

1. Вернитесь в Synapse Studio и выберите **Закрыть и обновить**.
1. Перейдите в центр **Разработка**.
1. Наведите указатель мыши на **Power BI** и выберите обновление узла **Отчеты Power BI**.
1. Теперь в **Power BI** должны отобразиться:
    1. В разделе **NYCTaxiWorkspace1** > **Наборы данных Power BI**, новый набор с именем **PassengerAnalysis**.
    1. В разделе **NYCTaxiWorkspace1** > **Отчеты Power BI**, новый отчет с именем **PassengerAnalysis**.
1. Выберите отчет **PassengerAnalysis**. Отчет откроется, и его можно изменить непосредственно в Synapse Studio.

## <a name="monitor-activities"></a>Действия Monitor

1. В Synapse Studio перейдите в центр **монитор**.
1. Здесь вы можете просмотреть журнал всех действий, выполняемых в рабочей области, и какие из них сейчас активны.
1. Изучите разделы **Выполнения конвейеров**, **Приложения Apache Spark** и **Запросы SQL**, а также просмотрите, что вы уже сделали в рабочей области.

## <a name="next-steps"></a>Дальнейшие действия

Узнайте больше об [Azure Synapse Analytics (предварительная версия рабочих областей)](overview-what-is.md).

