---
title: Как использовать OPENROWSET в службе SQL по запросу (предварительная версия)
description: В этой статье описан синтаксис функции OPENROWSET в службе SQL по запросу (предварительная версия) и использование аргументов.
services: synapse-analytics
author: filippopovic
ms.service: synapse-analytics
ms.topic: overview
ms.subservice: sql
ms.date: 05/07/2020
ms.author: fipopovi
ms.reviewer: jrasnick
ms.openlocfilehash: 786f277c1a46213b43f81b5cfa563303b3d7ddf9
ms.sourcegitcommit: dee7b84104741ddf74b660c3c0a291adf11ed349
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2020
ms.locfileid: "85921307"
---
# <a name="how-to-use-openrowset-with-sql-on-demand-preview"></a>Как использовать OPENROWSET в службе SQL по запросу (предварительная версия)

Функция `OPENROWSET(BULK...)` позволяет получить доступ к файлам в службе хранилища Azure. Функция `OPENROWSET` считывает содержимое удаленного источника данных (например, файла) и возвращает содержимое в виде набора строк. В ресурсе службы SQL по запросу (предварительная версия) доступ к поставщику больших наборов строк OPENROWSET осуществляется путем вызова функции OPENROWSET и задания параметра BULK.  

Из предложения `FROM` запроса можно ссылаться на функцию `OPENROWSET`, как если бы это было имя таблицы `OPENROWSET`. Функция также поддерживает массовые операции с помощью встроенного поставщика BULK, позволяющего считывать данные из файла и возвращать их в виде набора строк.

## <a name="data-source"></a>Источник данных

Функция OPENROWSET в Synapse SQL считывает содержимое файлов из источника данных. Источник данных — это учетная запись хранения Azure, которую можно явно указать в функции `OPENROWSET` или динамически выводить из URL-адреса файлов, которые вы намерены считать.
Функция `OPENROWSET` может содержать необязательный параметр `DATA_SOURCE` для указания источника данных с нужными файлами.
- `OPENROWSET` без `DATA_SOURCE` позволяет считать содержимого файлов напрямую по URL-адресу, указанному в параметре `BULK`:

    ```sql
    SELECT *
    FROM OPENROWSET(BULK 'http://storage..../container/folder/*.parquet',
                    TYPE = 'PARQUET') AS file
    ```

Это быстрый и простой способ считать содержимое файлов без предварительной настройки. Этот параметр позволяет использовать базовую проверку подлинности для доступа к хранилищу (сквозная проверка Azure AD для имен входа Azure AD или маркер SAS для имен входа SQL). 

- `OPENROWSET` с `DATA_SOURCE` можно использовать для доступа к файлам в указанной учетной записи хранения:

    ```sql
    SELECT *
    FROM OPENROWSET(BULK '/folder/*.parquet',
                    DATA_SOURCE='storage', --> Root URL is in LOCATION of DATA SOURCE
                    TYPE = 'PARQUET') AS file
    ```


    Этот параметр позволяет настроить расположение учетной записи хранения в источнике данных и указать метод проверки подлинности, который должен использоваться для доступа к хранилищу. 
    
    > [!IMPORTANT]
    > `OPENROWSET` без `DATA_SOURCE` обеспечивает быстрый и простой способ доступа к файлам хранилища, но поддерживает мало возможностей для проверки подлинности. Например, субъекты Azure AD могут обращаться к файлам только с использованием [удостоверения Azure AD](develop-storage-files-storage-access-control.md?tabs=user-identity) или общедоступным файлам. Если вам нужны более мощные возможности для проверки подлинности, используйте параметр `DATA_SOURCE` и определите учетные данные, которые нужно использовать для доступа к хранилищу.


## <a name="security"></a>Безопасность

Пользователь базы данных должен иметь разрешение `ADMINISTER BULK OPERATIONS`, чтобы использовать функцию `OPENROWSET`.

Администратор хранилища также должен разрешить пользователю доступ к файлам, предоставив действительный маркер SAS или разрешение субъекту Azure AD для доступа к файлам хранилища. Узнайте больше об управлении доступом к хранилищу в [этой статье](develop-storage-files-storage-access-control.md).

`OPENROWSET` использует следующие правила, чтобы выбрать способ проверки подлинности в хранилище:
- В `OPENROWSET` без `DATA_SOURCE` механизм проверки подлинности зависит от типа вызывающего объекта.
  - Любой пользователь может использовать `OPENROWSET` без `DATA_SOURCE`, чтобы считывать общедоступные файлы в службе хранилища Azure.
  - Имена входа Azure AD могут получать доступ к защищенным файлам с помощью собственных [удостоверений Azure AD](develop-storage-files-storage-access-control.md?tabs=user-identity#supported-storage-authorization-types), если служба хранилища Azure позволяет пользователю Azure AD получать доступ к базовым файлам (например, если у вызывающего объекта есть разрешение `Storage Reader` в службе хранилища Azure).
  - Для имен входа SQL также можно использовать `OPENROWSET` без `DATA_SOURCE` для доступа к общедоступным файлам, защищенным с помощью маркера SAS файлам и управляемым удостоверениям рабочей области Synapse. Чтобы разрешить доступ к файлам хранилища, необходимо [создать учетные данные уровня сервера](develop-storage-files-storage-access-control.md#examples). 
- В `OPENROWSET` с `DATA_SOURCE` механизм проверки подлинности определяется в учетных данных уровня базы данных, которые назначены указанному источнику данных. Этот параметр позволяет обращаться к общедоступному хранилищу, а также к защищенному хранилищу по маркеру SAS, управляемому удостоверению рабочей области или [удостоверению вызывающего объекта Azure AD](develop-storage-files-storage-access-control.md?tabs=user-identity#supported-storage-authorization-types) (если этот вызывающий объект является субъектом Azure AD). Если `DATA_SOURCE` ссылается на хранилище Azure, которое не является общедоступным, придется [создать учетные данные уровня базы данных](develop-storage-files-storage-access-control.md#examples) и указать их в `DATA SOURCE`, чтобы разрешить доступ к файлам хранилища.

Вызывающий объект должен иметь разрешение `REFERENCES` для этих учетных данных, чтобы использовать их для проверки подлинности в хранилище.

## <a name="syntax"></a>Синтаксис

```syntaxsql
--OPENROWSET syntax for reading Parquet files
OPENROWSET  
( { BULK 'unstructured_data_path' , [DATA_SOURCE = <data source name>, ]
    FORMAT='PARQUET' }  
)  
[WITH ( {'column_name' 'column_type' }) ]
[AS] table_alias(column_alias,...n)

--OPENROWSET syntax for reading delimited text files
OPENROWSET  
( { BULK 'unstructured_data_path' , [DATA_SOURCE = <data source name>, ] 
    FORMAT = 'CSV'
    [ <bulk_options> ] }  
)  
WITH ( {'column_name' 'column_type' [ 'column_ordinal'] })  
[AS] table_alias(column_alias,...n)
 
<bulk_options> ::=  
[ , FIELDTERMINATOR = 'char' ]    
[ , ROWTERMINATOR = 'char' ] 
[ , ESCAPE_CHAR = 'char' ] 
[ , FIRSTROW = 'first_row' ]     
[ , FIELDQUOTE = 'quote_characters' ]
[ , DATA_COMPRESSION = 'data_compression_method' ]
[ , PARSER_VERSION = 'parser_version' ]
```

## <a name="arguments"></a>Аргументы

Есть два варианта ввода входных файлов, содержащих целевые данные для запросов. Допустимые значения:

- "CSV" — включает любой текстовый файл с разделителями (разделители строк и столбцов). В качестве разделителя полей можно использовать любой символ, например TSV: FIELDTERMINATOR = знак табуляции.

- "PARQUET" — двоичный файл в формате Parquet. 

**unstructured_data_path**

Аргумент unstructured_data_path, который определяет путь к данным, может содержать абсолютный или относительный путь:
- Абсолютный путь в формате "\<prefix>://\<storage_account_path>/\<storage_path>" позволяет пользователю напрямую читать файлы.
- Относительный путь в формате "<путь_к_хранилищу>", который нужно использовать только с параметром `DATA_SOURCE`, описывает шаблон имени файла в расположении <путь_к_учетной_записи_хранения>, которое определено в `EXTERNAL DATA SOURCE`. 

 Ниже приведены соответствующие значения <storage account path>, которые будут связаны с конкретным внешним источником данных. 

| Внешний источник данных       | Prefix | Путь к учетной записи хранения                                 |
| -------------------------- | ------ | ---------------------------------------------------- |
| хранилище BLOB-объектов Azure         | HTTPS  | \<storage_account>.blob.core.windows.net/path/file   |
| хранилище BLOB-объектов Azure         | wasb   | \<container>@\<storage_account>.blob.core.windows.net/path/file |
| Azure Data Lake Store 1-го поколения | HTTPS  | \<storage_account>.azuredatalakestore.net/webhdfs/v1 |
| Azure Data Lake Store 2-го поколения | HTTPS  | \<storage_account>.dfs.core.windows.net /path/file   |
| Azure Data Lake Store 2-го поколения | abfss  | [\<file_system>@\<account_name>.dfs.core.windows.net/path/file](../../storage/blobs/data-lake-storage-introduction-abfs-uri.md#uri-syntax)              |
||||

'\<storage_path>'

 Позволяет задать путь в хранилище, указывающий на папку или файл, который нужно считать. Если путь указывает на контейнер или папку, все файлы будут считываться только из этого контейнера или папки. Файлы во вложенных папках не включаются. 

 Для выбора нескольких файлов или папок можно использовать подстановочные знаки. Допускается использование нескольких подстановочных знаков, если они размещены не подряд.
Ниже приведен пример для считывания всех файлов *.csv*, в начале имени которых указано *population*, из всех папок, в начале имени которых указано */csv/population*:  
`https://sqlondemandstorage.blob.core.windows.net/csv/population*/population*.csv`

Если указать в аргументе unstructured_data_path папку, после обращения к службе SQL по запросу будут получены файлы из этой папки. 

> [!NOTE]
> В отличие от Hadoop и Polybase, SQL по запросу не возвращает вложенные папки. Еще одно отличие от Hadoop и PolyBase заключается в том, что служба SQL по запросу не возвращает файлы, имя которых начинается с подчеркивания (_) или точки (.).

Если в приведенном ниже примере unstructured_data_path=`https://mystorageaccount.dfs.core.windows.net/webdata/`, после обращения в SQL по запросу будут возвращены строки из mydata.txt и _hidden.txt. Служба не будет возвращать mydata2.txt и mydata3.txt, так как они находятся во вложенной папке.

![Рекурсивные данные для внешних таблиц](./media/develop-openrowset/folder-traversal.png)

`[WITH ( {'column_name' 'column_type' [ 'column_ordinal'] }) ]`

Предложение WITH позволяет указать столбцы, которые нужно считать из файлов.

- Для чтения всех столбцов в файлах данных CSV укажите имена столбцов и их типы данных. Если нужно считать подмножество столбцов, используйте порядковые номера, чтобы выбрать столбцы из исходных файлов данных по порядковому номеру. Столбцы будут привязаны к порядковым обозначениям. 

    > [!IMPORTANT]
    > Предложение WITH является обязательным для CSV-файлов.
    >
    
- Для файлов данных Parquet укажите имена столбцов, совпадающих с именами столбцов в исходных файлах данных. Столбцы будут привязаны к именам. Если предложение WITH не указано, возвращаются все столбцы из файлов Parquet.

column_name (имя_столбца) = имя выходного столбца. Если значение указано, это имя переопределяет имя столбца в исходном файле.

column_type (тип_столбца) = тип данных в выходном столбце. Выполняется неявное преобразование типов данных.

column_ordinal (порядковый_номер_столбца) = порядковый номер столбца в исходных файлах. Этот аргумент не учитывается для файлов Parquet, так как привязка выполняется по имени. В следующем примере из CSV-файла будет возвращен только второй столбец:

```sql
WITH (
    --[country_code] VARCHAR (5) COLLATE Latin1_General_BIN2,
    [country_name] VARCHAR (100) COLLATE Latin1_General_BIN2 2
    --[year] smallint,
    --[population] bigint
)
```

**\<bulk_options>**

FIELDTERMINATOR ='field_terminator' (признак_конца_поля)

Указывает признак конца поля, который нужно использовать. Признак конца поля по умолчанию — запятая (" **,** ").

ROWTERMINATOR ='row_terminator' (признак_конца_строки)

Указывает признак конца строки, который нужно использовать. Если признак конца строки не указан, будет использоваться один из признаков конца строки по умолчанию. По умолчанию для версии PARSER_VERSION = "1.0" используются признаки \r\n, \n и \r. По умолчанию для версии PARSER_VERSION = "2.0" используются признаки \r\n и \n.

ESCAPE_CHAR = 'char'

Задает символ в файле, используемый для экранирования собственно этого символа и всех значений разделителей в файле. Если за escape-символом следует значение, отличное от него самого или какого-либо из значений разделителей, при считывании этого значения escape-символ пропускается. 

Параметр ESCAPE_CHAR будет применяться независимо от того, включен ли параметр FIELDQUOTE. Он не будет использоваться для экранирования символа кавычек. Символ кавычек нужно экранировать другим символом кавычек. Такой символ может использоваться в значении столбца только в том случае, если значение инкапсулировано с помощью символов кавычек.

FIRSTROW = 'first_row' (первая_строка) 

Указывает номер первой строки для загрузки. Значение по умолчанию — 1. Значение по умолчанию — первая строка указанного файла данных. Номера строк определяются с помощью подсчета признаков конца строки. Значения аргумента FIRSTROW начинаются с 1.

FIELDQUOTE = 'field_quote' (символ_кавычек) 

Определяет символ, который будет использоваться в качестве символа кавычки в CSV-файле. Если значение не указано, будут использоваться текущий символ кавычек ("). 

DATA_COMPRESSION = "метод_cжатия_данных"

Позволяет указать метод сжатия. Поддерживается следующий метод сжатия:

- org.apache.hadoop.io.compress.GzipCodec

PARSER_VERSION = "версия_средства_синтаксического_анализа"

Позволяет указать версию средства синтаксического анализа, которая используется при чтении файлов. В настоящее время поддерживаются версии 1.0 и 2.0 средства синтаксического анализа для CSV-файлов.

- PARSER_VERSION = "1.0"
- PARSER_VERSION = "2.0"

Средство синтаксического анализа для CSV-файлов версии 1.0 обладает широким набором функций и используется по умолчанию, а версия 2.0 оптимизирована для производительности и поддерживает не все параметры и кодировки. 

Особенности средства синтаксического анализа для CSV-файлов версии 2.0:

- Поддерживаются не все типы данных.
- Размер строки не может превышать 8 МБ.
- Приведенные ниже параметры не поддерживаются. DATA_COMPRESSION.
- Пустая строка в кавычках ("") интерпретируется как пустая строка.

## <a name="examples"></a>Примеры

В следующем примере из файлов population*.csv возвращаются только два столбца с порядковыми номерами 1 и 4. В файлах нет строки заголовка, поэтому чтение начинается с первой строки.

```sql
SELECT * 
FROM OPENROWSET(
        BULK 'https://sqlondemandstorage.blob.core.windows.net/csv/population/population*.csv',
        FORMAT = 'CSV',
        FIRSTROW = 1
    )
WITH (
    [country_code] VARCHAR (5) COLLATE Latin1_General_BIN2 1,
    [population] bigint 4
) AS [r]
```

В следующем примере возвращаются все столбцы первой строки из набора данных переписи в формате Parquet без указания имен столбцов и типов данных. 

```sql
SELECT 
    TOP 1 *
FROM  
    OPENROWSET(
        BULK 'https://azureopendatastorage.blob.core.windows.net/censusdatacontainer/release/us_population_county/year=20*/*.parquet',
        FORMAT='PARQUET'
    ) AS [r]
```

## <a name="next-steps"></a>Дальнейшие действия

См. примеры в [кратком руководстве по работе с запросами к хранилищу данных](query-data-storage.md), где показано, как использовать `OPENROWSET` для чтения файлов в формате [CSV](query-single-csv-file.md), [PARQUET](query-parquet-files.md) и [JSON](query-json-files.md). Вы также узнаете, как сохранить результаты запроса в службе хранилища Azure с помощью [CETAS](develop-tables-cetas.md).
