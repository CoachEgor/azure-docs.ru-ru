---
title: Рекомендации по разработке для синапсе SQL
description: Рекомендации и рекомендации, которые следует учитывать при разработке для синапсе SQL.
services: synapse-analytics
author: XiaoyuMSFT
manager: craigg
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: xiaoyul
ms.reviewer: igorstan
ms.openlocfilehash: ed2638cfe4ab7e849e428729ccd17ffdeb6314af
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "82086357"
---
# <a name="development-best-practices-for-synapse-sql"></a>Рекомендации по разработке для синапсе SQL
В этой статье приводятся руководство и рекомендации по разработке решения хранилища данных. 

## <a name="sql-pool-development-best-practices"></a>Рекомендации по разработке пула SQL

### <a name="reduce-cost-with-pause-and-scale"></a>Снижение расходов за счет приостановки и масштабирования ресурсов

Дополнительные сведения о сокращении затрат при помощи приостановки и масштабирования см. в статье об [управлении вычислительными ресурсами](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json).

### <a name="maintain-statistics"></a>Обеспечение статистики

Убедитесь, что статистика обновляется ежедневно или после каждой загрузки.  Однако всегда есть компромиссы между производительностью и затратами на создание и обновление статистики. Если вы обнаружите, что вся статистика занимает слишком много времени, более избирательно следует указать, какие столбцы имеют статистику или какие столбцы нуждаются в частом обновлении.  

Например, может потребоваться обновить столбцы даты, где новые значения могут добавляться ежедневно. 

> [!NOTE]
> Вы получите наибольшее преимущество, получая статистику по столбцам, участвующим в запросах JOIN, столбцам, используемым в предложении WHERE, и столбцам, найденным в поле GROUP BY.

См. также раздел [Управление статистикой таблицы](develop-tables-statistics.md), [Создание статистики](/sql/t-sql/statements/create-statistics-transact-sql?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest), [Обновление статистики](/sql/t-sql/statements/update-statistics-transact-sql?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest).

### <a name="hash-distribute-large-tables"></a>Хэш-распределение больших таблиц

По умолчанию таблицы распределяются по методу циклического перебора.  Это позволяет пользователям легко начать создавать таблицы, не принимая решение о том, как следует распределять их таблицы.  Таблицы с циклическим перебором могут работать достаточно эффективно для некоторых рабочих нагрузок. Но в большинстве случаев выбор столбца распределения будет выполняться гораздо лучше.  

Наглядно это превосходство можно увидеть при объединении больших таблиц фактов.  

Например, при наличии таблицы Orders, которая распространяется с order_id, и таблицей транзакций, которая также распространяется order_id, при присоединении таблицы Orders к таблице Transactions на order_id этот запрос становится передаваемым запросом. 

Это означает, что мы исключим операции перемещения данных.  Чем меньше в запросе действий, тем быстрее он выполняется.  Скорость выполнения запроса также зависит от объема перемещаемых данных.

> [!TIP]
> При загрузке распределенной таблицы входящие данные не должны быть отсортированы по ключу распределения, так как это замедлит процесс загрузки.  

Дополнительные сведения о том, как выбор столбца распределения может повысить производительность, а также определение распределенной таблицы в предложении WITH инструкции CREATE TABLEs, см. по следующим ссылкам.

См. также [Обзор таблиц](develop-tables-overview.md), [распределение таблиц](../sql-data-warehouse/sql-data-warehouse-tables-distribute.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json), [Выбор распределения таблиц](https://blogs.msdn.microsoft.com/sqlcat/20../../choosing-hash-distributed-table-vs-round-robin-distributed-table-in-azure-sql-dw-service/), [CREATE TABLE](/sql/t-sql/statements/create-table-azure-sql-data-warehouse?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest)и [CREATE TABLE в качестве SELECT](/sql/t-sql/statements/create-table-as-select-azure-sql-data-warehouse?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest).

### <a name="do-not-over-partition"></a>Недопущение избыточного секционирования
В то время как секционирование данных может быть эффективным для поддержания данных посредством переключения секций или оптимизации проверок с помощью исключения секций, наличие слишком большого количества секций может замедлить выполнение запросов.  Зачастую стратегия секционирования с высоким уровнем детализации, которая хорошо работает на SQL Server может работать не в пуле SQL.  

> [!NOTE]
> Зачастую стратегия секционирования с высоким уровнем детализации, которая хорошо работает на SQL Server может работать не в пуле SQL.  

Слишком большое количество секций снижает эффективность кластеризованных индексов Columnstore, если в секции содержится менее миллиона строк. Пул SQL разделяет ваши данные на базы данных 60. 

Таким образом, если создается таблица с 100 секциями, результат будет составлять 6000 секций.  Все рабочие нагрузки отличаются, поэтому рекомендуется поэкспериментировать с секционированием, чтобы выбрать наиболее подходящее количество секций для вашей рабочей нагрузки.  

Одним из вариантов является использование степени гранулярности, которая ниже, возможно, работала в SQL Server.  Например, попробуйте использовать еженедельные или ежемесячные секции вместо ежедневных.

См. также [секционирование таблиц](../sql-data-warehouse/sql-data-warehouse-tables-partition.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json).

### <a name="minimize-transaction-sizes"></a>Уменьшение размера транзакций

Инструкции INSERT, UPDATE и DELETE выполняются в транзакциях. В случае сбоя их необходимо откатить.  Чтобы сократить время выполнения отката, необходимо по возможности уменьшить размеры транзакций.  Это можно сделать, разделив инструкции INSERT, UPDATE и DELETE на части.  

Например, если имеется вставка, которая займет 1 час, можно разбить вставку на четыре части, тем самым сокращая каждый запуск на 15 минут.

> [!TIP]
> К пустым таблицам можно применять специальные операции, которые сопровождаются записью в журнал минимальных сведений, (такие как CTAS, TRUNCATE, DROP TABLE или INSERT), чтобы снизить риск отката.  

Устранить откаты также можно, используя для управления данными только операции с метаданными (например, переключение секций).  

Например, вместо выполнения инструкции DELETE для удаления всех строк в таблице, упорядоченной по идентификатору order_date (октябрь 2001 г.), данные можно секционировать ежемесячно, а потом переключить секцию с данными на пустую секцию из другой таблицы (см. примеры использования инструкции ALTER TABLE).  

Используя инструкцию CTAS вместо DELETE, можно записать данные, которые необходимо сохранить в несекционированной таблице.  Если на выполнение этих двух инструкций требуется одинаковое количество времени, целесообразно использовать инструкцию CTAS, так как для ее выполнения необходима минимальная нагрузка ведения журнала транзакций, и ее можно быстро отменить.

См. также раздел [Основные сведения о транзакциях](develop-transactions.md), [Оптимизация транзакций](../sql-data-warehouse/sql-data-warehouse-develop-best-practices-transactions.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json), [секционирование ТАБЛИЦ](../sql-data-warehouse/sql-data-warehouse-tables-partition.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json), [TRUNCATE TABLE](/sql/t-sql/statements/truncate-table-transact-sql?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest), [ALTER TABLE](/sql/t-sql/statements/alter-table-transact-sql?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest), а [также создание таблицы как SELECT (CTAS)](../sql-data-warehouse/sql-data-warehouse-develop-ctas.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json).

### <a name="use-the-smallest-possible-column-size"></a>Использование минимального размера столбца

При определении DDL рекомендуется использовать поддерживаемый тип данных с наименьшим размером. Это позволит повысить производительность запросов.  Это особенно важно для столбцов CHAR и VARCHAR.  

Если самое длинное значение в столбце состоит из 25 знаков, столбец необходимо определить как VARCHAR(25).  Не рекомендуется использовать по умолчанию длинные значения столбцов.  Кроме того, по возможности определяйте столбцы как VARCHAR, а не NVARCHAR.

См. также [Общие сведения о таблице](develop-tables-overview.md), [табличные типы данных](develop-tables-data-types.md)и [CREATE TABLE](/sql/t-sql/statements/create-table-azure-sql-data-warehouse?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest).

### <a name="optimize-clustered-columnstore-tables"></a>Оптимизация таблиц с кластеризованными индексами columnstore

Кластеризованные индексы columnstore — это один из наиболее эффективных способов хранения данных в пуле SQL.  По умолчанию таблицы в пуле SQL создаются как кластеризованный ColumnStore.  

Качество кластеризованного сегмента Columnstore существенно влияет на эффективность выполнения запросов в таблицах с кластеризованными индексами Columnstore.  Если во время записи строк в таблицы Columnstore возникает нехватка памяти, качество сегмента Columnstore может ухудшиться.  

Качество сегмента можно изменить по числу строк в сжатой группе строк.  Пошаговые инструкции по обнаружению и улучшению качества сегментов для кластеризованных таблиц columnstore см. в статье [причины низкого качества индекса columnstore](../sql-data-warehouse/sql-data-warehouse-tables-index.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json#causes-of-poor-columnstore-index-quality) и [табличных индексов](../sql-data-warehouse/sql-data-warehouse-tables-index.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json) .  

Так как высококачественные сегменты columnstore важны, рекомендуется использовать идентификаторы пользователей, которым назначен класс ресурсов среднего или большого размера для загрузки данных. Использование [единиц использования хранилища данных](resource-consumption-models.md) меньшего размера требует присвоения пользователю загрузки класса ресурсов большего размера.

Так как таблицы columnstore обычно не отправляют данные в сжатый сегмент columnstore до тех пор, пока в таблице не будет более 1 000 000 строк, а каждая таблица пула SQL секционирована на 60 таблиц, то таблицы columnstore не смогут использовать запрос, если только таблица не содержит более 60 000 000 строк.  

> [!TIP]
> Для таблиц, в которых менее 60 000 000 строк, наличие индекса columstore может оказаться неоптимальным решением.  

Более того, чтобы воспользоваться преимуществами кластеризованного индекса Columnstore при секционировании данных, каждая секция должна состоять из миллиона строк.  Если таблица содержит 100 секций, то для получения преимуществ из хранилища кластеризованных столбцов требуется по крайней мере 6 000 000 000 строк (60 распределений *100 секции* 1 000 000 строки).  

Если в таблице нет 6 000 000 000 строк, сократите количество секций или используйте вместо этого таблицу кучи.  Также может потребоваться эксперимент, чтобы узнать, можно ли повысить производительность с помощью таблицы кучи с вторичными индексами, а не с таблицей columnstore.

Если выбрать только необходимые столбцы, запросы к таблице ColumnStore будут выполняться быстрее.  

См. также инструкции по [индексам таблиц](../sql-data-warehouse/sql-data-warehouse-tables-index.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json), [индексам columnstore](/sql/relational-databases/indexes/columnstore-indexes-overview?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json&view=azure-sqldw-latest)и [перестроению индексов columnstore](../sql-data-warehouse/sql-data-warehouse-tables-index.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json#rebuilding-indexes-to-improve-segment-quality).

## <a name="sql-on-demand-development-best-practices"></a>Рекомендации по разработке по запросу SQL

### <a name="general-considerations"></a>Общие вопросы

SQL on-Demand позволяет запрашивать файлы в учетных записях хранения Azure. У него нет возможностей локального хранилища или приема, то есть все файлы, которые целевой запрос является внешними по отношению к SQL по запросу. Таким образом, все, что связано с чтением файлов из хранилища, может оказать влияние на производительность запросов.

### <a name="colocate-azure-storage-account-and-sql-on-demand"></a>Совместное размещение учетной записи хранения Azure и SQL по запросу

Чтобы максимально сокращать задержку, совместно находите учетную запись хранения Azure и конечную точку SQL по запросу. Учетные записи хранения и конечные точки, подготовленные во время создания рабочей области, находятся в одном регионе.

Для обеспечения оптимальной производительности при доступе к другим учетным записям хранения с помощью SQL по требованию убедитесь, что они находятся в одном регионе. В противном случае будет увеличена задержка передачи данных по сети из удаленного региона в регион конечной точки.

### <a name="azure-storage-throttling"></a>Регулирование хранилища Azure

Несколько приложений и служб могут получить доступ к вашей учетной записи хранения. При объединении операций ввода-вывода или пропускной способности, создаваемой приложениями, службами и рабочей нагрузкой SQL по запросу, превышены ограничения учетной записи хранения, выполняется регулирование хранилища. При регулировании хранилища возникает значительное отрицательное воздействие на производительность запросов.

После обнаружения регулирования в SQL по запросу предусмотрена встроенная обработка этого сценария. SQL по запросу будет выполнять запросы к хранилищу в более низком темпе, пока регулирование не будет разрешено. 

Однако для оптимального выполнения запросов рекомендуется не перегрузить учетную запись хранения другими рабочими нагрузками во время выполнения запроса.

### <a name="prepare-files-for-querying"></a>Подготовка файлов к запросам

По возможности вы можете подготовить файлы для повышения производительности:

- Преобразование CSV в Parquet – Parquet имеет формат столбцов. Так как он сжимается, размер файлов меньше, чем у CSV-файлов с теми же данными, и SQL по запросу требует меньше времени и запросов на хранение для чтения.
- Если запрос предназначен для одного большого файла, то будет полезно разделить его на несколько меньших файлов.
- Попробуйте сохранить размер CSV-файла ниже 10 ГБ.
- Рекомендуется иметь одинаковый размер файлов для одного пути OPENROWSET или расположения внешней таблицы.
- Разбейте данные путем хранения секций в разных папках или именах файлов. Установите флажок [использовать функции filename и FilePath для конкретных секций](#use-fileinfo-and-filepath-functions-to-target-specific-partitions).

### <a name="use-fileinfo-and-filepath-functions-to-target-specific-partitions"></a>Использование функций FileInfo и FilePath для назначения конкретных секций

Данные часто организованы в секции. Можно указать SQL по запросу на выполнение запросов к определенным папкам и файлам. Это позволит сократить количество файлов и объем данных, необходимых для чтения и обработки запроса. 

Следовательно, вы получите лучшую производительность. Дополнительные сведения см. в подменю функции [filename](develop-storage-files-overview.md#filename-function) и [FilePath](develop-storage-files-overview.md#filepath-function) и примеры [запросов к конкретным файлам](query-specific-files.md).

Если данные в хранилище не секционированы, рассмотрите возможность секционирования, чтобы можно было использовать эти функции для оптимизации запросов, предназначенных для этих файлов.

При [запросе секционированных таблиц Spark](develop-storage-files-spark-tables.md) из SQL по требованию запрос автоматически наследует только необходимые файлы.

### <a name="use-cetas-to-enhance-query-performance-and-joins"></a>Использование CETAS для повышения производительности и соединений запросов

[CETAS](develop-tables-cetas.md) — одна из наиболее важных функций, доступных в SQL по запросу. CETAS — это параллельная операция, которая создает метаданные внешней таблицы и экспортирует результат запроса SELECT в набор файлов в вашей учетной записи хранения.

CETAS можно использовать для хранения часто используемых частей запросов, например Объединенных ссылочных таблиц, в новый набор файлов. Позже можно будет присоединиться к этой отдельной внешней таблице вместо повторения общих соединений в нескольких запросах. 

Поскольку CETAS создает файлы Parquet, статистика будет создана автоматически, когда первый запрос обращается к этой внешней таблице, и вы получите повышенную производительность.

### <a name="next-steps"></a>Дальнейшие шаги

Если вам нужна информация, не указанная в этой статье, используйте команду "Поиск документов" в левой части этой страницы, чтобы найти все документы пула SQL.  [Форум пула SQL](https://social.msdn.microsoft.com/Forums/sqlserver/home?forum=AzureSQLDataWarehouse) — это место, где можно создавать вопросы для других пользователей и группы разработчиков пула SQL.  

Мы регулярно просматриваем этот форум и следим за тем, чтобы другие пользователи или наши специалисты ответили на интересующие вас вопросы.  Если вы предпочитаете задавать вопросы на Stack Overflow, у нас также есть [пул Azure SQL Stack overflow Forum](https://stackoverflow.com/questions/tagged/azure-sqldw).
 