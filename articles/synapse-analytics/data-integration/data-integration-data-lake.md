---
title: Прием данных в Azure Data Lake Storage 2-го поколения
description: Узнайте, как принимать данные в Azure Data Lake Storage 2-го поколения с помощью Azure Synapse Analytics
services: synapse-analytics
author: djpmsft
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: daperlov
ms.reviewer: jrasnick
ms.openlocfilehash: 8307f01e690536a71d98d5d5ca99f8f7a77a433f
ms.sourcegitcommit: 5b8fb60a5ded05c5b7281094d18cf8ae15cb1d55
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/29/2020
ms.locfileid: "87383925"
---
# <a name="ingest-data-into-azure-data-lake-storage-gen2"></a>Прием данных в Azure Data Lake Storage 2-го поколения 

В этой статье объясняется, как реализовать прием данных из одного расположения в другое в учетной записи хранения Azure Data Lake 2-го поколения с помощью Azure Synapse Analytics.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**: Если у вас еще нет подписки Azure, создайте [бесплатную учетную запись](https://azure.microsoft.com/free/) Azure, прежде чем начинать работу.
* **учетную запись хранения,** Azure Data Lake 2-го поколения используется в качестве хранилища *исходных* данных. Если у вас нет учетной записи хранения Azure, создайте ее по инструкциям из статьи [Создание учетной записи хранения Azure](../../storage/blobs/data-lake-storage-quickstart-create-account.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json).

## <a name="create-linked-services"></a>Создание связанных служб

В Azure Synapse Analytics связанная служба используется для определения сведений о подключении к другим службам. В этом разделе показано, как добавить Azure Synapse Analytics и Azure Data Lake 2-го поколения в качестве связанных служб.

1. Откройте пользовательский интерфейс Azure Synapse Analytics и перейдите на вкладку **Управление**.
1. В разделе **Внешние подключения** выберите **Связанные службы**.
1. Чтобы добавить связанную службу, щелкните **Создать**.
1. Выберите элемент Azure Data Lake Storage 2-го поколения из списка и щелкните **Продолжить**.
1. Введите учетные данные для проверки подлинности. В настоящее время поддерживаются следующие типы проверки подлинности: ключ учетной записи, субъект-служба и управляемое удостоверение. Нажмите кнопку проверки подключения, чтобы проверить правильность учетных данных. 
1. После завершения нажмите **Создать**.

## <a name="create-pipeline"></a>Создание конвейера

Конвейер содержит логический поток для выполнения набора действий. В этом разделе показано, как создать конвейер, содержащий действие копирования, которое принимает данные из Azure Data Lake 2-го поколения в пул SQL.

1. Перейдите на вкладку **Orchestrate** (Оркестрация). Щелкните значок плюса рядом с заголовком конвейеров и выберите **Конвейер**.
1. В разделе **Move and Transform** (Перемещение и преобразование) на панели действий перетащите **Копирование данных** на холст конвейера.
1. Щелкните действие копирования и перейдите на вкладку **Источник**. Щелкните **Создать**, чтобы создать исходный набор данных.
1. Выберите Azure Data Lake Storage 2-го поколения в качестве хранилища данных и щелкните "Продолжить".
1. Выберите DelimitedText в качестве формата и щелкните "Продолжить".
1. На панели задания свойств выберите созданную связанную службу ADLS. Укажите путь к исходным данным и укажите, содержит ли первая строка заголовок. Можно импортировать схему из хранилища файлов или из примера файла. Щелкните "OK", когда все будет готово.
1. Перейдите на вкладку **Приемник**. Щелкните **Создать**, чтобы создать набор данных приемника.
1. Выберите Azure Data Lake Storage 2-го поколения в качестве хранилища данных и щелкните "Продолжить".
1. Выберите DelimitedText в качестве формата и щелкните "Продолжить".
1. На панели задания свойств выберите созданную связанную службу ADLS. Укажите путь к папке, в которую нужно записать данные. Щелкните "OK", когда все будет готово.

## <a name="debug-and-publish-pipeline"></a>Отладка и публикация конвейера

Завершив настройку конвейера, можно выполнить отладку перед публикацией артефактов, чтобы убедиться, что все правильно.

1. Чтобы выполнить отладку конвейера, на панели инструментов щелкните **Отладка**. Состояние выполнения конвейера вы можете найти на вкладке **Выходные данные** в нижней части окна. 
1. После успешного запуска конвейера в верхней панели инструментов выберите **Опубликовать все**. Это действие опубликует сущности (наборы данных и конвейеры), которые вы создали в службе Synapse Analytics.
1. Дождитесь сообщения **Successfully published** (Публикация выполнена). Чтобы отобразить уведомления, щелкните кнопку в виде колокольчика в правом верхнем углу. 


## <a name="trigger-and-monitor-the-pipeline"></a>Активация и мониторинг конвейера

На этом шаге вы вручную активируете конвейер, опубликованный ранее. 

1. Выберите **Добавить триггер** на панели инструментов, а затем **Trigger Now** (Запустить сейчас). На странице **Pipeline Run** (Запуск конвейера) нажмите кнопку **Готово**.  
1. Перейдите на вкладку **Монитор** на левой боковой панели. Вы увидите выполнение конвейера, которое вы только что активировали вручную. Ссылки в столбце **действий** позволят вам просмотреть подробные сведения о действиях и (или) повторно выполнить конвейер.
1. Чтобы просмотреть запуски действий, связанные с этим запуском конвейера, щелкните ссылку **View Activity Runs** (Просмотр запусков действий) в столбце **Действия**. В нашем примере определено только одно действие, поэтому в списке вы увидите только одну запись. Чтобы увидеть сведения об операции копирования, щелкните ссылку **Сведения** (значок очков) в столбце **Действия**. Выберите **Конвейеры Runs** (Запуски конвейера) в верхней части окна, чтобы вернуться к представлению Pipeline Runs (Запуски конвейера). Чтобы обновить список, нажмите кнопку **Обновить**.
1. Убедитесь, что данные правильно записаны в пул SQL.


## <a name="next-steps"></a>Дальнейшие действия

Дополнительные сведения об интеграции данных для Synapse Analytics см. в статье [Прием данных в пул SQL](data-integration-sql-pool.md).
