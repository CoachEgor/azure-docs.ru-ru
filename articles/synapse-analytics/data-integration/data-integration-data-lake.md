---
title: ВЛавая данные хранилища данных Gen2 в azure Synapse Analytics
description: Узнайте, как глотать данные в Хранилище озер данных Azure Gen2 в azure Synapse Analytics
services: synapse-analytics
author: djpmsft
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: daperlov
ms.reviewer: jrasnick
ms.openlocfilehash: 4d7d7be523749797e5dbce0e50c307fc682974f2
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81430582"
---
# <a name="ingesting-data-into-azure-data-lake-storage-gen2"></a>Ввоз данных в Хранилище azure Data Lake Data Gen2 

В этой статье вы узнаете, как глотать данные из одного места в другое в учетной записи хранения Azure Data Lake Gen 2 (Azure Data Lake Gen 2) с помощью azure Synapse Analytics.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure:** Если у вас нет подписки Нацу, создайте [бесплатную учетную запись Azure](https://azure.microsoft.com/free/) перед началом.
* **Учетная запись хранения Azure:** Вы используете Azure Data Lake Gen 2 в качестве *хранилища исходных* данных. Если у вас нет учетной записи хранилища, [см. Создать учетную запись хранения Azure](../../storage/blobs/data-lake-storage-quickstart-create-account.md?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json) для создания.

## <a name="create-linked-services"></a>Создание связанных служб

В Azure Synapse Analytics связанная служба определяет информацию о связи с другими службами. В этом разделе вы добавите в качестве связанных служб служб ассоциированные службы Azure Synapse Analytics и Azure Data Lake Gen 2.

1. Откройте UX Аналитики Azure Synapse и перейдите на вкладку **«Управление».**
1. При **внешних подключениях**выберите **связанные службы.**
1. Чтобы добавить связанную услугу, нажмите **New**.
1. Выберите плитку Azure Data Lake Storage Gen2 из списка и нажмите **Кнопка Продолжить**.
1. Введите учетные данные аутентификации. Ключ учетной записи, основной сервис и управляемая идентификация в настоящее время поддерживаются типами аутентификации. Нажмите на тест-соединение, чтобы проверить правильность учетных данных. 
1. После завершения нажмите **Создать**.

## <a name="create-pipeline"></a>Создание конвейера

Конвейер содержит логический поток для выполнения набора действий. В этом разделе вы создадите конвейер, содержащий активность копирования, которая ввозит данные из Azure Data Lake Gen 2 в пул S'L.

1. Перейдите на вкладку **Orchestrate.** Нажмите на значок plus рядом с заголовком трубопроводов и выберите **Pipeline.**
1. Под **перемещать и трансформировать** в панели действий перетащите **данные Copy** на холст конвейера.
1. Нажмите на активность копирования и перейдите на вкладку **Source.** Нажмите **новый,** чтобы создать новый набор исходных данных.
1. Выберите Хранилище озер данных Azure, как ваш магазин данных и нажмите кнопку продолжить.
1. Выберите DelimitedText, как ваш формат и нажмите продолжить.
1. В наборе свойств панели выберите aDLS связанные службы вы создали. Укажите траекторию файла исходных данных и укажите, есть ли у первой строки заголовок. Можно импортировать схему из файлохранилища или примера файла. Щелкните "OK", когда все будет готово.
1. Перейдите на вкладку **Sink.** **Нажмите новый,** чтобы создать новый набор данных раковины.
1. Выберите Azure Data Lake Storage 2, как магазин данных и нажмите кнопку "Продолжить".
1. Выберите DelimitedText, как ваш формат и нажмите продолжить.
1. В наборе свойств панели выберите aDLS связанные службы вы создали. Укажите траекторию папки, где вы хотите написать данные. Щелкните "OK", когда все будет готово.

## <a name="debug-and-publish-pipeline"></a>Отчерепное и опубликовать конвейер

После завершения настройки конвейера можно выполнить отладку, прежде чем публиковать артефакты, чтобы убедиться, что все правильно.

1. Чтобы выполнить отладку конвейера, на панели инструментов щелкните **Отладка**. Состояние выполнения конвейера вы можете найти на вкладке **Выходные данные** в нижней части окна. 
1. После успешного запуска конвейера в верхней панели инструментов выберите **Опубликовать все**. Это действие публикует объекты (наборы данных и конвейеры), созданные для службы Synapse Analytics.
1. Дождитесь сообщения **Successfully published** (Публикация выполнена). Чтобы увидеть сообщения уведомлений, нажмите кнопку колокола в правом верхнем правом. 


## <a name="trigger-and-monitor-the-pipeline"></a>Триггер и мониторинг трубопровода

На этом этапе вы вручную запускаете конвейер, опубликованный на предыдущем этапе. 

1. Выберите **Добавить триггер** на панели инструментов, а затем **Trigger Now** (Запустить сейчас). На странице **Pipeline Run** (Запуск конвейера) нажмите кнопку **Готово**.  
1. Перейдите на вкладку **Monitor,** расположенную в левой боковой панели. Вы увидите выполнение конвейера, которое вы только что активировали вручную. Можно использовать ссылки в столбце **«Действия»** для просмотра деталей деятельности и повторного запуска конвейера.
1. Чтобы просмотреть запуски действий, связанные с этим запуском конвейера, щелкните ссылку **View Activity Runs** (Просмотр запусков действий) в столбце **Действия**. В нашем примере определено только одно действие, поэтому в списке вы увидите только одну запись. Чтобы увидеть сведения об операции копирования, щелкните ссылку **Сведения** (значок очков) в столбце **Действия**. Выберите **Конвейеры Runs** (Запуски конвейера) в верхней части окна, чтобы вернуться к представлению Pipeline Runs (Запуски конвейера). Чтобы обновить список, нажмите кнопку **Обновить**.
1. Проверка ваших данных правильно записана в пуле S'L.


## <a name="next-steps"></a>Дальнейшие действия

Для получения дополнительной информации об интеграции данных для Synapse Analytics см. [Ingesting data into a SQL pool](data-integration-sql-pool.md)
