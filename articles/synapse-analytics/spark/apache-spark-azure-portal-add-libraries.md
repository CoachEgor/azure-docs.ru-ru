---
title: Управление библиотеками для Apache Spark в Azure синапсе Analytics
description: Узнайте, как добавлять библиотеки, используемые Apache Spark, в Azure синапсе Analytics и управлять ими.
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: conceptual
ms.date: 07/22/2020
ms.author: euang
ms.reviewer: jrasnick, carlrab
ms.subservice: spark
ms.openlocfilehash: b7aea6565e8301e2aeb96263b8e7b1d2ea64995d
ms.sourcegitcommit: 02ca0f340a44b7e18acca1351c8e81f3cca4a370
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/19/2020
ms.locfileid: "88589567"
---
# <a name="manage-libraries-for-apache-spark-in-azure-synapse-analytics"></a>Управление библиотеками для Apache Spark в Azure синапсе Analytics

Библиотеки предоставляют многократно используемый код, который может потребоваться включить в программы или проекты. Чтобы предоставить приложениям сторонний или локально разработанный код, можно установить библиотеку на одном из пулов Spark (Предварительная версия). После установки библиотеки для пула Spark она будет доступна для всех сеансов, использующих тот же пул. 

## <a name="default-installation"></a>Установка по умолчанию
Apache Spark в Azure синапсе Analytics содержит полную установку Анакондас, а также дополнительные библиотеки. Список полных библиотек можно найти по адресу [Apache Spark поддержки версий](apache-spark-version-support.md). 

При запуске экземпляра Spark эти библиотеки будут автоматически добавлены. Дополнительные Python и пользовательские пакеты, созданные на языке, можно добавить на уровне пула Spark (Предварительная версия).


## <a name="manage-python-packages"></a>Управление пакетами Python
Определив библиотеки, которые вы хотите использовать для приложения Spark, вы можете установить их в пул Spark (Предварительная версия). 

 *requirements.txt* `pip freeze` Для обновления виртуальной среды можно использовать файлrequirements.txt(выходные данные команды). Пакеты, перечисленные в этом файле для установки или обновления, загружаются из PyPi во время запуска пула. Этот файл требований используется при каждом создании экземпляра Spark из пула Spark.

> [!IMPORTANT]
> - Если устанавливаемый пакет является большим или занимает много времени, это повлияет на время запуска экземпляра Spark.
> - Пакеты, требующие поддержки компилятора во время установки, например GCC, не поддерживаются.
> - Пакеты не могут быть понижены, только добавляются или обновляются.

### <a name="requirements-format"></a>Формат требований

В следующем фрагменте кода показан формат файла требований. Имя пакета PyPi отображается вместе с точной версией. Этот файл соответствует формату, описанному в справочной документации по [замораживанию PIP](https://pip.pypa.io/en/stable/reference/pip_freeze/) . В этом примере закрепляется конкретная версия. 

```
absl-py==0.7.0
adal==1.2.1
alabaster==0.7.10
```

### <a name="install-python-packages"></a>Установка пакетов Python
При разработке приложения Spark может оказаться, что необходимо обновить существующие или установить новые библиотеки. Библиотеки можно обновлять во время или после создания пула.

#### <a name="install-packages-during-pool-creation"></a>Установка пакетов во время создания пула
Чтобы установить библиотеки в пул Spark (Предварительная версия) во время создания пула, выполните следующие действия.
   
1. Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
2. Выберите **создать пул Apache Spark** и перейдите на вкладку **Дополнительные параметры** . 
   
3. Отправьте файл конфигурации среды с помощью средства выбора файлов в разделе " **пакеты** " страницы. 
   
![Добавление библиотек Python во время создания пула](./media/apache-spark-azure-portal-add-libraries/apache-spark-azure-portal-add-library-python.png "Добавление библиотек Python")
 

#### <a name="install-packages-from-the-synapse-workspace"></a>Установка пакетов из рабочей области синапсе
Чтобы обновить или добавить дополнительные библиотеки в пул Spark (Предварительная версия) на портале Azure синапсе Analytics, выполните следующие действия.

1.  Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
2.  Запустите рабочую область Azure синапсе Analytics из портал Azure.

3.  Выберите **Управление** на главной панели навигации, а затем выберите **Пулы Apache Spark**.
   
4. Выберите один пул Spark и отправьте файл конфигурации среды с помощью средства выбора файлов в разделе "  **пакеты** " страницы.

![Добавление библиотек Python в синапсе](./media/apache-spark-azure-portal-add-libraries/apache-spark-azure-portal-update.png "Добавление библиотек Python")
   
#### <a name="install-packages-from-the-azure-portal"></a>Установка пакетов из портал Azure
Чтобы установить библиотеку в пул Spark (Предварительная версия) непосредственно из портал Azure:
   
 1. Перейдите к рабочей области Azure синапсе Analytics из портал Azure.
   
 2. В разделе **ресурсов синапсе** выберите вкладку **Пулы Apache Spark** и выберите пул Spark из списка.
   
 3. Выберите **пакеты** из раздела **Параметры** пула Spark. 

 4. Отправьте файл конфигурации среды с помощью средства выбора файлов.

![Добавление библиотек Python](./media/apache-spark-azure-portal-add-libraries/apache-spark-add-library-azure.png "Добавление библиотек Python")

### <a name="verify-installed-libraries"></a>Проверка установленных библиотек

Чтобы проверить, установлены ли правильные версии правильных библиотек, выполните приведенный ниже код.

```python
import pip #needed to use the pip functions
for i in pip.get_installed_distributions(local_only=True):
    print(i)
```
### <a name="update-python-packages"></a>Обновление пакетов Python
Пакеты можно добавлять или изменять в любое время между сеансами. При передаче нового файла конфигурации пакета будут перезаписаны существующие пакеты и версии.  

Чтобы обновить или удалить библиотеку, выполните следующие действия.
1. Перейдите к рабочей области Azure синапсе Analytics. 

2. С помощью портал Azure или рабочей области Azure синапсе выберите **пул Apache Spark** , который требуется обновить.

3. Перейдите к разделу " **пакеты** " и передайте новый файл конфигурации среды.
   
4. После сохранения изменений необходимо будет завершить активные сеансы и разрешить перезапуск пула. При необходимости можно принудительно завершить активные сеансы, установив флажок для **принудительного применения новых параметров**.

![Добавление библиотек Python](./media/apache-spark-azure-portal-add-libraries/update-libraries.png "Добавление библиотек Python")
   

> [!IMPORTANT]
> Выбрав параметр для **принудительного создания новых параметров**, вы завершите все текущие сеансы для выбранного пула Spark. После завершения сеансов необходимо будет дождаться перезапуска пула. 
>
> Если этот параметр не установлен, необходимо дождаться завершения текущего сеанса Spark или завершить его вручную. После завершения сеанса необходимо разрешить перезапуск пула. 


## <a name="manage-a-python-wheel"></a>Управление колесом Python

### <a name="install-a-custom-wheel-file"></a>Установка пользовательского файла колеса
Пользовательские пакеты, построенные на основе колесика, можно установить в пул Apache Spark, загружая все файлы колеса в учетную запись Azure Data Lake Storage (Gen2), связанную с рабочей областью синапсе. 

Файлы должны быть отправлены по следующему пути в контейнере учетной записи хранения по умолчанию: 

```
abfss://<file_system>@<account_name>.dfs.core.windows.net/synapse/workspaces/<workspace_name>sparkpools/<pool_name>libraries/python/
```

>[!IMPORTANT]
>Пользовательские пакеты можно добавлять или изменять между сеансами. Тем не менее для просмотра обновленного пакета необходимо подождать, пока пул и сеанс перезапускаются.

## <a name="next-steps"></a>Дальнейшие действия
- Просмотр библиотек по умолчанию: [Поддержка версий Apache Spark](apache-spark-version-support.md)
