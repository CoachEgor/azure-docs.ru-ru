---
title: Используйте расширенный сервер истории Spark для отладки приложений - Apache Spark в Azure Synapse
description: Используйте расширенный сервер истории Spark для отладки и диагностики приложений Spark в Azure Synapse Analytics.
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: euang
ms.reviewer: euang
ms.openlocfilehash: 4f03033942517f4778192e0b12f84610df8fd469
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81429217"
---
# <a name="use-extended-apache-spark-history-server-to-debug-and-diagnose-apache-spark-applications"></a>Используйте расширенный сервер истории Apache Spark для отладки и диагностики приложений Apache Spark

В этой статье содержатся рекомендации о том, как использовать расширенный сервер истории Apache Spark для отладки и диагностики завершенных и запущенных приложений Spark.

Расширение включает вкладку данных, вкладку графика и вкладку диагностики. Используйте вкладку **Data** для проверки входных и выходных данных задания Spark. Вкладка **График** показывает поток данных и воспроизведение графика задания. Вкладка **Диагностика** показывает вам **скью данных,** **время Skew**, и **анализ использования исполнителя.**

## <a name="access-the-apache-spark-history-server"></a>Доступ к серверу истории Apache Spark

Сервер истории Apache Spark — это веб-пользовательский интерфейс для завершенных и запущенных приложений Spark. Веб-интерфейс сервера истории Apache Spark можно открыть из аналитики Azure Synapse.

### <a name="open-the-spark-history-server-web-ui-from-apache-spark-applications-node"></a>Откройте веб-ui Spark History Server из узлов ы

1. Открытая [аналитика Azure Synapse](https://web.azuresynapse.net/).

2. Нажмите **монитор**, затем выберите **Apache Spark приложений**.

    ![Нажмите на монитор, затем выберите приложение искры.](./media/apache-spark-history-server/click-monitor-spark-application.png)

3. Выберите приложение, а затем откройте **запрос журнала,** нажав на него.

    ![Открытое окно запроса журнала.](./media/apache-spark-history-server/open-application-window.png)

4. Выберите **сервер истории Spark,** затем появится веб-uI Spark History Server.

    ![Открытый сервер истории искры.](./media/apache-spark-history-server/open-spark-history-server.png)

### <a name="open-the-spark-history-server-web-ui-from-data-node"></a>Откройте веб-ui Spark History Server из узла данных

1. Из ноутбука Azure Synapse Studio выберите **сервер истории Spark** из ячейки вывода выполнения задания или из панели состояния в нижней части документа ноутбука. Выберите **Сведения о сеансе**.

   ![Запуск сервера истории Spark](./media/apache-spark-history-server/launch-history-server2.png "Запуск сервера истории Spark")

2. Выберите **сервер истории Spark** из панели слайдов.

   ![Запуск сервера истории Spark](./media/apache-spark-history-server/launch-history-server.png "Запуск сервера истории Spark")

## <a name="explore-the-data-tab-in-spark-history-server"></a>Исследуйте вкладку Data на сервере истории Spark

Выберите идентификатор вакансии для задания, которую вы хотите просмотреть. Затем выберите **данные** в меню инструментов, чтобы получить представление данных. В этом разделе показано, как выполнять различные задачи во вкладке Data.

* Выберите вкладку **Входы**, **Выходы** или **Операции с таблицей**, чтобы просмотреть соответствующие сведения.

    ![Данные для вкладок приложений Spark](./media/apache-spark-history-server/apache-spark-data-tabs.png)

* Копирование всех строк, выбрав **Copy**.

    ![Данные для копии приложения Spark](./media/apache-spark-history-server/apache-spark-data-copy.png)

* Сохранить все данные в виде файла CSV, выбрав **csv.**

    ![Сохранение данных для приложения Spark](./media/apache-spark-history-server/apache-spark-data-save.png)

* Поиск, введя ключевые слова в **поле поиска**. Результаты поиска отображаются немедленно.

    ![Данные для поиска приложений Spark](./media/apache-spark-history-server/apache-spark-data-search.png)

* Выберите заголовок столбца для сортировки таблицы, выберите знак плюс, чтобы расширить строку, чтобы показать больше деталей, или выберите знак минус, чтобы свернуть строку.

    ![Данные для таблицы приложений Spark](./media/apache-spark-history-server/apache-spark-data-table.png)

* Скачать один файл, выбрав **частичную загрузку.** Выбранный файл загружается в локальный. Если файл больше не существует, появляется новая вкладка с сообщением об ошибке.

    ![Данные для строки загрузки приложений Spark](./media/apache-spark-history-server/sparkui-data-download-row.png)

* Чтобы скопировать полный путь или относительный путь, выберите Параметры **копирования Полного Пути** или **Параметры относительного пути копирования,** которые расширяются из меню drop down. Для файлов хранения озер данных Azure **Open in Azure Storage Explorer** запускает Explorer хранения данных Azure и находит папку при входе в систему.

    ![Путь копирования приложения Spark](./media/apache-spark-history-server/sparkui-data-copy-path.png)

* Выберите номера страниц ниже таблицы для навигации по страницам, когда на одной странице слишком много строк.

    ![Данные для страницы приложения Spark](./media/apache-spark-history-server/apache-spark-data-page.png)

* Навистете на вопросительный знак рядом с **данными,** чтобы показать набор инструментов, или выберите вопросительный знак, чтобы получить больше информации.

    ![Данные для приложения Spark более подробная информация](./media/apache-spark-history-server/sparkui-data-more-info.png)

* Отправить обратную связь с проблемами, выбрав **Предоставьте нам обратную связь**.

    ![Искра график предоставить нам обратную связь снова](./media/apache-spark-history-server/sparkui-graph-feedback.png)

## <a name="graph-tab-in-apache-spark-history-server"></a>Вкладка График в сервере истории Apache Spark

Выберите идентификатор вакансии для задания, которую вы хотите просмотреть. Затем выберите **График** в меню инструментов, чтобы получить представление графика задания.

### <a name="overview"></a>Обзор

Вы можете увидеть обзор вашей работы в сгенерированном графике задания. По умолчанию на графике отображается все задания. Вы можете отфильтровать это представление по **идентификатору вакансий.**

![Идентификатор идентификатор идентификатор работы искрометного вакансии ис](./media/apache-spark-history-server/apache-spark-graph-jobid.png)

### <a name="display"></a>Отображение

По умолчанию выбирается дисплей **"Прогресс".** Вы можете проверить поток данных, выбрав **Чтение** или **Написано** в списке выпадающих **данных.**

![Применение искрометное приложение и отображение графика работы](./media/apache-spark-history-server/sparkui-graph-display.png)

Графический узлы отображают цвета, показанные в легенде тепловой карты.

![Применение искры и тепловая карта графика работы](./media/apache-spark-history-server/sparkui-graph-heatmap.png)

### <a name="playback"></a>Воспроизведение

Чтобы воспроизвести **Playback**задание, выберите Воспроизведение. Вы можете выбрать **Stop** в любое время, чтобы остановиться. Цвета задачи отображут различные статусы при воспроизведении:

|Color|Значение|
|-|-|
|Зеленый|Успешно: работа успешно завершена.|
|Оранжевый|Повторное повторение: Случаи задач, которые не выполняются, но не влияют на конечный результат задания. Эти задачи имеют дублирующиеся или повторные экземпляры, которые могут быть успешно выполнены позже.|
|Синий|Запуск: Задача запущена.|
|White|Ожидание или пропущено: задача ждет выполнения, или этап проскочил.|
|Красный|Не удалось: задача не удалась.|

На следующем изображении показаны цвета зеленого, оранжевого и синего цветов.

![Применение искры и выборка цвета графика работы, бег](./media/apache-spark-history-server/sparkui-graph-color-running.png)

На следующем изображении показаны цвета зеленого и белого статусов.

![Применение spark и образец цвета диаграммы работы, пропустить](./media/apache-spark-history-server/sparkui-graph-color-skip.png)

На следующем изображении показаны цвета красного и зеленого статусов.

![Применение искрометного графика и выборка цветов графика работы, неудачно](./media/apache-spark-history-server/sparkui-graph-color-failed.png)

> [!NOTE]  
> Допускается воспроизведение каждого задания. Для неполных заданий воспроизведение не поддерживается.

### <a name="zoom"></a>Zoom

Используйте прокрутку мыши, чтобы увеличить и выйти на график задания, или выберите **Увеличить, чтобы** сделать его пригодным для экрана.

![Применение искры и графический график работы в соответствии с](./media/apache-spark-history-server/sparkui-graph-zoom2fit.png)

### <a name="tooltips"></a>Всплывающие подсказки

Нависте на графике узла, чтобы увидеть набор инструментов, когда есть неудачные задачи, и выберите этап, чтобы открыть свою страницу стадии.

![Применение искрометного графика и набор инструментов для графиков работы](./media/apache-spark-history-server/sparkui-graph-tooltip.png)

На вкладке графика заданий этапы имеют набор инструментов и небольшой значок, если у них есть задачи, которые отвечают следующим условиям:

|Условие|Описание|
|-|-|
|Перекос данных|размер считывания данных > средний размер данных для чтения всех задач на данном этапе No 2, а размер чтения данных > 10 МБ|
|Время перекос|время выполнения > среднее время выполнения всех задач на этом этапе No 2 и время выполнения > 2 минут|
   
![Искра приложения и работы график косой значок](./media/apache-spark-history-server/sparkui-graph-skew-icon.png)

### <a name="graph-node-description"></a>Описание графического узла

Узла графика выполнения работ отображается следующая информация о каждом этапе:

  * ID.
  * имя или описание;
  * общее количество задач;
  * Чтение данных: сумма размера входных данных и размер данных чтения в случайном порядке.
  * Данные пишут: сумма размера вывода и перетасовки записывает размер.
  * время выполнения: время от начала первой попытки до завершения последней попытки;
  * число строк: сумма входных записей, выходных записей, записей смешанного чтения и записей смешанной записи;
  * ход выполнения.

    > [!NOTE]  
    > По умолчанию узла графика выполнения задания отображает информацию из последней попытки каждого этапа (за исключением времени выполнения этапа). Однако во время воспроизведения графический узла отображается информация о каждой попытке.
    >  
    > Размер данных чтения и записи составляет 1 МБ no 1000 КБ и 1000 1000 байтов.

### <a name="provide-feedback"></a>Отзывы

Отправить обратную связь с проблемами, выбрав **Предоставьте нам обратную связь**.

![Искра приложения и работы граф обратной связи](./media/apache-spark-history-server/sparkui-graph-feedback.png)

## <a name="explore-the-diagnosis-tab-in-apache-spark-history-server"></a>Исследуйте вкладку «Диагностика» на сервере истории Apache Spark

Чтобы получить доступ к вкладке «Диагноз», выберите идентификатор вакансии. Затем выберите **Диагноз** в меню инструмента, чтобы получить представление о работе Диагностика. На вкладке диагностики доступны вкладки **Неравномерное распределение данных**, **Неравномерное распределение времени** и **Анализ использования исполнителя**.

Выберите вкладку **Неравномерное распределение данных**, **Неравномерное распределение времени** или **Анализ использования исполнителя**, чтобы просмотреть соответствующие сведения.

![SparkUI диагностики данных перекос вкладке снова](./media/apache-spark-history-server/sparkui-diagnosis-tabs.png)

### <a name="data-skew"></a>Неравномерное распределение данных

При выборе вкладки **Data Skew** соответствующие перекосы отображаются на основе указанных параметров.

* **Укажите параметры** — в первом разделе отображаются параметры, которые служат для обнаружения неравномерного распределения данных. Правило по умолчанию: чтение данных задач превышает трехкратность средней считываемых данных задачи, а чтение данных о задачах — более 10 МБ. Если вы хотите определить свое собственное правило для перекосов задач, вы можете выбрать параметры, **skewed Stage** и **Skew Char** разделы обновляются соответствующим образом.

* **Этап с неравномерным распределением** — во втором разделе отображаются этапы, имеющие задачи с неравномерным распределением, которые отвечают указанным выше условиям. Если на этапе более одной задачи с неравномерным распределением, в таблице этапа с неравномерным распределением отображается только одна задача с наибольшим неравномерным распределением (например, наибольшим размером неравномерно распределенных данных).

    ![искруи диагностики данных косой вкладке](./media/apache-spark-history-server/sparkui-diagnosis-dataskew-section2.png)

* **Skew Chart** - При выборе строки в таблице этапа перекоса диаграмма перекоса отображает больше деталей распределения задач на основе времени чтения данных и выполнения. Задачи с неравномерным распределением отмечены красным цветом, а нормальные задачи — синим. Диаграмма отображает до 100 задач образца, а детали задачи отображаются в правой нижней панели.

    ![искруи перекос диаграммы для стадии 10](./media/apache-spark-history-server/sparkui-diagnosis-dataskew-section3.png)

### <a name="time-skew"></a>Неравномерное распределение времени

На вкладке **Неравномерное распределение времени** отображаются задачи с неравномерным распределением времени выполнения.

* **Укажите параметры** - Первый раздел отображает параметры, которые используются для обнаружения времени Skew. По умолчанию для обнаружения неравномерного распределения времени используется следующий критерий: время выполнения задачи больше среднего времени выполнения, умноженного на три, и превышает 30 секунд. Параметры можно изменить в соответствии с вашими потребностями. В разделах **Этап с неравномерным распределением** и **Диаграмма неравномерного распределения** отображаются соответствующие сведения об этапах и задачах, так же как на вкладке **Неравномерное распределение данных**, описанной выше.

* Выберите **Время Skew**, затем отфильтрованный результат отображается в разделе **Skewed Stage** в соответствии с параметрами, установленными в разделе **Указать Параметры.** Выберите один элемент в разделе **Skewed Stage,** затем соответствующая диаграмма составлена в разделе3, а детали задачи отображаются в правой нижней панели.

    ![искруи диагностики время перекос разделе](./media/apache-spark-history-server/sparkui-diagnosis-timeskew-section2.png)

### <a name="executor-usage-analysis"></a>Анализ использования исполнителя

Диаграмма использования исполнителя визуализирует распределение и состояние выполнения задания исполнителя Spark.  

1. Выберите **Анализ использования исполнителя**, затем начерчены четыре типы кривых об использовании исполнителя, включая **выделенные**исполнители, **Запущенные исполнители,** **Executors, Executors**, и **Max Executor Instances.** Что касается выделенных исполнителей, то каждое событие "Исполнитель добавил" или "Исполнитель удалено" увеличивает или уменьшает выделенные исполнители. Дополнительные возможности сравнения доступны на временной шкале событий на вкладке "Задания".

   ![искруи диагноз исполнителей вкладке](./media/apache-spark-history-server/sparkui-diagnosis-executors.png)

2. Выберите значок цвета, чтобы выбрать или не выбрать соответствующее содержимое во всех проектах.

    ![sparkui диагнозы выбрать диаграмму](./media/apache-spark-history-server/sparkui-diagnosis-select-chart.png)

## <a name="known-issues"></a>Известные проблемы

Данные ввода/вывода с использованием устойчивых распределенных наборов данных (RDD) не отображаются во вкладке данных.

## <a name="next-steps"></a>Дальнейшие действия

- [Azure Synapse Analytics](../overview-what-is.md)
- [.NET для документации Apache Spark](/dotnet/spark?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json)

