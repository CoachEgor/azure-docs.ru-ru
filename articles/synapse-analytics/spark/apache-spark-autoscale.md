---
title: Автоматическое масштабирование экземпляров Apache Spark Azure синапсе
description: Использование функции автомасштабирования Azure синапсе для автоматического масштабирования экземпляров Apache Spark
author: euangMS
ms.author: euang
ms.reviewer: euang
services: synapse-analytics
ms.service: synapse-analytics
ms.topic: conceptual
ms.date: 03/31/2020
ms.openlocfilehash: a2f907384326aa887c12c293feb8c988f42bbaf1
ms.sourcegitcommit: a8ee9717531050115916dfe427f84bd531a92341
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/12/2020
ms.locfileid: "83210518"
---
# <a name="automatically-scale-azure-synapse-analytics-apache-spark-pools"></a>Автоматическое масштабирование пулов Apache Spark Azure синапсе Analytics

Функция автомасштабирования пула Azure синапсе Spark автоматически масштабирует количество узлов в экземпляре кластера. При создании нового пула Azure синапсе Spark можно задать минимальное и максимальное количество узлов при выборе автомасштабирования. Затем Автомасштабирование отслеживает требования к ресурсам загрузки и масштабирует количество узлов. Для этой функции дополнительная плата не взимается.

## <a name="metrics-monitoring"></a>Мониторинг метрик

Автомасштабирование постоянно отслеживает экземпляр Spark и собирает следующие метрики:

|Метрика|Описание|
|---|---|
|Всего ожидающих ЦП|Общее число ядер, необходимое для начала выполнения всех ожидающих узлов.|
|Всего ожидающих памяти|Общий объем памяти (в МБ), необходимый для начала выполнения всех ожидающих узлов.|
|Всего свободных ЦП|Сумма всех неиспользуемых ядер на активных узлах.|
|Общий объем свободной памяти|Сумма неиспользуемой памяти (в МБ) на активных узлах.|
|Используемая память на узел|Нагрузка на узел. Узел, на котором используется 10 ГБ памяти, считается более загруженным, чем Рабочая роль с 2 ГБ используемой памяти.|

Указанные выше метрики проверяются каждые 30 секунд. Автомасштабирование позволяет принимать решения по масштабированию и уменьшению масштаба на основе этих метрик.

## <a name="load-based-scale-conditions"></a>Условия масштабирования на основе нагрузки

При обнаружении следующих условий Автомасштабирование выдаст запрос на масштабирование:

|Вертикальное масштабирование|Горизонтальное масштабирование|
|---|---|
|Общее число ожидающих ЦП больше, чем общее число свободных ЦП в течение более чем 1 минуты.|Всего ожидающих ЦП ниже общего свободного ЦП в течение более 2 минут.|
|Общий объем ожидающей памяти больше, чем общее число свободной памяти в течение более чем 1 минуты.|Общий объем незавершенной памяти меньше, чем общая свободная память в течение более 2 минут.|

Для увеличения масштаба служба автомасштабирования Azure синапсе вычисляет, сколько новых узлов требуется для удовлетворения текущих требований к ЦП и памяти, а затем выдает запрос на масштабирование для добавления необходимого числа узлов.

Для уменьшения масштаба в зависимости от количества исполнителей, главных приложений на узел и текущих требований к ЦП и памяти, автомасштабирование выдает запрос на удаление определенного числа узлов. Служба также определяет, какие узлы являются кандидатами на удаление в зависимости от текущего выполнения задания. Операция уменьшения масштаба сначала выведет из эксплуатации узлы, а затем удаляет их из кластера.

## <a name="get-started"></a>Начало работы

### <a name="create-a-spark-pool-with-autoscaling"></a>Создание пула Spark с автомасштабированием

Чтобы включить функцию автомасштабирования, выполните следующие действия в рамках обычного процесса создания пула:

1. На вкладке **Основные сведения** установите флажок **включить Автомасштабирование** .
1. Введите нужные значения для следующих свойств:  

    * **Минимальное** число узлов.
    * **Максимальное** число узлов.

Начальное число узлов будет минимальным. Это значение определяет начальный размер экземпляра при его создании. Минимальное число узлов не может быть меньше трех.

## <a name="best-practices"></a>Рекомендации

### <a name="consider-the-latency-of-scale-up-or-scale-down-operations"></a>Учитывайте задержку операций увеличения или уменьшения масштаба.

Выполнение операции масштабирования может занять от 1 до 5 минут.

### <a name="preparation-for-scaling-down"></a>Подготовка к уменьшению масштаба

Во время масштабирования экземпляра процесс автомасштабирования переместит узлы в состояние списания, чтобы новые исполнители не могли запуститься на этом узле.

Выполняемые задания будут по-прежнему выполняться и завершены. Ожидающие задания будут ожидать расписанию как обычные с меньшим количеством доступных узлов.

## <a name="next-steps"></a>Дальнейшие действия

Краткое руководство по настройке нового пула Spark [Создание пула Spark](..\quickstart-create-apache-spark-pool.md)
