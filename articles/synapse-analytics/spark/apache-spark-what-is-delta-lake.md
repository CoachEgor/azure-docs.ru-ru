---
title: Что такое Озеро Дельта
description: Обзор озера Дельта и как оно работает в рамках azure Synapse Analytics
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: ''
ms.date: 04/15/2020
ms.author: euang
ms.reviewer: euang
ms.openlocfilehash: 52758eab645fa0bb89cb499a5c617df62c21279e
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81429204"
---
# <a name="what-is-delta-lake"></a>Что такое Delta Lake?

Azure Synapse Analytics совместима с Linux Foundation Delta Lake. Delta Lake — это уровень хранения с открытым исходным кодом, который доводит транзакции ACID (атомика, согласованность, изоляция и долговечность) в Apache Spark и рабочие нагрузки больших данных.

## <a name="key-features"></a>Основные возможности

| Компонент | Описание |
| --- | --- |
| **Операции ACID** | Озера данных, как правило, заселены несколькими процессами и конвейерами, некоторые из которых пишут данные одновременно с считываниями. До Delta Lake и добавления транзакций инженерам по обработке данных приходилось проходить ручной процесс, подверженный ошибкам, чтобы обеспечить целостность данных. Delta Lake приносит знакомые транзакции ACID в озера данных. Она обеспечивает serializability, самый сильный уровень изоляции. Узнайте больше на [Погружение в Озеро Дельта: Распаковка журнала транзакций](https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html).|
| **Масштабируемая обработка метаданных** | В больших данных даже сами метаданные могут быть «большими данными». Delta Lake обрабатывает метаданные так же, как данные, используя распределенную вычислительную мощность Spark для обработки всех своих метаданных. В результате Delta Lake может обрабатывать таблицы по шкале петабайта с миллиардами перегородок и файлов в покое. |
| **Путешествие во времени (версия данных)** | Возможность "отменить" изменение или вернуться к предыдущей версии является одной из ключевых особенностей транзакций. Delta Lake предоставляет снимки данных, позволяющие вернуться к более ранним версиям данных для аудита, откатов или воспроизведения экспериментов. Узнайте больше в [Представляя Delta Lake Time Travel для больших озер данных.](https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html) |
| **Открытый формат** | Apache Parquet является базовым форматом для Delta Lake, что позволяет использовать эффективные схемы сжатия и кодирования, которые являются родными для формата. |
| **Единый пакет и потоковый источник и раковина** | Таблица в Озере Дельта является как пакетным столом, так и источником потоковой передачи и раковиной. Потоковая передача данных, пакетисторического запаса и интерактивные запросы - все это просто работает из коробки. |
| **Схема исполнения** | Обеспечение соблюдения схемы помогает гарантировать, что типы данных являются правильными и необходимые столбцы присутствуют, предотвращая неверные данные из-за несогласованности данных. Для получения дополнительной информации, см [Погружение в Озеро Дельта: Схема исполнения & эволюции](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **Схема Эволюция** | Delta Lake позволяет вносить изменения в схему таблицы, которая может быть применена автоматически, без необходимости записи миграции DDL. Для получения дополнительной информации, см [Погружение в Озеро Дельта: Схема исполнения & эволюции](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **История аудита** | Журнал транзакций Delta Lake записывает сведения о каждом изменении, внесенном в данные, обеспечивая полный аудиторский след изменений. |
| **Обновления и удаления** | Delta Lake поддерживает AIS Scala / Java / Python и S'L для различных функциональных возможностей. Поддержка операций слияния, обновления и удаления помогает выполнять требования соответствия требованиям. Для получения дополнительной информации [см. Объявление о выпуске Delta Lake 0.4.0](https://delta.io/news/delta-lake-0-4-0-released/) и [простых, надежных upserts и удалении на столах Delta Lake, использующих APIs Python,](https://databricks.com/blog/2019/10/03/simple-reliable-upserts-and-deletes-on-delta-lake-tables-using-python-apis.html)который включает фрагменты кода для слияния, обновления и удаления команд DML. |
| **100% совместима с Apache Spark API** | Разработчики могут использовать Delta Lake с существующими конвейерами данных с минимальными изменениями, поскольку оно полностью совместимо с существующими реализациями Spark. |

Для получения полной документации смотрите [страницу документации Дельта-Лейк](https://docs.delta.io/latest/delta-intro.html)

Для получения дополнительной информации [см.](https://lfprojects.org)

## <a name="next-steps"></a>Дальнейшие действия

- [.NET для документации Apache Spark](/dotnet/spark?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json)
- [Azure Synapse Analytics](https://docs.microsoft.com/azure/synapse-analytics)
