---
title: Сведения о Delta Lake
description: Обзор разностной версии Lake и принцип ее работы в рамках Azure синапсе Analytics
services: synapse-analytics
author: euangMS
ms.service: synapse-analytics
ms.topic: conceptual
ms.subservice: spark
ms.date: 04/15/2020
ms.author: euang
ms.reviewer: euang
ms.openlocfilehash: 244cdf5329e26fc7d928998b734a539f086051ad
ms.sourcegitcommit: 877491bd46921c11dd478bd25fc718ceee2dcc08
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2020
ms.locfileid: "85193385"
---
# <a name="what-is-delta-lake"></a>Что такое разностная Lake?

Azure синапсе Analytics совместима с Linux Foundation Delta Lake. Дельта Lake — это уровень хранилища с открытым кодом, который приносит транзакции ACID (атомарность, согласованность, изоляция и устойчивость) для Apache Spark и больших рабочих нагрузок данных.

## <a name="key-features"></a>Основные возможности

| Компонент | Описание |
| --- | --- |
| **Транзакции ACID** | Озера данных обычно заполняются с помощью нескольких процессов и конвейеров, некоторые из которых записывают данные параллельно с чтением. До разностной версии Lake и добавления транзакций инженеры по обработке данных должны были выполнить процесс, подверженный ошибкам вручную, чтобы обеспечить целостность данных. Дельта Lake приносит привычные транзакции ACID в озера данных. Он предоставляет возможности сериализации, самый высокий уровень изоляции. Дополнительные сведения [см. в статье разностного Lake: Распаковка журнала транзакций](https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html).|
| **Обработка масштабируемых метаданных** | В больших данных даже метаданные могут быть "большими данными". Дельта Lake обрабатывает метаданные так же, как данные, используя распределенную вычислительную мощность Spark для обработки всех своих метаданных. В результате Дельта Lake может работать с петабайтного уровня таблицами с миллиардами разделов и файлов. |
| **Время поездок (управление версиями данных)** | Возможность «отменить» изменение или вернуться к предыдущей версии является одной из основных функций транзакций. Разностная версия Lake предоставляет моментальные снимки данных, позволяющие вернуться к более ранним версиям данных для аудита, отката или воспроизведения экспериментов. Дополнительные сведения см. в статье о переносе [разностного времени для больших озера данных](https://databricks.com/blog/2019/02/04/introducing-delta-time-travel-for-large-scale-data-lakes.html). |
| **Открыть формат** | Apache Parquet — это базовый формат для Delta Lake, позволяющий использовать эффективные схемы сжатия и кодирования, которые являются собственными для формата. |
| **Единый пакет и источник потоковой передачи и приемник** | Таблица в Delta Lake — это как пакетная таблица, так и источник потоковой передачи и приемник. Прием потоковых данных, историческая обратная передача и Интерактивные запросы работают только за пределами поля. |
| **Принудительное применение схемы** | Применение схемы позволяет убедиться, что типы данных верны и присутствуют необходимые столбцы, предотвращая несогласованность данных. Дополнительные сведения см [. в разделе погружение в Delta Lake: применение схемы & развитие](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **Развитие схемы** | Дельта Lake позволяет вносить изменения в схему таблицы, которая может применяться автоматически, без необходимости написания языка DDL для миграции. Дополнительные сведения см [. в разделе погружение в Delta Lake: применение схемы & развитие](https://databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html) |
| **Журнал аудита** | В журнале операций с разностной операцией Lake регистрируются сведения обо всех изменениях, внесенных в данные, что обеспечивает полный журнал аудита изменений. |
| **Обновления и удаления** | Delta Lake поддерживает Scala/Java/Python и API SQL для различных функций. Поддержка операций слияния, обновления и удаления помогает удовлетворить требования соответствия. Дополнительные сведения см. в статьях [объявление о выпуске Delta Lake 0.4.0](https://delta.io/news/delta-lake-0-4-0-released/) и [простые, надежные операции Upsert и удаления в разностных таблицах с помощью API Python](https://databricks.com/blog/2019/10/03/simple-reliable-upserts-and-deletes-on-delta-lake-tables-using-python-apis.html), включая фрагменты кода для команд DML, Update и DELETE. |
| **100% совместим с Apache Spark API** | Разработчики могут использовать разностную версию Lake с существующими конвейерами данных с минимальными изменениями, так как они полностью совместимы с существующими реализациями Spark. |

Полную документацию см. на [странице разностной документации по службе Lake](https://docs.delta.io/latest/delta-intro.html)

Дополнительные сведения см. в разделе [Delta Lake Project](https://lfprojects.org).

## <a name="next-steps"></a>Дальнейшие действия

- [Документация по .NET для Apache Spark](/dotnet/spark?toc=/azure/synapse-analytics/toc.json&bc=/azure/synapse-analytics/breadcrumb/toc.json)
- [Azure Synapse Analytics](https://docs.microsoft.com/azure/synapse-analytics)
