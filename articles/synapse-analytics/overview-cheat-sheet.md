---
title: Краткий справочник. Azure Synapse Analytics (рабочие области, предварительная версия)
description: Справочное руководство по использованию Azure Synapse Analytics
services: synapse-analytics
author: saveenr
ms.service: synapse-analytics
ms.topic: overview
ms.subservice: overview
ms.date: 04/15/2020
ms.author: saveenr
ms.reviewer: jrasnick
ms.openlocfilehash: 98fc8b23369f961ca023832430d47c8868e42158
ms.sourcegitcommit: 32c521a2ef396d121e71ba682e098092ac673b30
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/25/2020
ms.locfileid: "91260671"
---
# <a name="azure-synapse-analytics-cheat-sheet"></a>Памятка по Azure Synapse Analytics

[!INCLUDE [preview](includes/note-preview.md)]

В памятке по Azure Synapse Analytics вы узнаете об основных понятиях службы и важных командах. Эта статья полезна как для начинающих, так и для тех, кто хочет узнать важные сведения об Azure Synapse.

## <a name="basics"></a>Основные сведения

**Рабочая область Synapse** — это защищаемая ограниченная область совместной работы для выполнения облачной корпоративной аналитики в Azure. Рабочая область развертывается в определенном регионе и с ней сопоставляются учетная запись и файловая система ADLS 2-го поколения (для хранения временных данных). Рабочая область принадлежит к группе ресурсов.

Рабочая область позволяет выполнять анализ с помощью SQL и Apache Spark. Ресурсы, доступные для анализа SQL и Spark, организованы в **пулы** SQL и Spark. 

## <a name="synapse-sql"></a>Synapse SQL
**Synapse SQL** позволяет выполнять анализ на основе T-SQL в рабочей области Synapse. Есть две модели потребления Synapse SQL: выделенная и бессерверная.  Для выделенной модели используйте выделенные **пулы SQL**. В рабочей области может быть любое количество таких пулов. Для бессерверной модели используйте бессерверный пул SQL с именем "SQL по запросу". В каждой рабочей области есть один такой пул.

## <a name="apache-spark-for-synapse"></a>Apache Spark для Synapse
Для анализа Spark создайте и используйте **пулы Spark** в рабочей области Synapse.

## <a name="terminology"></a>Терминология
| Термин                         | Определение      |
|:---                                 |:---                 |
|**Apache Spark для Synapse** | Среда выполнения Spark, используемая в пуле Spark. Поддерживаемая текущая версия — Spark 2.4 с Python 3.6.1, Scala 2.11.12, поддержка .NET для Apache Spark 0.5 и Delta Lake 0.3.  | 
| **Пул Apache Spark**  | В рабочей области можно развернуть от 0 до N подготовленных к работе ресурсов Spark с соответствующими базами данных. Работу пула Spark можно приостанавливать и возобновлять вручную или автоматически, а сам пул можно масштабировать.  |
| **Приложение Spark**  |   Его работа построена на процессе драйвера и наборе процессов исполнителя. Приложение Spark выполняется в пуле Spark.            |
| **Сеанс Spark**  |   Единая точка входа приложения Spark. Она предоставляет способ взаимодействия с различными функциями Spark, используя меньшее количество конструкций. Чтобы запустить записную книжку, необходимо создать сеанс. Сеанс можно настроить для выполнения с помощью указанного количества исполнителей определенного размера. Конфигурация по умолчанию для сеанса записной книжки предусматривает работу с помощью двух исполнителей среднего размера. |
| **Запрос SQL**  |   Такие операции, как запрос, выполняются через пул SQL или использование SQL по запросу. |
|**Интеграция данных**| Позволяет принимать данные из различных источников и управлять действиями, выполняемыми в рабочей области или вне ее.| 
|**Артефакты**| Инкапсулирует все объекты, необходимые пользователю для управления источниками данных, разработки, оркестрации и визуализации.|
|**Записная книжка**| Интерактивный и реактивный интерфейс обработки, анализа и инжиниринга данных с поддержкой Scala, PySpark, C# и SparkSQL. |
|**Определение задания Spark**|Интерфейс для отправки задания Spark с помощью JAR-файла сборки, содержащего код и его зависимости.|
|**Поток данных**|  Предоставляет полностью визуальную среду для преобразования больших данных без написания кода. Все операции оптимизации и выполнения обрабатываются бессерверным способом. |
|**Скрипт SQL**| Сохраненный в файле набор команд SQL. Скрипт SQL может содержать одну и более инструкций SQL. Его можно использовать для выполнения запросов SQL через пул SQL или SQL по запросу.|
|**Конвейер**| Логическая группа действий, которые вместе позволяют выполнить задачу.|
|**Действие**| Определяет действия, выполняемые с данными, например копирование данных, запуск записной книжки или скрипта SQL.|
|**Триггер**| Выполняет конвейер. Может запускаться вручную или автоматически (по расписанию, с помощью "переворачивающегося" окна или на основе событий).|
|**Связанная служба**| Строки подключения, определяющие сведения о соединении, необходимые для подключения рабочей области к внешним ресурсам.|
|**Набор данных**|  Именованное представление данных, которое указывает данные для использования в действии, разделяя их на входные и выходные. Принадлежит связанной службе.|

## <a name="next-steps"></a>Дальнейшие действия

- [Создание рабочей области](quickstart-create-workspace.md)
- [Использование Synapse Studio](quickstart-synapse-studio.md)
- [Создание пула SQL](quickstart-create-sql-pool-portal.md)
- [Создание пула Apache Spark](quickstart-create-apache-spark-pool-portal.md)
- [Использование службы SQL по запросу](quickstart-sql-on-demand.md)

