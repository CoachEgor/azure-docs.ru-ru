---
title: Конфигурации рабочих нагрузок SAP с использованием Зон доступности Azure | Документация Майкрософт
description: Архитектура с высоким уровнем доступности и сценарии для SAP NetWeaver с использованием Зон доступности Azure
services: virtual-machines-windows,virtual-network,storage
documentationcenter: saponazure
author: msjuergent
manager: patfilot
editor: ''
tags: azure-resource-manager
keywords: ''
ms.assetid: 887caaec-02ba-4711-bd4d-204a7d16b32b
ms.service: virtual-machines-windows
ms.topic: article
ms.tgt_pltfrm: vm-windows
ms.workload: infrastructure-services
ms.date: 07/15/2019
ms.author: juergent
ms.custom: H1Hack27Feb2017
ms.openlocfilehash: 3f5186f456003c341af41fc6067f3b5c08acb2b4
ms.sourcegitcommit: 44e85b95baf7dfb9e92fb38f03c2a1bc31765415
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/28/2019
ms.locfileid: "70078888"
---
# <a name="sap-workload-configurations-with-azure-availability-zones"></a>Конфигурации рабочих нагрузок SAP с использованием Зон доступности Azure
[Зоны доступности Azure](https://docs.microsoft.com/azure/availability-zones/az-overview) — одна из функций высокой доступности, предлагаемых Azure. Использование Зон доступности повышает общую доступность рабочих нагрузок SAP в Azure. Эта функция уже доступна в некоторых [регионах Azure](https://azure.microsoft.com/global-infrastructure/regions/). В дальнейшем она будет доступна во всех регионах.

На рисунке ниже показана базовая архитектура с высоким уровнем доступности SAP.

![Конфигурация высокой доступности цен. категории "Стандартный"](./media/sap-ha-availability-zones/standard-ha-config.png)

Прикладной уровень SAP развертывается в пределах одной [группы доступности](https://docs.microsoft.com/azure/virtual-machines/windows/manage-availability) Azure. Чтобы обеспечить высокую доступность центральных служб SAP, вы можете развернуть две виртуальные машины в отдельных группах доступности. Используйте службы отказоустойчивого кластера Windows Server или Pacemaker (Linux) в качестве платформы высокой доступности с автоматической отработкой отказа в случае проблем с инфраструктурой или программным обеспечением. Дополнительные сведения об этих развертываниях см. в следующих статьях:

- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk)
- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью файлового ресурса в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-file-share)
- [Руководство по обеспечению высокого уровня доступности виртуальных машин Azure для SAP NetWeaver на SUSE Linux Enterprise Server для приложений SAP](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse)
- [Обеспечение высокого уровня доступности SAP NetWeaver в виртуальных машинах Azure с Red Hat Enterprise Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-rhel)

Аналогичная архитектура применяется и для уровня СУБД SAP NetWeaver, S/4HANA или систем Hybris. Чтобы обеспечить защиту от сбоя инфраструктуры или программного обеспечения, вы развернете уровень СУБД в режиме "активный — пассивный" с решением отказоустойчивого кластера. Решением отказоустойчивого кластера может быть платформа отработки отказа для конкретной СУБД, службы отказоустойчивого кластера Windows Server или Pacemaker.

Чтобы развернуть аналогичную архитектуру на основе Зон доступности Azure, потребуется внести ряд изменений в описанную выше архитектуру. Они описаны в данной статье.

## <a name="considerations-for-deploying-across-availability-zones"></a>Рекомендации по развертыванию в зонах доступности


При использовании зон доступности необходимо учитывать следующее.

- Нет никаких гарантий относительно расстояний между различными зонами доступности в регионе Azure.
- Зоны доступности не следует считать идеальным решением для аварийного восстановления. Стихийное бедствие может причинить существенный ущерб мировым регионам, в том числе инфраструктуре электропитания. Расстояния между различными зонами могут быть недостаточно большими для реализации соответствующего решения аварийного восстановления.
- Задержка в сети между зонами доступности в регионах Azure различна. В некоторых случаях вы можете развернуть прикладной уровень SAP и выполнить его в разных зонах, так как задержка в сети при обращении из какой-либо из этих зон к активной виртуальной машине СУБД остается в допустимых пределах. Но в некоторых регионах Azure будет складываться такая ситуация, в которой задержка между активной виртуальной машиной СУБД и экземпляром приложением SAP, развернутыми в разных зонах, будет неприемлемой для бизнес-процессов SAP. В таких случаях архитектуры развертывания для приложений должны различаться: "активный — активный" или "активный — пассивный", если задержка в сети между зонами слишком высока.
- Выбор места применения зон доступности должен исходить из задержки в сети между зонами. Задержка в сети играет важную роль в двух областях.
    - Задержка между двумя экземплярами СУБД, между которыми нужно настроить синхронную репликацию. Чем выше задержка в сети, тем выше вероятность ухудшения масштабируемости вашей рабочей нагрузки.
    - Разница сетевой задержки между виртуальной машиной, выполняющей экземпляр диалога SAP в зоне, где расположен активный экземпляр СУБД, и аналогичной виртуальной машиной в другой зоне. Чем больше разница между ними, тем большее влияние они будут оказывать на время выполнения бизнес-процессов и пакетных заданий, в зависимости от того, находятся ли они в одной с СУБД зоне или в разных зонах.

При развертывании виртуальных машин Azure в зонах доступности или установке решений отработки отказа в одном регионе Azure накладываются некоторые ограничения.

- При развертывании в Зонах доступности Azure необходимо использовать [Управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). 
- Сопоставление перечислений зон с физическими зонами фиксируется на уровне подписки Azure. Если вы используете разные подписки для развертывания систем SAP, для каждой подписки следует определить оптимальные зоны.
- Вы не можете развертывать группы доступности Azure в пределах зоны доступности Azure, если не используете [группу размещения](https://docs.microsoft.com/azure/virtual-machines/linux/co-location)с учетом расположения в Azure. Способ развертывания уровня СУБД SAP и центральных служб между зонами и одновременно с развертыванием уровня приложений SAP с помощью групп доступности и по-прежнему достигнуть близкого сходства виртуальных машин описан в статье размещение в Azure с учетом расположения. [ Группы для оптимальной сетевой задержки в приложениях SAP](sap-proximity-placement-scenarios.md). Если вы не используете группы размещения с учетом расположения в Azure, необходимо выбрать одну или другую как платформу развертывания для виртуальных машин.
- Невозможно использовать [Azure Load Balancer (цен. категория "Базовый")](https://docs.microsoft.com/azure/load-balancer/load-balancer-overview#skus) для создания отказоустойчивых кластерных решений, основанных на службах отказоустойчивого кластера Windows Server или Linux Pacemaker. Вместо этого необходимо использовать [номер SKU Azure Load Balancer (цен. категория "Стандартный")](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones).



## <a name="the-ideal-availability-zones-combination"></a>Идеальное сочетание зон доступности
Прежде чем решить, как использовать зоны доступности, необходимо определить следующее.

- Задержка в сети между тремя зонами в регионе Azure. Это позволит выбрать зоны с наименьшей задержкой в сети для трафика между зонами.
- Разница задержек между виртуальными машинами в пределах одной из выбранных зон и задержка в сети между двумя выбранными зонами.
- Доступность типов виртуальных машин, которые вы намерены развернуть в соответствующих двух зонах. При выборе некоторых виртуальных машин, особенно виртуальных машин серии M, могут возникать ситуации, когда некоторые номера SKU будут доступны в только двух зонах из трех.

## <a name="network-latency-between-and-within-zones"></a>Задержка в сети между зонами и в пределах зоны.
Чтобы определить задержку между несколькими зонами, сделайте следующее.

- Разверните в каждой из трех зон виртуальную машину с тем номером SKU, который вы намерены использовать для экземпляра СУБД. Перед выполнением измерений убедитесь, что включено [ускорение работы в сети Azure](https://azure.microsoft.com/blog/maximize-your-vm-s-performance-with-accelerated-networking-now-generally-available-for-both-windows-and-linux/).
- Когда вы найдете две зоны с наименьшей задержкой в сети, разверните во всех трех зонах доступности еще три виртуальные машины с тем номером SKU, который вы планируете использовать для виртуальных машин прикладного уровня. Измерьте задержку в сети для двух виртуальных машин СУБД в двух выбранных зонах для СУБД. 
- Для измерения используйте инструмент **niping**. Это инструмент SAP, который описан в примечаниях по поддержке SAP [№ 500235](https://launchpad.support.sap.com/#/notes/500235) и [№ 1100926](https://launchpad.support.sap.com/#/notes/1100926/E). Уделите внимание описанным командам для измерения задержки. Так как **ping** не работает с путями кода для ускорения работы в сети Azure, мы не рекомендуем использовать этот инструмент.

По результатам этих измерений и с учетом доступности номеров SKU виртуальных машин в зонах доступности вам следует принять следующие решения.

- Определите оптимальные зоны для уровня СУБД.
- Исходя из различий задержки в сети в пределах зоны и между зонами определите, нужно ли распределить активный прикладной уровень SAP на одну, две или все три зоны.
- Определите, нужно ли развертывать конфигурацию "активный — пассивный" или "активный — активный" с точки зрения приложения. (Эти конфигурации описаны далее в статье.)

При принятии этих решений учитывайте также рекомендации компании SAP по задержкам в сети, которые описаны в примечании SAP [№ 1100926](https://launchpad.support.sap.com/#/notes/1100926/E).

> [!IMPORTANT]
> Все измерения и принятые решения применимы только для той подписки Azure, которую вы использовали для этих измерений. Если вы используете другую подписку Azure, необходимо будет повторить измерения. Соответствие перечисляемых зон для другой подписки Azure может отличаться.


> [!IMPORTANT]
> Считается нормальным, что описанные выше измерения дадут разные результаты в каждом из регионов Azure, который поддерживает [Зоны доступности](https://docs.microsoft.com/azure/availability-zones/az-overview). Даже если требования к задержке в сети будут такими же, для разных регионов Azure могут подходить разные стратегии развертывания из-за различий в задержках между зонами. В одних регионах Azure задержка в сети между тремя разными зонами может значительно отличаться. В других регионах Azure задержка в сети между тремя разными зонами может быть более схожей. Утверждать, что задержка в сети всегда составляет 1–2 миллисекунды, неправильно. Не существует общих правил, характеризующих задержку в сети между зонами доступности в регионах Azure.

## <a name="activeactive-deployment"></a>Развертывание архитектуры "активный — активный"
Эта архитектура развертывания называется "активный" или "активный", так как вы развертываете активные серверы приложений SAP в двух или трех зонах. Экземпляр центральных служб SAP, использующий службу постановки в очередь для репликации, будет развертываться в двух зонах. Это справедливо и для уровня СУБД, который будет развертываться в тех же зонах, что и центральная служба SAP.

При рассмотрении этой конфигурации необходимо найти в нужном регионе две зоны доступности, задержка в сети между которыми приемлема для используемой рабочей нагрузки и синхронной репликации СУБД. Кроме того, разница между задержками в сети в пределах выбранных зон и между ними не должна быть слишком большой. Это второе требование связано с тем, что время выполнения бизнес-процессов или пакетных заданий, которые запущены в одной зоне с сервером СУБД или в разных зонах, не должно слишком сильно отличаться. Небольшие колебания допустимы, но не системные различия.

Упрощенная схема развертывания "активный — активный" в двух зонах может выглядеть примерно так:

![Зональное развертывание архитектуры "активный — активный"](./media/sap-ha-availability-zones/active_active_zones_deployment.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Не используйте [группу размещения](https://docs.microsoft.com/azure/virtual-machines/linux/co-location)с учетом расположения Azure, вы обрабатываете зоны доступности Azure как домены сбоя и обновления для всех виртуальных машин, так как группы доступности не могут быть развернуты в зоны доступности Azure.
- Если вы хотите объединить развертывания зональные для уровня СУБД и центральных служб, но вы хотите использовать группы доступности Azure для уровня приложения, вам нужно воспользоваться группами близости Azure, как описано в статье [группы размещения Azure для достижения оптимальной сетевая задержка с приложениями SAP](sap-proximity-placement-scenarios.md).
- Подсистемы балансировки нагрузки, которые вы применяете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны использовать [номер SKU ценовой категории "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки (цен. категория "Базовый") не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. Нет необходимости выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин необходимо использовать [Управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure (цен. категория "Премиум") или [хранилище SSD (цен. категория "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Приложение (СУБД или центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такие общие диски или общие папки между зонами. Поддерживаются следующие технологии:
  - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
  - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).
    
    В настоящее время решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), не поддерживается для работы между зонами.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.
- Чтобы обеспечить согласованность во время выполнения критических бизнес-процессов, можно попытаться направить определенные пакетные задания и пользователей в экземпляры приложений, которые находятся в зоне с активным экземпляром СУБД, с помощью групп серверов пакетной службы SAP, групп входа SAP или групп RFC. Но в случае зональной отработки отказа вам придется вручную перемещать эти группы в экземпляры, выполняемые на виртуальных машинах в одной зоне с виртуальной машиной базы данных.  
- Может потребоваться развернуть неактивные экземпляры диалога в каждой из зон. Это позволит немедленно получить прежние объемы ресурсов, если зона, в которой вы развернули экземпляры приложения, вышла из строя.


## <a name="activepassive-deployment"></a>Развертывание архитектуры "активный — пассивный"
Если вы не сможете найти сочетание зон с приемлемой разницей задержек в сети внутри одной зоны и между зонами, то вы можете развернуть архитектуру типа "активный — пассивный" с точки зрения прикладного уровня SAP. В ней вы определяете *активную* зону, в которой будет развернут весь прикладной уровень и будут выполняться активный экземпляр СУБД и экземпляр центральных служб SAP. Такая конфигурация позволяет гарантировать, что различия во времени выполнения бизнес-транзакций и пакетных заданий не будут критически большими в зависимости от того, выполняется ли задание в зоне с активным экземпляром СУБД или в другой зоне.

Базовая схема такой архитектуры выглядит следующим образом.

![Зональное развертывание архитектуры "активный — пассивный"](./media/sap-ha-availability-zones/active_passive_zones_deployment.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Группы доступности невозможно развернуть в Зонах доступности Azure. Чтобы компенсировать это, вы можете использовать группы размещения службы "близость" Azure, как описано в статье [группы размещения службы "близость" Azure для оптимальной сетевой задержки в приложениях SAP](sap-proximity-placement-scenarios.md).
- Применяя такую архитектуру, вам придется внимательно отслеживать состояние и стараться удерживать активные экземпляры СУБД и центральных служб SAP в той же зоне, где развернут прикладной уровень. При отработке отказа экземпляра центральной службы SAP или СУБД вам важно как можно раньше вручную выполнить восстановление размещения в ту зону, где развернут прикладной уровень SAP.
- Подсистемы балансировки нагрузки, которые вы применяете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны использовать [номер SKU ценовой категории "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки (цен. категория "Базовый") не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. Нет необходимости выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин необходимо использовать [Управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure (цен. категория "Премиум") или [хранилище SSD (цен. категория "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Приложение (СУБД или центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такие общие диски или общие папки между зонами. Поддерживаются следующие технологии:
    - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
    - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).
    
  В настоящее время решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), не поддерживается для работы между зонами.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.
- Следует развернуть неактивные виртуальные машины в пассивной зоне (с точки зрения СУБД), чтобы иметь возможность запустить ресурсы приложения в случае сбоя зоны.
    - В настоящее время невозможно использовать [Azure Site Recovery](https://azure.microsoft.com/services/site-recovery/) для репликации активных виртуальных машин в неактивные виртуальные машины в другой зоне. 
- Следует создать средства автоматизации, которые позволят автоматически запускать прикладной уровень SAP во второй зоне в случае сбоя зоны.

## <a name="combined-high-availability-and-disaster-recovery-configuration"></a>Сочетание конфигураций высокого уровня доступности и аварийного восстановления
Корпорация Майкрософт не предоставляет сведений о географическом расстоянии между элементами инфраструктуры, на которых размещаются разные зоны доступности Azure в определенном регионе Azure. Несмотря на этот факт, некоторые клиенты успешно применяют зоны для создания конфигураций, поддерживающих одновременно высокий уровень доступности и аварийное восстановление с нулевым значением целевой точки восстановления. Это означает, что вы не потеряете зафиксированные в базе данных транзакции даже в случае аварийного восстановления. 

> [!NOTE]
> Мы рекомендуем использовать подобную конфигурацию только в определенных обстоятельствах. Например, ее можно использовать, если данные не должны покидать регион Azure из соображений безопасности и соответствия требованиям. 

Ниже приведен пример такой конфигурации.

![Конфигурация, поддерживающая одновременно высокий уровень доступности и аварийное восстановление в зонах](./media/sap-ha-availability-zones/combined_ha_dr_in_zones.png)

Для этой конфигурации следует принимать во внимание следующие соображения.

- Вам следует предполагать, что элементы инфраструктуры, на которых размещается зона доступности, далеко расположены друг от друга, иначе вам придется остаться в пределах определенного региона Azure. Группы доступности невозможно развернуть в Зонах доступности Azure. Чтобы компенсировать это, вы можете использовать группы размещения службы "близость" Azure, как описано в статье [группы размещения службы "близость" Azure для оптимальной сетевой задержки в приложениях SAP](sap-proximity-placement-scenarios.md).
- Применяя такую архитектуру, вам придется внимательно отслеживать состояние и стараться удерживать активные экземпляры СУБД и центральных служб SAP в той же зоне, где развернут прикладной уровень. При отработке отказа экземпляра центральной службы SAP или СУБД вам важно как можно раньше вручную выполнить восстановление размещения в ту зону, где развернут прикладной уровень SAP.
- У вас должны быть рабочие экземпляры приложения, предварительно установленные на виртуальных машинах, на которых выполняются активные экземпляры приложения для контроля качества.
- В случае сбоя зоны следует завершить работу экземпляров приложения для контроля качества и вместо них запустить рабочие экземпляры. Имейте в виду, что в этом случае нужно использовать для экземпляров приложения виртуальные имена.
- Подсистемы балансировки нагрузки, которые вы применяете для отказоустойчивых кластеров центральных служб SAP и для уровня СУБД, должны использовать [номер SKU ценовой категории "Стандартный"](https://docs.microsoft.com/azure/load-balancer/load-balancer-standard-availability-zones). Подсистема балансировки нагрузки (цен. категория "Базовый") не будет работать между зонами.
- Виртуальная сеть Azure и все подсети, развернутые для размещения системы SAP, распределяются по нескольким зонам. Нет необходимости выделять виртуальные сети для каждой зоны.
- Для всех развернутых виртуальных машин необходимо использовать [Управляемые диски Azure](https://azure.microsoft.com/services/managed-disks/). Неуправляемые диски не поддерживаются для зональных развертываний.
- Хранилище Azure (цен. категория "Премиум") или [хранилище SSD (цен. категория "Ультра")](https://docs.microsoft.com/azure/virtual-machines/windows/disks-ultra-ssd) не поддерживают репликацию хранилища между зонами. Приложение (СУБД или центральные службы SAP) должно самостоятельно реплицировать важные данные.
- Это относится и к общей папке sapmnt, которая содержит общий диск (для Windows), общую папку CIFS (для Windows) или общую папку NFS (Linux). Вам нужна технология, которая позволяет реплицировать такие общие диски или общие папки между зонами. Поддерживаются следующие технологии:
    - Для Windows между зонами можно применить кластерное решение на основе SIOS Datakeeper, которое описано в статье [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
    - Для SUSE Linux поддерживается общая папка NFS, созданная по инструкциям из статьи [Обеспечение высокого уровня доступности NFS на виртуальных машинах Azure в SUSE Linux Enterprise Server](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-nfs).

  В настоящее время решение на основе масштабируемых файловых служб (SOFS) Windows, которое описано в статье [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share), не поддерживается для работы между зонами.
- Третья зона используется для размещения устройства SBD, если вы создаете [кластер Pacemaker в SUSE Linux](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/high-availability-guide-suse-pacemaker#create-azure-fence-agent-stonith-device) или дополнительные экземпляры приложения.





## <a name="next-steps"></a>Следующие шаги
Ниже приведены дальнейшие действия по развертыванию в Зонах доступности Azure:

- [Кластеризация экземпляра SAP ASCS/SCS в отказоустойчивом кластере Windows с помощью общего диска кластера в Azure](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-guide-wsfc-shared-disk).
- [Подготовка высокодоступной инфраструктуры Azure для SAP с помощью отказоустойчивого кластера Windows и файлового ресурса для экземпляров SAP ASCS/SCS](https://docs.microsoft.com/azure/virtual-machines/workloads/sap/sap-high-availability-infrastructure-wsfc-file-share).






