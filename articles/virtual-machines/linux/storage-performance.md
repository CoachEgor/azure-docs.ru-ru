---
title: Оптимизация производительности на виртуальных машинах серии Lsv2 Azure — хранилище | Документация Майкрософт
description: Узнайте, как оптимизировать производительность решения на виртуальных машинах серии Lsv2.
services: virtual-machines-linux
author: laurenhughes
manager: gwallace
ms.service: virtual-machines-linux
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-linux
ms.workload: infrastructure-services
ms.date: 08/05/2019
ms.author: joelpell
ms.openlocfilehash: a06ae79181c70f1cb8519f703cb42a3d699bebf3
ms.sourcegitcommit: 3073581d81253558f89ef560ffdf71db7e0b592b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/06/2019
ms.locfileid: "68828382"
---
# <a name="optimize-performance-on-the-lsv2-series-virtual-machines"></a>Оптимизация производительности виртуальных машин серии Lsv2

Виртуальные машины серии Lsv2 поддерживают разнообразные рабочие нагрузки, требующие высокой скорости ввода-вывода и пропускной способности локального хранилища в широком спектре приложений и отраслей.  Серия Lsv2 идеально подходит для больших данных, баз данных SQL, NoSQL, хранилищ данных и больших транзакционных баз данных, включая Cassandra, MongoDB, Cloudera и Redis.

Архитектура виртуальных машин серии Lsv2 (VM) позволяет максимизировать процессор AMD ЕПИК™ 7551, чтобы обеспечить максимальную производительность между процессором, памятью, устройствами NVMe и виртуальными машинами. Работая с партнерами в Linux, доступны несколько сборок Azure Marketplace, которые оптимизированы для производительности серии Lsv2 и в настоящее время включают:

- Ubuntu 18.04
- Ubuntu 16.04
- RHEL 8,0
- Debian 9
- Debian 10

В этой статье приводятся советы и рекомендации по обеспечению максимальной производительности рабочих нагрузок и приложений, рассчитанных на виртуальные машины. Сведения на этой странице будут постоянно обновляться по мере добавления Lsv2 оптимизированных образов в Azure Marketplace.

## <a name="amd-eypc-chipset-architecture"></a>Архитектура набора микросхем AMD ЭЙПК™

Виртуальные машины серии Lsv2 используют процессоры AMD ЭЙПК™ Server на основе микроархитектуры Zen. Платформа AMD разработала бесконечную структуру (IF) для ЭЙПК™ в качестве масштабируемого межсетевого соединения для своей модели NUMA, которая может использоваться для встроенных, упакованных и многопакетных коммуникаций. По сравнению с QPI (быстрое подключение) и УПИ (Ultra-Path Interconnect), которые используются на современных процессорах Intel современного монолитного кристалла, архитектура с небольшим объемом архитектуры AMD многих NUMA может привести к повышению производительности и проблемам. Фактическое влияние ограничений пропускной способности памяти и задержки может различаться в зависимости от типа выполняемых рабочих нагрузок.

## <a name="tips-to-maximize-performance"></a>Советы по повышению производительности

* Если вы отправляете настраиваемую Гуестос Linux для рабочей нагрузки, обратите внимание, что функция ускорения сети будет отключена по умолчанию. Если вы планируете включить функцию ускорения сети, включите ее во время создания виртуальной машины, чтобы обеспечить наилучшую производительность.

* Оборудование, которое питает виртуальные машины серии Lsv2, использует устройства NVMe с восемью парами очередей ввода-вывода (QP). Каждая очередь ввода-вывода устройств NVMe на самом деле представляет собой пару: очередь отправки и очередь завершения. Драйвер NVMe настроен на оптимизацию использования этих восьми QPs ввода-вывода путем распределения операций ввода-вывода в расписании циклического перебора. Чтобы получить максимальную производительность, выполните восемь заданий на устройство для сопоставления.

* Старайтесь не смешивать команды администрирования NVMe (например, запрос по интеллектуальной информации NVMe и т. д.) с командами ввода-вывода NVMe во время активных рабочих нагрузок. Lsv2 устройства NVMe поддерживаются технологией прямого подключения Hyper-V NVMe, которая переключается в режим "в режиме ожидания" каждый раз, когда ожидаются команды администрирования NVMe. Пользователи Lsv2 могут видеть производительность операций ввода-вывода NVMe, если это происходит.

* Пользователи Lsv2 не должны полагаться на сведения об устройстве NUMA (все 0), полученные от виртуальной машины для дисков данных, чтобы принять решение о сходстве NUMA для своих приложений. Рекомендуемый способ повышения производительности — распределить рабочие нагрузки между процессорами, если это возможно.

* Максимальная поддерживаемая глубина очереди на каждую пару операций ввода-вывода для устройства NVMe виртуальной машины Lsv2 — 1024 (VS. Amazon i3 длина очереди 32. Пользователи Lsv2 должны ограничить свои (искусственные) рабочие нагрузки производительности до глубины 1024 или ниже, чтобы избежать запуска полных условий очереди, что может снизить производительность.

## <a name="utilizing-local-nvme-storage"></a>Использование локального хранилища NVMe

Локальное хранилище на диске NVMe 1,92 ТБ на всех Lsv2 виртуальных машинах является эфемерным. При успешной стандартной перезагрузке виртуальной машины данные на локальном диске NVMe будут сохранены. Данные не будут сохраняться в NVMe, если виртуальная машина повторно развернута, освобождена или удалена. Данные не сохраняются, если другая проблема вызывает виртуальную машину или оборудование, на котором она запущена, и становится неработоспособным. В этом случае любые данные на старом узле будут безопасно удалены.

Также возможны случаи, когда ВИРТУАЛЬную машину необходимо переместить на другой хост-компьютер, например во время планового обслуживания. С помощью [запланированные события](scheduled-events.md)можно ожидать плановых операций обслуживания и некоторых сбоев оборудования. Запланированные события следует использовать для обновления любых прогнозируемых операций обслуживания и восстановления.

Если запланированное событие обслуживания требует повторного создания виртуальной машины на новом узле с пустыми локальными дисками, необходимо повторно синхронизировать данные (опять же, при этом любые данные на старом узле будут безопасно удалены). Это происходит потому, что виртуальные машины серии Lsv2 в настоящее время не поддерживают динамическую миграцию на локальном диске NVMe.

Существует два режима планового обслуживания.

### <a name="standard-vm-customer-controlled-maintenance"></a>Обслуживание Standard VM, контролируемое клиентом

- Виртуальная машина перемещается на обновленный узел в течение 30-дневного периода.
- Lsv2 данные локального хранилища могут быть потеряны, поэтому рекомендуется выполнять резервное копирование данных до события.

### <a name="automatic-maintenance"></a>Автоматическое обслуживание

- Происходит, если клиент не выполняет обслуживание, контролируемое клиентом, или в случае аварийных процедур, таких как событие нулевого дня безопасности.
- Предназначен для сохранения данных клиентов, но существует небольшой риск заморозить или перезапустить виртуальную машину.
- Lsv2 данные локального хранилища могут быть потеряны, поэтому рекомендуется выполнять резервное копирование данных до события.

Для всех ближайших событий службы используйте контролируемый процесс обслуживания, чтобы выбрать наиболее удобное для обновления время. Перед событием вы можете создавать резервные копии данных в хранилище класса Premium. После завершения события обслуживания вы можете вернуть данные в локальное хранилище NVMe для виртуальных машин Lsv2.

Ниже перечислены сценарии, которые поддерживают данные на локальных дисках NVMe.

- Виртуальная машина работает и работоспособна.
- Виртуальная машина перезагружается на месте (с помощью или Azure).
- Виртуальная машина приостановлена (остановлена без отмены выделения).
- Большая часть плановых операций обслуживания.

Ниже перечислены сценарии, которые безопасно удаляют данные для защиты клиента.

- Виртуальная машина повторно развертывается, останавливается (освобождается) или удаляется (с помощью).
- Виртуальная машина станет неработоспособной и должна обслуживать ее на другом узле из-за проблемы с оборудованием.
- Небольшое количество плановых операций обслуживания, требующих повторного выделения виртуальной машины на другой узел для обслуживания.

Дополнительные сведения о вариантах резервного копирования данных в локальном хранилище см. в статье [резервное копирование и аварийное восстановление для дисков Azure IaaS](backup-and-disaster-recovery-for-azure-iaas-disks.md).

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

* **Разделы справки начать развертывание виртуальных машин серии Lsv2?**  
   Подобно любой другой виртуальной машине, для создания виртуальной машины используйте [портал](quick-create-portal.md), [Azure CLI](quick-create-cli.md)или [PowerShell](quick-create-powershell.md) .

* **Произойдет ли сбой одного диска NVMe, что приведет к сбою всех виртуальных машин на узле?**  
   Если на узле оборудования обнаружен сбой диска, оборудование находится в состоянии сбоя. В этом случае все виртуальные машины на узле автоматически освобождаются и перемещаются на работоспособный узел. Для виртуальных машин серии Lsv2 это означает, что данные клиента на узле, на который происходит сбой, также безопасно удаляются и должны быть созданы повторно клиентом на новом узле. Как уже отмечалось, до того, как динамическая миграция станет доступной в Lsv2, данные на узле, на который происходит сбой, будут заблаговременно перемещаться вместе с виртуальными машинами по мере их передачи на другой узел.

* **Нужно ли вносить изменения в rq_affinity для повышения производительности?**  
   Параметр rq_affinity является незначительной коррекцией при использовании абсолютного максимального числа операций ввода-вывода в секунду. Когда все остальное работает правильно, попытайтесь установить rq_affinity в значение 0, чтобы увидеть, отличается ли это.

* **Нужно ли изменять параметры blk_mq?**  
   RHEL/CentOS 7. x автоматически использует BLK-MQ для устройств NVMe. Изменения конфигурации и параметры не требуются. Параметр scsi_mod. use _blk_mq предназначен только для SCSI и использовался во время предварительной версии Lsv2, так как устройства NVMe были видны на гостевых виртуальных машинах как устройства SCSI. В настоящее время устройства NVMe видимы в виде устройств NVMe, поэтому параметр SCSI BLK-MQ не важен.

* **Нужно ли изменить "FIO"?**  
   Чтобы получить максимальное число операций ввода-вывода в секунду с помощью средства измерения производительности, например "FIO" в размерах виртуальных машин L64v2 и L80v2, установите для параметра "rq_affinity" значение 0 на каждом устройстве NVMe.  Например, эта командная строка установит значение "rq_affinity" равным нулю для всех 10 устройств NVMe в виртуальной машине L80v2:

   ```console
   for i in `seq 0 9`; do echo 0 >/sys/block/nvme${i}n1/queue/rq_affinity; done
   ```

   Также обратите внимание, что оптимальная производительность достигается, когда ввод-вывод выполняется непосредственно на каждом необработанном устройстве NVMe без секционирования, без файловых систем, без конфигурации RAID 0 и т. д. Перед запуском тестового сеанса убедитесь, что конфигурация находится в известном состоянии "новое/чистое `blkdiscard` ", выполнив на каждом устройстве NVMe.
   
## <a name="next-steps"></a>Следующие шаги

* См. спецификации для всех [виртуальных машин, оптимизированных для производительности хранилища](sizes-storage.md) в Azure.
