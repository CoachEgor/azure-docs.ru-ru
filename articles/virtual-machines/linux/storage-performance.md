---
title: Оптимизация производительности на виртуальных машинах Azure серии Lsv2 — хранилище | Документация Майкрософт
description: Узнайте, как оптимизировать производительность для вашего решения на виртуальных машинах серии Lsv2.
services: virtual-machines-linux
author: laurenhughes
manager: jeconnoc
ms.service: virtual-machines-linux
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: vm-linux
ms.workload: infrastructure-services
ms.date: 04/17/2019
ms.author: joelpell
ms.openlocfilehash: 7be86c8934b8766217f9fca432327d254204f0c4
ms.sourcegitcommit: d4dfbc34a1f03488e1b7bc5e711a11b72c717ada
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "60738950"
---
# <a name="optimize-performance-on-the-lsv2-series-virtual-machines"></a>Оптимизация производительности на виртуальных машинах серии Lsv2

Виртуальные машины серии Lsv2 поддержки различных рабочих нагрузок, которым требуется высокий уровень операций ввода-вывода и пропускной способности в локальном хранилище в самых различных приложений и отраслях.  Серии Lsv2 идеально подходит для больших данных, SQL, NoSQL баз данных, хранение данных и большие транзакционные базы данных, включая Cassandra, MongoDB, Cloudera и Redis.

Структура Lsv2 серии виртуальных машин (ВМ) максимально увеличивает процессора AMD EPYC 7551™, чтобы предоставить оптимальной между процессора, памяти, устройства NVMe и виртуальные машины. Помимо увеличения производительности оборудования, виртуальные машины серии Lsv2 предназначены для работы с учетом потребностей операционных систем Linux для повышения производительности с оборудования и программного обеспечения.

Помощник по настройке программного обеспечения и оборудования привел к оптимизированной версии [Canonical Ubuntu 18.04 и 16.04](https://azuremarketplace.microsoft.com/marketplace/apps/Canonical.UbuntuServer?tab=Overview), выпущенном в начале декабря 2018 года в Azure Marketplace, который поддерживает максимальную производительность на устройства NVMe в Виртуальные машины серии Lsv2.

В этой статье содержатся советы и рекомендации для обеспечения рабочих нагрузок и приложений достижения максимальной производительности, разработанные в виртуальные машины. Сведения на этой странице будет постоянно обновляться по мере добавляются другие Lsv2 оптимизированные образы Azure Marketplace.

## <a name="amd-eypc-chipset-architecture"></a>Архитектура микросхем AMD EYPC™

Виртуальные машины серии Lsv2 используют сервер AMD EYPC™, основанными на микроархитектуры Zen. AMD разработанные Fabric бесконечность (если) для EYPC™ масштабируемыми подключение между узлами для своей модели NUMA, которые могут использоваться для обмена данными на кристалл, -package и несколькими пакета. По сравнению с QPI (Interconnect экспресс-Path) и UPI (Interconnect Ultra-Path) используется для современных процессоров монолитных кристалле Intel, AMD NUMA многие малый die архитектуры могут использовать собственные обоих выигрыш в производительности и трудности. Влияние ограничений пропускной способности и задержки памяти может меняться в зависимости от типа рабочих нагрузок, выполняющихся.

## <a name="tips-to-maximize-performance"></a>Советы для повышения производительности

* При отправке пользовательских Linux GuestOS для рабочей нагрузки, обратите внимание, что повышение производительности сети **OFF** по умолчанию. Если вы планируете включить функцию ускорения сети, включите ее во время создания виртуальной Машины для достижения оптимальной производительности.

* Оборудовании, что виртуальные машины серии Lsv2 использует устройства NVMe с восемью пары очереди ввода-вывода (QP) s. Каждая очередь ввода-вывода устройства NVMe представляет собой пару: очередь отправки и очередь завершения. Драйвер NVMe предназначена для оптимизации использования этих восьми приблизительное число операций ввода-вывода, распределяя я / вывода в циклический перебор расписания. Для получения производительности, выполните восемь задания на каждом устройстве в соответствии с.

* Не смешивайте NVMe команды администратора (например, смарт-NVMe сведения запроса т. д.) с помощью команд NVMe ввода-вывода во время активных рабочих нагрузок. Устройства Lsv2 NVMe обеспечиваются технологии Hyper-V NVMe Direct, который переключается в режим «медленный» всякий раз, когда все NVMe администратора команды, ожидающих выполнения. Lsv2 могут наблюдаться существенного увеличения производительности, в drop в производительности ввода/вывода NVMe, если это произойдет.

* Lsv2 пользователи не должны полагаться на устройства сведения об архитектуре NUMA (0), отправленные из в рамках виртуальной Машины для дисков с данными, чтобы решить, NUMA для своих приложений. Для повышения производительности рекомендуется распределить рабочие процессы между несколькими ЦП, если это возможно.

* Глубина очереди максимальный поддерживаемый каждой пары очереди ввода-вывода для устройства NVMe Lsv2 виртуальной Машины — 1024 (vs. Amazon i3 32 длина Очереди, ограничением). Пользователи Lsv2 следует ограничить их (синтетическими) тестирования производительности рабочих нагрузок для длины очереди, 1024 или ниже, чтобы избежать активации очереди полный условий, которые могут снизить производительность.

## <a name="utilizing-local-nvme-storage"></a>Использование локального хранилища NVMe

Локальное хранилище на диске NVMe 1,92 ТБ на всех виртуальных машинах Lsv2 временные. Во время успешной обычной перезагрузки виртуальной машины данные на локальном диске NVMe, сохранятся. Данные не будут сохраняться на NVMe, если повторное развертывание, отменяется или удалили виртуальную Машину. Данные не сохраняются, если еще одна проблема приводит к виртуальной Машине, или устройства, на котором он выполняется, чтобы утратить работоспособность. В этом случае все данные на старого узла безопасно удаляется.

Также будет случаях когда виртуальная машина должна переместиться на другом хост-компьютере, например, во время операции запланированного обслуживания. Операции запланированного обслуживания и некоторые сбои оборудования можно предупредить с [запланированных событий](scheduled-events.md). Запланированные события должны использоваться обновлялись в любой прогнозируемое обслуживание и операций восстановления.

В случае планового обслуживания требует создать заново на новый узел с пустым локальные диски виртуальной Машины данные нужно будет повторно синхронизировать (опять же, с данными на безопасного удаления старого узла). Это происходит, поскольку виртуальные машины серии Lsv2 в настоящее время не поддерживают динамическую миграцию на локальном диске NVMe.

Существует два режима для выполнения планового обслуживания.

### <a name="standard-vm-customer-controlled-maintenance"></a>Стандартный обслуживание управляемых клиентом виртуальных Машин

- Виртуальная машина перемещается на обновленный узел в течение 30-дневного периода.
- Lsv2 локального хранилища данных могут быть потеряны, поэтому рекомендуется использовать резервное копирование данных перед событием.

### <a name="automatic-maintenance"></a>Автоматическое обслуживание

- Возникает, если клиент не выполняет управляемым клиентом обслуживания или в случае чрезвычайных ситуаций процедуры, например события безопасности нулевого дня.
- Предназначен для сохранения данных клиента, но есть небольшой риск замораживание виртуальной Машины или перезагрузки.
- Lsv2 локального хранилища данных могут быть потеряны, поэтому рекомендуется использовать резервное копирование данных перед событием.

Для любой о предстоящих событий управляемое обслуживание процесс можно используйте для выбора времени, наиболее удобное для вас, для обновления. До события может создавать резервные копии данных в хранилище уровня "премиум". После завершения события обслуживания, может возвращать данные в локальное хранилище NVMe обновленные Lsv2 виртуальных машин.

Сценарии, которые обеспечивают данных на локальных дисках NVMe:

- Виртуальная машина работает и исправен.
- Перезагрузке виртуальной Машины на месте (пользователем или Azure).
- Виртуальная машина приостановлена (остановлен без отмены выделения).
- Большинство операций по обслуживанию планового обслуживания.

Сценарии, которые безопасно удалить данные для защиты клиента:

- Виртуальная машина будет повторно развернута, остановлена (освобождена), или удалить (пользователем).
- Виртуальная машина переходит в неработоспособное и имеет к службе восстановления на другой узел из-за проблемы оборудования.
- Небольшое количество операций по обслуживанию планового обслуживания, требует перераспределить на другой узел для обслуживания виртуальной Машины.

Дополнительные сведения о резервном копировании данных в локальном хранилище, см. в разделе [резервное копирование и аварийное восстановление для дисков Azure IaaS](backup-and-disaster-recovery-for-azure-iaas-disks.md).

## <a name="frequently-asked-questions"></a>Часто задаваемые вопросы

* **Как начать, развертывание виртуальных машин серии Lsv2?**  
   Любой другой виртуальной машине использовать [портала](quick-create-portal.md), [Azure CLI](quick-create-cli.md), или [PowerShell](quick-create-powershell.md) для создания виртуальной Машины.

* **Приведет ли сбой одного диска NVMe все виртуальные машины на узле переход на другой?**  
   При обнаружении сбоя диска на узле оборудования оборудования находится в состоянии сбоя. Когда это происходит, все виртуальные машины на узле автоматически отменяется и перемещен в работоспособный узел. Для виртуальных машин серии Lsv2 это означает, что данные клиента неисправный узел также безопасно удаляется и нужно будет создать заново с клиента на новом узле. Как уже отмечалось, прежде чем динамической миграции станет доступной на Lsv2, данные на неисправный узел заранее перемещается с виртуальными машинами, они переносятся на другой узел.

* **Нужно ли вносить изменения с учетом для rq_affinity для производительности?**  
   Параметр rq_affinity представляет незначительная корректировка абсолютный максимальный операций ввода вывода в секунду (IOPS). Если все остальное работает хорошо, затем повторите rq_affinity присвоено значение 0, чтобы посмотреть, если никакой разницы.

* **Нужно ли изменить параметры blk_mq?**  
   RHEL или CentOS 7.x автоматически использует blk mq для устройства NVMe. Без изменения конфигурации или параметров не требуется. Параметр scsi_mod.use_blk_mq предназначена исключительно для SCSI и был использован на этапе предварительной версии Lsv2, так как устройства NVMe были видны в гостевых виртуальных машин как устройства SCSI. В настоящее время устройства NVMe видны как устройства NVMe, поэтому параметр blk mq SCSI не имеет значения.

* **Нужно ли изменить «fio»?**  
   Чтобы получить максимальное значение IOPS с такими инструментами, как «fio» L64v2 L80v2 виртуальных Машин размеров и производительности, равным «rq_affinity» 0 на каждом устройстве NVMe.  Например эта командная строка будет задать «rq_affinity» нулю для всех 10 устройств NVMe на виртуальной Машине L80v2:

   ```console
   for i in `seq 0 9`; do echo 0 >/sys/block/nvme${i}n1/queue/rq_affinity; done
   ```

   Также Обратите внимание, что получаемый наилучшую производительность при операции ввода-вывода выполняется непосредственно к каждому из устройства NVMe необработанного с без секционирования, не файловых систем без RAID 0 конфигурации и т. д. Перед началом сеанса тестирования, убедитесь, конфигурация в известном состоянии/clean нуля, выполнив `blkdiscard` на всех устройствах NVMe.
   
## <a name="next-steps"></a>Дальнейшие действия

* См. в разделе спецификации для всех [виртуальных машин, оптимизированных для производительности хранилища](sizes-storage.md) в Azure
