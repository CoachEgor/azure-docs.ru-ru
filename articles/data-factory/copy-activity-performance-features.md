---
title: Копирование функций оптимизации производительности
description: Узнайте о ключевых функциях, которые помогут оптимизировать производительность копирования на фабрике данных Azure.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/09/2020
ms.openlocfilehash: fd7844340553809e1429097a9dda70f6bdb3e075
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81414191"
---
# <a name="copy-activity-performance-optimization-features"></a>Копирование функций оптимизации производительности

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

В этой статье излагаются функции оптимизации производительности активности копирования, которые можно использовать на фабрике данных Azure.

## <a name="data-integration-units"></a>Единицы интеграции данных

Группа интеграции данных — это мера, представляющая мощность (комбинация процессора, памяти и распределения сетевых ресурсов) одного блока в Azure Data Factory. Группа интеграции данных применяется только к [времени выполнения интеграции Azure,](concepts-integration-runtime.md#azure-integration-runtime)но не [к самостоятельной интеграции.](concepts-integration-runtime.md#self-hosted-integration-runtime)

Разрешенные DIUs для расширения возможностей копирования деятельности перспективе **между 2 и 256**. Если вы не указаны или вы выбираете "Auto" на uI, Data Factory динамически применяет оптимальную настройку DIU на основе пары исходного погружения и шаблона данных. В следующей таблице перечислены поддерживаемые диапазоны DIU и поведение по умолчанию в различных сценариях копирования:

| Сценарий копирования | Поддерживаемый диапазон DIU | Число единиц интеграции данных, устанавливаемое по умолчанию службой |
|:--- |:--- |---- |
| Между файловыми магазинами |- **Копирование из или в один файл**: 2-4 <br>- **Копирование из и в несколько файлов**: 2-256 в зависимости от количества и размера файлов <br><br>Например, если копировать данные из папки с 4 большими файлами и выбрать для сохранения иерархии, максимальная эффективная DIU составляет 16; при выборе объединения файла максимальная эффективность DIU составляет 4. |От 4 до 32 в зависимости от количества и размера файлов |
| От файлохранилища до нефайлового хранилища |- **Копия из одного файла**: 2-4 <br/>- **Копирование из нескольких файлов**: 2-256 в зависимости от количества и размера файлов <br/><br/>Например, если копировать данные из папки с 4 большими файлами, максимальная эффективная DIU составляет 16. |- **Копирование в базу данных Azure S'L или Azure Cosmos DB:** от 4 до 16 в зависимости от уровня раковины (DTUs/RUs) и шаблона исходного файла<br>- **Копирование в Azure Synapse Analytics** с помощью полибазы или COPY выписки: 2<br>- Другой сценарий: 4 |
| От нефайлового хранилища до файлохранилища |- **Копирование из разделительных опционов с поддержкой хранилищ данных** (включая [Oracle](connector-oracle.md#oracle-as-source)/[Netezza](connector-netezza.md#netezza-as-source)/[Teradata):](connector-teradata.md#teradata-as-source)2-256 при записи в папку и 2-4 при написании в одном файле. Примечание на раздел исходных данных может использовать до 4 DIUs.<br>- **Другие сценарии**: 2-4 |- **Копия из REST или HTTP**: 1<br/>- **Копия из Amazon Redshift** с помощью UNLOAD: 2<br>- **Другой сценарий**: 4 |
| Между нефайлными магазинами |- **Копирование из разделительных опционов с поддержкой хранилищ данных** (включая [Oracle](connector-oracle.md#oracle-as-source)/[Netezza](connector-netezza.md#netezza-as-source)/[Teradata):](connector-teradata.md#teradata-as-source)2-256 при записи в папку и 2-4 при написании в одном файле. Примечание на раздел исходных данных может использовать до 4 DIUs.<br/>- **Другие сценарии**: 2-4 |- **Копия из REST или HTTP**: 1<br>- **Другой сценарий**: 4 |

Можно увидеть diUs, используемые для каждой запуска копии, в представлении мониторинга активности копирования или выходе активности. Для получения дополнительной информации [см.](copy-activity-monitoring.md) Чтобы переопределить этот по умолчанию, укажите значение для `dataIntegrationUnits` свойства следующим образом. *Фактическое число единиц интеграции данных*, используемых при копировании, не превышает заданного значения, в зависимости от формата данных.

С вас будет взиматься **плата за использование DIU \* copy aunit \* price/DIU-hour.** Смотрите текущие цены [здесь](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/). Местная валюта и отдельные скидки могут применяться на тип подписки.

**Примере:**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "dataIntegrationUnits": 128
        }
    }
]
```

## <a name="self-hosted-integration-runtime-scalability"></a>Масштабируемость автономной интеграции

Если вы хотите достичь более высокой пропускной выхадостительной пропускной платы, вы можете масштабировать или масштабировать самостоятельно размещенные ИК:

- Если процессор и доступная память на самостоятельно размещенном ИК-узеле не используются в полной мере, но выполнение одновременных заданий достигает предела, следует увеличить количество одновременных заданий, которые могут работать на узеле.  Смотрите [здесь](create-self-hosted-integration-runtime.md#scale-up) для инструкций.
- Если, с другой стороны, процессор находится высоко на самостоятельном ИК-узла или доступная память низкая, вы можете добавить новый узлы, чтобы помочь масштабировать нагрузку через несколько узлов.  Смотрите [здесь](create-self-hosted-integration-runtime.md#high-availability-and-scalability) для инструкций.

Примечание в следующих сценариях, выполнение одноразового действия копирования может использовать несколько самостоятельно размещенных ИК-узлов:

- Копирование данных из файловых хранилиц, в зависимости от количества и размера файлов.
- Копирование данных из хранилища данных с поддержкой опционов (включая [Oracle,](connector-oracle.md#oracle-as-source) [Netezza,](connector-netezza.md#netezza-as-source) [Teradata,](connector-teradata.md#teradata-as-source) [SAP HANA,](connector-sap-hana.md#sap-hana-as-source) [SAP Table](connector-sap-table.md#sap-table-as-source)и [SAP Open Hub)](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source)в зависимости от количества разделов данных.

## <a name="parallel-copy"></a>Параллельное копирование

Можно установить параллельную копию (свойство)`parallelCopies` на активности копирования, чтобы указать параллелизм, который вы хотите использовать в действии копирования. Это свойство можно считать максимальным количеством потоков в потоке копирования, которые считываются из вашего источника или пишут в хранилища данных раковины параллельно.

Параллельная копия является ортогоналдляной для [единиц интеграции данных](#data-integration-units) или [самохозня ИК-узлов.](#self-hosted-integration-runtime-scalability) Он учитывается во всех DIUs или самостоятельно размещенных ИК-узлах.

Для каждого выполнения действия копирования по умолчанию Azure Data Factory динамически применяет оптимальную параллельную настройку копии на основе пары исходного погружения и шаблона данных. 

> [!TIP]
> Поведение параллельной копии по умолчанию обычно дает вам лучшую пропускную схему, которая автоматически определяется ADF на основе пары исходного кода, шаблона данных и количества дуиили или самостоятельного иТ-процессора/памяти/узла. Ссылайтесь на [производительность действия копии Troubleshoot,](copy-activity-performance-troubleshooting.md) когда для настройки параллельной копии.

В следующей таблице перечислены параллельные примеры поведения:

| Сценарий копирования | Параллельное поведение копирования |
| --- | --- |
| Между файловыми магазинами | `parallelCopies`определяет параллелизм **на уровне файла.** Chunking внутри каждого файла происходит под автоматически и прозрачно. Он предназначен для использования наилучшего подходящего размера куска для данного типа хранилища данных для параллельной загрузки данных. <br/><br/>Фактическое количество параллельных копий копирования деятельности использует во время выполнения не больше, чем количество файлов, которые у вас есть. Если поведение копии **сливается** в раковину файла, активность копирования не может воспользоваться параллелизмом на уровне файлов. |
| От файлохранилища до нефайлового хранилища | - При копировании данных в базу данных Azure S'L или Azure Cosmos DB параллельная копия по умолчанию также зависит от уровня раковины (количество DTUs/RUs).<br>- При копировании данных в таблице Azure параллельная копия по умолчанию составляет 4. |
| От нефайлового хранилища до файлохранилища | - При копировании данных из магазина данных с поддержкой разделов (включая [Oracle,](connector-oracle.md#oracle-as-source) [Netezza,](connector-netezza.md#netezza-as-source) [Teradata,](connector-teradata.md#teradata-as-source) [SAP HANA,](connector-sap-hana.md#sap-hana-as-source) [SAP Table](connector-sap-table.md#sap-table-as-source)и [SAP Open Hub)](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source)по умолчанию параллельная копия составляет 4. Фактическое количество параллельных копий, которые используются во время выполнения, не превышает количество разделов данных. При использовании самоходного запуска интеграции и копировании в Azure Blob/ADLS Gen2, обратите внимание, что максимальная эффективная параллельная копия составляет 4 или 5 на ИК-узел.<br>- Для других сценариев параллельная копия не всняет в силу. Даже если указано параллелизм, он не применяется. |
| Между нефайлными магазинами | - При копировании данных в базу данных Azure S'L или Azure Cosmos DB параллельная копия по умолчанию также зависит от уровня раковины (количество DTUs/RUs).<br/>- При копировании данных из магазина данных с поддержкой разделов (включая [Oracle,](connector-oracle.md#oracle-as-source) [Netezza,](connector-netezza.md#netezza-as-source) [Teradata,](connector-teradata.md#teradata-as-source) [SAP HANA,](connector-sap-hana.md#sap-hana-as-source) [SAP Table](connector-sap-table.md#sap-table-as-source)и [SAP Open Hub)](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source)по умолчанию параллельная копия составляет 4.<br>- При копировании данных в таблице Azure параллельная копия по умолчанию составляет 4. |

Чтобы контролировать нагрузку на машины, в которых размещаются ваши хранилища данных, или настроить `parallelCopies` производительность копирования, можно переопределить значение по умолчанию и указать значение для свойства. Значение должно быть целым числом больше или равно 1. В момент выполнения, для наилучшей производительности, в действии копирования используется значение, которое меньше или равно установленному значению.

Когда вы указываете `parallelCopies` значение для свойства, учитывайте увеличение нагрузки на исходный источник и учесть хранилища данных. Также учитывайте увеличение нагрузки на самоходной интеграции, если действие копирования уполномочено им. Это увеличение нагрузки происходит особенно, когда у вас есть несколько действий или одновременных запусков одних и тех же действий, которые работают против одного и того же хранилища данных. Если вы заметили, что либо хранилище данных, либо самоходной `parallelCopies` интеграции время выполнения перегружено с нагрузкой, уменьшить значение, чтобы облегчить нагрузку.

**Примере:**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

## <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

- **Вы хотите, чтобы глотать данные из различных хранилиров данных в хранилище данных с помощью PolyBase.** Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Исходные данные должны находиться в хранилище Blob или хранилище Azure Data Lake Store и должны соответствовать дополнительным критериям. При загрузке данных не из хранилища BLOB-объектов или Azure Data Lake Store можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае Azure Data Factory выполняет необходимые преобразования данных, чтобы убедиться, что она отвечает требованиям PolyBase. Затем она эффективно загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
- **Иногда требуется некоторое время, чтобы выполнить гибридное движение данных (т.е. скопировать из предварительного хранилища данных в облачный хранилище данных) по медленному сетевому подключению.** Для повышения производительности можно использовать поэтапную копию для сжатия данных на территории, чтобы было меньше времени для перемещения данных в хранилище данных в облаке. Затем можно распаковать данные в промежуточном хранилище перед загрузкой в хранилище данных назначения.
- **Вы не хотите открывать порты, кроме порта 80 и порта 443 в брандмауэре, из-за корпоративных ИТ-политик.** Например, при копировании данных из локального хранилища в приемник Базы данных SQL Azure или приемник Хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом сценарии поэтапная копия может воспользоваться самоходном временем выполнения интеграции для первой копирования данных в экземпляр хранения Blob по сравнению с HTTP или HTTPS на порте 443. Затем он может загрузить данные в базу данных СЗЛ или Хранилище данных с момента постановки хранилища Blob. В таком сценарии не нужно включать порт 1433.

### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования

Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное хранилище BLOB-объектов (собственное). Оттуда данные копируются в приемник данных. Фабрика данных Azure автоматически управляет двухступенчатым потоком для вас. Фабрика данных Azure также очищает временные данные от промежуточного хранилища после завершения движения данных.

![промежуточное копирование](media/copy-activity-performance/staged-copy.png)

При активации движения данных с помощью промежуточного хранилища можно указать, хотите ли вы, чтобы данные были сжаты перед перемещением данных из хранилища исходных данных в промежуточный или промежуточный хранилище данных, а затем распаковываются перед перемещением данных из промежуточного или постановного хранилища данных в хранилище данных раковины.

В настоящее время нельзя копировать данные между двумя хранилищами данных, которые подключены через различные самоуправляемые ИК, ни с поэтапной копией, ни без нее. Для такого сценария можно настроить два явно цепных действия копий для копирования от источника к постановке, а затем от постановки до раковины.

### <a name="configuration"></a>Конфигурация

Настроите настройку **enableStaging** в действии копирования, чтобы указать, хотите ли вы, чтобы данные были поставлены в хранилище Blob, прежде чем загрузить их в хранилище данных назначения. При установке **enableStaging** укажите дополнительные `TRUE`свойства, перечисленные в следующей таблице. Кроме того, необходимо создать службу совместного хранения или хранения доступа Azure Storage для постановки, если у вас ее нет.

| Свойство | Описание | Значение по умолчанию | Обязательно |
| --- | --- | --- | --- |
| enableStaging |Укажите, следует ли копировать данные в промежуточное хранилище. |False |нет |
| linkedServiceName |Укажите имя связанной службы [AzureStorage](connector-azure-blob-storage.md#linked-service-properties), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Вы не можете использовать хранилище с общей подписью доступа для загрузки данных в хранилище данных с помощью PolyBase. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| path |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. Если вы не предоставляете путь, служба создает контейнер для хранения временных данных. <br/><br/>  Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |нет |
| enableCompression |Уточняется, следует ли сжимать данные до их копирования в пункт назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |False |нет |

>[!NOTE]
> Если вы используете поэтапную копию с включенным сжатием, принцип службы или проверка подлинности MSI для постановки службы, связанной с blob, не поддерживается.

Вот примеропределения активности копирования с свойствами, описанными в предыдущей таблице:

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

### <a name="staged-copy-billing-impact"></a>Принцип выставления счетов за промежуточное копирование

Плата взимается на основе двух этапов: продолжительность копирования и тип копирования.

* При использовании постановки во время облачной копии, которая копирует данные из облачного хранилища данных в другой магазин облачных данных, оба этапа, наделенные временем выполнения интеграции Azure, с вас взимается «сумма продолжительности копирования для шага 1 и шага 2» х «цена единицы облачной копии».
* При использовании постановки во время гибридной копии, которая копирует данные из собственного хранилища данных в хранилище облачных данных, на одном этапе, наделенный самоходной интеграцией, с вас взимается плата за «гибридную продолжительность копирования» x «гибридная цена единицы копирования» и «цена облачной копии» x «цена единицы облачной копии».

## <a name="next-steps"></a>Дальнейшие действия
Смотрите другие статьи деятельности копирования:

- [Общие сведения о действии копирования](copy-activity-overview.md)
- [Копирование руководства по производительности и масштабируемости](copy-activity-performance.md)
- [Производительность действия копирования troubleshoot](copy-activity-performance-troubleshooting.md)
- [Используйте фабрику данных Azure для переноса данных из озера данных или хранилища данных в Azure](data-migration-guidance-overview.md)
- [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)