---
title: Настройка преобразования приемника в функции потока данных сопоставления фабрики данных Azure
description: Узнайте, как настроить преобразование приемника в потоке данных сопоставления.
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: fa6a2fd853673493c93dbe65f889468c8e0c8617
ms.sourcegitcommit: a22cb7e641c6187315f0c6de9eb3734895d31b9d
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/14/2019
ms.locfileid: "74082930"
---
# <a name="sink-transformation-for-a-data-flow"></a>Преобразование приемника для потока данных

После преобразования потока данных можно передать данные в целевой набор данных. В преобразовании «приемник» выберите определение набора данных для выходных данных назначения. Можно использовать столько преобразований приемника, сколько требуется для потока данных.

Чтобы учитывать отклонение схемы и изменения во входящих данных, следует отменять выходные данные в папку без определенной схемы в выходном наборе данных. Можно также учитывать изменения столбцов в источниках, выбрав параметр **Разрешить смещение схемы** в источнике. Затем автоматическое сопоставление все поля в приемнике.

![Параметры на вкладке "приемник", включая параметр "автоматическое отображение"](media/data-flow/sink1.png "приемник 1")

Чтобы включить в приемник все входящие поля, включите **Автоподбор**. Чтобы выбрать поля для приемника в назначении или изменить имена полей в назначении, отключите **автокарту**. Затем откройте вкладку **сопоставление** , чтобы сопоставить поля выходных данных.

![Параметры на вкладке "сопоставление"](media/data-flow/sink2.png "приемник 2")

## <a name="output"></a>Выходные данные 
Для хранилища BLOB-объектов Azure или типов приемников Data Lake Storage выводит преобразованные данные в папку. Spark создает секционированные файлы выходных данных на основе схемы секционирования, которую использует преобразование «приемник». 

Схему секционирования можно задать на вкладке « **Оптимизация** ». Если требуется объединить выходные данные в один файл фабрикой данных, выберите **один раздел**. Если вы хотите поддерживать или создавать секционированные папки, используйте **секционирование ключей** и задайте ключи, которые следует использовать для структурированных структур папок.

![Параметры на вкладке "оптимизация"](media/data-flow/opt001.png "параметры приемника")

## <a name="field-mapping"></a>Сопоставление полей
На вкладке **сопоставление** преобразования «приемник» можно сопоставить входящие столбцы слева и места назначения справа. При передаче потоков данных в файлы фабрика данных всегда будет записывать новые файлы в папку. При сопоставлении с набором данных можно выбрать параметры операции таблицы базы данных для вставки, обновления, Upsert или удаления.

![Вкладка «Сопоставление»](media/data-flow/sink2.png "Приемники")

В таблице сопоставлений можно выполнить множественный выбор, чтобы связать несколько столбцов, отсоединить несколько столбцов или сопоставить несколько строк с одним и тем же именем столбца.

Чтобы всегда сопоставлять входящий набор полей целевому объекту, так как они и полностью принимают гибкие определения схемы, установите флажок **Разрешить смещение схемы**.

![Вкладка "сопоставление", отображающая поля, сопоставленные со столбцами в наборе данных](media/data-flow/multi1.png "несколько параметров")

Чтобы сбросить сопоставления столбцов, выберите **повторно сопоставить**.

![Вкладка "приемник"](media/data-flow/sink1.png "Один приемник")

Выберите **проверить схему** для сбоя приемника при изменении схемы.

Выберите **Очистить папку** , чтобы усечь содержимое папки приемника перед записью конечных файлов в эту целевую папку.

## <a name="fixed-mapping-vs-rule-based-mapping"></a>Фиксированное сопоставление и сопоставление на основе правил
При отключении автоматического сопоставления можно добавить сопоставление на основе столбцов (фиксированное сопоставление) или сопоставление на основе правил. Сопоставление на основе правил позволяет писать выражения с сопоставлением шаблонов, в то время как фиксированное сопоставление будет сопоставлять логические и физические имена столбцов.

![Сопоставление на основе правил](media/data-flow/rules4.png "Сопоставление на основе правил")

При выборе сопоставления на основе правил вы указываете ADF, что необходимо оценить выражение сопоставления, чтобы оно соответствовало входящим правилам шаблона, и определить имена исходящих полей. Вы можете добавить любое сочетание сопоставлений полей и на основе правил. Затем имена полей создаются в среде выполнения ADF на основе входящих метаданных из источника. Имена созданных полей можно просмотреть во время отладки и с помощью панели предварительного просмотра данных.

Подробные сведения о сопоставлении шаблонов см. в [документации по шаблону столбцов](concepts-data-flow-column-pattern.md).

Можно также вводить шаблоны регулярных выражений при использовании сопоставления на основе правил путем расширения строки и ввода регулярного выражения рядом с "совпадений имен:".

![Сопоставление регулярного выражения](media/data-flow/scdt1g4.png "Сопоставление регулярного выражения")

Самым простым распространенным примером сопоставления на основе правил и фиксированного сопоставления является случай, когда необходимо сопоставить все входящие поля с одним и тем же именем в целевом объекте. В случае фиксированных сопоставлений необходимо перечислить каждый отдельный столбец в таблице. Для сопоставления на основе правил можно использовать одно правило, которое сопоставляет все поля, используя ```true()```, с одним и тем же именем входящего поля, представленного ```$$```.

### <a name="sink-association-with-dataset"></a>Ассоциация приемника с набором данных

Набор данных, выбранный для приемника, может иметь или не иметь схему, определенную в определении набора данных. Если у него нет определенной схемы, необходимо разрешить отклонение схемы. При определении фиксированного сопоставления сопоставление логических и физических имен будет сохраняться в преобразовании приемника. Если изменить определение схемы набора данных, вы потенциально нарушите сопоставление приемника. Чтобы избежать этого, используйте сопоставление на основе правил. Сопоставления на основе правил являются обобщенными, то есть изменения схемы в наборе данных не приводят к нарушению сопоставления.

## <a name="file-name-options"></a>Параметры имени файла

Настройка именования файлов: 

   * **По умолчанию**: разрешить Spark использовать имена файлов на основе параметров по умолчанию.
   * **Шаблон**: введите шаблон для выходных файлов. Например, **займы [n]** будут создавать loans1. csv, loans2. csv и т. д.
   * **Для каждой секции**: введите одно имя файла для каждой секции.
   * **Как данные в столбце**: задайте для выходного файла значение столбца.
   * **Вывод в один файл**. Если выбран этот параметр, ADF объединит секционированные выходные файлы в один именованный файл. Для использования этого параметра набор данных должен быть разрешен в имя папки. Кроме того, имейте в виду, что эта операция слияния может завершиться сбоем в зависимости от размера узла.

> [!NOTE]
> Файловые операции запускаются только при выполнении действия потока выполнение данных. Они не запускаются в режиме отладки потока данных.

## <a name="database-options"></a>Параметры базы данных

Выберите параметры базы данных:

![Вкладка "Параметры", в которой отображаются параметры приемника SQL](media/data-flow/alter-row2.png "Параметры SQL")

* **Метод Update**: по умолчанию разрешены вставки. Снимите флажок **Разрешить вставку** , если требуется запретить вставку новых строк из источника. Чтобы обновить, Upsert или удалить строки, сначала добавьте преобразование «изменение строк» для добавления тегов к строкам для этих действий. 
* **Повторное создание таблицы**: удалите или создайте целевую таблицу перед завершением потока данных.
* **TRUNCATE TABLE**: удалить все строки из целевой таблицы до завершения потока данных.
* **Размер пакета**: введите число, записываемое в сегмент, в фрагменты. Используйте этот параметр для загрузки больших данных. 
* **Включить промежуточное хранение**. Используйте polybase при загрузке хранилища данных Azure в качестве набора данных приемника.
* **Пред-и POST-скрипты SQL**: введите многострочные скрипты SQL, которые будут выполняться до (Предварительная обработка) и после чего в базу данных приемника записываются данные (после обработки).

![пред и POST скрипты обработки SQL](media/data-flow/prepost1.png "Скрипты обработки SQL")

> [!NOTE]
> В потоке данных можно направить фабрику данных для создания нового определения таблицы в целевой базе данных. Чтобы создать определение таблицы, установите набор данных в преобразовании «приемник» с новым именем таблицы. В наборе данных SQL под именем таблицы выберите **изменить** и введите новое имя таблицы. Затем в преобразовании приемника включите параметр **Разрешить смещение схемы**. Задайте для параметра **импортировать схему** значение **нет**.

![Параметры набора данных SQL, в котором показано, где можно изменить имя таблицы](media/data-flow/dataset2.png "Схема SQL")

> [!NOTE]
> При обновлении или удалении строк в приемнике базы данных необходимо задать ключевой столбец. Этот параметр позволяет преобразованию «изменение строки» определить уникальную строку в библиотеке перемещения данных (DML).

### <a name="cosmosdb-specific-settings"></a>Специальные параметры CosmosDB

При размещении данных в CosmosDB необходимо учитывать следующие дополнительные параметры:

* Ключ раздела: это обязательное поле. Введите строку, представляющую ключ секции для коллекции. Пример: ```/movies/title```
* Пропускная способность. задайте необязательное значение для числа RUs, которое вы хотите применить к коллекции CosmosDB для каждого выполнения этого потока данных. Минимум — 400.

## <a name="next-steps"></a>Дополнительная информация
Теперь, когда вы создали поток данных, добавьте [в конвейер действие потока данных](concepts-data-flow-overview.md).
