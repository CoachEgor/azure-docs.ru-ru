---
title: Настройка преобразования приемника в функции сопоставления потока данных фабрики данных Azure
description: Узнайте, как настроить преобразование приемника в сопоставление потока данных.
author: kromerm
ms.author: makromer
ms.service: data-factory
ms.topic: conceptual
ms.date: 02/03/2019
ms.openlocfilehash: 4341cbb0e24330d535f5211c088f0068eab33af7
ms.sourcegitcommit: 1fbc75b822d7fe8d766329f443506b830e101a5e
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/14/2019
ms.locfileid: "65596264"
---
# <a name="sink-transformation-for-a-data-flow"></a>Приемник преобразования потока данных

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

После преобразования потока данных в целевой набор данных можно получить данные. В преобразовании приемника выберите определение набора данных для назначения выходных данных. Возможно, как многие приемника преобразований, как требует потока данных.

Для учетной записи для смещение схемы, а также изменения в входящих данных приемника выходных данных в папку без определенной схемы в выходной набор данных. Можно также учесть изменения столбцов в источниках, выбрав **разрешить смещение схемы** в источнике. Затем все автоматическое сопоставление полей в приемнике.

![Параметры на вкладке "приемник", т. ч. карты автоматически](media/data-flow/sink1.png "приемника 1")

Принять все входящие поля, включите **карты автоматически**. Чтобы выбрать поля для передачи в место назначения или изменить имена полей в месте назначения, отключите **карты автоматически**. Затем откройте **сопоставление** tab, чтобы сопоставить поля вывода.

![Параметры на вкладке «Сопоставление»](media/data-flow/sink2.png "приемника 2")

## <a name="output"></a>Выход 
Для типов в качестве приемника хранилище Data Lake или хранилище BLOB-объектов Azure вывода преобразованные данные в папку. Spark создает файлы данных секционированные выходные данные, на основе схемы секционирования, используемого в качестве приемника. 

Можно задать схему секционирования из **оптимизировать** вкладки. Фабрики данных для объединения выходных данных в один файл, выберите **один раздел**.

![Параметры на вкладке оптимизировать](media/data-flow/opt001.png "приемника параметры")

## <a name="field-mapping"></a>Сопоставление полей

На **сопоставление** вкладка приемника преобразований, можно сопоставить входящие столбцы в левой части назначения в правой части. Когда приемник потоки данных к файлам, фабрики данных всегда записывать новые файлы в папку. При подключении к набору данных базы данных, можно создать новую таблицу, которая использует эту схему, задав **сохранить политику** для **перезаписать**. Или вставлять новые строки в существующую таблицу, а затем сопоставить поля с существующей схемы. 

![На вкладке Сопоставление](media/data-flow/sink2.png "приемники")

В таблице сопоставлений можно множественный выбор, чтобы связать несколько столбцов, удаляют ссылки на несколько столбцов или сопоставить несколько строк, то же имя столбца.

Всегда сопоставить входящий набор полей к целевому объекту и полностью принимать определения гибкой схемой, выберите **разрешить смещение схемы**.

![На вкладке сопоставления, показывающая поля сопоставляются со столбцами в наборе данных](media/data-flow/multi1.png "несколько вариантов")

Чтобы сбросить сопоставления столбцов, выберите **повторного сопоставления**.

![Вкладка приемника](media/data-flow/sink1.png "один приемник")

Выберите **проверки схемы** ошибкой приемника в том случае, если изменения схемы.

Выберите **очистить папку** усекаемое содержимое папки приемника перед записью конечные файлы в этой целевой папке.

## <a name="file-name-options"></a>Параметры имени файла

Настройка имени файла: 

   * **По умолчанию**: Разрешите Spark к файлам имя на основе ЧАСТИ по умолчанию.
   * **Шаблон**: Ввести шаблон для выходных файлов. Например **loans [n]** создаст loans1.csv loans2.csv и т. д.
   * **На каждую секцию**: Введите одно имя файла на секцию.
   * **Как данные в столбце**: Выходной файл присвоено значение столбца.
   * **Выходные данные в один файл**: В этом случае ADF объединит секционированные выходные файлы в один с именем файла. Чтобы использовать этот параметр, набор данных следует разрешить имя папки. Кроме того Имейте в виду, что эта операция слияния могут отказать зависимости от размера узла.

> [!NOTE]
> Файл запуска операции только в том случае, если вы используете действие выполнения потока данных. Они не запускаются в режим отладки данных потока.

## <a name="database-options"></a>Параметры базы данных

Выберите параметры базы данных.

* **Обновите метод**: Значение по умолчанию — разрешить операции вставки. Очистить **разрешить insert** Если вы хотите отказаться от вставки новых строк из источника. Для обновления, upsert или delete строки, сначала добавьте преобразование строки alter тег строки для этих действий. 
* **Повторное создание таблицы**: Удалите или создайте целевой таблицы, до завершения потока данных.
* **Усечение таблицы**: Удалите все строки из целевой таблицы до завершения потока данных.
* **Размер пакета**. Введите число для разделения операций записи на блоки. Используйте этот параметр для больших объемов данных. 
* **Включить промежуточный режим**: При загрузке как набор данных в качестве приемника хранилище данных Azure с помощью PolyBase.

![На вкладке "Параметры", отображающий пункты приемника SQL](media/data-flow/alter-row2.png "параметры SQL")

> [!NOTE]
> В поток данных можно направить фабрики данных, чтобы создать новое определение таблицы в целевой базе данных. Чтобы создать определение таблицы, задайте набор данных в приемник преобразование, которое имеет имя новой таблицы. В наборе данных SQL, под именем таблицы, выберите **изменить** и введите новое имя таблицы. После этого в преобразовании приемника, включите **разрешить смещение схемы**. Задайте **Импорт схемы** для **None**.

![Параметры набора данных SQL, показывающий, где можно изменить имя таблицы](media/data-flow/dataset2.png "SQL схемы")

> [!NOTE]
> При обновлении или удалении строк в приемник вашей базы данных, необходимо задать ключевой столбец. Этот параметр позволяет преобразовывать строку alter для определения уникальных строк в библиотеке перемещения данных (DML).

## <a name="next-steps"></a>Дальнейшие действия

Теперь, после создания потока данных, добавить [действие потока данных в ваш конвейер](concepts-data-flow-overview.md).
