---
title: Сопоставление потоков данных
description: Обзор картографических потоков данных в Azure Data Factory
author: kromerm
ms.author: makromer
ms.reviewer: daperlov
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 01/28/2020
ms.openlocfilehash: 39d1f15b771168b618bfbc4951f2036a8b95b027
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81418462"
---
# <a name="what-are-mapping-data-flows"></a>Сведения о сопоставлении потоков данных

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Потоки картданных данных визуально разработаны преобразованиями данных в Azure Data Factory. Потоки данных позволяют инженерам обработки графических данных развивать логику преобразования данных без написания кода. Полученные потоки данных выполняются как действия в конвейерах Azure Data Factory, которые используют масштабированные кластеры Apache Spark. Действия потока данных могут быть задействованы через существующие возможности планирования, управления, потока и мониторинга Data Factory.

Потоки картографических данных обеспечивают совершенно визуальный опыт без необходимости кодирования. Потоки данных работают в кластере выполнения для масштабирования обработки данных. Фабрика данных Azure обрабатывает весь перевод кода, оптимизацию путей и выполнение заданий потока данных.

## <a name="getting-started"></a>Начало работы

Чтобы создать поток данных, выберите знак плюс под **заводскими ресурсами,** а затем выберите **поток данных.** 

![Новый поток данных](media/data-flow/newdataflow2.png "новый поток данных")

Это действие приведет вас к холсту потока данных, где можно создать логику преобразования. Выберите **источник добавления,** чтобы начать настройку преобразования источника. Для получения дополнительной информации [см.](data-flow-source.md)

## <a name="data-flow-canvas"></a>Полотно потока данных

Холст потока данных разделен на три части: верхнюю панель, график и панель конфигурации. 

![Canvas](media/data-flow/canvas1.png "Canvas")

### <a name="graph"></a>График

График отображает поток преобразования. Он показывает линию исходных данных, как она впадает в один или несколько раковин. Чтобы добавить новый источник, выберите **Источник Добавления.** Чтобы добавить новую трансформацию, выберите знак плюс в правом нижнем правом существующего преобразования.

![Canvas](media/data-flow/canvas2.png "Canvas")

### <a name="azure-integration-runtime-data-flow-properties"></a>Свойства потока потоков времени выполнения интеграции Azure

![Кнопка отладки](media/data-flow/debugbutton.png "Кнопка отладки")

Когда вы начинаете работать с потоками данных в ADF, вы хотите включить переключатель "Debug" для потоков данных в верхней части интерфейса браузера. Это вращает кластер Spark для использования для интерактивной отладки, предварительных просмотров данных и выполнения отладки конвейеров. Размер кластера можно установить, выбрав пользовательское [время интеграции Azure Runtime.](concepts-integration-runtime.md) Сеанс отладки остается в живых до 60 минут после предварительного просмотра данных или последнего выполнения конвейера.

При эксплуатации конвейеров с помощью действий потока данных ADF использует время интеграции Azure, связанное с [действием](control-flow-execute-data-flow-activity.md) в свойстве "Run On".

Время интеграции Azure по умолчанию — это небольшой кластер одного рабочего узла, который позволяет просматривать данные и быстро выполнять отладки конвейеров при минимальных затратах. Установите более широкую иС-конфигурацию Azure, если вы выполняете операции против больших наборов данных.

Можно поручить ADF поддерживать пул кластерных ресурсов (ВМ) путем установки TTL в свойствах иК-потока данных Azure. Это действие приводит к более быстрому выполнению задания на последующих действиях.

#### <a name="azure-integration-runtime-and-data-flow-strategies"></a>Стратегии интеграции Azure и потоков данных

##### <a name="execute-data-flows-in-parallel"></a>Выполнение потоков данных параллельно

При параллельном выполнении потоков данных в конвейере ADF подкручивает отдельные кластеры Spark для каждого выполнения действия на основе параметров в вашем времени интеграции Azure, прикрепленных к каждому действию. Для разработки параллельных выполнения в конвейерах ADF добавьте действия потока данных без ограничений в доступе к доступу.

Из этих трех вариантов этот параметр, вероятно, выполняется в кратчайшие сроки. Однако каждый параллельный поток данных выполняется одновременно на отдельных кластерах, поэтому порядок событий не детерминирован.

Если вы параллельно проводите действия потока данных внутри конвейеров, рекомендуется не использовать TTL. Это действие связано с тем, что параллельные выполнения потока данных одновременно с использованием одного и того же Runtime интеграции Azure приводит к нескольким экземплярам теплого пула для фабрики данных.

##### <a name="overload-single-data-flow"></a>Перегрузка одного потока данных

Если вы помещаете всю логику в единый поток данных, ADF выполняет тот же контекст выполнения задания в одном экземпляре кластера Spark.

Этот вариант может быть более сложным для подражания и устранения неполадок, потому что ваши бизнес-правила и бизнес-логика могут быть перемешаны вместе. This option also doesn't provide much reusability.

##### <a name="execute-data-flows-serially"></a>Выполнение потоков данных последовательно

Если вы выполняете действия потока данных в сериале в конвейере и устанавливается TTL в конфигурации ИК Azure, aDF повторно использует вычислительные ресурсы (VM), что приводит к более быстрому последующему выполнению. Вы по-прежнему получаете новый контекст Spark для каждого выполнения.

Из этих трех вариантов это действие, вероятно, занимает самое длительное время для выполнения сквозного. Но это обеспечивает четкое разделение логических операций на каждом этапе потока данных.

### <a name="configuration-panel"></a>Конфигурационная панель

Панель конфигурации показывает параметры, характерные для выбранной в настоящее время преобразования. Если преобразование не выбрано, он показывает поток данных. В общей конфигурации потока данных можно отсечь имя и описание под вкладкой **General** или добавить параметры через вкладку **Параметры.** Для получения дополнительной [информации](parameters-data-flow.md)см.

Каждое преобразование содержит по крайней мере четыре вкладки конфигурации.

#### <a name="transformation-settings"></a>Настройки преобразования

Первая вкладка в панели конфигурации каждой трансформации содержит параметры, характерные для этого преобразования. Для получения дополнительной информации смотрите страницу документации преобразования.

![Вкладка настройки источника](media/data-flow/source1.png "Вкладка настройки источника")

#### <a name="optimize"></a>Оптимизация

Вкладка **Optimize** содержит настройки для настройки схем раздела.

![Оптимизировать](media/data-flow/optimize1.png "Оптимизация")

Параметр по умолчанию — это **использование текущего раздела,** который поручает фабрике данных Azure использовать схему раздела, родную для потоков данных, работающих в Spark. В большинстве сценариев мы рекомендуем эту настройку.

Есть случаи, когда можно настроить раздел. Например, если требуется вывести преобразования в один файл в озере, выберите **единую разделвительную в преобразовании** раковины.

Другой случай, когда можно контролировать схемы раздела, — это оптимизация производительности. Корректировка раздела обеспечивает контроль над распределением данных по вычислительным узлам и оптимизацией локальности данных, что может оказать как положительное, так и отрицательное влияние на общую производительность потока данных. Для получения дополнительной [Data flow performance guide](concepts-data-flow-performance.md)информации см.

Чтобы изменить раздел при любом преобразовании, выберите вкладку **«Оптимизация»** и выберите радиокнопку **«Установка раздела».** Вам предоставляется ряд вариантов раздела. Лучший метод раздела отличается в зависимости от объемов данных, ключей кандидата, нулевых значений и кардинальности. 

Наилучшей практикой является начало с раздела по умолчанию, а затем попробуйте различные варианты раздела. Можно протестировать с помощью отладки конвейера и просмотра времени выполнения и использования раздела в каждой группе преобразования из представления мониторинга. Для получения дополнительной информации [см.](concepts-data-flow-monitoring.md)

Доступны следующие варианты раздела.

##### <a name="round-robin"></a>Круглый Робин 

Круглый малиновка представляет собой простую перегородку, которая автоматически распределяет данные поровну по разделам. Используйте круговой, когда у вас нет хороших ключевых кандидатов для реализации надежной, разумной стратегии раздела. Вы можете задать количество физических секций.

##### <a name="hash"></a>Хэш

Azure Data Factory производит хэш столбцов для создания однородных разделов, так что строки с аналогичными значениями попадают в один и тот же раздел. При использовании опции Hash проверьте возможный перекос раздела. Вы можете задать количество физических секций.

##### <a name="dynamic-range"></a>Динамический диапазон

Динамический диапазон использует динамические диапазоны Spark на основе столбцов или выражений, которые вы предоставляете. Вы можете задать количество физических секций. 

##### <a name="fixed-range"></a>Фиксированный диапазон

Создайте выражение, обеспечивающее фиксированный диапазон значений в столбцах разделенных данных. Чтобы избежать перекоса раздела, вы должны иметь хорошее понимание ваших данных, прежде чем использовать эту опцию. Значения, вводимые для выражения, используются как часть функции раздела. Вы можете задать количество физических секций.

##### <a name="key"></a>Клавиши

Если у вас есть хорошее понимание кардинальности ваших данных, ключевым разделом может быть хорошая стратегия. Ключевое разгородка создает разделы для каждого уникального значения в столбце. Вы не можете установить количество разделов, поскольку число основано на уникальных значениях в данных.

#### <a name="inspect"></a>Изучение

Вкладка **Inspect** предоставляет представление в метаданные потока данных, которые вы преобразуете. Можно увидеть количество столбцов, измененные столбцы, добавленные столбцы, типы данных, порядок столбцов и ссылки столбцов. **Inspect** — это только для чтения представление ваших метаданных. Для просмотра метаданных в панели **inspect** не требуется режим отладки.

![Проверить](media/data-flow/inspect1.png "Изучение")

При изменении формы данных с помощью преобразований вы увидите поток изменений метаданных в панели **inspect.** Если в преобразовании исходного кода нет определенной схемы, то метаданные не будут видны в панели **inspect.** Отсутствие метаданных распространено в сценариях дрейфа схем.

#### <a name="data-preview"></a>Предварительный просмотр данных

Если режим отладки в режиме, вкладка **Data Preview** дает вам интерактивный снимок данных при каждом преобразовании. Для получения дополнительной информации смотрите [предварительный просмотр данных в режиме отладки.](concepts-data-flow-debug-mode.md#data-preview)

### <a name="top-bar"></a>Верхняя панель

Верхняя панель содержит действия, влияющие на весь поток данных, такие как сохранение и проверка. Вы также можете переключаться между режимами графика и конфигурации с помощью кнопок **Show Graph** и **Hide Graph.**

![Скрытие графика](media/data-flow/hideg.png "Скрытие графика")

Если вы скрываете свой график, вы можете просматривать ваши узлы преобразования боковой через **Предыдущие** и **Следующие** кнопки.

![Предыдущие и следующие кнопки](media/data-flow/showhide.png "предыдущие и следующие кнопки")

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как создать [преобразование источника.](data-flow-source.md)
* Узнайте, как построить потоки данных в [режиме отладки.](concepts-data-flow-debug-mode.md)
