---
title: Сопоставление потоков данных
description: Обзор картографических потоков данных в Azure Data Factory
author: kromerm
ms.author: makromer
ms.reviewer: daperlov
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 12/19/2019
ms.openlocfilehash: 210c1814325e689dd70af9caa7fad08deed933e1
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79243800"
---
# <a name="what-are-mapping-data-flows"></a>Сведения о сопоставлении потоков данных

Потоки картданных данных визуально разработаны преобразованиями данных в Azure Data Factory. Потоки данных позволяют инженерам обработки графических данных развивать логику преобразования данных без написания кода. Полученные потоки данных выполняются как действия в конвейерах Azure Data Factory, которые используют кластеры spark с масштабом. Деятельность потока данных может быть оперативной через существующие возможности планирования, управления, потока и мониторинга Data Factory.

Потоки картографических данных обеспечивают полностью визуальный опыт без необходимости кодирования. Потоки данных будут работать в вашем собственном кластере выполнения для масштабирования обработки данных. Фабрика данных Azure обрабатывает весь перевод кода, оптимизацию путей и выполнение заданий потока данных.

## <a name="getting-started"></a>Начало работы

Чтобы создать поток данных, выберите знак плюс под **заводскими ресурсами,** а затем выберите **поток данных.** 

![Новый поток данных](media/data-flow/newdataflow2.png "новый поток данных")

Это приведет вас к холсту потока данных, где можно создать логику преобразования. Выберите **источник добавления,** чтобы начать настройку преобразования источника. Для получения дополнительной информации [см.](data-flow-source.md)

## <a name="data-flow-canvas"></a>Полотно потока данных

Холст потока данных разделен на три части: верхнюю панель, график и панель конфигурации. 

![Canvas](media/data-flow/canvas1.png "Canvas")

### <a name="graph"></a>График

График отображает поток преобразования. Он показывает линию исходных данных, как она впадает в один или несколько раковин. Чтобы добавить новый источник, выберите **Источник Добавления.** Чтобы добавить новую трансформацию, выберите знак плюс в правом нижнем правом существующего преобразования.

![Canvas](media/data-flow/canvas2.png "Canvas")

### <a name="azure-integration-runtime-data-flow-properties"></a>Свойства потока потоков времени выполнения интеграции Azure

![Кнопка отладки](media/data-flow/debugbutton.png "Кнопка отладки")

Когда вы начнете работать с потоками данных в ADF, вы хотите включить переключатель "Debug" для потоков данных в верхней части интерфейса браузера. Это позволит создать кластер Azure Databricks для интерактивной отладки, предварительного просмотра данных и выполнения отладок конвейеров. Размер кластера можно установить, выбрав пользовательское [время интеграции Azure Runtime.](concepts-integration-runtime.md) Сеанс отладки будет оставаться в живых до 60 минут после предварительного просмотра данных или последнего выполнения конвейера.

При эксплуатации конвейеров с помощью действий потока данных ADF будет использовать время интеграции Azure, связанное с [действием](control-flow-execute-data-flow-activity.md) в свойстве "Run On".

Время интеграции Azure по умолчанию — это небольшой кластер одного рабочего узла, предназначенный для просмотра данных и быстрого выполнения отладочных конвейеров при минимальных затратах. Установите более широкую иС-конфигурацию Azure, если вы выполняете операции против больших наборов данных.

Можно поручить ADF поддерживать пул кластерных ресурсов (ВМ) путем установки TTL в свойствах иК-потока данных Azure. Это приведет к более быстрому выполнению задания в последующих действиях.

#### <a name="azure-integration-runtime-and-data-flow-strategies"></a>Стратегии интеграции Azure и потоков данных

##### <a name="execute-data-flows-in-parallel"></a>Выполнение потоков данных параллельно

При параллельном выполнении потоков данных в конвейере ADF будет объединять отдельные кластеры Azure Databricks для каждого выполнения деятельности на основе параметров в вашем времени выполнения интеграции Azure, прикрепленных к каждому действию. Для разработки параллельных выполнения в конвейерах ADF добавьте действия потока данных без ограничений в доступе к доступу.

Из этих трех вариантов этот вариант, скорее всего, будет выполняться в кратчайшие сроки. Однако каждый параллельный поток данных будет выполняться одновременно на отдельных кластерах, поэтому порядок событий не детерминирован.

Если вы параллельно проводите действия потока данных внутри конвейеров, рекомендуется не использовать TTL. Это связано с тем, что параллельные выполнения потоков данных одновременно с использованием одного и того же Runtime интеграции Azure приведет к нескольким экземплярам теплого пула для фабрики данных.

##### <a name="overload-single-data-flow"></a>Перегрузка одного потока данных

Если поместить всю логику в единый поток данных, ADF выполнит в этом же контексте выполнения задания в одном экземпляре кластера Spark.

Этот вариант может быть более трудным для подражания и устранения неполадок, потому что ваши бизнес-правила и бизнес-логика будут перемешать вместе. Этот параметр также не обеспечивает много повторного использования.

##### <a name="execute-data-flows-serially"></a>Выполнение потоков данных последовательно

Если вы выполняете действия потока данных в сериале в конвейере и устанавливается TTL в конфигурации ИК Azure, то ADF будет повторно использовать вычислительные ресурсы (VM), что приведет к более быстрому последующему выполнению. Вы по-прежнему получите новый контекст Spark для каждого выполнения.

Из этих трех вариантов это, скорее всего, займет больше времени для выполнения сквозного. Но это обеспечивает четкое разделение логических операций на каждом этапе потока данных.

### <a name="configuration-panel"></a>Конфигурационная панель

Панель конфигурации показывает параметры, характерные для выбранной в настоящее время преобразования. Если преобразование не выбрано, он показывает поток данных. В общей конфигурации потока данных можно отсечь имя и описание под вкладкой **General** или добавить параметры через вкладку **Параметры.** Для получения дополнительной [информации](parameters-data-flow.md)см.

Каждое преобразование имеет по крайней мере четыре вкладки конфигурации.

#### <a name="transformation-settings"></a>Настройки преобразования

Первая вкладка в панели конфигурации каждой трансформации содержит параметры, характерные для этого преобразования. Для получения дополнительной информации смотрите страницу документации преобразования.

![Вкладка настройки источника](media/data-flow/source1.png "Вкладка настройки источника")

#### <a name="optimize"></a>Оптимизация

Вкладка **Optimize** содержит настройки для настройки схем раздела.

![Оптимизировать](media/data-flow/optimize1.png "Оптимизация")

Параметр по умолчанию — это **использование текущего раздела,** который поручает фабрике данных Azure использовать схему раздела, родную для потоков данных, работающих в Spark. В большинстве сценариев мы рекомендуем эту настройку.

Есть случаи, когда можно настроить раздел. Например, если требуется вывести преобразования в один файл в озере, выберите **единую разделвительную в преобразовании** раковины.

Другой случай, когда можно контролировать схемы раздела, — это оптимизация производительности. Корректировка раздела обеспечивает контроль над распределением данных по вычислительным узлам и оптимизацией локальности данных, что может оказать как положительное, так и отрицательное влияние на общую производительность потока данных. Для получения дополнительной [Data flow performance guide](concepts-data-flow-performance.md)информации см.

Чтобы изменить раздел при любом преобразовании, выберите вкладку **«Оптимизация»** и выберите радиокнопку **«Установка раздела».** Затем вам будет представлен ряд вариантов раздела. Лучший метод раздела будет отличаться в зависимости от объема данных, ключей кандидата, нулевых значений и кардинальности. 

Наилучшей практикой является начало с раздела по умолчанию, а затем попробуйте различные варианты раздела. Можно протестировать с помощью отладки конвейера и просмотра времени выполнения и использования раздела в каждой группе преобразования из представления мониторинга. Для получения дополнительной информации [см.](concepts-data-flow-monitoring.md)

Доступны следующие варианты раздела.

##### <a name="round-robin"></a>Круглый Робин 

Круглый малиновка представляет собой простую перегородку, которая автоматически распределяет данные поровну по разделам. Используйте круглый малиновку, когда у вас нет хороших ключевых кандидатов для реализации надежной, разумной стратегии раздела. Вы можете задать количество физических секций.

##### <a name="hash"></a>Хэш

Фабрика данных Azure создает хэш столбцов, чтобы получить равномерное распределение секций, и при этом строки со сходными значениями попадут в одну секцию. При использовании опции Hash проверьте возможный перекос раздела. Вы можете задать количество физических секций.

##### <a name="dynamic-range"></a>Динамический диапазон

Динамический диапазон будет использовать динамические диапазоны Spark на основе столбцов или выражений, которые вы предоставляете. Вы можете задать количество физических секций. 

##### <a name="fixed-range"></a>Фиксированный диапазон

Создайте выражение, обеспечивающее фиксированный диапазон значений в столбцах разделенных данных. Чтобы избежать перекоса раздела, вы должны иметь хорошее понимание ваших данных, прежде чем использовать эту опцию. Значения, вводимые для выражения, будут использоваться как часть функции раздела. Вы можете задать количество физических секций.

##### <a name="key"></a>Ключ

Если у вас есть хорошее понимание кардинальности ваших данных, ключевым разделом может быть хорошая стратегия. При секционировании по ключу создаются секции для каждого уникального значения в столбце. Вы не можете установить количество разделов, потому что число будет основано на уникальных значениях в данных.

#### <a name="inspect"></a>Изучение

Вкладка **Inspect** предоставляет представление в метаданные потока данных, которые вы преобразуете. Можно увидеть количество столбцов, измененные столбцы, добавленные столбцы, типы данных, заказы столбцов и ссылки столбцов. **Inspect** — это только для чтения представление ваших метаданных. Для просмотра метаданных в панели **inspect** не требуется режим отладки.

![Проверить](media/data-flow/inspect1.png "Изучение")

При изменении формы данных с помощью преобразований вы увидите поток изменений метаданных в панели **inspect.** Если в преобразовании исходного кода нет определенной схемы, то метаданные не будут видны в панели **inspect.** Отсутствие метаданных распространено в сценариях дрейфа схем.

#### <a name="data-preview"></a>Предварительный просмотр данных

Если режим отладки в режиме, вкладка **Data Preview** дает вам интерактивный снимок данных при каждом преобразовании. Для получения дополнительной информации смотрите [предварительный просмотр данных в режиме отладки.](concepts-data-flow-debug-mode.md#data-preview)

### <a name="top-bar"></a>Верхняя панель

Верхняя панель содержит действия, влияющие на весь поток данных, такие как сохранение и проверка. Вы также можете переключаться между режимами графика и конфигурации с помощью кнопок **Show Graph** и **Hide Graph.**

![Скрытие графика](media/data-flow/hideg.png "Скрытие графика")

Если вы скрываете свой график, вы можете просматривать ваши узлы преобразования боковой через **Предыдущие** и **Следующие** кнопки.

![Предыдущие и следующие кнопки](media/data-flow/showhide.png "предыдущие и следующие кнопки")

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как создать [преобразование источника.](data-flow-source.md)
* Узнайте, как построить потоки данных в [режиме отладки.](concepts-data-flow-debug-mode.md)
