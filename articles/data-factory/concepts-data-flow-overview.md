---
title: Сопоставление потоков данных
description: Общие сведения о сопоставлении потоков данных в фабрике данных Azure
author: kromerm
ms.author: makromer
ms.reviewer: daperlov
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 01/28/2020
ms.openlocfilehash: 9f280aafabd59878ee24a9c3fe809dd027a97284
ms.sourcegitcommit: 849bb1729b89d075eed579aa36395bf4d29f3bd9
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2020
ms.locfileid: "82187857"
---
# <a name="what-are-mapping-data-flows"></a>Сведения о сопоставлении потоков данных

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Сопоставление потоков данных — это визуально спроектированные преобразования данных в фабрике данных Azure. Потоки данных позволяют инженерам данных разрабатывать логику преобразования графических данных без написания кода. Результирующие потоки данных выполняются как действия в конвейерах фабрики данных Azure, использующие кластеры с горизонтальным масштабированием Apache Spark. Действия потока данных могут осуществляться через существующие возможности планирования фабрики данных, управления, потока и мониторинга.

Сопоставление потоков данных обеспечивает полностью визуальный интерфейс без необходимости написания кода. Потоки данных выполняются в кластере выполнения для обработки масштабируемых данных. Фабрика данных Azure обрабатывает все операции перевода кода, оптимизации пути и выполнения заданий потока данных.

## <a name="getting-started"></a>Начало работы

Чтобы создать поток данных, выберите знак "плюс" в разделе " **ресурсы фабрики**", а затем выберите **поток данных**. 

![Новый поток данных](media/data-flow/newdataflow2.png "новый поток данных")

Это действие выполняет переход к холсту потока данных, где можно создать логику преобразования. Выберите **Добавить источник** , чтобы начать настройку преобразования источника. Дополнительные сведения см. в разделе [Преобразование источника](data-flow-source.md).

## <a name="data-flow-canvas"></a>Холст потока данных

Холст потока данных разделяется на три части: Верхняя панель, диаграмма и панель конфигурации. 

![Canvas](media/data-flow/canvas1.png "Canvas")

### <a name="graph"></a>Graph

Граф отображает поток преобразования. Он показывает журнал преобразований источника данных по мере их последовательного в один или несколько приемников. Чтобы добавить новый источник, выберите **Добавить источник**. Чтобы добавить новое преобразование, выберите знак "плюс" в правом нижнем углу существующего преобразования.

![Canvas](media/data-flow/canvas2.png "Canvas")

### <a name="azure-integration-runtime-data-flow-properties"></a>Свойства потока данных среды выполнения интеграции Azure

![Кнопка отладки](media/data-flow/debugbutton.png "Кнопка отладки")

После начала работы с потоками данных в ADF необходимо включить параметр "Отладка" для потоков данных в верхней части пользовательского интерфейса браузера. Это позволяет использовать кластер Spark для интерактивной отладки, предварительного просмотра данных и выполнения отладки конвейера. Вы можете задать размер кластера, выбрав пользовательский [Azure Integration Runtime](concepts-integration-runtime.md). Сеанс отладки остается активным до 60 минут после последней предварительной версии данных или выполнения конвейера последней отладки.

Когда вы эксплуатацию конвейеры с действиями потока данных, ADF использует Azure Integration Runtime, связанный с [действием](control-flow-execute-data-flow-activity.md) в свойстве "Запуск в".

Azure Integration Runtime по умолчанию — небольшой кластер однорабочих узлов с четырьмя ядрами, который позволяет просматривать данные и быстро выполнять конвейеры отладки с минимальными затратами. Задайте более крупную конфигурацию Azure IR при выполнении операций с большими наборами данных.

Вы можете указать ADF-файл для поддержки пула ресурсов кластера (ВМ), установив TTL в Azure IR свойства потока данных. Это действие приводит к ускорению выполнения задания для последующих действий.

#### <a name="azure-integration-runtime-and-data-flow-strategies"></a>Среда выполнения интеграции Azure и стратегии потока данных

##### <a name="execute-data-flows-in-parallel"></a>Параллельное выполнение потоков данных

При параллельном выполнении потоков данных в конвейере ADF-файл начинает работать с отдельными кластерами Spark для каждого выполнения действия на основе параметров в Azure Integration Runtime, прикрепленных к каждому действию. Для разработки параллельных выполнений в конвейерах ADF добавьте в пользовательский интерфейс действия потока данных без ограничений очередностью.

Эти три параметра, скорее всего, будут выполняться в кратчайшее время. Однако каждый параллельный поток данных одновременно выполняется в разных кластерах, поэтому упорядочение событий не является детерминированным.

При параллельном запуске действий потока данных внутри конвейеров рекомендуется не использовать TTL. Это действие связано с тем, что параллельное выполнение потока данных с использованием одного и того же Azure Integration Runtime приводит к использованию нескольких экземпляров горячего пула для фабрики данных.

##### <a name="overload-single-data-flow"></a>Перегрузка одного потока данных

Если вся логика помещается в один поток данных, ADF выполняет тот же контекст выполнения задания в одном экземпляре кластера Spark.

Этот вариант может оказаться более трудным для выполнения и устранения неполадок, так как бизнес-правила и бизнес-логика могут быть жумблед вместе. Этот вариант также не обеспечивает существенного повторного использования.

##### <a name="execute-data-flows-sequentially"></a>Последовательно выполнять потоки данных

Если вы выполняете действия потока данных в последовательности в конвейере и установили TTL для конфигурации Azure IR, ADF будет повторно использовать вычислительные ресурсы (ВМ), что приведет к более быстрому последующему времени выполнения. Для каждого выполнения по-прежнему будет получен новый контекст Spark.

Из этих трех вариантов это действие, скорее всего, займет самое длинное время для выполнения сквозной операции. Но он обеспечивает четкое разделение логических операций на каждом шаге потока данных.

### <a name="configuration-panel"></a>Панель конфигурации

На панели конфигурация отображаются параметры, относящиеся к текущему выбранному преобразованию. Если преобразование не выбрано, то отображается поток данных. В общей конфигурации потока данных можно изменить имя и описание на вкладке **Общие** или добавить параметры с помощью вкладки **Параметры** . Дополнительные сведения см. в разделе [Сопоставление параметров потока данных](parameters-data-flow.md).

Каждое преобразование содержит по крайней мере четыре вкладки конфигурации.

#### <a name="transformation-settings"></a>Параметры преобразования

Первая вкладка в области конфигурации каждого преобразования содержит параметры, относящиеся к этому преобразованию. Дополнительные сведения см. на странице документации по преобразованию.

![Вкладка "Параметры источника"](media/data-flow/source1.png "Вкладка "Параметры источника"")

#### <a name="optimize"></a>Оптимизация

Вкладка **Оптимизация** содержит параметры для настройки схем секционирования.

![Увеличить](media/data-flow/optimize1.png "Оптимизация")

Значение по умолчанию — **использовать текущее секционирование**, которое указывает фабрике данных Azure использовать схему секционирования Native для потоков данных, выполняющихся в Spark. В большинстве случаев рекомендуется использовать этот параметр.

Существуют экземпляры, для которых может потребоваться изменить секционирование. Например, если вы хотите выводить преобразования в один файл в папке Lake, выберите **один раздел** в преобразовании приемника.

Другой случай, когда может потребоваться управлять схемами секционирования, — это оптимизация производительности. Настройка секционирования обеспечивает управление распределением данных между узлами вычислений и оптимизацией локализации данных, которые могут иметь как положительные, так и отрицательные последствия для общей производительности потока данных. Дополнительные сведения см. в разделе [Пошаговое руководств по производительности потока данных](concepts-data-flow-performance.md).

Чтобы изменить секционирование для любого преобразования, перейдите на вкладку **Оптимизация** и установите переключатель **задать секционирование** . Вы увидите ряд вариантов секционирования. Наилучший способ секционирования зависит от объема данных, потенциальных ключей, значений NULL и количества элементов. 

Рекомендуется начать с секционирования по умолчанию, а затем попробовать использовать другие параметры секционирования. Можно выполнять тестирование с помощью отладочных запусков конвейера и просматривать время выполнения и использование секций в каждой группе преобразования из представления мониторинга. Дополнительные сведения см. в разделе [наблюдение за потоками данных](concepts-data-flow-monitoring.md).

Доступны следующие параметры секционирования.

##### <a name="round-robin"></a>Циклический перебор 

Циклический перебор — это простая секция, которая автоматически распределяет данные между секциями. Используйте функцию циклического перебора, если у вас нет хороших ключевых кандидатов для реализации высокоплотной интеллектуальной стратегии секционирования. Вы можете задать количество физических секций.

##### <a name="hash"></a>Хэш

Фабрика данных Azure создает хэш столбцов для создания универсальных секций, в которых строки с одинаковыми значениями попадают в одну и ту же секцию. При использовании параметра hash проверьте возможное отклонение секций. Вы можете задать количество физических секций.

##### <a name="dynamic-range"></a>Динамический диапазон

Динамический диапазон использует динамические диапазоны Spark на основе предоставленных столбцов или выражений. Вы можете задать количество физических секций. 

##### <a name="fixed-range"></a>Фиксированный диапазон

Создайте выражение, которое предоставляет фиксированный диапазон значений в столбцах секционированных данных. Чтобы избежать смещения секций, перед использованием этого параметра следует хорошо понимать данные. Значения, вводимые для выражения, используются как часть функции секционирования. Вы можете задать количество физических секций.

##### <a name="key"></a>Клавиши

Если вы хорошо понимаете количество элементов данных, секционирование ключей может оказаться хорошей стратегией. Секционирование ключей создает секции для каждого уникального значения в столбце. Невозможно задать количество секций, так как число основано на уникальных значениях в данных.

#### <a name="inspect"></a>Изучение

На вкладке **Проверка** представлено представление метаданных потока данных, для которого выполняется преобразование. Можно увидеть количество столбцов, изменить столбцы, добавить столбцы, типы данных, порядок столбцов и ссылки на столбцы. **Проверка** — это представление метаданных, доступное только для чтения. Для просмотра метаданных в области **проверки** не нужно включать режим отладки.

![Проверить](media/data-flow/inspect1.png "Изучение")

При изменении формы данных с помощью преобразований в области **проверки** будут отображаться потоки изменений метаданных. Если в преобразовании источника не определена схема, метаданные не будут отображаться в области **проверки** . Отсутствие метаданных является распространенным в сценариях смещения схемы.

#### <a name="data-preview"></a>Предварительный просмотр данных

Если режим отладки включен, вкладка **Предварительный просмотр данных** предоставляет интерактивный моментальный снимок данных при каждом преобразовании. Дополнительные сведения см. [в разделе Предварительный просмотр данных в режиме отладки](concepts-data-flow-debug-mode.md#data-preview).

### <a name="top-bar"></a>Верхняя панель

Верхняя панель содержит действия, влияющие на весь поток данных, например сохранение и проверку. Можно также переключаться между режимами графика и конфигурации с помощью кнопок **Показать диаграмму** и **Скрыть граф** .

![Скрытие графика](media/data-flow/hideg.png "Скрытие графика")

Если скрыть диаграмму, вы сможете просматривать узлы преобразования позже с помощью кнопок **назад** и **Далее** .

![Кнопки «назад» и «далее»](media/data-flow/showhide.png "кнопки «назад» и «далее»")

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как создать [Преобразование источника](data-flow-source.md).
* Узнайте, как создавать потоки данных в [режиме отладки](concepts-data-flow-debug-mode.md).
