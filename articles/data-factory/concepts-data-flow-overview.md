---
title: Сопоставление потоков данных в фабрике данных Azure
description: Общие сведения о сопоставлении потоков данных в фабрике данных Azure
author: kromerm
ms.author: makromer
ms.reviewer: daperlov
ms.service: data-factory
ms.topic: conceptual
ms.date: 10/7/2019
ms.openlocfilehash: ed2502ffebbacf5e66e3e4738e2e88ce7fb8a562
ms.sourcegitcommit: 609d4bdb0467fd0af40e14a86eb40b9d03669ea1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/06/2019
ms.locfileid: "73681559"
---
# <a name="what-are-mapping-data-flows"></a>Что такое потоки данных сопоставления?

Сопоставление потоков данных — это визуально спроектированные преобразования данных в фабрике данных Azure. Потоки данных позволяют инженерам данных разрабатывать логику преобразования графических данных без написания кода. Результирующие потоки данных выполняются в виде действий в конвейерах фабрики данных Azure, использующих масштабируемые кластеры Spark. Действия потока данных могут быть реализованы с помощью существующих возможностей планирования фабрики данных, управления, потоков и мониторинга.

Сопоставление потоков данных обеспечивает полностью визуальный интерфейс без необходимости написания кода. Потоки данных будут выполняться в собственном кластере выполнения для обработки масштабируемых данных. Фабрика данных Azure обрабатывает все операции перевода кода, оптимизации пути и выполнения заданий потока данных.

## <a name="getting-started"></a>Приступая к работе

Чтобы создать поток данных, выберите знак "плюс" в разделе " **ресурсы фабрики**", а затем выберите **поток данных**. 

![Новый поток данных](media/data-flow/newdataflow2.png "новый поток данных")

Откроется холст потока данных, где можно создать логику преобразования. Выберите **Добавить источник** , чтобы начать настройку преобразования источника. Дополнительные сведения см. в разделе [Преобразование источника](data-flow-source.md).

## <a name="data-flow-canvas"></a>Холст потока данных

Холст потока данных разделяется на три части: Верхняя панель, диаграмма и панель конфигурации. 

![Маркер](media/data-flow/canvas1.png "Canvas")

### <a name="graph"></a>График

Граф отображает поток преобразования. Он показывает журнал преобразований источника данных по мере их последовательного в один или несколько приемников. Чтобы добавить новый источник, выберите **Добавить источник**. Чтобы добавить новое преобразование, выберите знак "плюс" в правом нижнем углу существующего преобразования.

![Маркер](media/data-flow/canvas2.png "Canvas")

### <a name="azure-integration-runtime-data-flow-properties"></a>Свойства потока данных среды выполнения интеграции Azure

![Кнопка "Отладка"](media/data-flow/debugbutton.png "Кнопка "Отладка"")

После начала работы с потоками данных в ADF необходимо включить параметр "Отладка" для потоков данных в верхней части пользовательского интерфейса браузера. Это позволит запустить кластер Azure Databricks для интерактивной отладки, предварительного просмотра данных и выполнения отладки конвейера. Вы можете задать размер кластера, выбрав пользовательский [Azure Integration Runtime](concepts-integration-runtime.md). Сеанс отладки будет оставаться активным до 60 минут после последней предварительной версии данных или выполнения конвейера последней отладки.

Когда вы эксплуатацию конвейеры с действиями потока данных, ADF будет использовать Azure Integration Runtime, связанный с [действием](control-flow-execute-data-flow-activity.md) в свойстве "Запуск в".

Azure Integration Runtime по умолчанию — небольшой кластер однорабочих узлов с четырьмя ядрами, предназначенный для предварительного просмотра данных и быстрого выполнения отладочных конвейеров с минимальными затратами. Задайте более крупную конфигурацию Azure IR при выполнении операций с большими наборами данных.

Вы можете указать ADF-файл для поддержки пула ресурсов кластера (ВМ), установив TTL в Azure IR свойства потока данных. Это приведет к более быстрому выполнению задания для последующих действий.

#### <a name="azure-integration-runtime-and-data-flow-strategies"></a>Среда выполнения интеграции Azure и стратегии потока данных

##### <a name="execute-data-flows-in-parallel"></a>Параллельное выполнение потоков данных

При параллельном выполнении потоков данных в конвейере ADF будет выполнять последовательный запуск отдельных кластеров Azure Databricks для каждого выполнения действия на основе параметров в Azure Integration Runtime, присоединенных к каждому действию. Для разработки параллельных выполнений в конвейерах ADF добавьте в пользовательский интерфейс действия потока данных без ограничений очередностью.

Из этих трех вариантов этот параметр, скорее всего, будет выполняться в кратчайший промежуток времени. Однако каждый параллельный поток данных будет выполняться в разных кластерах в одно и то же время, поэтому упорядочение событий не является детерминированным.

##### <a name="overload-single-data-flow"></a>Перегрузка одного потока данных

Если вы поместили всю логику в один поток данных, ADF будет выполняться в том же контексте выполнения задания в одном экземпляре кластера Spark.

Этот вариант может быть сложнее отслеживать и устранять неполадки, так как бизнес-правила и бизнес-логика будут смешиваете вместе. Этот вариант также не обеспечивает существенного повторного использования.

##### <a name="execute-data-flows-serially"></a>Выполнять потоки данных последовательно

Если вы выполняете действия потока данных в конвейере в последовательном задании и задали срок жизни в конфигурации Azure IR, ADF будет повторно использовать вычислительные ресурсы (ВМ), что приведет к более быстрому последующему времени выполнения. Для каждого выполнения по-прежнему будет получен новый контекст Spark.

Из этих трех вариантов это, скорее всего, займет самое длинное время для выполнения сквозной работы. Но он обеспечивает четкое разделение логических операций на каждом шаге потока данных.

### <a name="configuration-panel"></a>Панель конфигурации

На панели конфигурация отображаются параметры, относящиеся к текущему выбранному преобразованию. Если преобразование не выбрано, то отображается поток данных. В общей конфигурации потока данных можно изменить имя и описание на вкладке **Общие** или добавить параметры с помощью вкладки **Параметры** . Дополнительные сведения см. в разделе [Сопоставление параметров потока данных](parameters-data-flow.md).

Каждое преобразование имеет по крайней мере четыре вкладки конфигурации.

#### <a name="transformation-settings"></a>Параметры преобразования

Первая вкладка в области конфигурации каждого преобразования содержит параметры, относящиеся к этому преобразованию. Дополнительные сведения см. на странице документации по преобразованию.

![Вкладка "Параметры источника"](media/data-flow/source1.png "Вкладка "Параметры источника"")

#### <a name="optimize"></a>Оптимизация

Вкладка **Оптимизация** содержит параметры для настройки схем секционирования.

![Optimize](media/data-flow/optimize1.png "Оптимизация") (Оптимизация)

Значение по умолчанию — **использовать текущее секционирование**, которое указывает фабрике данных Azure использовать схему секционирования Native для потоков данных, выполняющихся в Spark. В большинстве случаев рекомендуется использовать этот параметр.

Существуют экземпляры, для которых может потребоваться изменить секционирование. Например, если вы хотите выводить преобразования в один файл в папке Lake, выберите **один раздел** в преобразовании приемника.

Другой случай, когда может потребоваться управлять схемами секционирования, — это оптимизация производительности. Настройка секционирования обеспечивает управление распределением данных между узлами вычислений и оптимизацией локализации данных, которые могут иметь как положительные, так и отрицательные последствия для общей производительности потока данных. Дополнительные сведения см. в разделе [Пошаговое руководств по производительности потока данных](concepts-data-flow-performance.md).

Чтобы изменить секционирование для любого преобразования, перейдите на вкладку **Оптимизация** и установите переключатель **задать секционирование** . После этого будет представлен ряд вариантов секционирования. Оптимальный метод секционирования будет отличаться в зависимости от объема данных, потенциальных ключей, значений NULL и количества элементов. 

Рекомендуется начать с секционирования по умолчанию, а затем попробовать использовать другие параметры секционирования. Можно выполнять тестирование с помощью отладочных запусков конвейера и просматривать время выполнения и использование секций в каждой группе преобразования из представления мониторинга. Дополнительные сведения см. в разделе [наблюдение за потоками данных](concepts-data-flow-monitoring.md).

Доступны следующие параметры секционирования.

##### <a name="round-robin"></a>Циклический перебор 

Циклический перебор — это простая секция, которая автоматически распределяет данные между секциями. Используйте метод циклического перебора, если у вас нет хороших ключевых кандидатов для реализации высококачественной интеллектуальной стратегии секционирования. Вы можете задать количество физических секций.

##### <a name="hash"></a>Хэш

Фабрика данных Azure создает хэш столбцов, чтобы получить равномерное распределение секций, и при этом строки со сходными значениями попадут в одну секцию. При использовании параметра hash проверьте возможное отклонение секций. Вы можете задать количество физических секций.

##### <a name="dynamic-range"></a>Динамический диапазон

Динамический диапазон будет использовать динамические диапазоны Spark на основе предоставленных столбцов или выражений. Вы можете задать количество физических секций. 

##### <a name="fixed-range"></a>Фиксированный диапазон

Создайте выражение, которое предоставляет фиксированный диапазон значений в столбцах секционированных данных. Чтобы избежать смещения секций, перед использованием этого параметра следует хорошо понимать данные. Значения, вводимые для выражения, будут использоваться как часть функции секционирования. Вы можете задать количество физических секций.

##### <a name="key"></a>Ключ

Если вы хорошо понимаете количество элементов данных, секционирование ключей может оказаться хорошей стратегией. При секционировании по ключу создаются секции для каждого уникального значения в столбце. Невозможно задать количество секций, так как число будет основано на уникальных значениях в данных.

#### <a name="inspect"></a>Обследован

На вкладке **Проверка** представлено представление метаданных потока данных, для которого выполняется преобразование. Вы видите количество столбцов, измененных столбцов, добавленных столбцов, типов данных, упорядочения столбцов и ссылок на столбцы. **Проверка** — это представление метаданных, доступное только для чтения. Для просмотра метаданных в области **проверки** не нужно включать режим отладки.

![Обследован](media/data-flow/inspect1.png "Обследован")

При изменении формы данных с помощью преобразований в области **проверки** будут отображаться потоки изменений метаданных. Если в преобразовании источника не определена схема, метаданные не будут отображаться в области **проверки** . Отсутствие метаданных является распространенным в сценариях смещения схемы.

#### <a name="data-preview"></a>Предварительный просмотр данных

Если режим отладки включен, вкладка **Предварительный просмотр данных** предоставляет интерактивный моментальный снимок данных при каждом преобразовании. Дополнительные сведения см. [в разделе Предварительный просмотр данных в режиме отладки](concepts-data-flow-debug-mode.md#data-preview).

### <a name="top-bar"></a>Верхняя панель

Верхняя панель содержит действия, влияющие на весь поток данных, например сохранение и проверку. Можно также переключаться между режимами графика и конфигурации с помощью кнопок **Показать диаграмму** и **Скрыть граф** .

![Скрыть график](media/data-flow/hideg.png "Скрытие графика")

Если скрыть диаграмму, вы сможете просматривать узлы преобразования позже с помощью кнопок **назад** и **Далее** .

![Кнопки «назад» и «далее»](media/data-flow/showhide.png "кнопки «назад» и «далее»")

## <a name="next-steps"></a>Дальнейшие действия

* Узнайте, как создать [Преобразование источника](data-flow-source.md).
* Узнайте, как создавать потоки данных в [режиме отладки](concepts-data-flow-debug-mode.md).
