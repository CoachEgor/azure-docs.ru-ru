---
title: Производительность действия копирования troubleshoot
description: Узнайте о том, как устранить неполадки производительности копирования на фабрике данных Azure.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/11/2020
ms.openlocfilehash: a14f4d548053fb7aaf6f450176fdc49bc7b119bf
ms.sourcegitcommit: 7581df526837b1484de136cf6ae1560c21bf7e73
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/31/2020
ms.locfileid: "80421035"
---
# <a name="troubleshoot-copy-activity-performance"></a>Производительность действия копирования troubleshoot

В этой статье описывается, как устранить проблему производительности копирования на фабрике данных Azure. 

После выполнения действия копирования можно собрать результаты выполнения и статистику производительности в представлении [мониторинга активности копирования.](copy-activity-monitoring.md) Пример приведен ниже.

![Мониторинг действия копирования выполнения деталей](./media/copy-activity-overview/monitor-copy-activity-run-details.png)

## <a name="performance-tuning-tips"></a>Советы по настройке производительности

В некоторых сценариях при запуске копирования на фабрике данных вы увидите **«Подсказки настройки производительности»** в верхней части, как показано в приведенном выше примере. Советы сказать вам узкое место определены ADF для данного запуска копии, наряду с предложением о том, как увеличить пропускную выемку копии. Попробуйте внести повторенные изменения, а затем запустите копию снова.

В качестве ссылки, в настоящее время советы по настройке производительности содержат предложения по следующим случаям:

| Категория              | Советы по настройке производительности                                      |
| --------------------- | ------------------------------------------------------------ |
| Специфика хранения данных   | Загрузка данных в **Azure Synpase Analytics (ранее S'L DW)** предлагает использовать заявление PolyBase или COPY, если оно не используется. |
| &nbsp;                | Копирование данных из/в **базу данных Azure S'L:** когда DTU находится под высоким уровнем использования, предложите перейти на более высокий уровень. |
| &nbsp;                | Копирование данных от/к **Azure Cosmos DB:** когда RU находится под высоким уровнем использования, предложите обновление до большего RU. |
| &nbsp;                | Проглочение данных из **Amazon Redshift**: предложить использовать UNLOAD, если он не используется. |
| Регулирование хранилища данных | Если несколько операций чтения/записи задушены хранилищем данных во время копирования, предложите проверить и увеличить допустимую скорость запроса для хранилища данных или уменьшить одновременный рабочий груз. |
| Время выполнения интеграции  | Если вы используете **автономное время выполнения интеграции (IR)** и копирование деятельности долго ждет в очереди, пока ИК имеет доступный ресурс для выполнения, предложите масштабирование /вверх ваш ИК. |
| &nbsp;                | Если вы используете **Runtime интеграции Azure,** который находится в неоптимальном регионе, что приводит к медленному чтению/записи, предложите настроить для использования ИК в другом регионе. |
| Отказоустойчивость       | Если настройка допуска к неисправности и пропуск несовместимых строк приводит к медленной производительности, предложите обеспечить совместимость исходных данных и данных раковины. |
| промежуточное копирование           | Если постановочная копия настроена, но не полезна для пары исходного погружения, предложите удалить ее. |
| Продолжить                | Когда активность копирования возобновляется с точки последнего сбоя, но вы измените настройку DIU после исходного запуска, обратите внимание, что новая настройка DIU не вступила в силу. |

## <a name="understand-copy-activity-execution-details"></a>Понимание деталей выполнения действий копирования

Детали выполнения и продолжительность в нижней части представления мониторинга активности копирования описывают ключевые этапы, через которые проходит активность копирования (см. пример в начале этой статьи), что особенно полезно для устранения неполадок в производительности копии. Узкое место в копии запуска является одним с самой длинной продолжительностью. Обратитесь к следующей таблице по определению каждого этапа и узнайте, как [проделать копировум Troubleshoot на Azure IR](#troubleshoot-copy-activity-on-azure-ir) и [Troubleshoot copy activity на самостоятельно размещенной ИК](#troubleshoot-copy-activity-on-self-hosted-ir) с такой информацией.

| Этап           | Описание                                                  |
| --------------- | ------------------------------------------------------------ |
| Очередь           | Прошло время, пока действие копирования фактически не начнется во время выполнения интеграции. |
| Предварительной копии сценария | Прошедшее время между действием копирования, начинающимся на ИК, и завершением деятельности копирования, заканчивающей выполнение сценария предварительной копии в хранилище данных раковины. При настройке сценария предварительной копирования для поглотителей базы данных, например, при записи данных в базу данных Azure S'L, перед копированием новых данных. |
| Transfer        | Прошло ежесодуе между окончанием предыдущего шага и ИК-переводом всех данных из источника в раковину. Подступении под "Transfer" проходят параллельно.<br><br>- **Время для первого байта:** Время, прошедшее между окончанием предыдущего шага и временем, когда ИК получает первый байт из хранилища исходных данных. Применяется к источникам, не основанным на файлах.<br>- **Источник листинга:** Время, затрачиваемые на перечисление исходных файлов или разделов данных. Последнее применяется при настройке параметров раздела для источников баз данных, например, при копировании данных из баз данных, таких как Oracle/SAP HANA/Teradata/Netezza/etc.<br/>-**Чтение из источника:** Количество времени, затрачиваемого на извлечение данных из хранилища исходных данных.<br/>- **Дать тонуть:** Количество времени, затрачиваемого на написание данных для потопа хранилища данных. |

## <a name="troubleshoot-copy-activity-on-azure-ir"></a>Действия по устранению проблем в ИК Azure

Следуйте [шагам настройки производительности,](copy-activity-performance.md#performance-tuning-steps) чтобы спланировать и провести тест производительности для вашего сценария. 

Если производительность активности копирования не соответствует вашим ожиданиям, чтобы устранить действие одной копии, выполняемые на Azure Integration Runtime, если вы видите советы по [настройке производительности,](#performance-tuning-tips) показанные в представлении мониторинга копирования, примените предложение и повторите попытку. В противном [случае, поймите детали выполнения действия копирования,](#understand-copy-activity-execution-details)проверьте, какая стадия имеет **самую длинную** продолжительность, и примените приведенное ниже руководство, чтобы повысить производительность копии:

- **"Предкопительный скрипт" имеет длительную продолжительность:** это означает, что предварительное копирование сценария, работая на базе данных раковины занимает много времени, чтобы закончить. Настройте заданную логику сценария предварительной копирования, чтобы повысить производительность. Если вам нужна дополнительная помощь в улучшении скрипта, обратитесь в группу данных.

- **"Transfer - Time to first byte" опытный длительный рабочий период:** это означает, что ваш исходный запрос занимает много времени, чтобы вернуть любые данные. Проверьте и оптимизируйте запрос или сервер. Если вам нужна дополнительная помощь, обратитесь в свою команду хранения данных.

- **"Передача - источник листинга" имеет длительный период работы:** это означает, что перечисление исходных файлов или разделов данных исходной базы данных происходит медленно.

  - При копировании данных из файлохранилища, если вы используете **фильтр подстановочных знаков** на пути папки или имя файла (или),`wildcardFolderPath` `wildcardFileName`или, если использовать **файл последний измененный фильтр времени** (или),`modifiedDatetimeStart` `modifiedDatetimeEnd`обратите внимание, что такой фильтр приведет к копированию деятельности, перечисляющей все файлы в указанной папке на сторону клиента, а затем применить фильтр. Такое перечисление файлов может стать узким местом, особенно когда только небольшой набор файлов соответствует правилу фильтра.

    - Проверьте, можно ли [копировать файлы на основе пути раздела или имени, основанного на времени даты.](tutorial-incremental-copy-partitioned-file-name-copy-data-tool.md) Такой способ не несет нагрузки на листинг источника стороны.

    - Проверьте, можно ли использовать нативный фильтр хранилища данных, в частности «**приставку»** для Amazon S3 и Azure Blob. Фильтр префикса — это фильтр сервера хранилища данных, который будет иметь гораздо более высокую производительность.

    - Рассмотрите возможность разделения одного большого набора данных на несколько небольших наборов данных и позволить этим заданиям копировать одновременно каждый из них решает часть данных. Вы можете сделать это с помощью Lookup/GetMetadata и ForEach . В качестве общего примера обратитесь к [файлам копирования из нескольких контейнеров](solution-template-copy-files-multiple-containers.md) или к переносу данных из шаблонов решений Amazon S3 в [ADLS Gen2.](solution-template-migration-s3-azure.md)

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования источника или находится ли ваш хранилище данных в состоянии высокого использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

  - Используйте ИК Azure в том же регионе или близко к исходной области хранилища данных.

- **"Трансфер - чтение от источника" опытный длительный рабочий период**: 

  - Принять разъем конкретных данных загрузки передовой практики, если это применяется. Например, при копировании данных amazon [Redshift](connector-amazon-redshift.md)нанастройка с использованием Redshift UNLOAD.

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования источника или находится ли в вашем хранилище данных под высоким уровнем использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

  - Проверьте свой источник копии и шаблон раковины: 

    - Если шаблон копирования поддерживает более 4 единиц интеграции данных (DIUs) - обратитесь к [этому разделу](copy-activity-performance-features.md#data-integration-units) о деталях, как правило, вы можете попробовать увеличить DIUs, чтобы получить более высокую производительность. 

    - В противном случае, рассмотреть вопрос о разделении одного большого набора данных на несколько небольших наборов данных, и пусть эти задания копировать одновременно каждый решает часть данных. Вы можете сделать это с помощью Lookup/GetMetadata и ForEach . Обратитесь к [файлам копирования из нескольких контейнеров,](solution-template-copy-files-multiple-containers.md) [переносу данных из Amazon S3 в ADLS Gen2](solution-template-migration-s3-azure.md)или [массовой копии с](solution-template-bulk-copy-with-control-table.md) шаблонами решений диспетчерских таблиц в качестве общего примера.

  - Используйте ИК Azure в том же регионе или близко к исходной области хранилища данных.

- **"Передача - письмо, чтобы потопить" опытные длительные сроки работы**:

  - Принять разъем конкретных данных загрузки передовой практики, если это применяется. Например, при копировании данных в [Azure Synapse Analytics](connector-azure-sql-data-warehouse.md) (ранее S'L DW) используйте выписку PolyBase или COPY. 

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования на раковине или находится ли ваш хранилище данных под высоким уровнем использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

  - Проверьте свой источник копии и шаблон раковины: 

    - Если шаблон копирования поддерживает более 4 единиц интеграции данных (DIUs) - обратитесь к [этому разделу](copy-activity-performance-features.md#data-integration-units) о деталях, как правило, вы можете попробовать увеличить DIUs, чтобы получить более высокую производительность. 

    - В противном случае, постепенно настроить [параллельные копии](copy-activity-performance-features.md), обратите внимание, что слишком много параллельных копий может даже повредить производительности.

  - Используйте ИК Azure в том же или близко к области хранилища данных раковины.

## <a name="troubleshoot-copy-activity-on-self-hosted-ir"></a>Устранение неполадок копирование деятельности на самостоятельной ИК

Следуйте [шагам настройки производительности,](copy-activity-performance.md#performance-tuning-steps) чтобы спланировать и провести тест производительности для вашего сценария. 

Если производительность копирования не соответствует вашим ожиданиям, чтобы устранить действие одной копии, выполняемые на Azure Integration Runtime, если вы видите советы по [настройке производительности,](#performance-tuning-tips) показанные в представлении мониторинга копирования, примените предложение и повторите попытку. В противном [случае, поймите детали выполнения действия копирования,](#understand-copy-activity-execution-details)проверьте, какая стадия имеет **самую длинную** продолжительность, и примените приведенное ниже руководство, чтобы повысить производительность копии:

- **"Очередь" опытных длительный период:** это означает, что копирование деятельности ждет долго в очереди, пока ваш Self-хостинг ИК имеет ресурс для выполнения. Проверьте иК-емкость и использование, а также [масштабируйте или выгоняйте в](create-self-hosted-integration-runtime.md#high-availability-and-scalability) соответствии с рабочей нагрузкой.

- **"Transfer - Time to first byte" опытный длительный рабочий период:** это означает, что ваш исходный запрос занимает много времени, чтобы вернуть любые данные. Проверьте и оптимизируйте запрос или сервер. Если вам нужна дополнительная помощь, обратитесь в свою команду хранения данных.

- **"Передача - источник листинга" имеет длительный период работы:** это означает, что перечисление исходных файлов или разделов данных исходной базы данных происходит медленно.

  - Проверьте, имеет ли Самохонцентричная ИК-машина низкую задержку, подключенную к хранилику исходных данных. Если ваш источник находится в Azure, вы можете использовать [этот инструмент,](http://www.azurespeed.com/Azure/Latency) чтобы проверить задержку от самостоятельно размещенной ИК-машины до региона Azure, чем меньше, тем лучше.

  - При копировании данных из файлохранилища, если вы используете **фильтр подстановочных знаков** на пути папки или имя файла (или),`wildcardFolderPath` `wildcardFileName`или, если использовать **файл последний измененный фильтр времени** (или),`modifiedDatetimeStart` `modifiedDatetimeEnd`обратите внимание, что такой фильтр приведет к копированию деятельности, перечисляющей все файлы в указанной папке на сторону клиента, а затем применить фильтр. Такое перечисление файлов может стать узким местом, особенно когда только небольшой набор файлов соответствует правилу фильтра.

    - Проверьте, можно ли [копировать файлы на основе пути раздела или имени, основанного на времени даты.](tutorial-incremental-copy-partitioned-file-name-copy-data-tool.md) Такой способ не несет нагрузки на листинг источника стороны.

    - Проверьте, можно ли использовать нативный фильтр хранилища данных, в частности «**приставку»** для Amazon S3 и Azure Blob. Фильтр префикса — это фильтр сервера хранилища данных, который будет иметь гораздо более высокую производительность.

    - Рассмотрите возможность разделения одного большого набора данных на несколько небольших наборов данных и позволить этим заданиям копировать одновременно каждый из них решает часть данных. Вы можете сделать это с помощью Lookup/GetMetadata и ForEach . В качестве общего примера обратитесь к [файлам копирования из нескольких контейнеров](solution-template-copy-files-multiple-containers.md) или к переносу данных из шаблонов решений Amazon S3 в [ADLS Gen2.](solution-template-migration-s3-azure.md)

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования источника или находится ли ваш хранилище данных в состоянии высокого использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

- **"Трансфер - чтение от источника" опытный длительный рабочий период**: 

  - Проверьте, имеет ли Самохонцентричная ИК-машина низкую задержку, подключенную к хранилику исходных данных. Если ваш источник находится в Azure, вы можете использовать [этот инструмент,](http://www.azurespeed.com/Azure/Latency) чтобы проверить задержку от самостоятельно размещенной ИК-машины до регионов Azure, чем меньше, тем лучше.

  - Проверьте, имеет ли самохлаженный ИК-машина достаточную пропускную способность для эффективного чтения и передачи данных. Если хранилище исходных данных находится в Azure, вы можете использовать [этот инструмент](https://www.azurespeed.com/Azure/Download) для проверки скорости загрузки.

  - Проверьте тенденцию к использованию процессора и использованию памяти самостоятельно гостов на портале Azure - > странице обзора фабрики данных - >. Рассмотрите возможность [масштабирования/выхода ИК,](create-self-hosted-integration-runtime.md#high-availability-and-scalability) если использование процессора является высоким или доступная память низка.

  - Принять разъем конкретных данных загрузки передовой практики, если это применяется. Пример:

    - При копировании данных [oracle,](connector-oracle.md#oracle-as-source) [Netezza,](connector-netezza.md#netezza-as-source) [Teradata,](connector-teradata.md#teradata-as-source) [SAP HANA,](connector-sap-hana.md#sap-hana-as-source) [SAP Table](connector-sap-table.md#sap-table-as-source)и [SAP Open Hub](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source)позволяет параметры раздела данных копировать данные параллельно.

    - При копировании данных из [HDFS,](connector-hdfs.md)настроить для использования DistCp.

    - При копировании данных amazon [Redshift](connector-amazon-redshift.md)наконфигурируйте для использования Redshift UNLOAD.

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования источника или находится ли в вашем хранилище данных под высоким уровнем использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

  - Проверьте свой источник копии и шаблон раковины: 

    - Если вы копируете данные из хранилив данных с поддержкой опций раздела, подумайте о постепенной настройке [параллельных копий,](copy-activity-performance-features.md)обратите внимание, что слишком много параллельных копий может даже повредить производительности.

    - В противном случае, рассмотреть вопрос о разделении одного большого набора данных на несколько небольших наборов данных, и пусть эти задания копировать одновременно каждый решает часть данных. Вы можете сделать это с помощью Lookup/GetMetadata и ForEach . Обратитесь к [файлам копирования из нескольких контейнеров,](solution-template-copy-files-multiple-containers.md) [переносу данных из Amazon S3 в ADLS Gen2](solution-template-migration-s3-azure.md)или [массовой копии с](solution-template-bulk-copy-with-control-table.md) шаблонами решений диспетчерских таблиц в качестве общего примера.

- **"Передача - письмо, чтобы потопить" опытные длительные сроки работы**:

  - Принять разъем конкретных данных загрузки передовой практики, если это применяется. Например, при копировании данных в [Azure Synapse Analytics](connector-azure-sql-data-warehouse.md) (ранее S'L DW) используйте выписку PolyBase или COPY. 

  - Проверьте, имеет ли Самохонцентричная ИК-машина низкую задержку, подключающуюся к хранилику данных. Если ваша раковина находится в Azure, вы можете использовать [этот инструмент,](http://www.azurespeed.com/Azure/Latency) чтобы проверить задержку от самостоятельно размещенной ИК-машины до региона Azure, чем меньше, тем лучше.

  - Проверьте, имеет ли самохлаженный ИК-машина достаточную исходящих полос для передачи и записи данных эффективно. Если хранилище данных раковины находится в Azure, вы можете использовать [этот инструмент](https://www.azurespeed.com/Azure/UploadLargeFile) для проверки скорости загрузки.

  - Проверить, является ли самостоятельно размещенный процессор ИК и тенденция использования памяти на портале Azure - > страницу обзора data factory - >. Рассмотрите возможность [масштабирования/выхода ИК,](create-self-hosted-integration-runtime.md#high-availability-and-scalability) если использование процессора является высоким или доступная память низка.

  - Проверьте, сообщает ли ADF о какой-либо ошибке регулирования на раковине или находится ли ваш хранилище данных под высоким уровнем использования. Если это так, либо уменьшите рабочие нагрузки в хранилище данных, либо попытайтесь связаться с администратором хранилища данных, чтобы увеличить лимит регулирования или доступный ресурс.

  - Рассмотрим постепенно настроить [параллельные копии](copy-activity-performance-features.md), обратите внимание, что слишком много параллельных копий может даже повредить производительности.

## <a name="other-references"></a>Прочие ссылки

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Хранение Azure Blob: [целевые показатели масштабируемости и производительности для хранения и](../storage/blobs/scalability-targets.md) производительности Blob [и контрольной перечень масштабируемости для хранения Blob.](../storage/blobs/storage-performance-checklist.md)
* Хранение таблицы Azure: [целевые показатели масштабируемости и производительности для хранения](../storage/tables/scalability-targets.md) таблицы и [контрольного списка масштабируемости для хранения таблицы.](../storage/tables/storage-performance-checklist.md)
* База данных Azure S'L: Вы можете [контролировать производительность](../sql-database/sql-database-single-database-monitor.md) и проверять процент транзакций группы данных (DTU).
* Хранилище данных Azure S'L: его возможности измеряются в единицах хранилища данных (DWUs). [См. Управление вычислительной мощностью в Хранилище данных Azure S'L (Обзор)](../synapse-analytics/sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB: [Уровни производительности в Azure Cosmos DB](../cosmos-db/performance-levels.md).
* На территории S'L Server: [монитор и настройка для производительности.](https://msdn.microsoft.com/library/ms189081.aspx)
* Внутренний файловый сервер: [настройка производительности для файловых серверов.](https://msdn.microsoft.com/library/dn567661.aspx)

## <a name="next-steps"></a>Следующие шаги
Смотрите другие статьи деятельности копирования:

- [Общие сведения о действии копирования](copy-activity-overview.md)
- [Копирование руководства по производительности и масштабируемости](copy-activity-performance.md)
- [Копирование функций оптимизации производительности](copy-activity-performance-features.md)
- [Используйте фабрику данных Azure для переноса данных из озера данных или хранилища данных в Azure](data-migration-guidance-overview.md)
- [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
