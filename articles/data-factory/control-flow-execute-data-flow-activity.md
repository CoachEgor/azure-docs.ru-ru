---
title: Выполнить действие потока данных в фабрике данных Azure | Документация Майкрософт
description: Как выполнить данные поступают из в конвейере фабрики данных.
services: data-factory
documentationcenter: ''
author: kromerm
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 02/22/2019
ms.author: makromer
ms.openlocfilehash: c33219eacb1d3bada5630a7792f98ba33dba824e
ms.sourcegitcommit: 509e1583c3a3dde34c8090d2149d255cb92fe991
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/27/2019
ms.locfileid: "66235864"
---
# <a name="execute-data-flow-activity-in-azure-data-factory"></a>Выполнить действие потока данных в фабрике данных Azure
Действие потока данных execute используется для выполнения потока данных ADF в конвейер debug (песочница) и активируется конвейер.

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

## <a name="syntax"></a>Синтаксис

```json
{
    "name": "MyDataFlowActivity",
    "type": "ExecuteDataFlow",
    "typeProperties": {
      "dataflow": {
         "referenceName": "dataflow1",
         "type": "DataFlowReference"
      },
        "compute": {
          "computeType": "General",
          "coreCount": 8,
      }
}

```

## <a name="type-properties"></a>Свойства типа

* ```dataflow``` имя сущности потока данных, который требуется выполнить
* ```compute``` Описывает среду выполнения Spark
* ```coreCount``` — количество ядер, чтобы назначить выполнение этого действия часть потока данных

![Выполнение потока данных](media/data-flow/activity-data-flow.png "выполнения потока данных")

### <a name="debugging-pipelines-with-data-flows"></a>Отладка конвейеры потоков данных

![Отладка кнопку](media/data-flow/debugbutton.png "кнопку отладки")

Используйте Отладка потока данных для использования warmed кластер для тестирования потоки данных в интерактивном режиме в запуска отладки конвейера. Используйте параметр отладки конвейера для тестирования потоки данных в конвейере.

### <a name="run-on"></a>Запуск на

Это обязательное поле, которое определяет, какая среда выполнения интеграции для выполнения действия вашего потока данных. По умолчанию фабрика данных будет использовать среды выполнения интеграции Azure по умолчанию автоматическое разрешение. Тем не менее можно создать собственные сред выполнения интеграции Azure, определить определенные регионы, вычислить тип числа ядер и срок ЖИЗНИ для выполнения действий потока данных.

Значение по умолчанию для выполнения потока данных — 8 ядер общих вычислительных со сроком ЖИЗНИ 60 минут.

Выберите вычислительную среду для этого выполнения потока данных. По умолчанию используется среда выполнения интеграции Azure по умолчанию автоматическое разрешение. Этот выбор будет выполняться поток данных в среде Spark в одном регионе с фабрикой данных. Тип вычисления будет кластера заданий, это означает, что вычислительная среда может занять несколько минут для запуска.

У вас есть контроль над средой выполнения Spark действия потока данных. В [среды выполнения интеграции Azure](concepts-integration-runtime.md) приведены параметры, чтобы задать тип вычисления (общего назначения, оптимизированных для памяти и оптимизированных для вычислений), число ядер рабочей роли и время жизни в соответствии с подсистему выполнения с вычислениями потока данных требования. Кроме того параметр срока ЖИЗНИ дает возможность обслуживания "горячего" резервирования, немедленно становятся доступными для выполнения заданий кластера.

![Среда выполнения интеграции Azure](media/data-flow/ir-new.png "среды выполнения интеграции Azure")

> [!NOTE]
> Выбор среды выполнения интеграции в действии потока данных применяется только к *активации выполнений* конвейера. Отладка конвейер с помощью обмена данными с помощью отладки будут выполнены для кластера Spark по умолчанию 8-ядерный.

### <a name="staging-area"></a>Промежуточная область

Если прием данных в хранилище данных Azure, вы должны выбрать расположение промежуточного хранения для вашей пакетной загрузки Polybase.

## <a name="parameterized-datasets"></a>Параметризованные наборы данных

Если вы используете параметризованные наборы данных, не забудьте задать значения параметров.

![Выполнение параметры потока данных](media/data-flow/params.png "параметров")

### <a name="debugging-parameterized-data-flows"></a>Отладка параметризованные потоки данных

Можно отладить только те потоки данных с параметризованные наборы данных из конвейера Debug запустить с помощью execute действие потока данных. В настоящее время сеансов интерактивной отладки в поток данных ADF не работают с параметризованные наборы данных. Выполнений конвейера и выполнения отладки будут работать с параметрами.

Рекомендуется для создания потока данных с помощью статического набора данных, чтобы получить полные метаданные столбца распространения доступны во время разработки. Затем замените статический набор данных динамических параметризованного набора данных при ввод в эксплуатацию конвейера потока данных.

## <a name="next-steps"></a>Дальнейшие действия
Ознакомьтесь с другими действиями потока управления, которые поддерживаются фабрикой данных: 

- [Действие условия If](control-flow-if-condition-activity.md)
- [Действие выполнения конвейера](control-flow-execute-pipeline-activity.md)
- [Действие ForEach](control-flow-for-each-activity.md)
- [Действие получения метаданных](control-flow-get-metadata-activity.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Веб-действие](control-flow-web-activity.md)
- [Действие Until](control-flow-until-activity.md)
