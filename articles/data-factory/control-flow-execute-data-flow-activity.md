---
title: Действие потока данных в фабрике данных Azure
description: Выполнение потоков данных внутри конвейера фабрики данных.
services: data-factory
documentationcenter: ''
author: kromerm
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.author: makromer
ms.date: 10/07/2019
ms.openlocfilehash: 5623907346ee3882ad53a27695336ba4bc449db8
ms.sourcegitcommit: 609d4bdb0467fd0af40e14a86eb40b9d03669ea1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/06/2019
ms.locfileid: "73679945"
---
# <a name="data-flow-activity-in-azure-data-factory"></a>Действие потока данных в фабрике данных Azure

Используйте действие потока данных для преобразования и перемещения данных посредством сопоставления потоков данных. Если вы не знакомы с потоками данных, см. раздел [Общие сведения о сопоставлении потока данных](concepts-data-flow-overview.md)

## <a name="syntax"></a>Синтаксис

```json
{
    "name": "MyDataFlowActivity",
    "type": "ExecuteDataFlow",
    "typeProperties": {
      "dataflow": {
         "referenceName": "MyDataFlow",
         "type": "DataFlowReference"
      },
      "staging": {
          "linkedService": {
              "referenceName": "MyStagingLinkedService",
              "type": "LinkedServiceReference"
          },
          "folderPath": "my-container/my-folder"
      },
      "integrationRuntime": {
          "referenceName": "MyDataFlowIntegrationRuntime",
          "type": "IntegrationRuntimeReference"
      }
}

```

## <a name="type-properties"></a>Свойства типа

Свойство | Description (Описание) | Допустимые значения | Обязательно
-------- | ----------- | -------------- | --------
DataFlow | Ссылка на выполняемый поток данных | датафловреференце | Да
интегратионрунтиме | Среда вычислений, на которой выполняется поток данных | интегратионрунтимереференце | Да
промежуточное хранение. linkedService | Если вы используете источник или приемник хранилища данных SQL, то учетная запись хранения, используемая для промежуточного хранения Polybase. | LinkedServiceReference | Только при считывании или записи потока данных в хранилище SQL
промежуточное хранение. folderPath | Если вы используете источник или приемник хранилища данных SQL, путь к папке в учетной записи хранения BLOB-объектов, используемый для промежуточного хранения Polybase. | string | Только при считывании или записи потока данных в хранилище SQL

![Выполнение потока данных](media/data-flow/activity-data-flow.png "Выполнение потока данных")

### <a name="data-flow-integration-runtime"></a>Среда выполнения интеграции потока данных

Выберите Integration Runtime, который будет использоваться для выполнения действия потока данных. По умолчанию фабрика данных будет использовать среду выполнения интеграции Azure для автоматического разрешения с четырьмя рабочими ядрами и без срока жизни (TTL). Этот IR имеет тип вычислений общего назначения и работает в том же регионе, что и фабрика. Вы можете создавать собственные среды выполнения интеграции Azure, определяющие конкретные регионы, тип вычислений, количество ядер и TTL для выполнения действий потока данных.

Для выполнения конвейера кластером является кластер заданий, для запуска которого требуется несколько минут перед началом выполнения. Если TTL не указан, это время запуска необходимо для каждого выполнения конвейера. Если указать срок жизни, горячий пул кластера останется активным в течение времени, указанного после последнего выполнения, что приведет к сокращению времени запуска. Например, если срок жизни составляет 60 минут и поток данных будет выполняться один раз в час, пул кластера останется активным. Дополнительные сведения см. в разделе [Среда выполнения интеграции Azure](concepts-integration-runtime.md).

![Azure Integration Runtime](media/data-flow/ir-new.png "Azure Integration Runtime")

> [!NOTE]
> Выбор Integration Runtime в действии потока данных применяется только к *запущенным выполнениям* конвейера. Отладка конвейера с потоками данных выполняется в кластере, указанном в сеансе отладки.

### <a name="polybase"></a>PolyBase

Если вы используете хранилище данных SQL Azure в качестве приемника или источника, необходимо выбрать промежуточное расположение для пакетной загрузки Polybase. Polybase обеспечивает неполное пакетную загрузку, а не загружает данные построчно. Polybase радикально сокращает время загрузки в хранилище данных SQL.

## <a name="parameterizing-data-flows"></a>Параметризация потоков данных

### <a name="parameterized-datasets"></a>Параметризованные наборы данных

Если в потоке данных используются параметризованные DataSet, задайте значения параметров на вкладке **Параметры** .

![Выполнение параметров потока данных](media/data-flow/params.png "Параметры")

### <a name="parameterized-data-flows"></a>Параметризованные потоки данных

Если поток данных является параметризованным, задайте динамические значения параметров потока данных на вкладке **Параметры** . Для назначения динамических или литеральных значений параметров можно использовать язык выражений конвейера ADF (только для строковых типов) или язык выражений потока данных. Дополнительные сведения см. в разделе [Параметры потока данных](parameters-data-flow.md).

![Пример выполнения параметра потока данных](media/data-flow/parameter-example.png "Пример параметра")

## <a name="pipeline-debug-of-data-flow-activity"></a>Отладка конвейера действия потока данных

Для выполнения конвейера отладки, выполняемого с действием потока данных, необходимо переключиться в режим отладки потока данных с помощью ползунка **отладки потока данных** на верхней панели. Режим отладки позволяет запускать поток данных в активном кластере Spark. Дополнительные сведения см. в разделе [режим отладки](concepts-data-flow-debug-mode.md).

![Кнопка "Отладка"](media/data-flow/debugbutton.png "Кнопка "Отладка"")

Конвейер отладки выполняется для активного кластера отладки, а не для среды выполнения интеграции, указанной в параметрах действия потока данных. При запуске режима отладки можно выбрать среду вычислений для отладки.

## <a name="monitoring-the-data-flow-activity"></a>Наблюдение за действием потока данных

В действии потока данных предусмотрена специальная процедура мониторинга, позволяющая просматривать сведения о секционировании, времени этапа и преобразовании данных. Откройте панель "Мониторинг" с помощью значка очков в разделе " **действия**". Дополнительные сведения см. в разделе [наблюдение за потоками данных](concepts-data-flow-monitoring.md).

## <a name="next-steps"></a>Дальнейшие действия

См. раздел действия потока управления, поддерживаемые фабрикой данных. 

- [действие условия If](control-flow-if-condition-activity.md);
- [Действие выполнения конвейера](control-flow-execute-pipeline-activity.md)
- [Действие ForEach](control-flow-for-each-activity.md)
- [Действие получения метаданных](control-flow-get-metadata-activity.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Веб-действие](control-flow-web-activity.md)
- [Действие Until](control-flow-until-activity.md)
