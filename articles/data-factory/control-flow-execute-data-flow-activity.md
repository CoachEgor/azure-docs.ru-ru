---
title: Действие потока данных в фабрике данных Azure | Документация Майкрософт
description: Выполнение потоков данных внутри конвейера фабрики данных.
services: data-factory
documentationcenter: ''
author: kromerm
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.author: makromer
ms.date: 10/07/2019
ms.openlocfilehash: cbfa1acac34187263f8c4203e41bbe61d7e4c745
ms.sourcegitcommit: 11265f4ff9f8e727a0cbf2af20a8057f5923ccda
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/08/2019
ms.locfileid: "72030510"
---
# <a name="data-flow-activity-in-azure-data-factory"></a>Действие потока данных в фабрике данных Azure

Используйте действие потока данных для преобразования и перемещения данных посредством сопоставления потоков данных. Если вы не знакомы с потоками данных, см. раздел [Общие сведения о сопоставлении потока данных](concepts-data-flow-overview.md)

## <a name="syntax"></a>Синтаксис

```json
{
    "name": "MyDataFlowActivity",
    "type": "ExecuteDataFlow",
    "typeProperties": {
      "dataflow": {
         "referenceName": "MyDataFlow",
         "type": "DataFlowReference"
      },
      "staging": {
          "linkedService": {
              "referenceName": "MyStagingLinkedService",
              "type": "LinkedServiceReference"
          },
          "folderPath": "my-container/my-folder"
      },
      "integrationRuntime": {
          "referenceName": "MyDataFlowIntegrationRuntime",
          "type": "IntegrationRuntimeReference"
      }
}

```

## <a name="type-properties"></a>Свойства типа

Свойство | Описание | Допустимые значения | Обязательно для заполнения
-------- | ----------- | -------------- | --------
DataFlow | Ссылка на выполняемый поток данных | датафловреференце | Да
интегратионрунтиме | Среда вычислений, на которой выполняется поток данных | интегратионрунтимереференце | Да
промежуточное хранение. linkedService | Если вы используете источник или приемник хранилища данных SQL, то учетная запись хранения, используемая для промежуточного хранения Polybase. | LinkedServiceReference | Только при считывании или записи потока данных в хранилище SQL
промежуточное хранение. folderPath | Если вы используете источник или приемник хранилища данных SQL, путь к папке в учетной записи хранения BLOB-объектов, используемый для промежуточного хранения Polybase. | Строка, | Только при считывании или записи потока данных в хранилище SQL

Выполнение(media/data-flow/activity-data-flow.png "потока данных для") выполнения ![потока данных]

### <a name="data-flow-integration-runtime"></a>Среда выполнения интеграции потока данных

Выберите Integration Runtime, который будет использоваться для выполнения действия потока данных. По умолчанию фабрика данных будет использовать среду выполнения интеграции Azure для автоматического разрешения с четырьмя рабочими ядрами и без срока жизни (TTL). Этот IR имеет тип вычислений общего назначения и работает в том же регионе, что и фабрика. Вы можете создавать собственные среды выполнения интеграции Azure, определяющие конкретные регионы, тип вычислений, количество ядер и TTL для выполнения действий потока данных.

Для выполнения конвейера кластером является кластер заданий, для запуска которого требуется несколько минут перед началом выполнения. Если TTL не указан, это время запуска необходимо для каждого выполнения конвейера. Если указать срок жизни, горячий пул кластера останется активным в течение времени, указанного после последнего выполнения, что приведет к сокращению времени запуска. Например, если срок жизни составляет 60 минут и поток данных будет выполняться один раз в час, пул кластера останется активным. Дополнительные сведения см. в разделе [Среда выполнения интеграции Azure](concepts-integration-runtime.md).

![Azure Integration Runtime](media/data-flow/ir-new.png "Azure Integration Runtime")

> [!NOTE]
> Выбор Integration Runtime в действии потока данных применяется только к *запущенным выполнениям* конвейера. Отладка конвейера с потоками данных выполняется в кластере, указанном в сеансе отладки.

### <a name="polybase"></a>PolyBase

Если вы используете хранилище данных SQL Azure в качестве приемника или источника, необходимо выбрать промежуточное расположение для пакетной загрузки Polybase. Polybase обеспечивает неполное пакетную загрузку, а не загружает данные построчно. Polybase радикально сокращает время загрузки в хранилище данных SQL.

## <a name="parameterizing-data-flows"></a>Параметризация потоков данных

### <a name="parameterized-datasets"></a>Параметризованные наборы данных

Если в потоке данных используются параметризованные DataSet, задайте значения параметров на вкладке **Параметры** .

(media/data-flow/params.png "Параметры") ![выполнения параметров потока данных]

### <a name="parameterized-data-flows"></a>Параметризованные потоки данных

Если поток данных является параметризованным, задайте динамические значения параметров потока данных на вкладке **Параметры** . Для назначения динамических или литеральных значений параметров можно использовать язык выражений конвейера ADF (только для строковых типов) или язык выражений потока данных. Дополнительные сведения см. в разделе [Параметры потока данных](parameters-data-flow.md).

(media/data-flow/parameter-example.png "Пример параметра") " ![выполнение параметра потока данных]"

## <a name="pipeline-debug-of-data-flow-activity"></a>Отладка конвейера действия потока данных

Для выполнения конвейера отладки, выполняемого с действием потока данных, необходимо переключиться в режим отладки потока данных с помощью ползунка **отладки потока данных** на верхней панели. Режим отладки позволяет запускать поток данных в активном кластере Spark. Дополнительные сведения см. в разделе [режим отладки](concepts-data-flow-debug-mode.md).

Кнопка отладки для ![кнопки](media/data-flow/debugbutton.png "отладки")

Конвейер отладки выполняется для активного кластера отладки, а не для среды выполнения интеграции, указанной в параметрах действия потока данных. При запуске режима отладки можно выбрать среду вычислений для отладки.

## <a name="monitoring-the-data-flow-activity"></a>Наблюдение за действием потока данных

В действии потока данных предусмотрена специальная процедура мониторинга, позволяющая просматривать сведения о секционировании, времени этапа и преобразовании данных. Откройте панель "Мониторинг" с помощью значка очков в разделе " **действия**". Дополнительные сведения см. в разделе [наблюдение за потоками данных](concepts-data-flow-monitoring.md).

## <a name="next-steps"></a>Следующие шаги

См. раздел действия потока управления, поддерживаемые фабрикой данных. 

- [Действие условия If](control-flow-if-condition-activity.md)
- [Действие выполнения конвейера](control-flow-execute-pipeline-activity.md)
- [Действие ForEach](control-flow-for-each-activity.md)
- [Действие получения метаданных](control-flow-get-metadata-activity.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Веб-действие](control-flow-web-activity.md)
- [Действие Until](control-flow-until-activity.md)
