---
title: Формат parquet в фабрике данных Azure | Документация Майкрософт
description: В этом разделе описывается, как работать с формат Parquet в фабрике данных Azure.
author: linda33wj
manager: craigg
ms.reviewer: craigg
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.date: 04/29/2019
ms.author: jingwang
ms.openlocfilehash: 360b794f0d8ba9c145a92f015f264eb624fbb0f1
ms.sourcegitcommit: f6ba5c5a4b1ec4e35c41a4e799fb669ad5099522
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/06/2019
ms.locfileid: "65144881"
---
# <a name="parquet-format-in-azure-data-factory"></a>Формат parquet в фабрике данных Azure

Выполните в этой статье, если вы хотите **проанализировать файлы Parquet или записать данные в формат Parquet**. 

Формат parquet поддерживается для следующих соединителей: [Amazon S3](connector-amazon-simple-storage-service.md), [BLOB-объектов Azure](connector-azure-blob-storage.md), [Gen1 хранилища Озера данных Azure](connector-azure-data-lake-store.md), [хранилища Озера данных Azure 2-го поколения](connector-azure-data-lake-storage.md), [хранилища файлов Azure](connector-azure-file-storage.md), [Файловая система](connector-file-system.md), [FTP](connector-ftp.md), [Google Cloud Storage](connector-google-cloud-storage.md), [HDFS](connector-hdfs.md), [HTTP](connector-http.md)и [ SFTP](connector-sftp.md).

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в статье о [наборах данных](concepts-datasets-linked-services.md). Этот раздел содержит список свойств, поддерживаемых набором данных Parquet.

| Свойство         | ОПИСАНИЕ                                                  | Обязательно для заполнения |
| ---------------- | ------------------------------------------------------------ | -------- |
| Тип             | Свойство type набора данных должно быть присвоено **Parquet**. | Yes      |
| location         | Параметры расположения файлов. Каждый соединитель на основе файлов имеет собственный тип расположения и поддерживаемые свойства в разделе `location`. **Подробнее см. в статье о соединителе "->" в разделе "Свойства набора данных"**. | Yes      |
| compressionCodec | Кодек сжатия для использования при записи в файлы Parquet. При чтении из файлов Parquet, фабрика данных автоматически определять на основе файла метаданных кодек сжатия.<br>Поддерживаемые типы: "**none**«,»**gzip**«,»**snappy**" (по умолчанию), и "**lzo**«. В настоящее время, обратите внимание, что действие копирования не поддерживает LZO. | Нет        |

> [!NOTE]
> Пробелы в имени столбца не поддерживается для файлов Parquet.

Ниже приведен пример набора данных Parquet в хранилище BLOB-объектов:

```json
{
    "name": "ParquetDataset",
    "properties": {
        "type": "Parquet",
        "linkedServiceName": {
            "referenceName": "<Azure Blob Storage linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, retrievable during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureBlobStorageLocation",
                "container": "containername",
                "folderPath": "folder/subfolder",
            },
            "compressionCodec": "snappy"
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, используемых для определения действий, см. в статье [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). Этот раздел содержит список свойств, поддерживаемых Parquet источника и приемника.

### <a name="parquet-as-source"></a>Parquet как источник

Следующие свойства поддерживаются в действии копирования ***\*источника\**** раздел.

| Свойство      | ОПИСАНИЕ                                                  | Обязательно для заполнения |
| ------------- | ------------------------------------------------------------ | -------- |
| Тип          | Свойство type источника действия копирования должно быть присвоено **ParquetSource**. | Yes      |
| storeSettings | Группа свойств о том, как считывать данные из хранилища данных. Каждый соединитель на основе файлов имеет свой собственный поддерживаемых параметров чтения в группе `storeSettings`. **Подробнее см. в статье о соединителе "->" в разделе "Свойства" Действие копирования**. | Нет        |

### <a name="parquet-as-sink"></a>Parquet как приемник

Следующие свойства поддерживаются в действии копирования ***\*приемника\**** раздел.

| Свойство      | ОПИСАНИЕ                                                  | Обязательно для заполнения |
| ------------- | ------------------------------------------------------------ | -------- |
| Тип          | Свойство type источника действия копирования должно быть присвоено **ParquetSink**. | Yes      |
| storeSettings | Группа свойств о том, как записывать данные в хранилище данных. Каждый соединитель на основе файлов имеет свои собственные параметры записи, поддерживаемые в разделе `storeSettings`. **Подробнее см. в статье о соединителе "->" в разделе "Свойства" Действие копирования**. | Нет        |

## <a name="mapping-data-flow-properties"></a>Сопоставление свойств потока данных

Дополнительные сведения см. в [преобразование исходного](data-flow-source.md) и [приемника преобразования](data-flow-sink.md) в сопоставление потока данных.

## <a name="data-type-support"></a>Поддержка типов данных

Parquet, сложные типы данных в настоящее время не поддерживается (например, MAP, LIST, СТРУКТУРЫ).

## <a name="using-self-hosted-integration-runtime"></a>С помощью локальной среды выполнения интеграции

> [!IMPORTANT]
> Для копирования посредством локальной среды выполнения интеграции (IR), то есть между локальным и облачным хранилищами данных, если вы не копируете файлы Parquet **как есть**, на компьютере среды выполнения интеграции необходимо установить **64-разрядную JRE 8 (среду выполнения Java) или OpenJDK**. Подробные сведения приведены в следующем абзаце.

Для операций копирования, выполняемых в локальной среде IR с сериализацией или десериализацией файлов Parquet, файл определения приложения определяет среду выполнения Java, сначала проверив реестр *`(SOFTWARE\JavaSoft\Java Runtime Environment\{Current Version}\JavaHome)`* для поиска JRE, а затем (если не ничего найдено) — системную переменную *`JAVA_HOME`* для поиска OpenJDK.

- **Для использования JRE**. Для 64-разрядной версии среды выполнения интеграции требуется 64-разрядная версия JRE. Ее можно найти [здесь](https://go.microsoft.com/fwlink/?LinkId=808605).
- **Для использования OpenJDK**: он поддерживается в среде выполнения интеграции, начиная с версии 3.13. Упакуйте jvm.dll со всеми другими необходимыми сборками OpenJDK на компьютере с локальной IR и соответственно установите системную переменную среды JAVA_HOME.

> [!TIP]
> Если вы копируете данные в формат Parquet или из формата Parquet с помощью локальной среди выполнения интеграции и возникает ошибка: "Ошибка при вызове Java, сообщение: **java.lang.OutOfMemoryError:Java heap space**", можно добавить переменную среды `_JAVA_OPTIONS` в компьютере, на котором размещена локальная среда выполнения интеграции для настройки минимального и максимального размера кучи для виртуальной машины Java, чтобы расширить возможности такой копии, а затем повторно запустить конвейер.

![Установка размера кучи виртуальной машины Java на локальной среде выполнения интеграции](C:/AzureContent/azure-docs-pr/articles/data-factory/media/supported-file-formats-and-compression-codecs/set-jvm-heap-size-on-selfhosted-ir.png)

Пример: установите переменную `_JAVA_OPTIONS` со значением `-Xms256m -Xmx16g`. Флаг `Xms` указывает начальный пул выделения памяти для виртуальной машины Java (JVM), а `Xmx` указывает максимальный пул выделения памяти. Это означает, что JVM будет запущена с объемом памяти `Xms` и сможет использовать не более `Xmx` объема памяти. По умолчанию ADF использует минимум 64 МБ и максимум 1 ГБ.

## <a name="next-steps"></a>Дальнейшие действия

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Процесс сопоставления данных](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)