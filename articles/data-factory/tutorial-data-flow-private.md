---
title: Преобразование данных с помощью потока данных сопоставления управляемой виртуальной сети фабрики данных Azure
description: В этом руководстве содержатся пошаговые инструкции по использованию фабрики данных Azure для преобразования данных с помощью потока данных сопоставления.
author: djpmsft
ms.author: daperlov
ms.reviewer: makromer
ms.service: data-factory
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 05/19/2019
ms.openlocfilehash: 5515f6c4dfbc5d3c0e391373e763597d7fdc89ed
ms.sourcegitcommit: 3543d3b4f6c6f496d22ea5f97d8cd2700ac9a481
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/20/2020
ms.locfileid: "86532318"
---
# <a name="transform-data-securely-using-mapping-data-flows"></a>Безопасное преобразование данных с помощью сопоставления потоков данных

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Если вы еще не работали с фабрикой данных Azure, ознакомьтесь со статьей [Введение в фабрику данных Azure](https://docs.microsoft.com/azure/data-factory/introduction).

В этом руководстве вы будете использовать пользовательский интерфейс фабрики данных Azure (UI) для создания конвейера, который копирует и преобразует данные **из источника Azure Data Lake Storage (ADLS) Gen2 в приемник ADLS 2-го поколения (разрешающий доступ только к выбранным сетям)** с использованием потока данных сопоставления в [управляемой виртуальной сети фабрики данных Azure](managed-virtual-network-private-endpoint.md). Шаблон конфигурации в этом руководстве можно расширить при преобразовании данных с помощью потока данных сопоставления.

Вот какие шаги выполняются в этом руководстве:

> [!div class="checklist"]
>
> * Создали фабрику данных.
> * Создание конвейера с действием потока данных.
> * Создание потока данных сопоставления с четырьмя преобразованиями.
> * тестовый запуск конвейера;
> * Наблюдение за действием потока данных

## <a name="prerequisites"></a>Предварительные требования
* **Подписка Azure**. Если у вас еще нет подписки Azure, создайте [бесплатную учетную запись](https://azure.microsoft.com/free/) Azure, прежде чем начинать работу.
* **Учетная запись хранения Azure**. Хранилище ADLS используется в качестве хранилища данных *источника* и *приемника* . Если у вас нет учетной записи хранения, создайте ее, следуя действиям в [этом разделе](https://docs.microsoft.com/azure/storage/common/storage-account-create?tabs=azure-portal). **Убедитесь, что учетная запись хранения разрешает доступ только из "выбранных сетей".** 

Файл, который мы преобразовывать в этом учебнике, MoviesDB.csv, который можно найти [здесь](https://raw.githubusercontent.com/djpmsft/adf-ready-demo/master/moviesDB.csv). Чтобы получить файл из GitHub, скопируйте его содержимое в текстовый редактор по своему усмотрению, чтобы сохранить его локально в виде CSV-файла. Сведения о передаче файла в учетную запись хранения см. [в разделе Отправка больших двоичных объектов с помощью портал Azure](https://docs.microsoft.com/azure/storage/blobs/storage-quickstart-blobs-portal). Примеры будут ссылаться на контейнер с именем Sample-Data.

## <a name="create-a-data-factory"></a>Создание фабрики данных

На этом шаге вы создадите фабрику данных и откроете интерфейс взаимодействия фабрики данных, чтобы создать конвейер в фабрике данных.

1. Откройте **Microsoft Edge** или **Google Chrome**. В настоящее время пользовательский интерфейс фабрики данных поддерживается только в веб-браузерах Microsoft ребр и Google Chrome.
2. В меню слева выберите **Создать ресурс** > **Аналитика** > **Фабрика данных**.
3. На странице **Новая фабрика данных** в поле **Имя** введите **ADFTutorialDataFactory**.

   Имя фабрики данных Azure должно быть *глобально уникальным*. Если вы увидите следующую ошибку касательно значения имени, введите другое имя фабрики данных. (Например, используйте yournameADFTutorialDataFactory.) Дополнительные сведения о правилах именования артефактов фабрики данных см. в статье [Фабрика данных Azure — правила именования](naming-rules.md).

4. Выберите **подписку** Azure, в рамках которой вы хотите создать фабрику данных.
5. Для **группы ресурсов** выполните одно из следующих действий:

    а. Выберите **Использовать существующую**и укажите существующую группу ресурсов в раскрывающемся списке.

    b. Выберите **Создать новую**и укажите имя группы ресурсов. 
         
    Сведения о группах ресурсов см. в статье [Общие сведения об Azure Resource Manager](../azure-resource-manager/management/overview.md). 
6. В качестве **версии** выберите **V2**.
7. В поле **Расположение** выберите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных (например, служба хранилища Azure и база данных SQL) и расчеты (например, Azure HDInsight), используемые фабрикой данных, могут находиться в других регионах.

8. Нажмите кнопку **создания**.

9. После завершения создания вы увидите уведомление в центре уведомлений. Нажмите кнопку **Перейти к ресурсу**, чтобы открыть страницу фабрики данных.
10. Выберите **Создание и мониторинг**, чтобы запустить на отдельной вкладке пользовательский интерфейс фабрики данных.

## <a name="create-an-azure-integration-runtime-in-adf-managed-virtual-network"></a>Создание Azure Integration Runtime в управляемой виртуальной сети ADF
На этом шаге вы создадите Azure Integration Runtime и включите управляемую виртуальную сеть.

1. На портале ADF перейдите в раздел **Управление центром** и щелкните **создать** , чтобы создать новый Azure Integration Runtime.
   ![Создание нового Azure Integration Runtime](./media/tutorial-copy-data-portal-private/create-new-azure-ir.png)
2. Выберите создание Integration Runtime **Azure** .
   ![Новые Azure Integration Runtime](./media/tutorial-copy-data-portal-private/azure-ir.png)
3. Включить **виртуальную сеть**.
   ![Новые Azure Integration Runtime](./media/tutorial-copy-data-portal-private/enable-managed-vnet.png)
4. Нажмите кнопку **создания**.

## <a name="create-a-pipeline-with-a-data-flow-activity"></a>Создание конвейера с действием потока данных

На этом шаге вы создадите конвейер, содержащий действие потока данных.

1. На странице **Начало работы** выберите **Create pipeline** (Создать конвейер).

   ![Создание конвейера](./media/doc-common-process/get-started-page.png)

1. На панели **свойств** конвейера введите **Трансформмовиес** в поле **имя** конвейера.
1. На верхней панели фабрики подвиньте ползунок **Отладка потока данных** на. Режим отладки позволяет выполнять интерактивное тестирование логики преобразования в динамическом кластере Spark. Подготовка кластеров потоков данных занимает 5-7 минут, и пользователям рекомендуется включить отладку первыми, если планируется разработка потока данных. Дополнительные сведения см. в статье [Режим отладки](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-debug-mode).

    ![Отладка потока данных](media/tutorial-data-flow-private/dataflow-debug.png)
1. В области **действия** разверните элемент Гармошка **Перемещение и преобразование** . Перетащите действие **поток данных** из панели на холст конвейера.

1. Во всплывающем окне **Добавление потока данных** выберите **создать новый поток данных** , а затем выберите **сопоставление потока данных**. Когда закончите, нажмите кнопку **ОК**.

    ![Поток данных для сопоставления](media/tutorial-data-flow-private/mapping-dataflow.png)

1. Назовите **трансформмовиес** потока данных в области свойств.

## <a name="build-transformation-logic-in-the-data-flow-canvas"></a>Логика преобразования "сборка" на холсте потока данных

После создания потока данных он будет автоматически отправлен на холст потока данных. На этом шаге вы создадите поток данных, который принимает moviesDB.csv в хранилище ADLS и суммирует среднюю оценку комедиес с 1910 до 2000. Затем вы запишете этот файл обратно в хранилище ADLS.

### <a name="add-the-source-transformation"></a>Добавление преобразования «источник»

На этом шаге вы настроите Azure Data Lake Storage 2-го поколения в качестве источника.

1. В холсте потока данных добавьте источник, щелкнув поле **Добавить источник** .

1. Присвойте имя исходному **мовиесдб**. Щелкните **создать** , чтобы создать новый исходный набор данных.

1. Выберите **Azure Data Lake Storage 2-го поколения**. Нажмите кнопку "Продолжить".

1. Выберите **DelimitedText**. Нажмите кнопку "Продолжить".

1. Назовите свой набор данных **мовиесдб**. В раскрывающемся списке связанная служба выберите **создать**.

1. На экране создания связанной службы назовите связанную службу ADLS Gen2 **ADLSGen2** и укажите метод проверки подлинности. Затем введите учетные данные подключения. В этом руководстве мы используем ключ учетной записи для подключения к нашей учетной записи хранения. 

1. Убедитесь, что вы включили **интерактивную разработку**. Включение может занять около 1 минуты.

    ![Интерактивная разработка](./media/tutorial-data-flow-private/interactive-authoring.png)

1. Выберите **проверить подключение**. это должно привести к сбою, так как учетная запись хранения не обеспечивает доступ к ней без создания и утверждения частной конечной точки. В сообщении об ошибке должна отобразиться ссылка на создание **частной конечной точки** , которую можно выполнить для создания управляемой частной конечной точки. *В качестве альтернативы можно перейти непосредственно на вкладку Управление и выполнить инструкции в [этом разделе](#create-a-managed-private-endpoint) , чтобы создать управляемую закрытую конечную точку.*

1. Не закрывайте диалоговое окно, а затем перейдите к вашей учетной записи хранения, выбранной выше.

1. Следуйте инструкциям в [этом разделе](#approval-of-a-private-link-in-storage-account) , чтобы утвердить частную ссылку.

1. Вернитесь к диалоговому окну. Снова **Проверьте соединение** и выберите **создать** , чтобы развернуть связанную службу.

1. Когда вы вернетесь на экран создания набора данных, укажите, где находится файл, в поле **путь к файлу** . В этом руководстве файл moviesDB.csv находится в примере Container-Data. Так как файл содержит заголовки, установите флажок **Первая строка в качестве заголовка**. Выберите **из подключения или хранилища** , чтобы импортировать схему заголовка непосредственно из файла в хранилище. Когда закончите, нажмите кнопку ОК.

    ![Исходный путь](media/tutorial-data-flow-private/source-file-path.png)

1. Если кластер отладки запущен, перейдите на вкладку **Предварительный просмотр данных** преобразования источник и нажмите кнопку **Обновить** , чтобы получить моментальный снимок данных. Вы можете использовать предварительный просмотр данных, чтобы убедиться, что преобразование настроено правильно.

    ![Предварительный просмотр данных](media/tutorial-data-flow-private/data-preview.png)

#### <a name="create-a-managed-private-endpoint"></a>Создание управляемой частной конечной точки

Если вы не щелкнули гиперссылку при проверке соединения выше, перейдите по следующему пути. Теперь необходимо создать управляемую закрытую конечную точку, которая будет подключаться к связанной службе, созданной ранее.

1. Перейдите на вкладку Управление.
> [!NOTE]
> Вкладка "Управление" может быть недоступна для всех экземпляров фабрики данных. Если вы не видите его, вы по-прежнему можете получить доступ к частным конечным точкам через вкладку "**Author**" (> "**подключения**"--> "**Частная конечная точка**")
1. Перейдите в раздел управляемые частные конечные точки.
1. В разделе управляемые частные конечные точки выберите **+ создать** .

    ![Новая управляемая частная конечная точка](./media/tutorial-data-flow-private/new-managed-private-endpoint.png) 

1. Выберите плитку Azure Data Lake Storage 2-го поколения из списка и нажмите кнопку **продолжить**.
1. Введите имя созданной ранее учетной записи хранения.
1. Нажмите кнопку **создания**.
1. После ожидания в течение нескольких секунд вы увидите, что для созданной закрытой ссылки требуется утверждение.
1. Выберите закрытую конечную точку, созданную ранее. Вы видите гиперссылку, которая приведет к утверждению частной конечной точки на уровне учетной записи хранения.

    ![Управление частной конечной точкой](./media/tutorial-data-flow-private/manage-private-endpoint.png) 

#### <a name="approval-of-a-private-link-in-storage-account"></a>Утверждение частной ссылки в учетной записи хранения

1. В разделе "Параметры" учетной записи хранения перейдите в раздел " **частные конечные точки подключения** ".

1. Заметьте закрытую конечную точку, созданную ранее, и выберите **утвердить**.

    ![Утверждение частной конечной точки](./media/tutorial-data-flow-private/approve-private-endpoint.png)

1. Добавьте описание и нажмите кнопку **Да**.
1. Вернитесь в раздел **управляемые частные конечные точки** на вкладке **Управление** в фабрике данных Azure.
1. Получение утверждения для частной конечной точки займет около 1 минуты.

### <a name="add-the-filter-transformation"></a>Добавление преобразования «фильтр»

1. Рядом с исходным узлом на холсте потока данных щелкните значок "плюс", чтобы добавить новое преобразование. Первое добавляемое преобразование является **фильтром**.

    ![Добавление фильтра](media/tutorial-data-flow-private/add-filter.png)
1. Назовите преобразование фильтра **филтереарс**. Щелкните поле Выражение рядом с полем **Фильтр** , чтобы открыть построитель выражений. Здесь вы укажете условие фильтрации.

    ![Фильтровать годы](media/tutorial-data-flow-private/filter-years.png)
1. Построитель выражений потока данных позволяет интерактивно создавать выражения для использования в различных преобразованиях. Выражения могут включать встроенные функции, столбцы из входной схемы и определяемые пользователем параметры. Дополнительные сведения о построении выражений см. в разделе [Построитель выражений потока данных](https://docs.microsoft.com/azure/data-factory/concepts-data-flow-expression-builder).

    * В этом руководстве вы хотите отфильтровать фильмы для жанров комедия, которые поступили между годами 1910 и 2000. Поскольку в настоящее время в качестве года используется строка, ее необходимо преобразовать в целое число с помощью ```toInteger()``` функции. Используйте операторы "больше или равно" (>=) и "меньше или равно" (<=) для сравнения значений литерального года 1910 и 200-. Объедините эти выражения вместе с оператором AND (&&). Выражение выйдет следующим образом:

        ```toInteger(year) >= 1910 && toInteger(year) <= 2000```

    * Чтобы узнать, какие фильмы являются комедиес, можно использовать ```rlike()``` функцию, чтобы найти шаблон "комедия" в столбцах жанров. Объединение выражения рлике с сравнением year для получения:

        ```toInteger(year) >= 1910 && toInteger(year) <= 2000 && rlike(genres, 'Comedy')```

    * Если кластер отладки активен, можно проверить логику, нажав кнопку **Обновить** , чтобы увидеть результат выражения по сравнению с используемыми входными данными. Существует более одного правого ответа на то, как можно реализовать эту логику с помощью языка выражений потока данных.

        ![Выражения фильтра](media/tutorial-data-flow-private/filter-expression.png)

    * После завершения работы с выражением нажмите кнопку **сохранить и завершить** .

1. Получите **Предварительный просмотр данных** , чтобы убедиться, что фильтр работает правильно.

    ![Предварительный просмотр данных фильтра](media/tutorial-data-flow-private/filter-data.png)

### <a name="add-the-aggregate-transformation"></a>Добавление преобразования «Статистическая обработка»

1. Следующее преобразование, которое вы добавите, является преобразованием « **Статистическая обработка** » в **модификаторе схемы**.

    ![Добавить агрегатную функцию](media/tutorial-data-flow-private/add-aggregate.png)
1. Назовите **аггрегатекомедиратингс**преобразования «Статистическая обработка». На вкладке **Группировать по** выберите **год** из раскрывающегося списка, чтобы сгруппировать агрегаты по году, в котором был получен фильм.

    ![Агрегатная группа](media/tutorial-data-flow-private/group-by-year.png)
1. Перейдите на вкладку **статистические выражения** . В левом текстовом поле Назовите столбец Aggregate **аверажекомедиратинг**. Щелкните правой кнопкой мыши поле выражения, чтобы ввести статистическое выражение с помощью построителя выражений.

    ![Имя столбца агрегирования](media/tutorial-data-flow-private/name-column.png)
1. Чтобы получить среднее значение **рейтинга**столбца, используйте ```avg()``` агрегатную функцию. Так как **Оценка** является строкой и ```avg()``` принимает числовой ввод, необходимо преобразовать значение в число с помощью ```toInteger()``` функции. Это выражение выглядит следующим образом:

    ```avg(toInteger(Rating))```

    По завершении нажмите кнопку **сохранить и завершить** .

    ![Сохранить статистическую функцию](media/tutorial-data-flow-private/save-aggregate.png)
1. Перейдите на вкладку **Предварительный просмотр данных** , чтобы просмотреть выходные данные преобразования. Обратите внимание, что здесь есть только два столбца: **year** и **аверажекомедиратинг**.

### <a name="add-the-sink-transformation"></a>Добавление преобразования приемника

1. Затем необходимо добавить преобразование « **приемник** » в **место назначения**.

    ![Добавить приемник](media/tutorial-data-flow-private/add-sink.png)
1. Присвойте имя **приемнику**приемника. Нажмите кнопку **создать** , чтобы создать набор данных приемника.

    ![Создать приемник](media/tutorial-data-flow-private/create-sink.png)
1. На странице новый набор данных выберите **Azure Data Lake Storage 2-го поколения**. Нажмите кнопку "Продолжить".

1. На странице Выбор формата выберите **DelimitedText**. Нажмите кнопку "Продолжить".

1. Назовите свой набор данных приемника **мовиессинк**. Для связанной службы выберите ту же связанную службу ADLSGen2, которая была создана для преобразования источника. Введите выходную папку для записи данных. В этом руководстве мы выполним запись в папку "Output" в контейнере "Sample-Data". Папка не должна существовать заранее и может быть создана динамически. Задайте для параметра **Первая строка в качестве заголовка** значение true и выберите значение **нет** для параметра **схема импорта**. Щелкните ОК.

    ![Путь к приемнику](media/tutorial-data-flow-private/sink-file-path.png)

Теперь вы завершили сборку потока данных. Все готово для запуска в конвейере.

## <a name="running-and-monitoring-the-data-flow"></a>Выполнение и мониторинг потока данных

Вы можете выполнить отладку конвейера перед его публикацией. На этом шаге будет активирован запуск отладки конвейера потока данных. В то время как предварительный просмотр данных не записывает данные, отладочный запуск будет записывать данные в место назначения приемника.

1. Перейдите на холст конвейера. Нажмите кнопку **Отладка** , чтобы запустить отладку.

1. При отладке конвейера для действий потока данных используется активный кластер отладки, но инициализация по-прежнему займет не менее минуты. Ход выполнения можно отслеживать с помощью вкладки **вывод** . После успешного выполнения щелкните значок очков для сведений о запуске.

1. На странице сведений можно увидеть количество строк и время, потраченное на каждый шаг преобразования.

    ![Мониторинг выполнения](media/tutorial-data-flow-private/run-details.png)
1. Щелкните преобразование, чтобы получить подробные сведения о столбцах и секционировании данных.

Если вы выполнили это руководство правильно, в папку приемника должны быть записаны 83 строк и 2 столбца. Проверить правильность данных можно, проверив хранилище BLOB-объектов.

## <a name="summary"></a>Итоги

В этом руководстве вы будете использовать пользовательский интерфейс фабрики данных Azure (UI) для создания конвейера, который копирует и преобразует данные **из источника Azure Data Lake Storage (ADLS) Gen2 в приемник ADLS 2-го поколения (разрешающий доступ только к выбранным сетям)** с использованием потока данных сопоставления в [управляемой виртуальной сети фабрики данных Azure](managed-virtual-network-private-endpoint.md).
