---
title: Действие копирования в фабрике данных Azure | Документация Майкрософт
description: Узнайте о действии копирования в фабрике данных Azure, которое можно использовать для копирования данных из поддерживаемых источников в поддерживаемые приемники.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 08/12/2019
ms.author: jingwang
ms.openlocfilehash: 59ac4b36a4bc2b3ff454b3a2ae98ce60f6bfcb5f
ms.sourcegitcommit: 4b8a69b920ade815d095236c16175124a6a34996
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/23/2019
ms.locfileid: "69996608"
---
# <a name="copy-activity-in-azure-data-factory"></a>Действие копирования в фабрике данных Azure

## <a name="overview"></a>Обзор

> [!div class="op_single_selector" title1="Выберите используемую версию службы "Фабрика данных":"]
> * [Версия 1](v1/data-factory-data-movement-activities.md)
> * [Текущая версия](copy-activity-overview.md)

В фабрике данных Azure с помощью действия копирования можно копировать данные между локальными и облачными хранилищами данных. После копирования данные можно преобразовать и проанализировать с помощью других действий. С помощью действия копирования можно также публиковать результаты преобразования и анализа для бизнес-аналитики и использования приложения.

![Роль действия копирования](media/copy-activity-overview/copy-activity.png)

Действие копирования выполняется в [интегрированной среде выполнения](concepts-integration-runtime.md). Для различных сценариев копирования данных можно использовать различные разновидности Integration Runtime:

* При копировании данных между хранилищами данных, которые доступны для общего доступа через Интернет от любых IP-адресов, действие копирования может быть предоставлено **Azure Integration Runtime**, которое является безопасным, надежным, масштабируемым и [глобально доступным](concepts-integration-runtime.md#integration-runtime-location).
* При копировании данных в хранилища данных, расположенные локально или в сети с управлением доступом (например, виртуальная сеть Azure), и из них необходимо настроить **локальную интегрированную среду выполнения** для расширения возможностей копирования данных.

Интегрированную среду выполнения следует связать с каждым источником и приемником данных. Дополнительные сведения о том, как действие копирования определяет, какую IR использовать, см. в [этом разделе](concepts-integration-runtime.md#determining-which-ir-to-use).

При копировании данных из источника в приемник действие копирования выполняет такие действия: Служба, на основе которой реализовано действие копирования, выполняет следующее:

1. Считывает данные из источника данных.
2. Выполняет сериализацию или десериализацию, сжатие или распаковку, сопоставление столбцов и т. д. Она выполняет эти операции в соответствии с конфигурациями наборов входных данных, наборов выходных данных и действия копирования.
3. Записывает данные в приемник или целевое хранилище данных.

![Общие сведения о действии копирования](media/copy-activity-overview/copy-activity-overview.png)

## <a name="supported-data-stores-and-formats"></a>Поддерживаемые хранилища данных и форматы

[!INCLUDE [data-factory-v2-supported-data-stores](../../includes/data-factory-v2-supported-data-stores.md)]

### <a name="supported-file-formats"></a>Поддерживаемые форматы файлов

Действие копирования можно использовать для **копирования файлов "как есть"** между двумя хранилищами данных на основе файлов. При этом данные эффективно копируются без какой-либо сериализации или десериализации.

Кроме того, действие копирования поддерживает считывание и запись файлов в таких форматах: **Text, JSON, Avro, ORC и Parquet**, сжатие и распаковка файлов с помощью следующих кодеков: **Gzip, Deflate, bzip2 и ZipDeflate**. Дополнительные сведения см. в разделе [Форматы файлов и сжатия данных, поддерживаемые фабрикой данных Azure](supported-file-formats-and-compression-codecs.md).

Например, можно выполнять следующие действия копирования:

* Копирование данных в локальную SQL Server и запись в Azure Data Lake Storage 2-го поколения в формате Parquet.
* копирование файлов в текстовом формате (CSV) из локальной файловой системы и запись в большой двоичный объект Azure в формате AVRO;
* Скопируйте ZIP-файлы из локальной файловой системы и распакуйте их в Azure Data Lake Storage 2-го поколения.
* копирование данных в сжатом с помощью GZip текстовом формате (CSV) из большого двоичного объекта Azure и запись в Базу данных SQL Azure;
* И многие другие варианты, необходимые для сериализации, десериализации или сжатия и распаковки.

## <a name="supported-regions"></a>Поддерживаемые регионы

Служба, управляющая действием копирования, является общедоступной в регионах и географических областях, перечисленных в разделе [Расположение среды выполнения интеграции](concepts-integration-runtime.md#integration-runtime-location). Глобально доступная топология обеспечивает эффективное перемещение данных, обычно позволяя избежать "прыжков" по разным регионам. Дополнительные сведения о доступности фабрики данных и перемещения данных в регионе см. на [этой странице](https://azure.microsoft.com/regions/#services).

## <a name="configuration"></a>Конфигурация

Чтобы использовать действие копирования в фабрике данных Azure, необходимо:

1. **Создать связанные службы для источника и приемника данных.** Дополнительные сведения о настройке и поддерживаемых свойствах см. в разделе "Свойства связанных служб" статьи о соединителях. Список поддерживаемых соединителей приведен в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats).
2. **Создать наборы данных для источника и приемника.** Дополнительные сведения о настройке и поддерживаемых свойствах см. в разделе "Свойства набора данных" статьи о соединителях источника и приемника.
3. **Создать конвейер с действием копирования.** В следующем разделе приведен пример.

### <a name="syntax"></a>Синтаксис

Следующий шаблон действия копирования содержит исчерпывающий список поддерживаемых свойств. Выберите свойства для своего сценария.

```json
"activities":[
    {
        "name": "CopyActivityTemplate",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<source dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<sink dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>",
                <properties>
            },
            "sink": {
                "type": "<sink type>"
                <properties>
            },
            "translator":
            {
                "type": "TabularTranslator",
                "columnMappings": "<column mapping>"
            },
            "dataIntegrationUnits": <number>,
            "parallelCopies": <number>,
            "enableStaging": true/false,
            "stagingSettings": {
                <properties>
            },
            "enableSkipIncompatibleRow": true/false,
            "redirectIncompatibleRowSettings": {
                <properties>
            }
        }
    }
]
```

### <a name="syntax-details"></a>Сведения о синтаксисе

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Свойство type действия копирования должно иметь значение **Copy**. | Да |
| Входные данные | Укажите созданный набор данных, который указывает на исходные данные. Действие копирования поддерживает один экземпляр входных данных. | Да |
| выходные данные | Укажите созданный набор данных, который указывает на данные приемника. Действие копирования поддерживает один экземпляр выходных данных. | Да |
| typeProperties | Группа свойств для настройки действия копирования. | Да |
| источник | Укажите тип источника копирования и соответствующие свойства, определяющие конкретный сценарий извлечения данных.<br/><br/>Дополнительные сведения см. в разделе "Свойства действия копирования" в статье о соединителях, приведенных в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats). | Да |
| приемник | Укажите тип приемника копирования и соответствующие свойства, определяющие конкретный сценарий записи данных.<br/><br/>Дополнительные сведения см. в разделе "Свойства действия копирования" в статье о соединителях, приведенных в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats). | Да |
| translator | Укажите явные сопоставления столбцов от источника к приемнику. Применяется, когда действие копирования по умолчанию не может удовлетворить ваши потребности.<br/><br/>Дополнительные сведения см. в статье [Schema mapping in copy activity](copy-activity-schema-and-type-mapping.md) (Сопоставление диаграммы в действии копирования). | Нет |
| dataIntegrationUnits | Укажите число единиц перемещения для [интегрированной среды выполнения Azure](concepts-integration-runtime.md), обеспечивающей копирование данных. Прежнее название — единицы перемещения облачных данных <br/><br/>См. дополнительные сведения об [единицах интеграции данных](copy-activity-performance.md#data-integration-units). | Нет |
| parallelCopies | Укажите показатель параллелизма, который должно использовать действие копирования при считывании данных из источника и записи данных в приемник.<br/><br/>Дополнительные сведения см. в разделе [Parallel copy](copy-activity-performance.md#parallel-copy) (Параллельное копирование). | Нет |
| enableStaging<br/>stagingSettings | Выберите размещение промежуточных данных в хранилище BLOB-объектов вместо прямого копирования данных из источника в приемник.<br/><br/>Дополнительные сведения о полезных сценариях и конфигурации см. в разделе [Staged copy](copy-activity-performance.md#staged-copy) (Промежуточное копирование). | Нет |
| enableSkipIncompatibleRow<br/>redirectIncompatibleRowSettings| Позволяет выбрать способ обработки несовместимых строк при копировании данных из источника в приемник.<br/><br/>Дополнительные сведения см. в статье [Fault tolerance of copy activity in Azure Data Factory](copy-activity-fault-tolerance.md) (Отказоустойчивость действия копирования в фабрике данных Azure). | Нет |

## <a name="monitoring"></a>Отслеживание

Вы можете отслеживать выполнение действия копирования в пользовательском интерфейсе "Создание и мониторинг" службы "Фабрика данных Azure" или при помощи программных средств.

### <a name="monitor-visually"></a>Визуальный мониторинг

Чтобы визуально отслеживать выполнение действия копирования, в фабрике данных последовательно выберите **Создание и мониторинг** -> **Вкладка монитора**. Здесь отображается список запусков конвейера, для каждого из которых в столбце **Действия** предоставлена ссылка View Activity Runs (Просмотр выполнений действий).

![Мониторинг выполнений конвейера](./media/load-data-into-azure-data-lake-store/monitor-pipeline-runs.png)

Щелкните ее, чтобы отобразился список действий для конкретного запуска конвейера. В столбце **Действия** есть ссылки на входные и выходные данные, ошибки (если действие копирования завершилось сбоем) и подробные сведения о действии копирования.

![Мониторинг выполнений действий](./media/load-data-into-azure-data-lake-store/monitor-activity-runs.png)

Щелкните ссылку **Сведения** в столбце **Действия**, чтобы просмотреть сведения о выполнении и о производительности действия копирования. Для каждого сценария копирования отображаются такие сведения, как объем данных, количество строк и (или) файлов, скопированных из источника в приемник, пропускная способность, полный список процессов с указанием времени выполнения, а также выбранная конфигурация.

>[!TIP]
>В некоторых сценариях вы также увидите "**Советы по настройке производительности**" в верхней части страницы "мониторинг копирования", которая сообщает об обнаружении узкого места и рассказывает о том, что нужно изменить. чтобы повысить пропускную способность копирования, см. пример с подробными сведениями [здесь](#performance-and-tuning).

**Пример: копирование из Amazon S3 в Azure Data Lake Store**
![Сведения о выполнении действия](./media/copy-activity-overview/monitor-activity-run-details-adls.png)

**Пример: копирование из службы "База данных SQL Azure" в хранилище данных SQL Azure с применением промежуточного копирования**
![Сведения о выполнении действия](./media/copy-activity-overview/monitor-activity-run-details-sql-dw.png)

### <a name="monitor-programmatically"></a>Мониторинг при помощи программных средств

Сведения о выполнении действия копирования и характеристики производительности также возвращаются в разделе вывод результатов выполнения действия копирования — >. Ниже приведен полный список параметров, из которых будут отображаться только применимые к вашему сценарию копирования. Дополнительные сведения о мониторинге выполняемого действия см. в [этом разделе](quickstart-create-data-factory-dot-net.md#monitor-a-pipeline-run).

| Имя свойства  | Описание | Единица измерения |
|:--- |:--- |:--- |
| dataRead | Размер данных, считанных из источника. | Значение Int64 в **байтах** |
| dataWritten | Размер данных, записанных в приемник. | Значение Int64 в **байтах** |
| filesRead | Число файлов, скопированных из хранилища файлов. | Значение Int64 (не единица измерения) |
| filesWritten | Число файлов, скопированных в хранилище файлов. | Значение Int64 (не единица измерения) |
| саурцепеакконнектионс | Максимальное число одновременных подключений, установленных для исходного хранилища данных во время выполнения действия копирования. | Значение Int64 (не единица измерения) |
| синкпеакконнектионс | Максимальное число одновременных подключений, установленных для приемника хранилища данных во время выполнения действия копирования. | Значение Int64 (не единица измерения) |
| ровсреад | Число строк, считываемых из источника (неприменимо для двоичного копирования). | Значение Int64 (не единица измерения) |
| rowsCopied | Число строк, копируемых в приемник (неприменимо для двоичного копирования). | Значение Int64 (не единица измерения) |
| rowsSkipped | Число пропущенных несовместимых строк. Эту возможность можно включить, задав свойству enableSkipIncompatibleRow значение true. | Значение Int64 (не единица измерения) |
| copyDuration | Длительность копирования. | Значение Int32 в секундах |
| throughput | Коэффициент передачи данных. | Число с плавающей запятой (**КБ/с**) |
| саурцепеакконнектионс | Пиковое число одновременных подключений, установленных для исходного хранилища данных во время копирования. | Значение Int32 |
| синкпеакконнектионс| Пиковое число одновременных подключений, установленных в хранилище данных приемника во время копирования.| Значение Int32 |
| sqlDwPolyBase | Если при копировании данных в хранилище данных SQL используется PolyBase. | логический |
| redshiftUnload | Если при копировании данных из Redshift используется команда UNLOAD. | логический |
| hdfsDistcp | Если при копировании данных из HDFS используется DistCp. | логический |
| effectiveIntegrationRuntime | Показывает, какие среды Integration Runtime используются для выполнения действия, в формате `<IR name> (<region if it's Azure IR>)`. | Текст (string) |
| usedDataIntegrationUnits | Единицы интеграции актуальных данных во время копирования. | Значение Int32 |
| usedParallelCopies | Использованное количество параллельных процессов копирования. | Значение Int32 |
| redirectRowPath | Путь к журналу пропущенных несовместимых строк в хранилище BLOB-объектов, который настраивается в разделе redirectIncompatibleRowSettings. См. пример ниже. | Текст (string) |
| executionDetails | Дополнительные сведения о стадиях, которые проходит действие копирования, с указанием всех шагов, длительности, конфигураций и т. п. Не рекомендуем применять синтаксический анализ для этого раздела, поскольку его формат может изменяться.<br/><br/>Кроме того, ADF-файл содержит подробные сведения о длительности (в секундах `detailedDurations`), затраченные на выполнение соответствующих действий. Продолжительность этих шагов является исключительной, и только те, которые относятся к заданному действию копирования, будут отображаться следующим образом:<br/>- **Длительность очереди** (`queuingDuration`): Время, прошедшее до фактического запуска действия копирования в среде выполнения интеграции. Если используется локально размещенное IR и это значение велико, рекомендуется проверить емкость и использование IR, а также увеличить или уменьшить масштаб в соответствии с рабочей нагрузкой. <br/>- **Длительность скрипта перед копированием** (`preCopyScriptDuration`): Время, прошедшее между действием копирования, начинающимся с IR и действием копирования, которое завершило выполнение скрипта, выполняемого перед копированием, в приемнике хранилища данных. Применяется при настройке скрипта перед копированием. <br/>- **Время до первого байта** (`timeToFirstByte`): Время, прошедшее между окончанием предыдущего шага и ИК-сигналом, получающим первый байт из исходного хранилища данных. Применяется к источнику, отличному от файла. Если это значение велико, рекомендуется проверить и оптимизировать запрос или сервер.<br/>- **Длительность перемещения** (`transferDuration`): Время, прошедшее между окончанием предыдущего шага и передачей данных от источника к приемнику. | Array |
| перфрекоммендатион | Скопируйте советы по настройке производительности. Дополнительные сведения см. в разделе [производительность и настройка](#performance-and-tuning) . | Array |

```json
"output": {
    "dataRead": 6198358,
    "dataWritten": 19169324,
    "filesRead": 1,
    "sourcePeakConnections": 1,
    "sinkPeakConnections": 2,
    "rowsRead": 39614,
    "rowsCopied": 39614,
    "copyDuration": 1325,
    "throughput": 4.568,
    "errors": [],
    "effectiveIntegrationRuntime": "DefaultIntegrationRuntime (West US)",
    "usedDataIntegrationUnits": 4,
    "usedParallelCopies": 1,
    "executionDetails": [
        {
            "source": {
                "type": "AzureBlobStorage"
            },
            "sink": {
                "type": "AzureSqlDatabase"
            },
            "status": "Succeeded",
            "start": "2019-08-06T01:01:36.7778286Z",
            "duration": 1325,
            "usedDataIntegrationUnits": 4,
            "usedParallelCopies": 1,
            "detailedDurations": {
                "queuingDuration": 2,
                "preCopyScriptDuration": 12,
                "transferDuration": 1311
            }
        }
    ],
    "perfRecommendation": [
        {
            "Tip": "Sink Azure SQL Database: The DTU utilization was high during the copy activity run. To achieve better performance, you are suggested to scale the database to a higher tier than the current 1600 DTUs.",
            "ReferUrl": "https://go.microsoft.com/fwlink/?linkid=2043368",
            "RuleName": "AzureDBTierUpgradePerfRecommendRule"
        }
    ]
}
```

## <a name="schema-and-data-type-mapping"></a>Сопоставление типов данных и схемы

Дополнительные сведения о том, как действие копирования сопоставляет данные источника в приемнике, см. в статье [Schema mapping in copy activity](copy-activity-schema-and-type-mapping.md) (Сопоставление схемы в действии копирования).

## <a name="fault-tolerance"></a>Отказоустойчивость

По умолчанию действие копирования прекращает копирование данных и возвращает ошибку при обнаружении несовместимых данных между источником и приемником. Для успешного копирования данных можно явно настроить пропуск и запись несовместимых строк и копировать только совместимые данные. Дополнительные сведения см. в разделе [Отказоустойчивость действий копирования](copy-activity-fault-tolerance.md).

## <a name="performance-and-tuning"></a>Производительность и настройка

Сведения о ключевых факторах, влияющих на производительность перемещения данных (действие копирования) в фабрике данных Azure см. в [руководстве по настройке производительности действия копирования](copy-activity-performance.md). В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.

Как показано в следующем примере, в некоторых случаях при выполнении операции копирования в ADF появляются **Советы по настройке производительности** в верхней части [страницы мониторинга действия копирования](#monitor-visually). Там не только показано узкое место, определенное для данного прогона копирования, но и указано, что нужно изменить, чтобы повысить пропускную способность копирования. Сейчас в советах по настройке производительности предлагается использование PolyBase при копировании данных в Хранилище данных SQL Azure, что увеличит размер баз данных Azure Cosmos DB RU или Azure SQL DB DTU, в то время как ресурс на стороне хранилища данных является узким местом из-за удаления ненужной поэтапной копии и т. д. Правила настройки производительности будут постепенно улучшаться.

**Пример. Копирование в базу данных SQL Azure с помощью советов по настройке производительности**

В этом примере во время выполнения копирования служба ADF замечает, что приемник базы данных SQL Azure достигает высокой степени использования DTU, что замедляет операции записи, поэтому рекомендуется увеличить уровень базы данных SQL Azure с большим количеством DTU.

![Мониторинг копирования с помощью советов по настройке производительности](./media/copy-activity-overview/copy-monitoring-with-performance-tuning-tips.png)

## <a name="incremental-copy"></a>Добавочное копирование
Фабрика данных поддерживает сценарии для постепенного копирования разностных данных из исходного хранилища данных в приемниковый. Дополнительные сведения см. в [руководстве по добавочному копированию данных](tutorial-incremental-copy-overview.md).

## <a name="next-steps"></a>Следующие шаги
Ознакомьтесь со следующими руководствами и примерами:

- [Create a data factory and pipeline using .NET SDK](quickstart-create-data-factory-dot-net.md) (Создание фабрики данных и конвейера с помощью пакета SDK для .NET)
- [Copy data from Azure Blob to Azure SQL Database using Azure Data Factory](tutorial-copy-data-dot-net.md) (Копирование данных из большого двоичного объекта Azure в Базу данных SQL Azure с помощью Фабрики данных Azure)
- [Copy data between on-premises and cloud](tutorial-hybrid-copy-powershell.md) (Копирование данных между локальным расположением и облаком)
