---
title: Копирование активности на фабрике данных Azure
description: Узнайте об активности Copy на фабрике данных Azure. Его можно использовать для копирования данных из поддерживаемого хранилища исходных данных в поддерживаемый хранилище данных раковины.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.date: 03/25/2020
ms.author: jingwang
ms.openlocfilehash: 2557ce7be44f0505b96df06cd2b44a2fa3ce3fdb
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81414223"
---
# <a name="copy-activity-in-azure-data-factory"></a>Копирование активности на фабрике данных Azure

> [!div class="op_single_selector" title1="Выберите используемую версию фабрики данных:"]
> * [Версия 1](v1/data-factory-data-movement-activities.md)
> * [Текущая версия](copy-activity-overview.md)

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

На фабрике данных Azure можно использовать действие Copy для копирования данных в хранилищах данных, расположенных в помещениях и в облаке. После копирования данных можно использовать другие действия для их дальнейшей трансформации и анализа. Вы также можете использовать деятельность Copy для публикации результатов трансформации и анализа для бизнес-аналитики (BI) и потребления приложений.

![Роль деятельности Copy](media/copy-activity-overview/copy-activity.png)

Действие Copy выполняется во [время выполнения интеграции.](concepts-integration-runtime.md) Можно использовать различные типы времени выполнения интеграции для различных сценариев копирования данных:

* При копировании данных между двумя хранилищами данных, которые общедоступны через Интернет с любого IP, можно использовать время выполнения интеграции Azure для копирования. Эта интеграция работает безопасно, надежно, масштабируема и [доступна во всем мире.](concepts-integration-runtime.md#integration-runtime-location)
* При копировании данных в хранилища данных, расположенных в помещениях или в сети с контролем доступа (например, в виртуальную сеть Azure), необходимо настроить самохознянное время выполнения интеграции.

Время выполнения интеграции должно быть связано с каждым источником и хранилищем данных. Для получения информации о том, как действие Copy определяет время выполнения интеграции, [см.](concepts-integration-runtime.md#determining-which-ir-to-use)

Для копирования данных от источника до раковины служба, выполняя действие Copy, выполняет следующие действия:

1. Считывает данные из источника данных.
2. Выполняет сериализацию/десериализацию, сжатие/декомпрессию, отображение столбцов и так далее. Он выполняет эти операции на основе конфигурации набора входных данных, набора выходных данных и активности копирования.
3. Записывает данные в приемник или целевое хранилище данных.

![Общие сведения о действии копирования](media/copy-activity-overview/copy-activity-overview.png)

## <a name="supported-data-stores-and-formats"></a>Поддерживаемые хранилища данных и форматы

[!INCLUDE [data-factory-v2-supported-data-stores](../../includes/data-factory-v2-supported-data-stores.md)]

### <a name="supported-file-formats"></a>Поддерживаемые форматы файлов

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Вы можете использовать действие Copy для копирования файлов как между двумя файлохранилищами данных, и в этом случае данные копируются эффективно без сериализации или десериализации. Кроме того, можно также разобрать или сгенерировать файлы данного формата, например, вы можете выполнить следующее:

* Копируйте данные из предварительной базы данных S'L Server и записывайте в Azure Data Lake Storage Gen2 в формате Parquet.
* Копирование файлов в текстовом формате (CSV) из файловой системы и запись в хранилище Azure Blob в формате Avro.
* Копируйте файлы на молнии из файловой системы, распаковывайте их на лету и записывайте извлеченные файлы в Azure Data Lake Storage Gen2.
* Копирование данных в формате сжатого текста Gzip (CSV) из хранилища Azure Blob и запишите их в базу данных Azure S'L.
* Гораздо больше мероприятий, которые требуют сериализации/ десериализации или сжатия/ декомпрессии.

## <a name="supported-regions"></a>Поддерживаемые регионы

Служба, позволяющая выполнять действия Copy, доступна по всему миру в регионах и географических регионах, перечисленных в [местах выполнения интеграции Azure.](concepts-integration-runtime.md#integration-runtime-location) Глобально доступная топология обеспечивает эффективное перемещение данных, обычно позволяя избежать "прыжков" по разным регионам. Ознакомьтесь с [продуктами по регионам,](https://azure.microsoft.com/regions/#services) чтобы проверить наличие фабрики данных и движения данных в определенном регионе.

## <a name="configuration"></a>Конфигурация

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

Как правило, для использования действия Copy на фабрике данных Azure необходимо:

1. **Создание связанных служб для хранилища исходных данных и хранилища данных раковины.** Список поддерживаемых разъемов можно найти в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats) этой статьи. Обратитесь к разделу раздела "Связанные свойства обслуживания" статьи разъема для получения информации о конфигурации и поддерживаемых свойств. 
2. **Создавайте наборы данных для источника и раковины.** Ссылка на разделы "Свойства данных" в статьях источника и разъема раковины для получения информации о конфигурации и поддерживаемых свойств.
3. **Создайте конвейер с помощью действия Copy.** В следующем разделе приведен пример.

### <a name="syntax"></a>Синтаксис

Следующий шаблон действия Copy содержит полный список поддерживаемых свойств. Выберите свойства для своего сценария.

```json
"activities":[
    {
        "name": "CopyActivityTemplate",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<source dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<sink dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>",
                <properties>
            },
            "sink": {
                "type": "<sink type>"
                <properties>
            },
            "translator":
            {
                "type": "TabularTranslator",
                "columnMappings": "<column mapping>"
            },
            "dataIntegrationUnits": <number>,
            "parallelCopies": <number>,
            "enableStaging": true/false,
            "stagingSettings": {
                <properties>
            },
            "enableSkipIncompatibleRow": true/false,
            "redirectIncompatibleRowSettings": {
                <properties>
            }
        }
    }
]
```

#### <a name="syntax-details"></a>Сведения о синтаксисе

| Свойство | Описание | Обязательно? |
|:--- |:--- |:--- |
| type | Для действия Copy, установленного на`Copy` | Да |
| inputs | Укажите созданный набор данных, указывающий на исходные данные. Активность Copy поддерживает только один вход. | Да |
| outputs | Укажите созданный набор данных, указывающий на данные раковины. Активность Copy поддерживает только один выход. | Да |
| typeProperties | Укажите свойства для настройки действия Copy. | Да |
| source | Укажите тип источника копии и соответствующие свойства для извлечения данных.<br/>Для получения дополнительной информации смотрите раздел "Копировать свойства активности" в статье разъема, указанной в [поддерживаемых хранилищах и форматах данных.](#supported-data-stores-and-formats) | Да |
| sink | Укажите тип раковины копии и соответствующие свойства для написания данных.<br/>Для получения дополнительной информации смотрите раздел "Копировать свойства активности" в статье разъема, указанной в [поддерживаемых хранилищах и форматах данных.](#supported-data-stores-and-formats) | Да |
| translator | Укажите явные сопоставления столбцов от источника к приемнику. Это свойство применяется, когда поведение копии по умолчанию не отвечает вашим потребностям.<br/>Для получения дополнительной информации смотрите [отображение Schema в активности копирования](copy-activity-schema-and-type-mapping.md). | нет |
| dataIntegrationUnits | Укажите меру, представляющую объем мощности, который использует [время выполнения интеграции Azure](concepts-integration-runtime.md) для копирования данных. Эти устройства ранее были известны как облачные блоки движения данных (DMU). <br/>Для получения дополнительной [Data Integration Units](copy-activity-performance-features.md#data-integration-units)информации см. | нет |
| parallelCopies | Укажите параллелизм, который вы хотите, чтобы активность Copy использовалась при чтении данных из источника и записи данных в раковину.<br/>Для получения дополнительной информации, см [Параллельная копия](copy-activity-performance-features.md#parallel-copy). | нет |
| охранная зона | Укажите, следует ли сохранять метаданные/АПЛ во время копирования данных. <br/>Для получения дополнительной информации [см.](copy-activity-preserve-metadata.md) |нет |
| enableStaging<br/>stagingSettings | Укажите, следует ли наказывать промежуточные данные в хранилище Blob вместо того, чтобы напрямую копировать данные от источника к раковине.<br/>Для получения информации о полезных сценариях и деталях конфигурации, [см.](copy-activity-performance-features.md#staged-copy) | нет |
| enableSkipIncompatibleRow<br/>redirectIncompatibleRowSettings| Выберите, как обрабатывать несовместимые строки при копировании данных из источника в раковину.<br/>Для получения дополнительной [Fault tolerance](copy-activity-fault-tolerance.md)информации см. | нет |

## <a name="monitoring"></a>Наблюдение

Вы можете контролировать активность copy, запущенную на фабрике данных Azure, как визуально, так и программно. Для получения подробной информации [см.](copy-activity-monitoring.md)

## <a name="incremental-copy"></a>Добавочное копирование

Фабрика данных позволяет постепенно копировать данные дельты из хранилища исходных данных в хранилище данных раковины. Для получения подробной информации [см.](tutorial-incremental-copy-overview.md)

## <a name="performance-and-tuning"></a>Производительность и настройка

Опыт [мониторинга активности копирования](copy-activity-monitoring.md) показывает статистику производительности копий для каждого запуска деятельности. [Руководство по производительности и масштабируемости копирования](copy-activity-performance.md) описывает ключевые факторы, влияющие на производительность движения данных с помощью активности Copy в Azure Data Factory. Он также перечисляет значения производительности, наблюдаемые во время тестирования, и обсуждает, как оптимизировать производительность действия Copy.

## <a name="resume-from-last-failed-run"></a>Возобновление после последнего неудачного запуска

Копирование активности поддерживает резюме с последнего неудачного запуска, когда вы копируете большой размер файлов как двоичного формата между файлохранилищами и выбираете сохранение иерархии папок/файлов от источника к раковине, например, для переноса данных из Amazon S3 в Azure Data Lake Storage Gen2. Это относится к следующим файловым разъемам: [Amazon S3](connector-amazon-simple-storage-service.md), [Azure Blob](connector-azure-blob-storage.md), [Azure Data Lake Storage Gen1](connector-azure-data-lake-store.md), [Azure Data Lake Storage Gen2](connector-azure-data-lake-storage.md), [Azure File Storage](connector-azure-file-storage.md), File [System,](connector-file-system.md) [FTP,](connector-ftp.md) [Google Cloud Storage,](connector-google-cloud-storage.md) [HDFS](connector-hdfs.md)и [SFTP](connector-sftp.md).

Вы можете использовать резюме копирования деятельности следующими двумя способами:

- **Повторная попытка уровня активности:** Можно установить повторную попытку на активность копирования. Во время выполнения конвейера, если этот запуск действия копирования завершается неудачей, следующая автоматическая повторная попытка начнется с точки отказа последнего испытания.
- **Повтор из неудавшейся деятельности:** После завершения выполнения выполнения конвейера можно также вызвать повтор из неудавшейся активности в представлении мониторинга UI ADF или программно. Если сбой действия является копированием, конвейер не только будет перезапущен из этого действия, но и возобновится с точки сбоя предыдущего запуска.

    ![Копирование резюме](media/copy-activity-overview/resume-copy.png)

Несколько моментов, чтобы отметить:

- Резюме происходит на уровне файла. Если действие копирования не удается при копировании файла, в следующем запуске, этот конкретный файл будет повторно скопирован.
- Чтобы резюме работало должным образом, не изменяйте настройки активности копирования между повторами.
- При копировании данных из Amazon S3, Azure Blob, Azure Data Lake Storage Gen2 и Google Cloud Storage можно возобновить действие копий из произвольного количества скопированных файлов. В то время как для остальных файловых разъемов в качестве источника, в настоящее время активность копирования поддерживает резюме из ограниченного числа файлов, как правило, в диапазоне десятков тысяч и варьируется в зависимости от длины путей файла; файлы за пределами этого числа будут повторно копированы во время повторов.

Для других сценариев, помимо двоичной копии файла, повтор активности копирования начинается с самого начала.

## <a name="preserve-metadata-along-with-data"></a>Сохранение метаданных вместе с данными

Копируя данные от источника до погружения, в таких сценариях, как миграция озера данных, можно также сохранить метаданные и АПл вместе с данными с использованием активности копирования. Подробнее о [сохранении метаданных.](copy-activity-preserve-metadata.md)

## <a name="schema-and-data-type-mapping"></a>Сопоставление типов данных и схемы

См [Schema и отображение типа данных](copy-activity-schema-and-type-mapping.md) для получения информации о том, как активность Copy отображает ваши исходные данные в раковину.

## <a name="add-additional-columns-during-copy"></a>Добавление дополнительных столбцов во время копирования

В дополнение к копированию данных из хранилища исходных данных в sink, вы также можете настроить, чтобы добавить дополнительные столбцы данных, чтобы скопировать вместе, чтобы потопить. Пример:

- При копировании из исходного источника, основанного на файле, храните относительный путь файла в качестве дополнительного столбца для отслеживания, из какого файла поступают данные.
- Добавьте столбец с выражением ADF, чтобы прикрепить переменные системы ADF, такие как имя конвейера/идентификатор конвейера, или сохранить другое динамическое значение от вывода активности вверх по течению.
- Добавьте столбец со статическим значением для удовлетворения потребностей в потреблении ниже по течению.

Вы можете найти следующую конфигурацию на вкладке источника действия копирования: 

![Добавление дополнительных столбцов в действие копирования](./media/copy-activity-overview/copy-activity-add-additional-columns.png)

>[!TIP]
>Эта функция работает с последней моделью набора данных. Если вы не видите эту опцию из системы мотосвязи, попробуйте создать новый набор данных.

Чтобы настроить его программно, добавьте `additionalColumns` свойство в источник активности копирования:

| Свойство | Описание | Обязательно |
| --- | --- | --- |
| дополнительныеКолонки | Добавьте дополнительные столбцы данных для копирования для погружения.<br><br>Каждый объект `additionalColumns` под массивом представляет собой дополнительную колонку. Определение `name` имени столбца и `value` указывает значение данных этого столбца.<br><br>Допустимые значения данных:<br>- **`$$FILEPATH`**- зарезервированная переменная указывает на хранение относительного пути исходных файлов в путь папки, указанный в наборе данных. Применить к источнику на основе файлов.<br>- **Выражение**<br>- **Статическое значение** | нет |

**Примере:**

```json
"activities":[
    {
        "name": "CopyWithAdditionalColumns",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "<source type>",
                "additionalColumns": [
                    {
                        "name": "filePath",
                        "value": "$$FILEPATH"
                    },
                    {
                        "name": "pipelineName",
                        "value": {
                            "value": "@pipeline().Pipeline",
                            "type": "Expression"
                        }
                    },
                    {
                        "name": "staticValue",
                        "value": "sampleValue"
                    }
                ],
                ...
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

## <a name="fault-tolerance"></a>Отказоустойчивость

По умолчанию активность Copy прекращает копирование данных и возвращает сбой, когда строки исходных данных несовместимы с строками данных раковины. Чтобы сделать копию успешной, можно настроить действие Copy, чтобы пропустить и войти в несовместимые строки и скопировать только совместимые данные. См [Допуск неисправностей активности Copy](copy-activity-fault-tolerance.md) для деталей.

## <a name="next-steps"></a>Дальнейшие действия
Ознакомьтесь со следующими руководствами и примерами:

- [Копирование данных из одного места в другое место в той же учетной записи хранения Azure Blob](quickstart-create-data-factory-dot-net.md)
- [Копирование данных из хранилища Azure Blob в базу данных Azure S'L](tutorial-copy-data-dot-net.md)
- [Копирование данных из предварительной базы данных сервера S'L В Azure](tutorial-hybrid-copy-powershell.md)
