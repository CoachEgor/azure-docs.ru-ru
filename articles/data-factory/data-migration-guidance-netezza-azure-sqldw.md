---
title: Перенос данных с внутреннего сервера Netezza в Azure
description: Используйте фабрику данных Azure для переноса данных с сервера Netezza в Azure.
services: data-factory
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: shwang
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 9/03/2019
ms.openlocfilehash: a0263880262da95f4d26ee8388da464e9a59efca
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81416458"
---
# <a name="use-azure-data-factory-to-migrate-data-from-an-on-premises-netezza-server-to-azure"></a>Используйте фабрику данных Azure для переноса данных с сервера Netezza в Azure 

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

Azure Data Factory предоставляет эффективный, надежный и экономичный механизм для переноса данных в масштабе с собственного сервера Netezza в учетную запись хранения Azure или базу данных хранилища данных Azure S'L. 

В этой статье содержится следующая информация для разработчиков данных и разработчиков:

> [!div class="checklist"]
> * Производительность 
> * Устойчивость копирования
> * Безопасность сети
> * Архитектура решений высокого уровня 
> * Внедрение передовой практики  

## <a name="performance"></a>Производительность

Azure Data Factory предлагает бессерверную архитектуру, которая позволяет проводить параллелизм на различных уровнях. Если вы разработчик, это означает, что вы можете построить конвейеры, чтобы полностью использовать пропускную способность сети и базы данных для максимизации пропускной способности передачи данных для вашей среды.

![Диаграмма производительности](media/data-migration-guidance-netezza-azure-sqldw/performance.png)

Предыдущая диаграмма может быть интерпретирована следующим образом:

- Одноразовая копия может использовать масштабируемые вычислительные ресурсы. При использовании Azure Integration Runtime можно указать [до 256 diUS](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#data-integration-units) для каждой деятельности копии без сервера. С самоходной интеграцией времени выполнения (самоходной ИК), вы можете вручную масштабировать машину или масштабировать до нескольких машин[(до четырех узлов),](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)и одна копия деятельности распределяет его раздел по всем узлам. 

- Одноразовая копия действия считывается из хранилища данных и записывается с помощью нескольких потоков. 

- Поток управления фабрикой данных Azure может начать несколько действий копирования параллельно. Например, он может начать их с помощью [цикла Для каждого.](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity) 

Для получения дополнительной [Copy activity performance and scalability guide](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)информации см.

## <a name="resilience"></a>Устойчивость

В рамках выполнения одной копирования Фабрика данных Имеет встроенный механизм повторной работы, который позволяет ей обрабатывать определенный уровень временных сбоев в хранилищах данных или в базовой сети.

При копировании активности Azure Data Factory при копировании данных между хранилищами исходных данных и хранилищ данных раковины у вас есть два способа обработки несовместимых строк. Можно либо прервать и свести на нет действие копирования, либо продолжить копирование остальных данных, пропустив несовместимые строки данных. Кроме того, чтобы узнать причину сбоя, можно войти в несовместимые строки в хранилище Azure Blob или хранилище Azure Data Lake Store, исправить данные об источнике данных и повторить действие копирования.

## <a name="network-security"></a>Безопасность сети 

По умолчанию Azure Data Factory передает данные с сервера Netezza на учетную запись хранения Azure или базу данных хранилища данных Azure S'L, используя зашифрованное соединение через Hypertext Transfer Protocol Secure (HTTPS). HTTPS обеспечивает шифрование данных в пути и предотвращает подслушивание и атаки «человек в середине».

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, вы можете помочь достичь более высокой безопасности, передавая данные по частной вглядывающей ссылке через Azure Express Route. 

В следующем разделе рассматриваются способы обеспечения более высокой безопасности.

## <a name="solution-architecture"></a>Архитектура решения

В этом разделе рассматриваются два способа переноса данных.

### <a name="migrate-data-over-the-public-internet"></a>Миграция данных через общедоступный Интернет

![Миграция данных через общедоступный Интернет](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-public-network.png)

Предыдущая диаграмма может быть интерпретирована следующим образом:

- В этой архитектуре вы безопасно передаете данные с помощью HTTPS через общедоступный Интернет.

- Для достижения этой архитектуры необходимо установить время выполнения интеграции Azure Data Factory (самохумещается) на компьютер Windows за корпоративным брандмауэром. Убедитесь, что эта интеграция времени выполнения может получить прямой доступ к серверу Netezza. Чтобы в полной мере использовать пропускную способность сети и хранилищ данных для копирования данных, можно вручную масштабировать машину или масштабировать ее до нескольких машин.

- Используя эту архитектуру, можно перенести как исходные данные моментального снимка, так и данные дельты.

### <a name="migrate-data-over-a-private-network"></a>Миграция данных через частную сеть 

![Миграция данных через частную сеть](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-private-network.png)

Предыдущая диаграмма может быть интерпретирована следующим образом:

- В этой архитектуре данные мигрируют через приватную вонючейшую ссылку через Azure Express Route, и данные никогда не пересекаются через общедоступный Интернет. 

- Для достижения этой архитектуры необходимо установить время выполнения интеграции Azure Data Factory (самохумещаемый) на виртуальную машину Windows (VM) в виртуальной сети Azure. Чтобы в полной мере использовать пропускную способность сети и хранилищ данных для копирования данных, можно вручную масштабировать VM или масштабировать до нескольких ВМ.

- Используя эту архитектуру, можно перенести как исходные данные моментального снимка, так и данные дельты.

## <a name="implement-best-practices"></a>Внедрение передового опыта 

### <a name="manage-authentication-and-credentials"></a>Управление аутентификацией и учетных данных 

- Чтобы проверить подлинность Netezza, вы можете использовать [проверку подлинности ODBC через строку подключения.](https://docs.microsoft.com/azure/data-factory/connector-netezza#linked-service-properties) 

- Для проверки подлинности в хранилище Azure Blob: 

   - Мы настоятельно рекомендуем использовать [управляемые идентификаторы для ресурсов Azure.](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity) Управляемые идентификаторы, созданные поверх автоматически управляемой идентификатора Azure Data Factory в каталоге Azure Active Directory (Azure AD), позволяют настраивать конвейеры без предоставления учетных данных в определении службы linked.  

   - Кроме того, можно проверить подлинность хранилища Azure Blob с помощью [принципа службы,](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication) [общей подписи доступа](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication)или ключа [учетной записи хранилища.](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication) 

- Чтобы проверить подлинность в Azure Data Lake Storage Gen2: 

   - Мы настоятельно рекомендуем использовать [управляемые идентификаторы для ресурсов Azure.](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity)
   
   - Вы также можете использовать [принцип обслуживания](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключ учетной записи хранилища.](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication) 

- Для проверки подлинности в Хранилище данных Azure S'L:

   - Мы настоятельно рекомендуем использовать [управляемые идентификаторы для ресурсов Azure.](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#managed-identity)
   
   - Вы также можете использовать [основную услугу](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#service-principal-authentication) или [проверку подлинности S'L.](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#sql-authentication)

- При неиспользовании управляемых идентификаторов для ресурсов Azure мы настоятельно рекомендуем [хранить учетные данные в Azure Key Vault,](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) чтобы упростить централизованное управление и изменение ключей без изменения подключенных служб Azure Data Factory. Это также одна из [лучших практик для CI/ CD](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="migrate-initial-snapshot-data"></a>Мигрировать исходные данные моментального снимка 

Для небольших таблиц (т.е. таблиц с объемом менее 100 ГБ или которые могут быть перенесены в Azure в течение двух часов), можно сделать каждую копию данных о загрузке рабочих мест в таблице. Для большей пропускной выхажнение пропускной однако можно выполнить несколько заданий Azure Data Factory для одновременной загрузки отдельных таблиц. 

В каждом задания миге, для выполнения параллельных запросов и копирования данных по разделам, можно также достичь определенного уровня параллелизма, используя [ `parallelCopies` настройку свойства](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#parallel-copy) с любым из следующих вариантов раздела данных:

- Для повышения эффективности мы рекомендуем вам начать с среза данных.  Убедитесь, что значение `parallelCopies` в настройках меньше, чем общее количество разделов среза данных в таблице на сервере Netezza.  

- Если объем каждой раздела среза данных по-прежнему велик (например, 10 ГБ или больше), мы рекомендуем вам перейти на раздел динамического диапазона. Этот параметр дает вам большую гибкость для определения количества разделов и объема каждого раздела по столбу раздела, верхней границы и нижней границы.

Для больших таблиц (т.е. таблиц с объемом 100 ГБ или больше или не *могут* быть перенесены в Azure в течение двух часов) мы рекомендуем перегородить данные пользовательским запросом, а затем сделать каждую копию-заработок копированием по одной разделу за один раз. Для лучшей пропускной системы можно одновременно запускать несколько заданий Azure Data Factory. Для каждой целевой группы копирования- задания, загружающей одну часть пользовательским запросом, можно увеличить пропускную связь, включив параллелизм либо семкой данных, либо динамическим диапазоном. 

Если какая-либо задания копирования не удается из-за проблемы с переходной сетью или хранилищем данных, можно перезапустить неудавшую работу копирования для перезарядки определенного раздела из таблицы. Другие задания копирования, которые загружают другие разделы, не затрагиваются.

При загрузке данных в базу данных хранилища данных Azure S'L мы предлагаем включить PolyBase в работу копирования с хранением Azure Blob как постановку.

### <a name="migrate-delta-data"></a>Миграция данных дельты 

Чтобы определить новые или обновленные строки из таблицы, используйте столбец метки времени или клавишу приращения в схеме. Затем можно хранить последнее значение в качестве высокого водяного знака во внешней таблице, а затем использовать его для фильтрации данных дельты при следующей загрузке данных. 

Каждая таблица может использовать различные столбец водяного знака для определения своих новых или обновленных строк. Мы предлагаем создать таблицу внешнего управления. В таблице каждая строка представляет собой одну таблицу на сервере Netezza с определенным названием столба водяного знака и высоким значением водяного знака. 

### <a name="configure-a-self-hosted-integration-runtime"></a>Настройка автономного времени выполнения интеграции

Если вы перемещаете данные с сервера Netezza в Azure, независимо от того, находится ли сервер за брандмауэром корпорации или в виртуальной сетевой среде, необходимо установить самостоятельно размещенный ИК на машине Windows или VM, которая является движок, который используется для перемещения данных. При установке самостоятельной ИК-иК мы рекомендуем следующий подход:

- Для каждой машины Windows или VM начните с конфигурации 32 vCPU и 128-ГБ памяти. Вы можете продолжать мониторинг использования процессора и памяти ИК-машины во время миграции данных, чтобы увидеть, нужно ли дополнительно масштабировать машину для повышения производительности или сократить масштаб машины, чтобы сэкономить затраты.

- Вы также можете масштабироваться, связывая до четырех узлов с одним самоуправляемым ИК. Одноразовая работа, работающее против самостоятельно гостоуправляемого ИК, автоматически применяет все VM-узлы для параллельной копирования данных. Для высокой доступности начните с четырех узлов VM, чтобы избежать одной точки сбоя во время миграции данных.

### <a name="limit-your-partitions"></a>Ограничьте разделы

В качестве наилучшей практики, провести доказательство производительности концепции (POC) с репрезентативным набором данных образца, так что вы можете определить соответствующий размер раздела для каждой деятельности копирования. Мы предлагаем загрузить каждую часть в Azure в течение двух часов.  

Чтобы скопировать таблицу, начните с одной копирования деятельности с одной, самостоятельной ИК-машины. Постепенно увеличивайте настройки `parallelCopies` в зависимости от количества разделов среза данных в таблице. Узнайте, можно ли загрузить всю таблицу в Azure в течение двух часов, в соответствии с пропускной прокладкой, которая является результатом задания копирования. 

Если он не может быть загружен в Azure в течение двух часов, а емкость самостоятельного ИК-узла и хранилища данных не используются полностью, постепенно увеличивайте количество параллельных действий копирования, пока не достигнете предела сети или предела пропускной способности хранилищ данных. 

Продолжайте мониторинг процессора и использования памяти на самостоятельно йопоге ИК-машины, и будьте готовы к масштабу машины или масштабировать до нескольких машин, когда вы видите, что процессор и память полностью используются. 

При возникновении ошибок в запоре, о чем сообщается в `parallelCopies` деятельности копирования Azure Data Factory, либо уменьшите параллелизм или настройку на фабрике данных Azure, либо подумайте об увеличении пропускной способности или ввоза или второго времени (IOPS) пределов сети и хранилищ данных. 


### <a name="estimate-your-pricing"></a>Оцените цены 

Рассмотрим следующий конвейер, который построен для переноса данных с сервера Netezza в базу данных хранилища данных Azure S'L:

![Ценовой конвейер](media/data-migration-guidance-netezza-azure-sqldw/pricing-pipeline.png)

Допустим, что следующие утверждения верны: 

- Общий объем данных составляет 50 терабайт (ТБ). 

- Мы переносим данные с помощью архитектуры первого решения (сервер Netezza находится в центре, за брандмауэром).

- Объем 50 ТБ делится на 500 разделов, и каждая копия действия перемещает один раздел.

- Каждая копия деятельности настроена с одной самостоятельной ИК против четырех машин и достигает пропускной четырка 20 мегабайт в секунду (MBps). (В рамках `parallelCopies` копирования деятельности, устанавливается до 4, и каждый поток для загрузки данных из таблицы достигает 5-MBps пропускной выгоды.)

- Параллель ForEach установлена на 3, а совокупная пропускная стоимость составляет 60 Мбит/с.

- В общей сложности для завершения миграции требуется 243 часа.

Исходя из предыдущих предположений, вот оценочная цена: 

![Таблица ценообразования](media/data-migration-guidance-netezza-azure-sqldw/pricing-table.png)

> [!NOTE]
> Цены, указанные в предыдущей таблице, гипотетические. Фактические цены зависят от фактической пропускной выхаживаемостью в вашей среде. Цена на машину Windows (с самостоятельной установки ИК) не включена. 

### <a name="additional-references"></a>Дополнительные ссылки

Для получения дополнительной информации смотрите следующие статьи и руководства:

- [Переносите данные из предварительной базы данных хранилища данных в Azure с помощью Azure Data Factory](https://azure.microsoft.com/resources/data-migration-from-on-premise-relational-data-warehouse-to-azure-data-lake-using-azure-data-factory/)
- [Разъем Netezza](https://docs.microsoft.com/azure/data-factory/connector-netezza)
- [Соединитель ODBC](https://docs.microsoft.com/azure/data-factory/connector-odbc)
- [Разъем для хранения Azure Blob](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Разъем хранилища данных Azure S'L](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse)
- [Копирование руководства по настройке производительности](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и настройка локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Самохонугированная интеграция времени выполнения HA и масштабируемость](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности при перемещении данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Хранение учетных данных в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Копирование данных постепенно из одной таблицы](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-portal)
- [Копирование данных постепенно из нескольких таблиц](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-multiple-tables-portal)
- [Страница ценообразования Фабрики данных Azure](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Дальнейшие действия

- [Копирование файлов из нескольких контейнеров с помощью Azure Data Factory](solution-template-copy-files-multiple-containers.md)
