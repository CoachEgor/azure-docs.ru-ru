---
title: Перенос данных с локального сервера Netezza в Azure с помощью фабрики данных Azure | Документация Майкрософт
description: Используйте фабрику данных Azure для переноса данных с локального сервера Netezza в Azure.
services: data-factory
documentationcenter: ''
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 9/03/2019
ms.openlocfilehash: 4690fd81247035267861b06c204c6db7a052eba5
ms.sourcegitcommit: 267a9f62af9795698e1958a038feb7ff79e77909
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/04/2019
ms.locfileid: "70259565"
---
# <a name="use-azure-data-factory-to-migrate-data-from-on-premises-netezza-server-to-azure"></a>Перенос данных с локального сервера Netezza в Azure с помощью фабрики данных Azure 

Фабрика данных Azure предоставляет производительный, надежный и экономичный механизм переноса данных с локального сервера Netezza в службу хранилища Azure или хранилище данных SQL Azure. Эта статья содержит следующие сведения для инженеров и разработчиков данных:

> [!div class="checklist"]
> * Производительность 
> * Устойчивость к копированию
> * Безопасность сети
> * Архитектура высокого уровня решения 
> * Рекомендации по реализации  

## <a name="performance"></a>Производительность

Фабрика данных Azure предлагает бессерверную архитектуру, которая обеспечивает параллелизм на разных уровнях, что позволяет разработчикам создавать конвейеры для полного использования пропускной способности сети, а также пропускной способности базы данных, чтобы максимально увеличить пропускную способность перемещения данных для PXE.

![производительность](media/data-migration-guidance-netezza-azure-sqldw/performance.png)

- Одно действие копирования может воспользоваться преимуществами масштабируемых вычислений: при использовании Azure Integration Runtime можно указать [до 256 диус](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#data-integration-units) для каждого действия копирования на бессерверном сервере. При использовании автономного Integration Runtime можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до 4 узлов](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)), и одно действие копирования будет распределять раздел по всем узлам. 
- Одно действие копирования считывает из хранилища данных и выполняет запись в него с помощью нескольких потоков. 
- Поток управления фабрики данных Azure может запускать несколько операций копирования параллельно, например, с использованием [циклов for each](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity). 

Дополнительные сведения можно получить из [руководств по производительности действия копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance) .

## <a name="resilience"></a>Устойчивость

В рамках одного действия копирования фабрика данных Azure имеет встроенный механизм повторных попыток для обработки определенного уровня временных сбоев в хранилищах данных или в базовой сети.

Действие копирования фабрики данных Azure также предлагает два способа обработки несовместимых строк при копировании данных между хранилищами данных источника и приемника. Можно прервать и завершить действие копирования, если обнаружены несовместимые данные, или продолжить копирование данных, пропуская несовместимые строки данных. Кроме того, можно регистрировать несовместимые строки в хранилище BLOB-объектов Azure или Azure Data Lake Store, чтобы узнать причину сбоя, исправить данные в источнике данных и повторить действие копирования.

## <a name="network-security"></a>Безопасность сети 

По умолчанию фабрика данных Azure передает данные с локального сервера Netezza в службу хранилища Azure или хранилище данных SQL Azure, используя зашифрованное подключение по протоколу HTTPS. Он обеспечивает шифрование данных при передаче и предотвращает атаки перехвата и атак типа "злоумышленник в середине".

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, вы можете повысить уровень безопасности, передавая данные через частный пиринг через маршрут Azure Express. Сведения о том, как это можно сделать, см. в описании архитектуры решения.

## <a name="solution-architecture"></a>Архитектура решения

Перенос данных через общедоступный Интернет:

![решение — архитектура — общедоступная — сеть](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-public-network.png)

- В этой архитектуре данные безопасно передаются по протоколу HTTPS через общедоступный Интернет.
- Для достижения этой архитектуры необходимо установить локальную среду выполнения интеграции фабрики данных Azure на компьютере под управлением Windows, который находится за корпоративным брандмауэром. Убедитесь, что локальная среда выполнения интеграции фабрики данных Azure на компьютере Windows может получить доступ к серверу Netezza напрямую. Вы можете вручную увеличить масштаб компьютера или развернуть его на нескольких компьютерах, чтобы полностью использовать сеть и пропускную способность хранилища данных для копирования данных.
- С помощью этой архитектуры можно достичь первоначальной миграции данных моментальных снимков и переноса разностных данных.

Перенос данных по частной ссылке: 

![решение — архитектура — частный — сеть](media/data-migration-guidance-netezza-azure-sqldw/solution-architecture-private-network.png)

- В этой архитектуре миграция данных выполняется через ссылку частного пиринга через Azure Express Route, так что данные никогда не проходят через общедоступный Интернет. 
- Для достижения этой архитектуры необходимо установить локальную среду выполнения интеграции фабрики данных Azure на виртуальной машине Windows в виртуальной сети Azure. Вы можете вручную масштабировать виртуальные машины или масштабировать их до нескольких виртуальных машин, чтобы полностью использовать сеть и пропускную способность хранения данных для копирования данных.
- С помощью этой архитектуры можно достичь первоначальной миграции данных моментальных снимков и переноса разностных данных.

## <a name="implementation-best-practices"></a>Рекомендации по реализации 

### <a name="authentication-and-credential-management"></a>Проверка подлинности и управление учетными данными 

- Для проверки подлинности в Netezza можно использовать [проверку подлинности ODBC с помощью строки подключения](https://docs.microsoft.com/azure/data-factory/connector-netezza#linked-service-properties). 
- Для подключения к хранилищу BLOB-объектов Azure поддерживаются несколько типов проверки подлинности.  Настоятельно рекомендуется использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity) : на основе автоматически управляемой фабрики данных Azure в Azure AD можно настроить конвейеры без предоставления учетных данных в определении связанной службы.  Кроме того, можно выполнить аутентификацию в хранилище BLOB-объектов Azure с помощью [субъекта-службы](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication), [подписанного URL-имени](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication) или [ключа учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication). 
- Для подключения к Azure Data Lake Storage 2-го поколения также поддерживаются несколько типов проверки подлинности.  Настоятельно рекомендуется использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity) , хотя также можно использовать [субъект-службу](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключ учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication) . 
- Для подключения к хранилищу данных SQL Azure также поддерживаются несколько типов проверки подлинности. Настоятельно рекомендуется использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#managed-identity) , хотя также можно использовать [субъект-службу](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#service-principal-authentication) или [проверку подлинности SQL](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse#sql-authentication) .
- Если вы не используете управляемые удостоверения для ресурсов Azure, настоятельно рекомендуется [хранить учетные данные в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) , чтобы упростить централизованное управление и вращение ключей без изменения связанных служб фабрики данных Azure.  Это также один из рекомендаций [по интеграции и откомпакт-диску](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="initial-snapshot-data-migration"></a>Исходный моментальный снимок — перенос данных 

Для небольших таблиц, если размер тома меньше 100 ГБ, или его можно перенести в Azure в течение 2 часов, можно создать каждое задание копирования для каждой таблицы. Вы можете запустить несколько заданий копирования фабрики данных Azure для одновременной загрузки разных таблиц для повышения пропускной способности. 

В каждом задании копирования можно также достичь некоторого уровня параллелизма, используя параметр [parallelCopies](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#parallel-copy) с параметром секции данных для выполнения параллельных запросов и копирования данных по секциям. Ниже приведены два варианта выбора секции данных.
- Рекомендуется начать с среза данных, так как он более эффективен.  Убедитесь, что число параллелизма в параметре parallelCopies ниже общего количества секций срезов данных в таблице на сервере Netezza.  
- Если размер тома для каждого раздела среза данных по-прежнему большой (например, больше 10 ГБ), рекомендуется переключиться на динамический диапазон секций, где вы получите большую гибкость для определения числа секций и размера тома для каждой секции. по столбцу секционирования, верхней и нижней границам.

Для больших таблиц, если размер тома превышает 100 ГБ или не может быть перенесен в Azure в течение 2 часов, рекомендуется секционировать данные по пользовательскому запросу, а затем делать каждое задание копирования копировать по одной секции за раз. Для повышения пропускной способности можно одновременно запустить несколько заданий копирования фабрики данных Azure. Имейте в виду, что для каждого целевого объекта задания копирования, чтобы загрузить один раздел по пользовательскому запросу, можно по-прежнему включить параллелизм с помощью среза данных или динамического диапазона, чтобы увеличить пропускную способность. 

Если какое-либо из заданий копирования завершилось сбоем из – за временной ошибки сети или хранилища данных, можно повторно выполнить задание копирования, завершившееся сбоем, чтобы повторно загрузить эту конкретную секцию из таблицы. Все остальные задания копирования, загружают другие секции, не будут затронуты.

При загрузке данных в хранилище данных SQL Azure рекомендуется включить polybase в задании копирования с хранилищем BLOB-объектов Azure в качестве промежуточного хранения.

### <a name="delta-data-migration"></a>Перенос разностных данных 

Для обнаружения новых или обновленных строк таблицы используется столбец timestamp или увеличивающийся ключ в схеме, а затем Последнее значение сохраняется в виде верхнего предела во внешней таблице, который может использоваться для фильтрации разностных данных при следующей загрузке данных. 

Для обнаружения новых или обновленных строк различные таблицы могут использовать разные столбцы с водяными знаками. Мы рекомендуем создать таблицу внешнего элемента управления, где каждая строка представляет одну таблицу на сервере Netezza с его именем столбца подложки и значением верхнего предела. 

### <a name="self-hosted-integration-runtime-configuration-on-azure-vm-or-machine"></a>Настройка локальной среды выполнения интеграции на ВИРТУАЛЬНОЙ машине Azure или на компьютере

Учитывая, что вы переносите данные с сервера Netezza в Azure, независимо от того, какой сервер Netezza не входит в систему на брандмауэре вашей организации или в среде виртуальной сети, необходимо установить локальную среду выполнения интеграции на компьютере Windows или виртуальной машине, которая является подсистемой для перемещения Data.

- Рекомендуемая конфигурация для запуска для каждого компьютера или виртуальной машины — 32 виртуальных ЦП и 128 ГБ памяти. Вы можете отслеживать использование ЦП и памяти на IR-компьютере во время переноса данных, чтобы узнать, требуется ли дальнейшее масштабирование компьютера для повышения производительности или уменьшения масштаба компьютера, чтобы сэкономить затраты.
- Кроме того, можно выполнить горизонтальное масштабирование, связав до 4 узлов с одним локальным IR. Одно задание копирования, выполняемое для локальной среды IR, автоматически будет использовать все узлы виртуальной машины для параллельного копирования данных. Для обеспечения высокой доступности рекомендуется начинать с 2 узлов виртуальных машин, чтобы избежать единой точки отказа во время переноса данных.

### <a name="rate-limiting"></a>Ограничение частоты

Рекомендуется провести оценку производительности с помощью репрезентативного примера набора данных, чтобы можно было определить подходящий размер раздела для каждого действия копирования. Мы рекомендуем сделать каждую секцию загружаемой в Azure в течение 2 часов.  

Начните с одного действия копирования с одной локальной виртуальной машиной для копирования таблицы. Постепенно увеличивайте значение параметра parallelCopies на основе количества секций срезов данных в таблице и Узнайте, можно ли загрузить всю таблицу в Azure в течение 2 часов в соответствии с пропускной способностью, которую вы видите в задании копирования. 

Если это невозможно, и в то же время емкость автономного узла IR и хранилища данных не используется полностью, постепенно увеличивайте количество одновременных операций копирования до тех пор, пока не будут достигнуты ограничения сети или пропускной способности хранилищ данных. 

Отслеживайте использование ресурсов ЦП и памяти на автономном IR-компьютере и будьте готовы к увеличению масштаба компьютера или масштабированию на нескольких компьютерах, когда вы видите, что ЦП и память полностью загружены. 

При возникновении ошибок регулирования, о которых сообщает действие копирования фабрики данных Azure, следует либо уменьшить значение параметра Concurrency или parallelCopies в фабрике данных Azure, либо увеличить ограничения пропускной способности и операций ввода-вывода для сети и хранилищ данных. 


### <a name="estimating-price"></a>Оценка цены 

Рассмотрим следующий конвейер, созданный для переноса данных с локального сервера Netezza в хранилище данных SQL Azure:

![цены — конвейер](media/data-migration-guidance-netezza-azure-sqldw/pricing-pipeline.png)

Предположим, что мы предполагаем следующее: 

- Общий объем данных составляет 50 ТБ. 
- Перенос данных с использованием первой архитектуры решения (сервер Netezza находится в локальной среде за брандмауэром)
- 50 ТБ делится на секции 500, и каждое действие копирования перемещает одну секцию.
- Для каждого действия копирования настраивается один автономный IR-сервер с 4 компьютерами и достигается пропускная способность 20 Мбит/с. (В рамках действия копирования parallelCopies имеет значение 4, и каждый поток для загрузки данных из таблицы достигает пропускной способности 5 Мбит/с).
- Параметр параллелизма ForEach имеет значение 3, а суммарная пропускная способность — 60 Мбит/с.
- В итоге выполнение миграции займет 243 часа.

Ниже приведена Оценочная цена, основанная на указанных выше допущениях. 

![цены — таблица](media/data-migration-guidance-netezza-azure-sqldw/pricing-table.png)

> [!NOTE]
> Это гипотетический пример цены. Реальная цена зависит от фактической пропускной способности в вашей среде. Цена на компьютере Windows (с установленной локальной средой выполнения интеграции) не включена. 

### <a name="additional-references"></a>Дополнительные ссылки 
- [Перенос данных из локального хранилища реляционных данных в Azure с помощью фабрики данных Azure](https://azure.microsoft.com/mediahandler/files/resourcefiles/data-migration-from-on-premise-relational-data-warehouse-to-azure-data-lake-using-azure-data-factory/Data_migration_from_on-prem_RDW_to_ADLS_using_ADF.pdf)
- [Соединитель Netezza](https://docs.microsoft.com/azure/data-factory/connector-netezza)
- [Соединитель ODBC](https://docs.microsoft.com/azure/data-factory/connector-odbc)
- [Соединитель хранилища BLOB-объектов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Перемещение данных в хранилище данных Azure SQL и из него с помощью фабрики данных Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-sql-data-warehouse).
- [Краткое руководств по настройке производительности действий копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и Настройка автономных Integration Runtime](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Высокая доступность и масштабируемость локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности перемещения данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Хранение учетных данных в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Добавочное копирование данных из одной таблицы](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-portal)
- [Добавочное копирование данных из нескольких таблиц](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-multiple-tables-portal)
- [Страница с ценами на фабрику данных Azure](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Следующие шаги

- [Копирование файлов из нескольких контейнеров с помощью фабрики данных Azure](solution-template-copy-files-multiple-containers.md)