---
title: Руководство по сопоставление производительность потока данных и настройке в фабрике данных Azure | Документация Майкрософт
description: Узнайте о ключевых факторах, влияющих на производительность потоков данных в фабрике данных Azure при использовании сопоставления потоков данных.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.date: 05/16/2019
ms.openlocfilehash: d4acc620fb2a4c41615c745516e5ccfafd59d848
ms.sourcegitcommit: 41ca82b5f95d2e07b0c7f9025b912daf0ab21909
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "67057953"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Сопоставление производительность потоков данных и руководство по настройке

[!INCLUDE [notes](../../includes/data-factory-data-flow-preview.md)]

Azure фабрики сопоставление данных потоки данных предоставляют интерфейс без кода браузера для проектировать, развертывать и оркестрировать преобразования данных в масштабе.

> [!NOTE]
> Если вы не знакомы с ADF сопоставление потоки данных в целом, см. в разделе [Обзор потоки данных](concepts-data-flow-overview.md) перед чтением этой статьи.
>

> [!NOTE]
> При разработке и тестировании потоков данных в пользовательском Интерфейсе фабрики данных AZURE, не забудьте включить ключом Debug, чтобы можно выполнить в потоках данных в режиме реального времени без ожидания кластер для прогрева.
>

![Отладка кнопку](media/data-flow/debugb1.png "отладки")

## <a name="monitor-data-flow-performance"></a>Наблюдение за производительностью потока данных

При разработке сопоставления данных проходит в браузере, вы можете модульного теста каждого отдельного преобразования, щелкнув вкладку Предварительный просмотр данных в нижней области параметров для каждого преобразования. Необходимо выполнить следующий шаг — проверить ваш данных потока end-to-end в конструкторе конвейера. Добавьте действие выполнения потока данных и используйте кнопку отладки для тестирования производительности потока данных. В нижней части окна конвейера вы увидите значок eyeglass в разделе «действия»:

![Монитор потока данных](media/data-flow/mon002.png "потока данных монитора 2")

Щелкнуть этот значок будет отображаться в план выполнения и профиль производительности последующих часть потока данных. Эти сведения можно использовать для оценки производительности потока данных к источникам данных различных размеров. Обратите внимание, что предполагается, минуту настройки кластера задания выполнения кода в вычислении общей производительности, и если вы используете среду выполнения интеграции Azure по умолчанию, может потребоваться добавить 5 минут времени регулировать кластер также.

![Наблюдение за потоком данных](media/data-flow/mon003.png "монитора 3 потока данных")

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse"></a>Оптимизация для базы данных Azure SQL и хранилище данных Azure SQL

![Исходной части](media/data-flow/sourcepart3.png "исходной части")

### <a name="partition-your-source-data"></a>Секции исходными данными

* Перейдите к «Оптимизация» и выберите «Источник». Задайте тип либо столбцом определенной таблицы в запросе.
* Если вы выбрали «столбец», затем выберите столбец секционирования.
* Кроме того можно задайте максимальное число подключений для базы данных SQL Azure. Вы можете попробовать установите более высокое значение для получения параллельных подключений к базе данных. Тем не менее иногда может привести высокая производительность с ограниченное число подключений.
* Таблицы базы данных с исходными не обязательно должны быть секционированы.
* Параметр запроса в свое преобразование источника, который соответствует схеме секционирования таблицы базы данных позволит использовать функцию устранения секций СУБД источника.
* Если источник не секционирована, ADF по-прежнему будет использовать секционирование в среде Spark преобразования, основанный на ключе, выбранного в преобразование источника данных.

### <a name="set-batch-size-and-query-on-source"></a>Задать размер пакета и запроса в источнике

![Источник](media/data-flow/source4.png "источника")

* Задание размера пакета проинструктирует фабрики данных AZURE для хранения данных в наборах в памяти, а не по строкам. Это необязательный параметр, и вы можете исчерпать ресурсы на вычислительных узлах, если они не являются надлежащего размера.
* Параметр запроса можно разрешить для фильтрации строк справа в источнике, до получения даже для потока данных для обработки, что может быстрее приобретения начальных данных.
* Если вы используете запрос, можно добавить подсказки в запросе необязательно для вашей базы данных SQL Azure, т. е. READ UNCOMMITTED

### <a name="set-sink-batch-size"></a>Задать размер пакета в качестве приемника

![Приемник](media/data-flow/sink4.png "приемника")

* Во избежание row-by-row обработки потоков данных, задайте «размер пакета» в параметрах приемника для базы данных SQL Azure. Это заставит ADF, чтобы обработать базу данных, запись в пакеты на основании укажите размер.

### <a name="set-partitioning-options-on-your-sink"></a>Задайте параметры на приемнику секционирования

* Даже если у вас нет данные секционированы в таблицах целевой базы данных SQL Azure, перейдите на вкладку Оптимизировать и секционирование набора.
* Очень часто просто указываете ADF на использование циклического секционирование в кластерах Spark выполнения приводит к гораздо быстрее загрузки вместо принудительного все подключения из одной секции и узла данных.

### <a name="increase-size-of-your-compute-engine-in-azure-integration-runtime"></a>Увеличьте размер модуль вычислений в среде выполнения интеграции Azure

![Новый IR](media/data-flow/ir-new.png "новой среды выполнения Интеграции")

* Увеличьте количество ядер, которые будут увеличивать количество узлов, а также позволяют с большей вычислительной мощностью для запроса и записи базы данных SQL Azure.
* Попробуйте «Вычислений оптимизированных» и «Оптимизированные для памяти» параметры применяются дополнительные ресурсы на вычислительных узлах.

### <a name="unit-test-and-performance-test-with-debug"></a>Модульный тест и тест производительности с помощью отладки

* Когда модульного тестирования потоков данных, кнопка «Данных потока Debug» в значение ON.
* В конструкторе потока данных используйте на вкладке предварительного просмотра данных на преобразования для просмотра результатов преобразования логики.
* Модульный тест, данные перемещаются из конструктора конвейера, размещая действием потока данных в конвейер разработки на основе холста и тестирования с помощью кнопки «Отладка».
* Тестирование в режиме отладки будет работать с динамической последующее кластерной среде без необходимости ожидать регулировать кластер just-in-time.

### <a name="disable-indexes-on-write"></a>Отключить индексы при записи
* Используйте действие ADF конвейера хранимой процедуры до вашего потока данных действие, которое отключает индексы для целевой таблицы, которые записываются из приемника.
* После действия потока данных добавьте еще одно действие хранимая процедура, которая включена этих индексов.

### <a name="increase-the-size-of-your-azure-sql-db"></a>Увеличить размер базы данных SQL Azure
* Запланировать изменение размера источника и приемника превышение, который ограничивает свой конвейер, чтобы повысить пропускную способность и уменьшить регулирование Azure, по достижении DTU базы данных SQL Azure.
* После завершения выполнения вашего конвейера вы можете изменить размер баз данных обратно в их нормальной скорости выполнения.

## <a name="optimizing-for-azure-sql-data-warehouse"></a>Оптимизация для хранилища данных Azure SQL

### <a name="use-staging-to-load-data-in-bulk-via-polybase"></a>Использовать промежуточное хранение данных для загрузки данных в пакетном режиме с помощью Polybase

* Во избежание row-by-row обработки потоков данных, задайте параметр «Staging» в настройки приемника, таким образом, чтобы ADF могут использовать Polybase в хранилище данных во избежание вставки по строкам. Это укажет ADF, чтобы использовать Polybase, таким образом, данные могут быть загружены в пакетном режиме.
* При выполнении действия потока данных из конвейера, с промежуточным хранением включен, вам потребуется выбрать расположение хранилища BLOB-объектов для массовой загрузки промежуточных данных.

### <a name="increase-the-size-of-your-azure-sql-dw"></a>Увеличить размер хранилище данных SQL Azure

* Запланировать изменение размера источника и приемника хранилища данных SQL Azure, прежде чем запустить свой конвейер, чтобы повысить пропускную способность и уменьшить регулирование Azure, по достижении ограничений DWU.

* После завершения выполнения вашего конвейера вы можете изменить размер баз данных обратно в их нормальной скорости выполнения.

## <a name="optimize-for-files"></a>Оптимизировать для файлов

* Вы можете контролировать количество секций, которые будут использовать ADF. На каждое преобразование источника и приемника, а также отдельные каждое из преобразований можно задать схему секционирования. Для небольших файлов можно обнаружить, что выбор «Одну секцию» может иногда работает лучше и быстрее, чем запрос Spark для секционирования небольших файлов.
* Если у вас достаточно информации о исходных данных, можно выбрать «Циклический перебор» секционирование и задайте число секций.
* Если изучение данных и показать, что столбцы, которые могут быть хорошей хэш-ключей, используйте вариант секционирования хэш.

### <a name="file-naming-options"></a>Имен файлов

* По умолчанию характер написание преобразованные данные в ADF сопоставление потоки данных заключается в написании для набора данных большого двоичного объекта или связанной службы ADLS. Необходимо задать этот набор данных, чтобы указать папку или контейнер, не файл с именем.
* Использование потоков данных, Azure Databricks Spark для выполнения, это означает, что выходные данные будут разделены на несколько файлов, на основе либо по умолчанию секционирование Spark или секционирование для схемы, которые явным образом выбрали.
* Это очень распространенная операция в потоках данных ADF в — выберите «Выходные данные в один файл», чтобы все выходные файлы ЧАСТИ объединяются в один выходной файл.
* Тем не менее эта операция требует, что сокращает выходные данные в одну секцию для одного узла кластера.
* Имейте это в виду при выборе этой популярной. Ресурсы узла кластера может закончиться, если необходимо скомбинировать много большими исходными файлами в секцию один выходной файл.
* Избежание вычислительных ресурсов узла, можно оставить значения по умолчанию или явной схемы секционирования в ADF. он оптимизирует производительность, и добавьте в неё последующие действия копирования в конвейере, которая объединяет все части файлов из папки выходных данных в один новый файл. По существу эта методика отделяет действия для преобразования из слияние файлов и тот же результат, как и настройка «результаты в один файл».

## <a name="next-steps"></a>Дальнейшие действия
См. другие потока данных статьи, относящиеся к производительности:

- [Вкладка оптимизация потока данных](concepts-data-flow-optimize-tab.md)
- [Действие потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
