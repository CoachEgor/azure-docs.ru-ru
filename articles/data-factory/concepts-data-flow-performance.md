---
title: Руководство по настройке производительности потоков данных для сопоставления
description: Узнайте о ключевых факторах, которые влияют на производительность потоков данных для сопоставления в Фабрике данных Azure.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 07/06/2020
ms.openlocfilehash: 9f420b37bd44a46d4149e89cf5876d8e8b712581
ms.sourcegitcommit: d7008edadc9993df960817ad4c5521efa69ffa9f
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/08/2020
ms.locfileid: "86114386"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Руководство по настройке производительности потоков данных для сопоставления

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Потоки данных для сопоставления в Фабрике данных Azure предоставляют интерфейс для проектирования, развертывания и координации преобразований данных в необходимом масштабе без написания кода. Если вы не знакомы с потоками данных для сопоставления, см. статью [Общие сведения о потоках данных для сопоставления](concepts-data-flow-overview.md).

При проектировании и тестировании потоков данных в пользовательском интерфейсе ADF необходимо переключиться в режим отладки, чтобы выполнять потоки данных в режиме реального времени, не дожидаясь подготовки кластера. Дополнительные сведения см. в статье [Режим отладки](concepts-data-flow-debug-mode.md).

В этом видео показано несколько примеров преобразования данных с помощью потоков данных:
> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="monitoring-data-flow-performance"></a>Отслеживание производительности потоков данных

При проектировании потоков данных для сопоставления можно проводить модульное тестирование каждого преобразования на вкладке предварительного просмотра данных на панели настройки. После проверки логики полностью протестируйте поток данных в качестве действия в конвейере. Добавьте действие "Выполнить поток данных" и нажмите кнопку "Отладка", чтобы протестировать производительность потока данных. Чтобы открыть план выполнения и профиль производительности потока данных, щелкните значок очков в разделе "Действия" на вкладке выходных данных конвейера.

![Монитор потока данных](media/data-flow/mon002.png "Монитор потока данных 2")

 Эти сведения можно использовать для оценки производительности потока данных с источниками данных разного размера. Дополнительные сведения см. в статье [Мониторинг потоков данных для сопоставления](concepts-data-flow-monitoring.md).

![Data Flow Monitoring](media/data-flow/mon003.png "Монитор потока данных 3") (Мониторинг потоков данных)

 При выполнении отладки конвейера в расчет общей производительности следует включить примерно одну минуту на подготовку кластера. При инициализации Azure Integration Runtime по умолчанию время запуска может занять около 4 минут.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Увеличение объема вычислительных ресурсов в Azure Integration Runtime

Чем больше ядер в среде Integration Runtime, тем больше узлов в вычислительных средах Spark и тем больше вычислительная мощность для чтения, записи и преобразования данных. Потоки данных ADF используют Spark в качестве вычислительной подсистемы. Среда Spark отлично работает с ресурсами, оптимизированными для памяти.

Мы рекомендуем использовать **память, оптимизированную** для рабочей нагрузки. Вы сможете хранить больше данных в памяти и сокращать ошибки нехватки памяти. Оптимизированная для памяти Цена имеет более высокую ценовую точку на ядро, чем оптимизировано для вычислений, но, скорее всего, приведет к более быстрой скорости преобразования и более успешному выполнению конвейеров. Если при выполнении потоков данных возникают ошибки нехватки памяти, перейдите на конфигурацию Azure IR, оптимизированную для памяти.

**Оптимизация вычислений** может быть достаточной для предварительной версии отладки и предварительного просмотра данных с ограниченным количеством строк данных. Оптимизация вычислений, скорее всего, не будет работать и с рабочими нагрузками.

![Новая среда IR](media/data-flow/ir-new.png "Новая среда IR")

Дополнительные сведения о создании среды Integration Runtime см. в статье [Среда выполнения интеграции в Фабрике данных Azure](concepts-integration-runtime.md).

### <a name="increase-the-size-of-your-debug-cluster"></a>Увеличение размера отладочного кластера

По умолчанию при включении отладки используется среда Azure Integration Runtime по умолчанию, которая создается автоматически для каждой фабрики данных. В этой среде Azure IR по умолчанию настроено восемь ядер: четыре для узла драйвера и четыре для рабочего узла — с помощью общих свойств вычислений. При тестировании с большим объемом данных можно увеличить размер отладочного кластера, создав среду Azure IR с более крупной конфигурацией и выбрав ее при переключении в режим отладки. Это позволит ADF использовать данную среду Azure IR для предварительного просмотра данных и отладки конвейера с потоками данных.

### <a name="decrease-cluster-compute-start-up-time-with-ttl"></a>Уменьшение времени запуска вычислений в кластере с помощью срока жизни

В Azure IR в свойствах потока данных есть свойство, которое позволяет настроить пул вычислительных ресурсов кластера для фабрики. С помощью этого пула можно поочередно отправлять действия потока данных на выполнение. После создания пула для выполнения каждого последующего задания в кластере Spark по запросу потребуется 1–2 минуты. Первоначальная настройка пула ресурсов займет около 4 минут. Укажите период времени, в течение которого должен существовать пул ресурсов, в параметре срока жизни.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse-synapse"></a>Оптимизация для Базы данных SQL Azure и Хранилища данных SQL Azure Synapse

### <a name="partitioning-on-source"></a>Секционирование источника

1. На вкладке **Оптимизация** выберите **Настроить секционирование**.
1. выберите значение **Источник**.
1. В поле **Число разделов** укажите максимальное число подключений к Базе данных SQL Azure. Вы можете попробовать более высокое значение, чтобы обеспечить параллельное подключение к базе данных. Однако в некоторых случаях более высокая производительность достигается при небольшом числе подключений.
1. Выберите, следует ли выполнять секционирование по определенному столбцу таблицы или запросу.
1. Если вы выбрали вариант **Столбец**, выберите столбец секционирования.
1. Если вы выбрали вариант **Запрос**, введите запрос, соответствующий схеме секционирования таблицы в базе данных. Этот запрос позволяет ядру базы данных-источника использовать устранение секций. Таблицы в базе данных-источнике секционировать не нужно. Если источник еще не секционирован, ADF будет использовать секционирование данных в среде преобразования Spark на основе ключа, выбранного в преобразовании источника.

![Часть источника](media/data-flow/sourcepart3.png "Часть источника")

> [!NOTE]
> Выбирать количество секций для источника рекомендуется на основе числа ядер, заданного для среды Azure Integration Runtime, умножая это число на пять. Например, если вы преобразуете ряд файлов в папках ADLS и планируете использовать 32-ядерную среду Azure IR, то требуемое количество секций составляет 32 x 5 = 160.

### <a name="source-batch-size-input-and-isolation-level"></a>Размер исходного пакета, входные данные и уровень изоляции

В разделе **Параметры источника** преобразования источника следующие параметры могут влиять на производительность.

* Параметр "Размер пакета" предписывает ADF хранить данные в памяти Spark наборами, а не построчно. Размер пакета является необязательным параметром. Если вычислительные узлы имеют неправильный размер, в них могут закончиться ресурсы. Если не задать это свойство, будут использоваться параметры пакета кэширования Spark по умолчанию.
* Задав запрос, можно отфильтровать строки в источнике до того, как они поступят в поток данных для обработки. Это может ускорить получение начальных данных. При использовании запроса можно добавить дополнительные указания запроса для Базы данных SQL Azure, такие как READ UNCOMMITTED.
* Указание READ UNCOMMITTED позволяет быстрее получать результаты запроса при преобразовании источника.

![Source](media/data-flow/source4.png "Источник")

### <a name="sink-batch-size"></a>Размер пакета приемника

Чтобы избежать построчной обработки потоков данных, задайте **размер пакета** на вкладке "Параметры" для приемников Базы данных SQL Azure и Хранилища данных SQL Azure. Если размер пакета задан, ADF обрабатывает операции записи в базу данных пакетами указанного размера. Если не задать это свойство, будут использоваться параметры пакета кэширования Spark по умолчанию.

![Приемник](media/data-flow/sink4.png "Приемник")

### <a name="partitioning-on-sink"></a>Секционирование приемника

Даже если данные в конечных таблицах не секционированы, рекомендуется секционировать данные в преобразовании приемника. Секционирование данных часто приводит к более быстрой загрузке по сравнению с принудительном использованием одного узла и секции всеми подключениями. Перейдите на вкладку "Оптимизация" приемника и выберите *циклическое* секционирование, чтобы выбрать идеальное количество секций для записи в приемник.

### <a name="disable-indexes-on-write"></a>Отключение индексов при записи

В конвейере добавьте перед действием потока данных [действие хранимой процедуры](transform-data-using-stored-procedure.md), которое отключает индексы в конечных таблицах, записываемых из приемника. После действия потока данных добавьте еще одно действие хранимой процедуры, которое включает эти индексы. Вы также можете использовать скрипты предварительной и последующей обработки в приемнике базы данных.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Увеличение размера Базы данных SQL Azure и Хранилища данных SQL Azure

Запланируйте изменение размеров Базы данных SQL Azure и Хранилища данных SQL Azure, выступающих в роли источника и приемника, перед выполнением конвейера, чтобы увеличить пропускную способность и минимизировать регулирование Azure по достижении ограничений DTU. После завершения выполнения конвейера восстановите нормальные размеры баз данных.

* Преобразование исходной таблицы Базы данных SQL с 887 тысячами строк и 74 столбцами в таблицу Базы данных SQL с одним производным столбцом занимает всего около 3 минут при использовании оптимизированной для памяти отладочной среды Azure IR с 80 ядрами.

### <a name="azure-synapse-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Только для Хранилища данных SQL Azure Synapse] Использование промежуточного процесса для пакетной загрузки данных с помощью Polybase

Чтобы избежать построчной вставки в хранилище данных, установите флажок **Включить промежуточный режим** в параметрах приемника. Это позволит ADF использовать [PolyBase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide). PolyBase позволяет ADF загружать данные пакетами.
* При выполнении действия потока данных из конвейера необходимо выбрать большой двоичный объект или ADLS 2-го поколения в качестве места промежуточного хранения данных во время массовой загрузки.

* Преобразование исходного файла размером 421 МБ с 74 столбцами в таблицу Synapse с одним производным столбцом занимает всего около 4 минут при использовании оптимизированной для памяти отладочной среды Azure IR с 80 ядрами.

## <a name="optimizing-for-files"></a>Оптимизация для файлов

При каждом преобразовании можно задать схему секционирования, которую должна использовать фабрика данных, на вкладке "Оптимизация". Рекомендуется сначала протестировать приемники на основе файлов с секционированием и оптимизациями по умолчанию. Если включить секционирование в "текущее секционирование" в приемнике для назначения файла, Spark будет устанавливать соответствующее секционирование по умолчанию для рабочих нагрузок. Секционирование по умолчанию использует 128 МБ на секцию.

* Для файлов меньшего размера небольшое количество секций может иногда оказаться эффективнее, чем секционирование небольших файлов в Spark.
* Если у вас недостаточно сведений об исходных данных, выберите *циклическое* секционирование и задайте количество секций.
* Если в данных есть столбцы, которые подходят в качестве хэш-ключей, выберите *хэш-секционирование*.

* Преобразование исходного файла размером 421 МБ с 74 столбцами и одним производным столбцом из файлового приемника занимает всего около 2 минут при использовании оптимизированной для памяти отладочной среды Azure IR с 80 ядрами.

При отладке в режимах предварительного просмотра данных и отладки конвейера максимальный размер и размер выборки для исходных наборов файловых данных применяются только к количеству возвращаемых, но не считываемых строк. Это может повлиять на производительность отладки и привести к сбою потока.
* Отладочные кластеры — это по умолчанию небольшие кластеры с одним узлом. Для отладки рекомендуется использовать небольшие файлы в качестве образцов. Перейдите в параметры отладки и укажите небольшое подмножество данных с помощью временного файла.

    ![Параметры отладки](media/data-flow/debugsettings3.png "Параметры отладки")

### <a name="file-naming-options"></a>Параметры именования файлов

Наиболее распространенный способ записи преобразованных данных в потоках данных для сопоставления — запись в большой двоичный объект или файловое хранилище ADLS. В приемнике необходимо выбрать набор данных, связанный с контейнером или папкой, а не именованным файлом. Так как для выполнения потока данных для сопоставления используется Spark, выходные данные разбиваются на несколько файлов в соответствии со схемой секционирования.

Распространенной схемой секционирования является _вывод в один файл_. В этом случае все выходные файлы PART объединяются в один файл в приемнике. Эта операция требует сокращения выходных данных до одной секции в одном узле кластера. При объединении большого количества исходных файлов в один выходной файл в узле кластера могут закончиться ресурсы.

Чтобы избежать исчерпания ресурсов в узлах кластера, оставьте оптимизированную схему по умолчанию в потоке данных и добавьте в конвейер действие копирования, которое объединяет все файлы PART из выходной папки в один новый файл. Этот метод отделяет действие преобразования от слияния файлов и дает тот же результат, что и выбор _вывода в один файл_.

### <a name="looping-through-file-lists"></a>Циклический перебор списков файлов

Поток данных для сопоставления работает лучше, когда преобразование источника выполняет перебор нескольких файлов, а не циклический перебор с помощью действия For Each. В преобразовании источника рекомендуется использовать подстановочные знаки или списки файлов. Процесс потока данных будет выполняться быстрее благодаря циклическому перебору в кластере Spark. Дополнительные сведения см. в разделе [Использование подстановочных знаков в преобразовании источника](connector-azure-data-lake-storage.md#mapping-data-flow-properties).

Например, если у вас в папке в хранилище BLOB-объектов есть список файлов данных за июль 2019 года, которые вы хотите обработать, ниже приведен шаблон, который можно использовать в преобразовании источника.

```DateFiles/*_201907*.txt```

Благодаря подстановочным знакам конвейер будет содержать только одно действие потока данных. Такой подход будет эффективнее, чем запрос поиска к хранилищу BLOB-объектов, который затем выполняет перебор всех соответствующих файлов с помощью ForEach с вложенным действием "Выполнить поток данных".

Действие For Each конвейера в параллельном режиме порождает несколько кластеров из-за подготовки кластеров заданий для каждого выполняемого действия потока данных. Это может привести к регулированию службы Azure с большим количеством одновременных выполнений. Однако использование действия "Выполнить поток данных" внутри For Each с упорядоченным набором в конвейере позволяет избежать регулирования и исчерпания ресурсов. В этом случае Фабрика данных последовательно выполняет поток данных применительно к каждому файлу.

При последовательном использовании For Each с потоком данных рекомендуется использовать параметр срока жизни в Azure Integration Runtime. Это связано с тем, что каждый файл будет иметь полное время запуска кластера в течение 4 минут в пределах итератора.

### <a name="optimizing-for-cosmosdb"></a>Оптимизация для CosmosDB

Заданные в приемниках CosmosDB свойства пропускной способности и пакетов действуют только во время выполнения потока данных из действия конвейера. После выполнения потока данных в CosmosDB вступают в силу исходные параметры сбора.

* Размер пакета. Вычислите приблизительный размер строк данных и убедитесь в том, что размер строки, умноженный на размер пакета, меньше двух миллионов. Если это так, увеличьте размер пакета, чтобы улучшить пропускную способность.
* Пропускная способность. Задайте более высокую пропускную способность, чтобы документы быстрее записывались в CosmosDB. Имейте в виду, что чем выше пропускная способность, тем выше стоимость ЕЗ.
*   Бюджет на пропускную способность записи. Используйте значение, которое меньше общего количества ЕЗ в минуту. Если у вас есть поток данных с большим количеством секций Spark, настройка бюджета пропускной способности позволит сбалансировать эти секции.

## <a name="join-and-lookup-performance"></a>Производительность присоединение и Уточняющий запрос

Управление производительностью операций объединения в потоке данных — очень распространенная операция, которая выполняется на протяжении всего жизненного цикла преобразований данных. В ADF потоки данных не требуют сортировки данных до объединения, так как эти операции выполняются в Spark как хэш-соединения. Однако вы можете повысить производительность благодаря оптимизации объединения "Рассылка", которая применяется к преобразованиям Joins, Exists и Lookup.

Это позволит избежать перемешивания в процессе выполнения благодаря передаче содержимого обеих сторон отношения объединения в узел Spark. Такой метод хорошо подходит для небольших таблиц, используемых для поиска ссылок. Большие таблицы, которые могут не помещаться в память узла, плохо подходят для оптимизации рассылкой.

Рекомендуемая конфигурация для потоков данных с множеством операций объединения заключается в том, чтобы задать для оптимизации значение "Авто" для "вещания" и использовать ***оптимизированную для памяти*** Azure Integration Runtime конфигурацию. При возникновении ошибок нехватки памяти или истечения времени ожидания рассылки во время выполнения потока данных можно отключить оптимизацию рассылкой. Однако это приведет к более медленному выполнению потоков данных. При необходимости можно указать, что поток данных должен принудительно отправлять только левую часть объединения, только правую часть или обе части.

![Параметры рассылки](media/data-flow/newbroad.png "Параметры рассылки")

Еще одна оптимизация объединения заключается в построении объединения таким образом, чтобы избежать реализации перекрестных соединений в Spark. Например, при включении литеральных значений в условия объединения Spark может расценить это как требование получить в первую очередь полное декартово произведение, а затем отфильтровать объединенные значения. Но если вы убедитесь в том, что на обеих сторонах условия объединения есть значения столбцов, то вы можете избежать этой операции в Spark и повысить производительность объединений и потоков данных.

## <a name="next-steps"></a>Дальнейшие действия

Ознакомьтесь с другими статьями о производительности потоков данных.

- [Вкладка оптимизации потока данных](concepts-data-flow-overview.md#optimize)
- [Действие потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
