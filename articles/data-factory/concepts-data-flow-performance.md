---
title: Картирование производительности потока данных и руководство по настройке
description: Узнайте о ключевых факторах, влияющих на производительность картографических потоков данных на фабрике данных Azure.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 03/11/2020
ms.openlocfilehash: 95a60abef283984d66736358d2d02048f08d700d
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "80246999"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Руководство по картированию потоков данных и настройке

Картирование потоков данных в Azure Data Factory обеспечивает без кодовый интерфейс для проектирования, развертывания и организации преобразований данных в масштабе. Если вы не знакомы с картографическими [Mapping Data Flow Overview](concepts-data-flow-overview.md)потоками данных, см.

При проектировании и тестировании потоков данных из ADF UX убедитесь, что переключите режим отладки для выполнения потоков данных в режиме реального времени, не дожидаясь разогрева кластера. Для получения дополнительной [Debug Mode](concepts-data-flow-debug-mode.md)информации см.

Это видео показывает некоторые выборки тайминги преобразования данных с потоками данных:
> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="monitoring-data-flow-performance"></a>Мониторинг производительности потока данных

При проектировании потоков картографических данных можно уединить тестирование каждой трансформации, нажав на вкладку предварительного просмотра данных в панели конфигурации. Как только вы проверите свою логику, проверьте сквозной поток данных как действие в конвейере. Добавьте действия «Выполняйте поток данных» и используйте кнопку «Ошибка» для проверки производительности потока данных. Чтобы открыть план выполнения и профиль производительности потока данных, нажмите на значок очков под "действиями" в вкладке вывода конвейера.

![Монитор потока данных](media/data-flow/mon002.png "Монитор потока данных 2")

 Эту информацию можно использовать для оценки производительности потока данных на основе различных источников данных. Для получения дополнительной информации [см.](concepts-data-flow-monitoring.md)

![Data Flow Monitoring](media/data-flow/mon003.png "Монитор потока данных 3") (Мониторинг потоков данных)

 Для отладки конвейера требуется около одной минуты времени настройки кластера в общих расчетах производительности для теплого кластера. Если вы инициализируете время интеграции Azure по умолчанию, время вращения может занять около 5 минут.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Увеличение размера вычислений в Runtime интеграции Azure

Интеграция Runtime с большим количеством ядер увеличивает количество узлов в вычислительных средах Spark и обеспечивает большую вычислительную мощность для чтения, записи и преобразования данных.
* Попробуйте **оптимизированный кластер Compute,** если вы хотите, чтобы скорость обработки была выше, чем скорость ввода.
* Попробуйте кластер **«Оптимизированная память»,** если требуется кэшировать больше данных в памяти. Оптимизированная память имеет более высокую цену на ядро, чем Compute Optimized, но, скорее всего, приведет к более быстрым скоростям преобразования.

![Новый ИК](media/data-flow/ir-new.png "Новый ИК")

Для получения дополнительной информации о том, как создать время выполнения интеграции, [см.](concepts-integration-runtime.md)

### <a name="increase-the-size-of-your-debug-cluster"></a>Увеличьте размер кластера отладки

По умолчанию включение отладки будет использовать время выполнения интеграции Azure по умолчанию, которое создается автоматически для каждой фабрики данных. Этот ИК Azure по умолчанию устанавливается для восьми ядер, четырех для узла драйвера и четырех для рабочего узла с использованием свойств General Compute. При тестировании с большими данными можно увеличить размер кластера отладки, создав ИК Azure с большими конфигурациями и выберите новую ИК Azure при включении отладки. Это поручит ADF использовать эту ИК Azure для предварительного просмотра данных и отладки конвейера с потоками данных.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse"></a>Оптимизация для базы данных Azure S'L и хранилища данных Azure S'L

### <a name="partitioning-on-source"></a>Раздел на источнике

1. Перейдите на вкладку **«Оптимизация»** и выберите **раздел «Установить»**
1. Выберите **Источник**.
1. Под **номером разделов**установите максимальное количество подключений к вашему Azure S'L DB. Вы можете попробовать более высокую настройку, чтобы получить параллельные соединения с базой данных. Однако в некоторых случаях может быть более высокой производительностью при ограниченном количестве подключений.
1. Выберите, следует ли развести определенным столбцом таблицы или запросом.
1. Если вы выбрали **столбец,** выберите столбец раздела.
1. Если вы выбрали **запрос,** введите запрос, который соответствует схеме раздела таблицы базы данных. Этот запрос позволяет движку исходной базы данных использовать устранение раздела. Таблицы исходной базы данных не должны быть разделены. Если ваш источник еще не разделен, ADF по-прежнему будет использовать раздел данных в среде преобразования Spark на основе ключа, выбранного в преобразовании источника.

![Исходная часть](media/data-flow/sourcepart3.png "Исходная часть")

> [!NOTE]
> Хорошее руководство, которое поможет вам выбрать количество разделов для вашего источника, основано на количестве ядер, установленных для выполнения интеграции Azure, и умножить это число на пять. Так, например, если вы преобразуете серию файлов в папках ADLS и собираетесь использовать 32-ядерный ИК Azure, количество разделов, на которые вы бы нацелились, составляет 32 х 5 и 160 разделов.

### <a name="source-batch-size-input-and-isolation-level"></a>Размер партии исходного кода, входные данные и уровень изоляции

В **соответствии с параметрыми исхода** в преобразовании исходного кода следующие параметры могут повлиять на производительность:

* Размер пакета поручает ADF хранить данные в наборах памяти вместо строки за строкой. Размер пакета является необязательным параметром, и у вас могут не быть ресурсов на вычислительных узлах, если они не рассчитаны должным образом.
* Установка запроса позволяет фильтровать строки в источнике до их поступления в Поток данных для обработки. Это может ускорить процесс получения первоначальных данных. Если вы используете запрос, можно добавить дополнительные подсказки запроса для вашего Azure S'L DB, например READ UNCOMMITTED.
* Чтение незафиксированных обеспечит более быстрые результаты запроса по преобразованию Источника

![Источник](media/data-flow/source4.png "Источник")

### <a name="sink-batch-size"></a>Размер партии раковины

Чтобы избежать перевалки потоков данных, установите **размер пакета** во вкладке «Настройки» для поглотителей Azure S'L DB и Azure S'L DW. Если размер пакета установлен, база данных ADF обрабатывает данные, записывая пакетами в зависимости от предоставленного размера.

![Раковина](media/data-flow/sink4.png "Приемник")

### <a name="partitioning-on-sink"></a>Раздел на раковине

Даже если данные не разделены в таблицах назначения, рекомендуется, чтобы ваши данные были разделены в преобразовании раковины. Разделенные данные часто приводят к гораздо более быстрой загрузке по сравнению с принуждением всех соединений к использованию одного узла/раздела. Перейдите на вкладку Оптимизация вашего раковины и выберите *раунд Робин* раздела, чтобы выбрать идеальное количество разделов, чтобы написать на раковину.

### <a name="disable-indexes-on-write"></a>Отогивание индексов на записи

В конвейер до всадили [действие «Сохраненная процедура»](transform-data-using-stored-procedure.md) перед действием потока данных, которое отсваляет индексы на целевых таблицах, записанных с вине Sink. После действия Data Flow добавьте еще одно действие Stored Procedure, которое позволяет эти индексы. Или используйте сценарии предварительной обработки и пост-обработки в раковине базы данных.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Увеличьте размер ваших Azure S'L DB и DW

Запланируйте изменение размера исходного кода и потопить Azure S'L DB и DW перед запуском конвейера, чтобы увеличить пропускную мощность и свести к минимуму регулирование Azure, как только вы достигнете пределов DTU. После завершения выполнения конвейера изыскните базы данных до нормального уровня выполнения.

* Исходная таблица S'L DB с 887k строками и 74 столбцов к таблице S'L DB с одной выведенной трансформацией столбца занимает около 3 минут сквозной с помощью оптимизированной памяти 80-ядерных отливных ИКОв Azure.

### <a name="azure-synapse-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>«Только Azure Synapse S'L DW» Используйте постановку для загрузки данных оптом через Polybase

Чтобы избежать вставок строки за строкой в DW, проверьте **постановку Enable** в настройках sink, чтобы ADF мог использовать [PolyBase.](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide) PolyBase позволяет ADF загружать данные оптом.
* При выполнении действия потока данных из конвейера необходимо выбрать место хранения Blob или ADLS Gen2 для постановки данных во время массовой загрузки.

* Источник файла 421Mb файла с 74 столбиками к таблице Synapse и одно производное преобразование столбца занимает около 4 минут сквозной с помощью памяти оптимизированной 80-ягнического отладки Azure IRs.

## <a name="optimizing-for-files"></a>Оптимизация для файлов

При каждом преобразовании можно настроить схему раздела, которая вы хотите, чтобы фабрика данных использовалась во вкладке «Оптимизация». Это хорошая практика для первого тестирования файловых раковин, сохраняя раздел и оптимизацию по умолчанию.

* Для небольших файлов можно найти выбор меньшего количества разделов, который иногда может работать лучше и быстрее, чем запрашивать Spark для раздела небольших файлов.
* Если у вас недостаточно информации об исходных данных, выберите раздел *раунда Робин* а также установите количество разделов.
* Если ваши данные имеют столбцы, которые могут быть хорошими ключами хэша, выберите *раздел хэш.*

* Источник файлов с файлом раковина 421Mb файл с 74 столбцов и одной производной преобразования столбца занимает около 2 минут сквозной с помощью памяти оптимизированной 80-яговой отладить Azure IRs.

При отладке предварительного просмотра данных и отладке конвейера размеры лимита и выборки для наборов исходных данных на основе файлов применяются только к количеству возвращенных строк, а не к количеству прочитаных строк. Это может повлиять на производительность выполнения отладок и, возможно, привести к сбою потока.
* Кластеры debug по умолчанию представляют небольшие одноузловые кластеры, и мы рекомендуем использовать небольшие файлы образца для отладки. Перейдите к настройкам оттачек и укажите на небольшой подмножество данных с помощью временного файла.

    ![Настройки дебага](media/data-flow/debugsettings3.png "Параметры отладки")

### <a name="file-naming-options"></a>Параметры именования файлов

Наиболее распространенный способ записи преобразованных данных в картографии потоков данных, пишущих хранилище файлов Blob или ADLS. В раковине необходимо выбрать набор данных, который указывает на контейнер или папку, а не на именованный файл. Поскольку поток данных для отображения данных использует Spark для выполнения, вывод делится на несколько файлов на основе схемы раздела.

Общей схемой раздела является выбор _вывода в один файл,_ который объединяет все выходные файлы PART в один файл в раковине. Эта операция требует сокращения вывода до одного раздела на одном кластерном узлах. При объединении большого исходного файла в единый выводной файл может быть запущено ресурсы кластерного узла.

Чтобы избежать исчерпания ресурсов вычислительных узлов, сохраните значение по умолчанию, оптимизированная схема в потоке данных и добавьте в конвейер действие copy, которое объединяет все файлы PART из папки вывода в новый единый файл. Этот метод отделяет действие преобразования от слияния файлов и достигает того же результата, что и _настройка вывода в один файл._

### <a name="looping-through-file-lists"></a>Цикл через списки файлов

Поток данных отображения будет выполняться лучше, когда преобразование Источника итерирует несколько файлов вместо цикла через для каждого действия. Мы рекомендуем использовать подстановочные знаки или списки файлов в преобразовании исходного кода. Процесс потока данных будет выполняться быстрее, позволяя циклу происходить внутри кластера Spark. Для получения дополнительной [информации см.](connector-azure-data-lake-storage.md#mapping-data-flow-properties)

Например, если у вас есть список файлов данных с июля 2019 года, который вы хотите обработать в папке в Blob Storage, ниже приведен подстановочный знак, который можно использовать в преобразовании Исходного кода.

```DateFiles/*_201907*.txt```

С помощью подстановочного знака конвейер будет содержать только одну активность потока данных. Это будет работать лучше, чем Lookup против Blob Store, который затем итерирует все соответствующие файлы с помощью ForEach с выполнением активности потока данных внутри.

### <a name="optimizing-for-cosmosdb"></a>Оптимизация для CosmosDB

Установка пропускной силы и пакетных свойств на поглотителях CosmosDB действует только при выполнении этого потока данных из деятельности потока данных конвейера. Исходные настройки сбора будут выполнены CosmosDB после выполнения потока данных.

* Размер пакета: Рассчитайте грубый размер строки данных и убедитесь, что размер пакета rowSize составляет менее двух миллионов. Если это так, увеличьте размер партии, чтобы получить лучшую пропускную выливку
* Пропускная запись: Установите более высокую настройку пропускной записи здесь, чтобы позволить документам быстрее писать в CosmosDB. Пожалуйста, имейте в виду более высокие затраты RU на основе высокой пропускной установки.
*   Напишите бюджет пропускной записи: Используйте значение, которое меньше, чем общее количество RUs в минуту. Если у вас есть поток данных с большим количеством разделов Spark, установление бюджетной пропускной всей перевалки позволит обеспечить больший баланс между этими разделами.

## <a name="join-performance"></a>Присоединиться к производительности

Управление производительностью соединений в потоке данных является очень распространенной операцией, которую вы будете выполнять на протяжении всего жизненного цикла преобразований данных. В ADF потоки данных не требуют отсортировки данных до соединения, поскольку эти операции выполняются при хэш-соединениях в Spark. Тем не менее, вы можете извлечь выгоду из повышения производительности с "Вещание" Присоединиться к оптимизации. Это позволит избежать перетасовки, нажав вниз содержимое обеих сторон вашего соединения отношения в узла Spark. Это хорошо работает для небольших таблиц, которые используются для поиска ссылок. Большие таблицы, которые могут не вписаться в память узла, не являются хорошими кандидатами для оптимизации вещания.

Еще одна оптимизация Join заключается в том, чтобы построить соединения таким образом, чтобы избежать тенденции Spark к реализации кросс-соединений. Например, когда вы включаете буквальные значения в условия соединения, Spark может рассматривать это как требование сначала выполнять полный декартовый продукт, а затем отфильтровать объединенные значения. Но если вы гарантируете, что у вас есть значения столбцов по обе стороны от состояния соединения, вы можете избежать этого индуцированного искрятся spark декартового продукта и улучшить производительность ваших соединений и потоков данных.

## <a name="next-steps"></a>Дальнейшие действия

Смотрите другие статьи Data Flow, связанные с производительностью:

- [Вкладка оптимизации потока данных](concepts-data-flow-overview.md#optimize)
- [Активность потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
