---
title: Сопоставление руководств по производительности потока данных и настройке в фабрике данных Azure | Документация Майкрософт
description: Узнайте о ключевых факторах, влияющих на производительность при сопоставлении потоков данных в фабрике данных Azure.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.date: 10/07/2019
ms.openlocfilehash: 24b0deb60f1047228dc3ff6000d423e7cb6939ca
ms.sourcegitcommit: e0e6663a2d6672a9d916d64d14d63633934d2952
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 10/21/2019
ms.locfileid: "72387317"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Сопоставление потоков данных о производительности и настройке

Сопоставление потоков данных в фабрике данных Azure обеспечивает интерфейс без кода для проектирования, развертывания и координации преобразований данных в масштабе. Если вы не знакомы с потоками данных сопоставления, см. раздел [Общие сведения о потоке данных сопоставления](concepts-data-flow-overview.md).

При проектировании и тестировании потоков данных от пользовательского интерфейса ADF необходимо переключиться в режим отладки для выполнения потоков данных в режиме реального времени, не дожидаясь прогрева кластера. Дополнительные сведения см. в разделе [режим отладки](concepts-data-flow-debug-mode.md).

## <a name="monitoring-data-flow-performance"></a>Наблюдение за производительностью потока данных

При проектировании потоков данных сопоставления можно выполнить модульное тестирование каждого преобразования, щелкнув вкладку Предварительный просмотр данных на панели конфигурация. После проверки логики протестируйте поток данных в качестве действия в конвейере. Добавьте действие выполнение потока данных и используйте кнопку Отладка для проверки производительности потока данных. Чтобы открыть план выполнения и профиль производительности потока данных, щелкните значок очков в разделе "действия" на вкладке "выходные данные" конвейера.

![Монитор потока данных](media/data-flow/mon002.png "Монитор потока данных 2")

 Эти сведения можно использовать для оценки производительности потока данных по различным источникам данных. Дополнительные сведения см. в разделе [наблюдение за потоками данных сопоставления](concepts-data-flow-monitoring.md).

![Data Flow Monitoring](media/data-flow/mon003.png "Монитор потока данных 3") (Мониторинг потоков данных)

 Для выполнения отладки конвейера около минуты настройки кластера в общих вычислениях производительности требуется для работы горячего кластера. При инициализации Azure Integration Runtime по умолчанию время запуска может занять около 5 минут.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Увеличение размера вычислений в Azure Integration Runtime

Integration Runtime с большим числом ядер увеличивает количество узлов в вычислительных средах Spark и обеспечивает дополнительную вычислительную мощность для чтения, записи и преобразования данных.
* Попробуйте кластер, **оптимизированный для вычислений** , если вы хотите, чтобы скорость обработки превышала скорость ввода
* Если требуется кэшировать больше данных в памяти, попробуйте использовать кластер, **оптимизированный для памяти** .

![Создать IR](media/data-flow/ir-new.png "Создать IR")

Дополнительные сведения о создании Integration Runtime см. [в разделе Integration Runtime в фабрике данных Azure](concepts-integration-runtime.md).

### <a name="increase-the-size-of-your-debug-cluster"></a>Увеличение размера кластера отладки

По умолчанию при включении отладки будет использоваться среда выполнения интеграции Azure по умолчанию, которая создается автоматически для каждой фабрики данных. Этот Azure IR по умолчанию задан для восьми ядер, четыре для узла драйвера и четыре для рабочего узла с использованием общих свойств вычислений. При тестировании с большим объемом данных можно увеличить размер кластера отладки, создав Azure IR с более крупными конфигурациями и выбрав этот новый Azure IR при переключении на отладку. Это позволит ADF использовать этот Azure IR для предварительной версии данных и отладки конвейера с потоками данных.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse"></a>Оптимизация для базы данных SQL Azure и хранилища данных SQL Azure

### <a name="partitioning-on-source"></a>Секционирование по источнику

1. Перейдите на вкладку " **Оптимизация** " и выберите команду " **задать секционирование** ".
1. Выберите **источник**.
1. В разделе **число секций**задайте максимальное число подключений к базе данных SQL Azure. Вы можете использовать более высокий параметр для получения параллельных подключений к базе данных. Однако в некоторых случаях может повыситься производительность с ограниченным числом подключений.
1. Выберите, следует ли секционировать по определенному столбцу таблицы или запросу.
1. Если выбран параметр **столбец**, выберите столбец секционирования.
1. Если вы выбрали **запрос**, введите запрос, соответствующий схеме секционирования таблицы базы данных. Этот запрос позволяет ядру базы данных источника использовать исключение секций. Таблицы базы данных источника не обязательно должны быть секционированы. Если источник еще не секционирован, ADF будет по-прежнему использовать секционирование данных в среде преобразования Spark на основе ключа, выбранного в преобразовании источника.

![Часть источника](media/data-flow/sourcepart3.png "Часть источника")

### <a name="source-batch-size-input-and-isolation-level"></a>Размер исходного пакета, входные данные и уровень изоляции

В разделе **Параметры источника** в преобразовании «источник» следующие параметры могут повлиять на производительность.

* Размер пакета указывает, что ADF-файл должен хранить данные в наборах памяти, а не построчно. Размер пакета является необязательным параметром, и на этих узлах могут быть исчерпаны ресурсы, если они имеют неправильный размер.
* Задание запроса позволяет фильтровать строки в источнике до того, как они поступают в поток данных для обработки. Это может ускорить получение начального данных. При использовании запроса можно добавить дополнительные указания запросов для базы данных SQL Azure, такие как READ UNCOMMITTED.
* Чтение незафиксированных данных обеспечит более быстрый результат выполнения запроса при преобразовании источника

![Источник](media/data-flow/source4.png "Источник")

### <a name="sink-batch-size"></a>Размер пакета приемника

Чтобы избежать построчной обработки потоков данных, задайте **Размер пакета** на вкладке Параметры для базы данных SQL Azure и приемников хранилища Azure SQL. Если задан размер пакета, ADF обрабатывает запись в пакетах на основе указанного размера.

![Приемник](media/data-flow/sink4.png "Приемник")

### <a name="partitioning-on-sink"></a>Секционирование в приемнике

Даже если у вас нет данных, секционированных в целевых таблицах, рекомендуется, чтобы данные были секционированы в преобразовании приемника. Секционированные данные часто приводят к более быстрой нагрузке при принудительном использовании одного узла или раздела всеми подключениями. Перейдите на вкладку Оптимизация своего приемника и выберите *циклическое* перераспределение секционирования, чтобы выбрать оптимальное количество секций для записи в ваш приемник.

### <a name="disable-indexes-on-write"></a>Отключить индексы при записи

В конвейере добавьте [действие хранимой процедуры](transform-data-using-stored-procedure.md) перед действием потока данных, которое отключает индексы в целевых таблицах, записанных из приемника. После действия потока данных добавьте еще одно действие хранимой процедуры, которое включает эти индексы.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Увеличение размера базы данных SQL Azure и хранилища DW

Запланируйте изменение размера исходного и приемника базы данных SQL Azure и хранилища DW перед выполнением конвейера, чтобы увеличить пропускную способность и снизить регулирование Azure после достижения ограничений DTU. После завершения выполнения конвейера измените размер баз данных на нормальную скорость выполнения.

### <a name="azure-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Только хранилище данных SQL Azure] Использование промежуточного хранения для загрузки данных с помощью polybase

Чтобы избежать вставки строк в хранилище данных, установите флажок **включить промежуточное хранение** в параметрах приемника, чтобы ADF-файл мог использовать [polybase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide). Polybase позволяет ADF загружать данные в небольшого объема.
* При выполнении действия потока данных из конвейера необходимо выбрать BLOB-объект или место хранения ADLS 2-го поколения для размещения данных во время выполнения групповой загрузки.

## <a name="optimizing-for-files"></a>Оптимизация для файлов

При каждом преобразовании можно задать схему секционирования, которую должна использовать фабрика данных на вкладке Оптимизация.
* Для небольших файлов может оказаться, что выбор *одного раздела* может работать лучше и быстрее, чем при запросе Spark разбивать небольшие файлы.
* Если у вас недостаточно сведений об исходных данных, выберите *циклический перебор* секционирования и задайте количество секций.
* Если в данных есть столбцы, которые могут быть хорошими хэш-ключами, выберите *хэш-секционирование*.

При отладке в предварительной версии данных и отладке конвейера размер и выборка для наборов файловых источников на основе файлов применяются только к количеству возвращаемых строк, а не к числу считанных строк. Это может повлиять на производительность выполнения отладки и, возможно, привести к сбою потока.
* Отладочные кластеры по умолчанию — это небольшие кластеры с одним узлом. для отладки рекомендуется использовать примеры небольших файлов. Перейдите в раздел Параметры отладки и укажите небольшое подмножество данных с помощью временного файла.

    ![Параметры отладки](media/data-flow/debugsettings3.png "Параметры отладки")

### <a name="file-naming-options"></a>Параметры именования файлов

Наиболее распространенный способ записи преобразованных данных в потоках сопоставления, записывающих хранилище файлов BLOB или ADLS. В приемнике необходимо выбрать набор данных, указывающий на контейнер или папку, а не на именованный файл. Так как поток данных сопоставления использует Spark для выполнения, выходные данные разбиваются на несколько файлов на основе схемы секционирования.

Распространенной схемой секционирования является выбор _выходных данных в один файл_, который объединяет все выходные файлы части в один файл в приемнике. Эта операция требует, чтобы выходные данные уменьшились до одной секции на одном узле кластера. При объединении большого количества исходных файлов в один выходной файл можно запустить ресурсы узла кластера.

Чтобы избежать исчерпания ресурсов кластерных узлов, сохраните по умолчанию оптимизированную схему в потоке данных и добавьте в конвейер действие копирования, которое объединяет все файлы частей из выходной папки в новый отдельный файл. Этот метод отделяет действие преобразования от слияния файлов и достигает того же результата, что и _Вывод данных в один файл_.

### <a name="looping-through-file-lists"></a>Цикл по спискам файлов

Поток данных сопоставления будет работать лучше, когда преобразование источника выполняет итерацию нескольких файлов, а не циклически с помощью действия For Each. В преобразовании источника рекомендуется использовать подстановочные знаки или списки файлов. Процесс потока данных будет выполняться быстрее, позволяя выполнять цикл в кластере Spark. Дополнительные сведения см. [в разделе подстановочные знаки в преобразовании источника](data-flow-source.md#file-based-source-options).

Например, если у вас есть список файлов данных с июля 2019, которые вы хотите обработать в папке в хранилище BLOB-объектов, ниже приведен шаблон, который можно использовать в преобразовании источника.

```DateFiles/*_201907*.txt```

С помощью подстановочных знаков конвейер будет содержать только одно действие потока данных. Это будет работать лучше, чем поиск хранилища больших двоичных объектов, который затем проходит по всем соответствующим файлам с помощью ForEach с действием «выполнение потока данных» внутри.

## <a name="next-steps"></a>Дальнейшие действия

См. Другие статьи о потоках данных, связанные с производительностью:

- [Вкладка «оптимизация потока данных»](concepts-data-flow-overview.md#optimize)
- [Действие потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
