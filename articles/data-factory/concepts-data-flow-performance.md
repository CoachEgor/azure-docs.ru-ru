---
title: Сопоставление с производительностью потока данных и руководством по настройке
description: Узнайте о ключевых факторах, влияющих на производительность при сопоставлении потоков данных в фабрике данных Azure.
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.custom: seo-lt-2019
ms.date: 02/24/2020
ms.openlocfilehash: cca22c499efde74bb1469222d2f8a6e576452aa2
ms.sourcegitcommit: d45fd299815ee29ce65fd68fd5e0ecf774546a47
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/04/2020
ms.locfileid: "78273219"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Сопоставление потоков данных о производительности и настройке

Сопоставление потоков данных в фабрике данных Azure обеспечивает интерфейс без кода для проектирования, развертывания и координации преобразований данных в масштабе. Если вы не знакомы с потоками данных сопоставления, см. раздел [Общие сведения о потоке данных сопоставления](concepts-data-flow-overview.md).

При проектировании и тестировании потоков данных от пользовательского интерфейса ADF необходимо переключиться в режим отладки для выполнения потоков данных в режиме реального времени, не дожидаясь прогрева кластера. Дополнительные сведения см. в разделе [режим отладки](concepts-data-flow-debug-mode.md).

## <a name="monitoring-data-flow-performance"></a>Наблюдение за производительностью потока данных

При проектировании потоков данных сопоставления можно выполнить модульное тестирование каждого преобразования, щелкнув вкладку Предварительный просмотр данных на панели конфигурация. После проверки логики протестируйте поток данных в качестве действия в конвейере. Добавьте действие выполнение потока данных и используйте кнопку Отладка для проверки производительности потока данных. Чтобы открыть план выполнения и профиль производительности потока данных, щелкните значок очков в разделе "действия" на вкладке "выходные данные" конвейера.

![Монитор потока данных](media/data-flow/mon002.png "Монитор потока данных 2")

 Эти сведения можно использовать для оценки производительности потока данных по различным источникам данных. Дополнительные сведения см. в разделе [наблюдение за потоками данных сопоставления](concepts-data-flow-monitoring.md).

![Data Flow Monitoring](media/data-flow/mon003.png "Монитор потока данных 3") (Мониторинг потоков данных)

 Для выполнения отладки конвейера около минуты настройки кластера в общих вычислениях производительности требуется для работы горячего кластера. При инициализации Azure Integration Runtime по умолчанию время запуска может занять около 5 минут.

## <a name="increasing-compute-size-in-azure-integration-runtime"></a>Увеличение размера вычислений в Azure Integration Runtime

Integration Runtime с большим числом ядер увеличивает количество узлов в вычислительных средах Spark и обеспечивает дополнительную вычислительную мощность для чтения, записи и преобразования данных.
* Попробуйте кластер, **оптимизированный для вычислений** , если вы хотите, чтобы скорость обработки была выше, чем скорость ввода.
* Если требуется кэшировать больше данных в памяти, попробуйте использовать кластер, **оптимизированный для памяти** . Оптимизированная для памяти Цена имеет более высокую ценовую точку на ядро, чем оптимизировано для вычислений, но, скорее всего, приведет к более быстрой скорости преобразования.

![Создать IR](media/data-flow/ir-new.png "Создать IR")

Дополнительные сведения о создании Integration Runtime см. [в разделе Integration Runtime в фабрике данных Azure](concepts-integration-runtime.md).

### <a name="increase-the-size-of-your-debug-cluster"></a>Увеличение размера кластера отладки

По умолчанию при включении отладки будет использоваться среда выполнения интеграции Azure по умолчанию, которая создается автоматически для каждой фабрики данных. Этот Azure IR по умолчанию задан для восьми ядер, четыре для узла драйвера и четыре для рабочего узла с использованием общих свойств вычислений. При тестировании с большим объемом данных можно увеличить размер кластера отладки, создав Azure IR с более крупными конфигурациями и выбрав этот новый Azure IR при переключении на отладку. Это позволит ADF использовать этот Azure IR для предварительной версии данных и отладки конвейера с потоками данных.

## <a name="optimizing-for-azure-sql-database-and-azure-sql-data-warehouse"></a>Оптимизация для базы данных SQL Azure и хранилища данных SQL Azure

### <a name="partitioning-on-source"></a>Секционирование по источнику

1. Перейдите на вкладку " **Оптимизация** " и выберите команду " **задать секционирование** ".
1. Выберите **источник**.
1. В разделе **число секций**задайте максимальное число подключений к базе данных SQL Azure. Вы можете использовать более высокий параметр для получения параллельных подключений к базе данных. Однако в некоторых случаях может повыситься производительность с ограниченным числом подключений.
1. Выберите, следует ли секционировать по определенному столбцу таблицы или запросу.
1. Если выбран параметр **столбец**, выберите столбец секционирования.
1. Если вы выбрали **запрос**, введите запрос, соответствующий схеме секционирования таблицы базы данных. Этот запрос позволяет ядру базы данных источника использовать исключение секций. Таблицы базы данных источника не обязательно должны быть секционированы. Если источник еще не секционирован, ADF будет по-прежнему использовать секционирование данных в среде преобразования Spark на основе ключа, выбранного в преобразовании источника.

![Часть источника](media/data-flow/sourcepart3.png "Часть источника")

> [!NOTE]
> Хорошим руководством, помогающим выбрать количество секций для источника, является число ядер, заданное для Azure Integration Runtime, и умножение этого числа на пять. Например, если вы преобразуете ряд файлов в папки ADLS и планируете использовать 32-ядерную Azure IR, то количество секций, которое вы намерены, составляет 32 x 5 = 160 секций.

### <a name="source-batch-size-input-and-isolation-level"></a>Размер исходного пакета, входные данные и уровень изоляции

В разделе **Параметры источника** в преобразовании «источник» следующие параметры могут повлиять на производительность.

* Размер пакета указывает, что ADF-файл должен хранить данные в наборах памяти, а не построчно. Размер пакета является необязательным параметром, и на этих узлах могут быть исчерпаны ресурсы, если они имеют неправильный размер.
* Задание запроса позволяет фильтровать строки в источнике до того, как они поступают в поток данных для обработки. Это может ускорить получение начального данных. При использовании запроса можно добавить дополнительные указания запросов для базы данных SQL Azure, такие как READ UNCOMMITTED.
* Чтение незафиксированных данных обеспечит более быстрый результат выполнения запроса при преобразовании источника

![Source](media/data-flow/source4.png "Источник")

### <a name="sink-batch-size"></a>Размер пакета приемника

Чтобы избежать построчной обработки потоков данных, задайте **Размер пакета** на вкладке Параметры для базы данных SQL Azure и приемников хранилища Azure SQL. Если задан размер пакета, ADF обрабатывает запись в пакетах на основе указанного размера.

![Приемник](media/data-flow/sink4.png "Приемник")

### <a name="partitioning-on-sink"></a>Секционирование в приемнике

Даже если у вас нет данных, секционированных в целевых таблицах, рекомендуется, чтобы данные были секционированы в преобразовании приемника. Секционированные данные часто приводят к более быстрой нагрузке при принудительном использовании одного узла или раздела всеми подключениями. Перейдите на вкладку Оптимизация своего приемника и выберите *циклическое* перераспределение секционирования, чтобы выбрать оптимальное количество секций для записи в ваш приемник.

### <a name="disable-indexes-on-write"></a>Отключить индексы при записи

В конвейере добавьте [действие хранимой процедуры](transform-data-using-stored-procedure.md) перед действием потока данных, которое отключает индексы в целевых таблицах, записанных из приемника. После действия потока данных добавьте еще одно действие хранимой процедуры, которое включает эти индексы. Или использовать скрипты предварительной обработки и последующей обработки в приемнике базы данных.

### <a name="increase-the-size-of-your-azure-sql-db-and-dw"></a>Увеличение размера базы данных SQL Azure и хранилища DW

Запланируйте изменение размера исходного и приемника базы данных SQL Azure и хранилища DW перед выполнением конвейера, чтобы увеличить пропускную способность и снизить регулирование Azure после достижения ограничений DTU. После завершения выполнения конвейера измените размер баз данных на нормальную скорость выполнения.

* Исходная таблица базы данных SQL с 887k строками и 74 столбцами в таблицу базы данных SQL с одним преобразованием «производный столбец» занимает около 3 минут, используя оптимизированную для памяти 80-Core отладку Azure IRs.

### <a name="azure-synapse-sql-dw-only-use-staging-to-load-data-in-bulk-via-polybase"></a>[Только для хранилища данных SQL Azure синапсе] Использование промежуточного хранения для загрузки данных с помощью polybase

Чтобы избежать вставки строк в хранилище данных, установите флажок **включить промежуточное хранение** в параметрах приемника, чтобы ADF-файл мог использовать [polybase](https://docs.microsoft.com/sql/relational-databases/polybase/polybase-guide). Polybase позволяет ADF загружать данные в небольшого объема.
* При выполнении действия потока данных из конвейера необходимо выбрать BLOB-объект или место хранения ADLS 2-го поколения для размещения данных во время выполнения групповой загрузки.

* Источник файла 421Mb-файла с 74 столбцами в таблицу синапсе и преобразование одного производного столбца выполняются примерно через 4 минуты с использованием оптимизированной для обработки в памяти 80-Core отладки Azure IRs.

## <a name="optimizing-for-files"></a>Оптимизация для файлов

При каждом преобразовании можно задать схему секционирования, которую должна использовать фабрика данных на вкладке Оптимизация. Рекомендуется сначала протестировать приемники на основе файлов, сохранив секционирование и оптимизацию по умолчанию.

* Для небольших файлов может оказаться, что выбор меньшего количества разделов может работать лучше и быстрее, чем при запросе Spark разбивать небольшие файлы.
* Если у вас недостаточно сведений об исходных данных, выберите *циклический перебор* секционирования и задайте количество секций.
* Если в данных есть столбцы, которые могут быть хорошими хэш-ключами, выберите *хэш-секционирование*.

* Источник файла с приемником файлов 421Mb-файла с 74 столбцами и одним преобразованием «производный столбец» занимает около 2 минут с использованием оптимизированной для обработки в памяти 80-Core отладки Azure IRs.

При отладке в предварительной версии данных и отладке конвейера размер и выборка для наборов файловых источников на основе файлов применяются только к количеству возвращаемых строк, а не к числу считанных строк. Это может повлиять на производительность выполнения отладки и, возможно, привести к сбою потока.
* Отладочные кластеры по умолчанию — это небольшие кластеры с одним узлом. для отладки рекомендуется использовать примеры небольших файлов. Перейдите в раздел Параметры отладки и укажите небольшое подмножество данных с помощью временного файла.

    ![Параметры отладки](media/data-flow/debugsettings3.png "Параметры отладки")

### <a name="file-naming-options"></a>Параметры именования файлов

Наиболее распространенный способ записи преобразованных данных в потоках сопоставления, записывающих хранилище файлов BLOB или ADLS. В приемнике необходимо выбрать набор данных, указывающий на контейнер или папку, а не на именованный файл. Так как поток данных сопоставления использует Spark для выполнения, выходные данные разбиваются на несколько файлов на основе схемы секционирования.

Распространенной схемой секционирования является выбор _выходных данных в один файл_, который объединяет все выходные файлы части в один файл в приемнике. Эта операция требует, чтобы выходные данные уменьшились до одной секции на одном узле кластера. При объединении большого количества исходных файлов в один выходной файл можно запустить ресурсы узла кластера.

Чтобы избежать исчерпания ресурсов кластерных узлов, сохраните по умолчанию оптимизированную схему в потоке данных и добавьте в конвейер действие копирования, которое объединяет все файлы частей из выходной папки в новый отдельный файл. Этот метод отделяет действие преобразования от слияния файлов и достигает того же результата, что и _Вывод данных в один файл_.

### <a name="looping-through-file-lists"></a>Цикл по спискам файлов

Поток данных сопоставления будет работать лучше, когда преобразование источника выполняет итерацию нескольких файлов, а не циклически с помощью действия For Each. В преобразовании источника рекомендуется использовать подстановочные знаки или списки файлов. Процесс потока данных будет выполняться быстрее, позволяя выполнять цикл в кластере Spark. Дополнительные сведения см. [в разделе подстановочные знаки в преобразовании источника](connector-azure-data-lake-storage.md#mapping-data-flow-properties).

Например, если у вас есть список файлов данных с июля 2019, которые вы хотите обработать в папке в хранилище BLOB-объектов, ниже приведен шаблон, который можно использовать в преобразовании источника.

```DateFiles/*_201907*.txt```

С помощью подстановочных знаков конвейер будет содержать только одно действие потока данных. Это будет работать лучше, чем поиск хранилища больших двоичных объектов, который затем проходит по всем соответствующим файлам с помощью ForEach с действием «выполнение потока данных» внутри.

### <a name="optimizing-for-cosmosdb"></a>Оптимизация для CosmosDB

Установка свойств пропускной способности и пакетов в приемниках CosmosDB вступит в силу только во время выполнения потока данных из действия потока данных конвейера. После выполнения потока данных параметры исходной коллекции будут учитываться CosmosDB.

* Размер пакета: Вычислите приблизительный размер строк данных и убедитесь, что размер пакета размер строки * меньше 2 000 000. Если это так, увеличьте размер пакета, чтобы получить лучшую пропускную способность
* Пропускная способность. Установите более высокую пропускную способность, чтобы документы можно было быстрее писать в CosmosDB. Обратите внимание на более высокие затраты на ЕДИНИЦу, основанные на настройке высокой пропускной способности.
*   Пропускная способность записи: используйте значение, которое меньше общего числа получателей в минуту. Если у вас есть поток данных с большим количеством секций Spark, Настройка пропускной способности бюджета позволит повысить баланс между этими секциями.

## <a name="join-performance"></a>Производительность присоединение

Управление производительностью соединений в потоке данных является очень распространенной операцией, которая будет выполняться на протяжении всего жизненного цикла преобразований данных. В ADF потоки данных не нуждаются в сортировке данных перед соединением, так как эти операции выполняются в качестве хэш-соединений в Spark. Однако вы можете воспользоваться преимуществами оптимизации подключения "вещание". Это позволит избежать случайного перемещения, отправляя содержимое любой стороны отношения объединения в узел Spark. Это хорошо подходит для небольших таблиц, используемых для поиска ссылок. Большие таблицы, которые могут не поместиться в память узла, не являются хорошими кандидатами для оптимизации вещания.

Еще одна оптимизация объединения заключается в создании соединений таким образом, чтобы избежать тенденции Spark для реализации перекрестных соединений. Например, при включении литеральных значений в условия соединения Spark может увидеть, что в первую очередь необходимо сначала выполнить полное декартово произведение, а затем отфильтровать объединенные значения. Но если вы убедитесь, что на обеих сторонах условия объединения есть значения столбцов, вы можете избежать этого, приводящего к возникновению декарти Spark, и повысить производительность соединений и потоков данных.

## <a name="next-steps"></a>Следующие шаги

См. Другие статьи о потоках данных, связанные с производительностью:

- [Вкладка «оптимизация потока данных»](concepts-data-flow-overview.md#optimize)
- [Действие потока данных](control-flow-execute-data-flow-activity.md)
- [Мониторинг производительности потока данных](concepts-data-flow-monitoring.md)
