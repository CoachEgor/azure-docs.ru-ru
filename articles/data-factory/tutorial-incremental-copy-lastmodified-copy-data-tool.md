---
title: Инструмент данных для копирования новых и обновленных файлов постепенно
description: Создайте фабрику данных Azure, а затем используйте инструмент Copy Data для постепенной загрузки новых файлов на основе LastModifiedDate.
services: data-factory
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.devlang: na
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 3/18/2020
ms.openlocfilehash: 3098ca0d3d5e41c298d3058ffa84fcf129648281
ms.sourcegitcommit: b80aafd2c71d7366838811e92bd234ddbab507b6
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2020
ms.locfileid: "81399487"
---
# <a name="incrementally-copy-new-and-changed-files-based-on-lastmodifieddate-by-using-the-copy-data-tool"></a>Постепенно копируйте новые и измененные файлы на основе LastModifiedDate с помощью инструмента Copy Data

[!INCLUDE[appliesto-adf-xxx-md](includes/appliesto-adf-xxx-md.md)]

В этом уроке вы будете использовать портал Azure для создания фабрики данных. Затем вы будете использовать инструмент Copy Data для создания конвейера, который постепенно копирует только новые и измененные файлы, от хранения Azure Blob до хранения Azure Blob. Он `LastModifiedDate` использует, чтобы определить, какие файлы для копирования.

После завершения этих шагов Azure Data Factory будет сканировать все файлы в `LastModifiedDate`хранилище исходных источников, применять фильтр файла и копировать в хранилище только в хранилище, которые являются новыми или были обновлены с момента последнего раза. Обратите внимание, что если Data Factory сканирует большое количество файлов, все равно следует ожидать длительности. Сканирование файлов занимает много времени, даже если объем скопированных данных уменьшается.

> [!NOTE]
> Если вы еще не работали с фабрикой данных, ознакомьтесь со статьей [Введение в фабрику данных Azure](introduction.md).

При работе с этим руководством вы выполните следующие задачи:

> [!div class="checklist"]
> * Создали фабрику данных.
> * Создание конвейера с помощью средства копирования данных.
> * Мониторинг конвейера и выполнения действий.

## <a name="prerequisites"></a>Предварительные требования

* **Подписка Azure**: Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/), прежде чем начинать работу.
* **Учетная запись хранения Azure**: Используйте хранилище Blob для хранилищ исходных данных и данных. Если у вас нет учетной записи хранилища Azure, следуйте инструкциям в [«Создайте учетную запись хранения».](../storage/common/storage-account-create.md)

## <a name="create-two-containers-in-blob-storage"></a>Создание двух контейнеров в хранилище Blob

Подготовьте хранилище Blob для учебника, выполнив следующие шаги:

1. Создайте источник названного **источника**контейнера. Для выполнения этой задачи можно использовать различные инструменты, такие как [Azure Storage Explorer.](https://storageexplorer.com/)

2. Создайте контейнер с именем **назначения.**

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. В области слева выберите **Создать ресурс**. Выберите **фабрику аналитических** > **данных:**

   ![Выберите фабрику данных](./media/doc-common-process/new-azure-data-factory-menu.png)

2. На странице **Новая фабрика данных** в поле **Имя** введите **ADFTutorialDataFactory**.

   Имя фабрики данных должно быть глобально уникальным. Вы можете получить сообщение об ошибке:

   ![Имя недоступное сообщение об ошибке](./media/doc-common-process/name-not-available-error.png)

   Если вы увидите следующую ошибку касательно значения имени, введите другое имя фабрики данных. Например,**_ваше_имя_****ADFTutorialDataFactory**. Правила именования артефактов службы "Фабрика данных" см. в [этой](naming-rules.md) статье.
3. Под **подпиской**выберите подписку Azure, в которой вы создадите новую фабрику данных.
4. В рамках **Группы ресурсов,** принять один из этих шагов:

    * Выберите **Использовать существующую,** а затем выберите существующую группу ресурсов в списке.

    * Выберите **Создать новое,** а затем введите имя для группы ресурсов.
         
    Сведения о группах ресурсов см. в статье [Общие сведения об Azure Resource Manager](../azure-resource-manager/management/overview.md).

5. В качестве **версии** выберите **V2**.
6. В качестве **расположения** выберите расположение фабрики данных. В списке отображаются только поддерживаемые места. Хранилища данных (например, база данных Azure Storage и Azure S'L) и вычисления (например, Azure HDInsight), которые использует фабрика данных, могут находиться в других местах и регионах.
8. Нажмите кнопку **создания**.
9. После создания фабрики данных появляется главная страница фабрики данных.
10. Чтобы открыть пользовательский интерфейс Azure Data Factory (UI) на отдельной вкладке, выберите плитку **Author & Monitor:**

    ![Домашняя страница фабрики данных](./media/doc-common-process/data-factory-home-page.png)

## <a name="use-the-copy-data-tool-to-create-a-pipeline"></a>Создание конвейера с помощью средства копирования данных

1. На странице **«Давайте начнем»** выберите плитку **Copy Data,** чтобы открыть инструмент Copy Data:

   ![Копирование плитки данных](./media/doc-common-process/get-started-page.png)

2. На странице **Properties** следующие шаги:

    а. Под **названием задачи**введите **DeltaCopyFromBlobPipeline**.

    b. В соответствии **с расписанием каденции задачи или задачами,** выберите **Выполнить регулярно по расписанию.**

    c. Под **типом триггера**выберите **окно Tumbling.**

    d. Под **повторением,** введите **15 минут (ы)**.

    д) Выберите **Далее**.

    Фабрика данных создает конвейер с указанным названием задачи.

    ![Копирование страницы свойств данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/copy-data-tool-properties-page.png)

3. На странице **хранилища данных Источника** выполните следующие действия:

    а. Выберите **Создать новое соединение** для добавления соединения.

    b. Выберите **Хранилище Azure Blob** из галереи, а затем выберите **Продолжить:**

    ![Выберите хранилище блогов Azure](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page-select-blob.png)

    c. На странице **New Linked Service (Azure Blob Storage)** выберите учетную запись хранения из списка **имен учетной записи хранилища.** Проверьте соединение, а затем выберите **Создать**.

    d. Выберите новую связанную услугу, а затем выберите **Следующий:**

   ![Выберите новую связанную службу](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page-select-linkedservice.png)

4. На странице **Choose the input file or folder** (Выбор входного файла или папки) выполните следующие действия:

    а. Просмотрите и выберите **исходную** папку, а затем выберите **Выберите.**

    ![Выбор файла или папки входных данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/choose-input-file-folder.png)

    b. Под **поведением загрузки файлов**выберите **инкрементную нагрузку: LastModifiedDate**.

    c. Выберите **двоичную копию,** а затем выберите **Следующую:**

     ![Выберите файл ввода или страницу папки](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/check-binary-copy.png)

5. На странице **хранилища данных Destination** выберите созданный вами сервис **AzureBlobStorage.** Это та же учетная запись хранения, что и хранилище исходных данных. Выберите **Далее**.

6. На странице **Choose the output file or folder** (Выбор целевого файла или папки) выполните следующие действия:

    а. Просмотрите папку **назначения** и выберите, а затем выберите **Выберите:**

    ![Выберите выходной файл или страницу папки](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/choose-output-file-folder.png)

    b. Выберите **Далее**.

7. На странице **Параметры** выберите **Далее**.

8. На странице **Резюме** просмотрите настройки, а затем выберите **следующий**.

    ![Страница "Сводка"](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/summary-page.png)

9. На **странице развертывания** выберите **Мониторинг**, чтобы отслеживать созданный конвейер (задачу).

    ![Страница развертывания](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/deployment-page.png)

10. Обратите внимание, что слева автоматически выбирается вкладка **Мониторинг**. Приложение переключается на вкладку **Монитор.** Вы видите состояние конвейера. Щелкните **Обновить**, чтобы обновить список. Выберите ссылку под **PIPELINE NAME** для просмотра сведений о запуске активности или повторного запуска конвейера.

    ![Обновление списка и просмотр сведений о запуске действий](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs1.png)

11. В конвейере есть только одно действие (активность копирования), так что вы видите только одну запись. Для получения подробной информации об операции копирования выберите **ссылку «Подробности»** (значок очков) в колонке **ACTIVITY NAME.** Подробную информацию о свойствах можно узнать [в обзоре активности Copy.](copy-activity-overview.md)

    ![Копирование активности в конвейере](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs2.png)

    Поскольку в исходном контейнере в учетной записи хранилища Blob нет файлов, вы не увидите никаких файлов, скопированных в контейнер назначения в учетной записи:

    ![Нет файлов в исходном контейнере или контейнере назначения](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs3.png)

12. Создайте пустой текстовый файл и назовите его **file1.txt.** Загрузите этот текстовый файл в исходный контейнер в учетной записи хранилища. Для выполнения этих задач можно использовать различные инструменты, такие как [Azure Storage Explorer.](https://storageexplorer.com/)

    ![Создайте file1.txt и загрузите его в исходный контейнер](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs3-1.png)

13. Чтобы вернуться к представлению **прогонов конвейера,** выберите **все запуски конвейеров**и дождитесь автоматического срабатывания одного и того же конвейера.  

    ![Выберите все прогона конвейера](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs4.png)

14. Когда второй запуск конвейера завершается, выполните те же шаги, которые упоминались ранее, чтобы просмотреть детали выполнения действия.  

    Вы увидите, что один файл (file1.txt) был скопирован из исходного контейнера в контейнер назначения вашей учетной записи хранения Blob:

    ![file1.txt был скопирован из исходного контейнера в контейнер назначения](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs6.png)

15. Создайте еще один пустой текстовый файл и назовите его **file2.txt.** Загрузите этот текстовый файл в исходный контейнер в вашей учетной записи хранения Blob.

16. Повторите шаги 13 и 14 для второго текстового файла. Вы увидите, что только новый файл (file2.txt) был скопирован из исходного контейнера в контейнер назначения вашей учетной записи хранения во время выполнения этого конвейера.  

    Вы также можете проверить, что только один файл был скопирован с помощью [Azure Storage Explorer](https://storageexplorer.com/) для сканирования файлов:

    ![Сканирование файлов с помощью Azure Storage Explorer](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs8.png)


## <a name="next-steps"></a>Дальнейшие действия
Перейдите к следующему учебнику, чтобы узнать, как преобразовывать данные с помощью кластера Apache Spark в Azure:

> [!div class="nextstepaction"]
>[Преобразование данных в облаке с помощью кластера Apache Spark](tutorial-transform-data-spark-portal.md)
