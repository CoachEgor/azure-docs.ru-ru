---
title: Добавочное копирование новых и измененных файлов, основанный на Дата последнего изменения с помощью средства копирования данных | Документация Майкрософт
description: Создание фабрики данных Azure и применение средства копирования данных для добавочной загрузки новых файлов в зависимости от Дата последнего изменения.
services: data-factory
documentationcenter: ''
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 1/24/2019
ms.openlocfilehash: 3865bb10346c4a55adbf94a7df225eacf2c11252
ms.sourcegitcommit: 17411cbf03c3fa3602e624e641099196769d718b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/10/2019
ms.locfileid: "65519134"
---
# <a name="incrementally-copy-new-and-changed-files-based-on-lastmodifieddate-by-using-the-copy-data-tool"></a>Добавочное копирование новых и измененных файлов, основанный на Дата последнего изменения с помощью средства копирования данных

В этом руководстве вы используете портал Azure для создания фабрики данных. Затем используем средства копирования данных для создания конвейера добавочного копирования только новые и измененные файлы на основе их **LastModifiedDate** из хранилища BLOB-объектов Azure в хранилище BLOB-объектов Azure.

Таким образом, ADF будет проверять все файлы из исходного хранилища, применить фильтр по их Дата последнего изменения файла и скопируйте новых и обновленных файлов только с момента последнего в целевое хранилище.  Обратите внимание на то, что если позволить ADF сканирования огромные объемы файлы, но только Копировать несколько файлов в место назначения, будет по-прежнему ожидается, что длительные из-за сканирование файлов занимает много времени, а также.   

> [!NOTE]
> Если вы еще не работали с фабрикой данных Azure, ознакомьтесь со статьей [Введение в фабрику данных Azure](introduction.md).

В этом руководстве выполняются следующие задачи:

> [!div class="checklist"]
> * Создали фабрику данных.
> * Создание конвейера с помощью средства копирования данных.
> * Мониторинг конвейера и выполнения действий.

## <a name="prerequisites"></a>Технические условия

* **Подписка Azure.** Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/) , прежде чем начинать работу.
* **Учетная запись хранения Azure.** Использование хранилища BLOB-объектов как _источника_ и _приемника_ хранилища данных. Если у вас нет учетной записи хранения Azure, см. инструкции по [ее созданию](../storage/common/storage-quickstart-create-account.md).

### <a name="create-two-containers-in-blob-storage"></a>Создание двух контейнеров в хранилище BLOB-объектов

Подготовьте хранилище больших двоичных объектов для работы с руководством, выполнив следующие действия.

1. Создайте контейнер с именем **источника**. Можно использовать различные инструменты для выполнения этой задачи, такие как [обозреватель службы хранилища Azure](https://storageexplorer.com/).

2. Создайте контейнер с именем **назначения**. 

## <a name="create-a-data-factory"></a>Создание фабрики данных

1. В меню слева выберите **Создать ресурс** > **Данные и аналитика** > **Фабрика данных**. 
   
   ![Выбор фабрики данных в области "Создать"](./media/quickstart-create-data-factory-portal/new-azure-data-factory-menu.png)

2. На странице **Новая фабрика данных** в поле **Имя** введите **ADFTutorialDataFactory**. 
      
     ![Новая фабрика данных](./media/tutorial-copy-data-tool/new-azure-data-factory.png)
 
   Имя фабрики данных должно быть _глобально уникальным_. Вы можете получить следующее сообщение об ошибке.
   
   ![Сообщение об ошибке фабрики данных](./media/tutorial-copy-data-tool/name-not-available-error.png)

   Если вы увидите следующую ошибку касательно значения имени, введите другое имя фабрики данных. Например, _**ваше_имя**_**ADFTutorialDataFactory**. Правила именования артефактов службы "Фабрика данных" см. в [этой](naming-rules.md) статье.
3. Выберите Azure **подписки** в которой создается новая фабрика данных. 
4. Для **группы ресурсов** выполните одно из следующих действий:
     
    * Выберите **Использовать существующий** и выберите существующую группу ресурсов из раскрывающегося списка.

    * Выберите **Создать** и введите имя группы ресурсов. 
         
    Сведения о группах ресурсов см. в статье [Общие сведения об Azure Resource Manager](../azure-resource-manager/resource-group-overview.md).

5. В разделе **версии**выберите **V2**.
6. В качестве **расположения** выберите расположение фабрики данных. В раскрывающемся списке отображаются только поддерживаемые расположения. Хранилища данных (например, служба хранилища Azure и базы данных SQL) и вычислительные ресурсы (например, Azure HDInsight), используемые фабрикой данных можно в других регионах или расположениях.
7. Кроме того, установите флажок **Закрепить на панели мониторинга**. 
8. Нажмите кнопку **Создать**.
9. На панели мониторинга см. **развертывание фабрики данных** плитку, чтобы просмотреть состояние процесса.

    ![Элемент Deploying Data Factory](media/tutorial-copy-data-tool/deploying-data-factory.png)
10. Когда создание завершится, откроется домашняя страница **Фабрика данных**.
   
    ![Домашняя страница фабрики данных](./media/tutorial-copy-data-tool/data-factory-home-page.png)
11. Чтобы открыть пользовательский интерфейс фабрики данных Azure (UI) на отдельной вкладке, выберите **Создание и мониторинг** плитку. 

## <a name="use-the-copy-data-tool-to-create-a-pipeline"></a>Создание конвейера с помощью средства копирования данных

1. На **приступим к работе** выберите **копирования данных** заголовок, чтобы открыть инструмент копирования данных. 

   ![Плитка средства копирования данных](./media/tutorial-copy-data-tool/copy-data-tool-tile.png)
   
2. На **свойства** странице, выполните следующие действия:

    a. В разделе **имя задачи**, введите **DeltaCopyFromBlobPipeline**.

    2. В разделе **периодичность задачи** или **расписании задач**выберите **регулярно запускаться по расписанию**.

    c. В разделе **тип триггера**выберите **"переворачивающегося" окна**.
    
    d. В разделе **повторения**, введите **15 мин**. 
    
    д. Щелкните **Далее**. 
    
    Пользовательский интерфейс фабрики данных создаст конвейер с указанным именем задачи. 

    ![Страница свойств](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/copy-data-tool-properties-page.png)
    
3. На странице **Исходное хранилище данных** сделайте следующее:

    a. Выберите **+ создать новое соединение**, чтобы добавить подключение.
    
    ![Страница исходного хранилища данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page.png)

    2. Выберите **хранилище BLOB-объектов** из коллекции, а затем выберите **Продолжить**.
    
    ![Страница исходного хранилища данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page-select-blob.png)

    c. На **новая связанная служба** выберите учетную запись хранения из **имя учетной записи хранения** перечисления и выбора **Готово**.
    
    ![Страница исходного хранилища данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page-linkedservice.png)
    
    d. Выберите только что созданную связанную службу, а затем выберите **Далее**. 
    
   ![Страница исходного хранилища данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/source-data-store-page-select-linkedservice.png)

4. На странице **Choose the input file or folder** (Выбор входного файла или папки) выполните следующие действия:
    
    a. Найдите и выберите **источника** папку, а затем выберите **Выбор**.
    
    ![Выбор файла или папки входных данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/choose-input-file-folder.png)
    
    2. В разделе **поведения при загрузке файла**выберите **добавочную загрузку: Дата последнего изменения**.
    
    ![Выбор файла или папки входных данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/choose-loading-behavior.png)
    
    c. Проверьте **двоичное копирование** и выберите **Далее**.
    
     ![Выбор файла или папки входных данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/check-binary-copy.png)
     
5. На **целевое хранилище данных** выберите **AzureBlobStorage**. Это той же учетной записи хранения источника данных. Затем нажмите кнопку **Далее**.

    ![Страница целевого хранилища данных](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/destination-data-store-page-select-linkedservice.png)
    
6. На странице **Choose the output file or folder** (Выбор целевого файла или папки) выполните следующие действия:
    
    a. Найдите и выберите **назначения** папку, а затем выберите **Выбор**.
    
    ![Выбор целевого файла или папки](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/choose-output-file-folder.png)
    
    2. Щелкните **Далее**.
    
     ![Выбор целевого файла или папки](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/click-next-after-output-folder.png)
    
7. На странице **Параметры** выберите **Далее**. 

    ![Страница «Параметры»](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/settings-page.png)
    
8. На **Сводка** странице просмотрите параметры и нажмите кнопку **Далее**.

    ![Страница "Сводка"](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/summary-page.png)
    
9. На **странице развертывания** выберите **Мониторинг**, чтобы отслеживать созданный конвейер (задачу).

    ![Страница развертывания](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/deployment-page.png)
    
10. Обратите внимание, что слева автоматически выбирается вкладка **Мониторинг**. В столбце **действий** отображаются ссылки для просмотра сведений о запусках действий и (или) повторного выполнения на конвейере. Выберите **обновить** обновите список и выберите **Просмотр выполнений действий** ссылку в **действия** столбца. 

    ![Обновите список и выберите Просмотр выполнений действий](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs1.png)

11. Есть только одно действие (действие копирования) в конвейере, поэтому вы увидите только одну запись. Чтобы увидеть сведения об операции копирования, щелкните ссылку **Сведения** (значок очков) в столбце **Действия**. 

    ![— Действия копирования в конвейере](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs2.png)
    
    Так как файл отсутствует в **источника** контейнер в вашей учетной записи хранения BLOB-объектов, вы не увидите любой файл, скопировать **назначения** контейнер в вашей учетной записи хранения BLOB-объектов.
    
    ![Нет файла в исходной или целевой контейнер](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs3.png)
    
12. Создайте пустой текстовый файл и назовите его **file1.txt**. Отправьте этот текстовый файл **источника** контейнер в вашей учетной записи хранения. Это можно сделать при помощи таких средств, как [обозреватель службы хранилища Azure](https://storageexplorer.com/).   

    ![Создать file1.txt и загрузить исходный контейнер](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs3-1.png)
    
13. Чтобы вернуться к **запусков конвейера** представление, выберите **все запуски конвейера**и дождитесь одном конвейере активироваться автоматически.  

    ![Выберите все запуски конвейера](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs4.png)

14. Выберите **просмотрите сведения о выполнении действия** для второго конвейера, выполнять, когда вы видите его. Затем просмотрите сведения в так же, как и для первого выполнения конвейера.  

    ![Выберите представление действие выполняется и просмотреть сведения](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs5.png)

    Будут, см. один файл (file1.txt) будет скопирован из **источника** контейнера для **назначения** контейнер учетной записи хранения BLOB-объектов.
    
    ![File1.txt был скопирован из контейнера-источника в целевой контейнер](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs6.png)
    
15. Создайте еще один пустой текстовый файл и назовите его **file2.txt**. Отправьте этот текстовый файл **источника** контейнер в вашей учетной записи хранения BLOB-объектов.   
    
16. Повторите шаги 13 и 14 для этой второй текстовый файл. Вы увидите, что только новый файл (file2.txt) был скопирован из **источника** контейнера для **назначения** контейнер учетной записи хранения запуска следующего конвейера.  
    
    ![File2.txt был скопирован из контейнера-источника в целевой контейнер](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs7.png)

    Это также можно проверить с помощью [обозреватель службы хранилища Azure](https://storageexplorer.com/) для проверки файлов.
    
    ![Проверять файлы, с помощью обозревателя хранилищ Azure](./media/tutorial-incremental-copy-lastmodified-copy-data-tool/monitor-pipeline-runs8.png)

    
## <a name="next-steps"></a>Дальнейшие действия
Перейдите к следующему руководству, чтобы узнать о преобразовании данных с помощью кластера Apache Spark в Azure:

> [!div class="nextstepaction"]
>[Преобразование данных в облаке с помощью кластера Apache Spark](tutorial-transform-data-spark-portal.md)