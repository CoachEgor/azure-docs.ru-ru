---
title: Копирование данных в Azure Data Lake Storage 1-го поколения или из него
description: Узнайте, как копировать данные из поддерживаемых исходных хранилищ данных в Azure Data Lake Store или из Data Lake Store в поддерживаемые приемники хранилищ с помощью фабрики данных.
services: data-factory
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/12/2020
ms.openlocfilehash: 50e88d43d159ba5ac8f7b6c196c9843faad9eaf1
ms.sourcegitcommit: 7b25c9981b52c385af77feb022825c1be6ff55bf
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/13/2020
ms.locfileid: "79246231"
---
# <a name="copy-data-to-or-from-azure-data-lake-storage-gen1-using-azure-data-factory"></a>Копирование данных в Azure Data Lake Storage 1-го поколения с помощью фабрики данных Azure или из нее

> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-azure-datalake-connector.md)
> * [Текущая версия](connector-azure-data-lake-store.md)

В этой статье описано, как копировать данные в Azure Data Lake Storage 1-го поколения и обратно. Дополнительные сведения о Фабрике данных Azure см. во [вводной статье](introduction.md).

## <a name="supported-capabilities"></a>Поддерживаемые возможности

Этот соединитель Azure Data Lake Storage 1-го поколения поддерживается для следующих действий:

- [Действие копирования](copy-activity-overview.md) с [поддерживаемой матрицей источника и приемника](copy-activity-overview.md) 
- [Поток данных сопоставления](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)
- [Удалить действие](delete-activity.md)

В частности, с помощью этого соединителя можно:

- Скопируйте файлы с помощью одного из следующих методов проверки подлинности: субъект-служба или управляемые удостоверения для ресурсов Azure.
- Скопируйте файлы как есть или Проанализируйте или создайте файлы с [поддерживаемыми форматами файлов и кодеками сжатия](supported-file-formats-and-compression-codecs.md).
- [Сохранять списки управления доступом](#preserve-acls-to-data-lake-storage-gen2) при копировании в Azure Data Lake Storage 2-го поколения.

> [!IMPORTANT]
> При копировании данных с помощью локальной среды выполнения интеграции Настройте корпоративный брандмауэр, чтобы разрешить исходящий трафик для `<ADLS account name>.azuredatalakestore.net` и `login.microsoftonline.com/<tenant>/oauth2/token` через порт 443. Последняя – это служба токенов безопасности Azure, с которой должна взаимодействовать среда выполнения интеграции для получения маркера доступа.

## <a name="get-started"></a>Начало работы

> [!TIP]
> Пошаговые инструкции по использованию соединителя Azure Data Lake Store см. в разделе [Загрузка данных в Azure Data Lake Store](load-azure-data-lake-store.md).

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

Следующие разделы содержат сведения о свойствах, которые используются для определения сущностей фабрики данных, относящихся к Azure Data Lake Store.

## <a name="linked-service-properties"></a>Свойства связанной службы

Для связанной службы Azure Data Lake Store поддерживаются следующие свойства:

| Свойство | Description | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства `type` следует задать значение **AzureDataLakeStore**. | Да |
| dataLakeStoreUri | Сведения об учетной записи Azure Data Lake Store. Эти данные принимают один из следующих форматов: `https://[accountname].azuredatalakestore.net/webhdfs/v1` или `adl://[accountname].azuredatalakestore.net/`. | Да |
| subscriptionId | Идентификатор подписки Azure, к которой принадлежит учетная запись Data Lake Store. | Необходимо для приемника |
| имя_группы_ресурсов | Имя группы ресурсов Azure, к которой принадлежит учетная запись Data Lake Store. | Необходимо для приемника |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду выполнения интеграции, если хранилище данных находится в частной сети. Если это свойство не указано, используется среда выполнения интеграции Azure по умолчанию. |нет |

### <a name="use-service-principal-authentication"></a>Использование аутентификации субъекта-службы

Чтобы использовать проверку подлинности субъекта-службы, выполните следующие действия.

1. Зарегистрируйте сущность приложения в Azure Active Directory и предоставьте ей доступ к Data Lake Store. Подробные инструкции см. в статье [Аутентификация между службами в Data Lake Store с помощью Azure Active Directory](../data-lake-store/data-lake-store-authenticate-using-active-directory.md). Запишите следующие значения, которые используются для определения связанной службы:

    - Идентификатор приложения
    - Ключ приложения
    - Идентификатор клиента

2. Предоставьте субъекту-службе соответствующее разрешение. См. примеры того, как разрешение работает в Data Lake Storage 1-го поколения из [контроля доступа в Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-access-control.md#common-scenarios-related-to-permissions).

    - **В качестве источника**: в **обозревателе данных** > **доступ**предоставьте по крайней мере разрешение на **выполнение** для всех исходящих папок, включая корневой каталог, а также разрешение на **Чтение** файлов для копирования. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Нет необходимости в контроле доступа на уровне учетной записи (IAM).
    - В **качестве приемника**: в **обозревателе данных** > **доступ**предоставьте по крайней мере разрешение на **выполнение** для всех исходящих папок, включая корневой каталог, а также разрешение на **запись** для папки приемника. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Если вы используете среду выполнения интеграции Azure для копирования (источник и приемник находятся в облаке), в IAM предоставьте по крайней мере роль **читателя** , чтобы фабрика данных определяла регион для Data Lake Store. Если вы хотите избежать этой роли IAM, явным образом [создайте среду выполнения интеграции Azure](create-azure-integration-runtime.md#create-azure-ir) с расположением Data Lake Store. Например, если Data Lake Store находится в Западной Европе, создайте среду выполнения интеграции Azure с параметром location, имеющим значение "Западная Европа". Свяжите их со связанной службой Data Lake Store, как показано в следующем примере.

Поддерживаются следующие свойства:

| Свойство | Description | Обязательно |
|:--- |:--- |:--- |
| servicePrincipalId | Укажите идентификатора клиента приложения. | Да |
| servicePrincipalKey | Укажите ключ приложения. Пометьте это поле как `SecureString`, чтобы безопасно хранить его в фабрике данных, или [добавьте ссылку на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). | Да |
| tenant | Укажите сведения о клиенте, такие как доменное имя или идентификатор клиента, в котором находится ваше приложение. Эти сведения можно получить, наведя указатель мыши на правый верхний угол страницы портала Azure. | Да |

**Пример**.

```json
{
    "name": "AzureDataLakeStoreLinkedService",
    "properties": {
        "type": "AzureDataLakeStore",
        "typeProperties": {
            "dataLakeStoreUri": "https://<accountname>.azuredatalakestore.net/webhdfs/v1",
            "servicePrincipalId": "<service principal id>",
            "servicePrincipalKey": {
                "type": "SecureString",
                "value": "<service principal key>"
            },
            "tenant": "<tenant info, e.g. microsoft.onmicrosoft.com>",
            "subscriptionId": "<subscription of ADLS>",
            "resourceGroupName": "<resource group of ADLS>"
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="managed-identity"></a> Использование аутентификации управляемых удостоверений для ресурсов Azure

Фабрика данных может быть связана с [управляемым удостоверением для ресурсов Azure](data-factory-service-identity.md), которое представляет эту фабрику данных. Вы можете напрямую использовать это управляемое удостоверение для проверки подлинности Data Lake Store, как и при использовании собственного субъекта-службы. Оно разрешает назначенной фабрике обращаться к данным и копировать их из службы Data Lake Store и в нее.

Чтобы использовать управляемые удостоверения для проверки подлинности ресурсов Azure, выполните следующие действия.

1. [Получите сведения об управляемом удостоверении фабрики данных](data-factory-service-identity.md#retrieve-managed-identity) , СКОПИРОВАВ значение идентификатора приложения удостоверения службы, созданного вместе с фабрикой.

2. Предоставьте управляемому удостоверению доступ к Data Lake Store. См. примеры того, как разрешение работает в Data Lake Storage 1-го поколения из [контроля доступа в Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-access-control.md#common-scenarios-related-to-permissions).

    - **В качестве источника**: в **обозревателе данных** > **доступ**предоставьте по крайней мере разрешение на **выполнение** для всех исходящих папок, включая корневой каталог, а также разрешение на **Чтение** файлов для копирования. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Нет необходимости в контроле доступа на уровне учетной записи (IAM).
    - В **качестве приемника**: в **обозревателе данных** > **доступ**предоставьте по крайней мере разрешение на **выполнение** для всех исходящих папок, включая корневой каталог, а также разрешение на **запись** для папки приемника. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Если вы используете среду выполнения интеграции Azure для копирования (источник и приемник находятся в облаке), в IAM предоставьте по крайней мере роль **читателя** , чтобы фабрика данных определяла регион для Data Lake Store. Если вы хотите избежать этой роли IAM, явным образом [создайте среду выполнения интеграции Azure](create-azure-integration-runtime.md#create-azure-ir) с расположением Data Lake Store. Свяжите их со связанной службой Data Lake Store, как показано в следующем примере.

В фабрике данных Azure не нужно указывать ничего, кроме общих сведений о Data Lake Store в связанной службе.

**Пример**.

```json
{
    "name": "AzureDataLakeStoreLinkedService",
    "properties": {
        "type": "AzureDataLakeStore",
        "typeProperties": {
            "dataLakeStoreUri": "https://<accountname>.azuredatalakestore.net/webhdfs/v1",
            "subscriptionId": "<subscription of ADLS>",
            "resourceGroupName": "<resource group of ADLS>"
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в статье о [наборах данных](concepts-datasets-linked-services.md). 

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Для Azure Data Lake Store Gen1 в параметрах `location` в наборе данных на основе формата поддерживаются следующие свойства:

| Свойство   | Description                                                  | Обязательно |
| ---------- | ------------------------------------------------------------ | -------- |
| type       | Свойство Type в разделе `location` в наборе данных должно иметь значение **азуредаталакесторелокатион**. | Да      |
| folderPath | Путь к папке. Если вы хотите использовать подстановочный знак для фильтрации папок, пропустите этот параметр и укажите его в параметрах источника действия. | нет       |
| fileName   | Имя файла в заданной folderPath. Если вы хотите использовать подстановочный знак для фильтрации файлов, пропустите этот параметр и укажите его в параметрах источника действия. | нет       |

**Пример**.

```json
{
    "name": "DelimitedTextDataset",
    "properties": {
        "type": "DelimitedText",
        "linkedServiceName": {
            "referenceName": "<ADLS Gen1 linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, auto retrieved during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureDataLakeStoreLocation",
                "folderPath": "root/folder/subfolder"
            },
            "columnDelimiter": ",",
            "quoteChar": "\"",
            "firstRowAsHeader": true,
            "compressionCodec": "gzip"
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, доступных для определения действий, см. в разделе [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). Этот раздел содержит список свойств, поддерживаемых источником и приемником Azure Data Lake Store.

### <a name="azure-data-lake-store-as-source"></a>Azure Data Lake Store в качестве источника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Следующие свойства поддерживаются для Azure Data Lake Store Gen1 в разделе Параметры `storeSettings` в источнике копирования на основе формата:

| Свойство                 | Description                                                  | Обязательно                                      |
| ------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| type                     | Свойство Type в разделе `storeSettings` должно иметь значение **азуредаталакесторереадсеттингс**. | Да                                           |
| рекурсивные                | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если параметру recursive присвоено значение true и приемник является хранилищем на основе файлов, пустая папка или подпапка не копируется или не создается в приемнике. Допустимые значения: **true** (по умолчанию) и **false**. | нет                                            |
| вилдкардфолдерпас       | Путь к папке с подстановочными знаками для фильтрации исходных папок. <br>Разрешенные подстановочные знаки `*` (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или escape-символ внутри. <br>Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | нет                                            |
| вилдкардфиленаме         | Имя файла с подстановочными знаками в заданной folderPath/Вилдкардфолдерпас для фильтрации исходных файлов. <br>Разрешенные подстановочные знаки `*` (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или escape-символ внутри. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Да, если `fileName` не указан в наборе данных |
| modifiedDatetimeStart    | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах диапазона времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime. | нет                                            |
| modifiedDatetimeEnd      | То же, что и выше.                                               | нет                                            |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу хранилища. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | нет                                            |

**Пример**.

```json
"activities":[
    {
        "name": "CopyFromADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<Delimited text input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "DelimitedTextSource",
                "formatSettings":{
                    "type": "DelimitedTextReadSettings",
                    "skipLineCount": 10
                },
                "storeSettings":{
                    "type": "AzureDataLakeStoreReadSettings",
                    "recursive": true,
                    "wildcardFolderPath": "myfolder*A",
                    "wildcardFileName": "*.csv"
                }
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="azure-data-lake-store-as-sink"></a>Azure Data Lake Store в качестве приемника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Для Azure Data Lake Store Gen1 в параметрах `storeSettings` в приемнике копирования на основе формата поддерживаются следующие свойства:

| Свойство                 | Description                                                  | Обязательно |
| ------------------------ | ------------------------------------------------------------ | -------- |
| type                     | Свойство Type в разделе `storeSettings` должно иметь значение **азуредаталакесторевритесеттингс**. | Да      |
| copyBehavior             | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | нет       |
| експиридатетиме | Указывает время окончания срока действия записанных файлов. Время применяется к времени в формате UTC в формате "2020-03-01T08:00:00Z". По умолчанию он имеет значение NULL, что означает, что срок действия записанных файлов никогда не истечет. | нет |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | нет       |

**Пример**.

```json
"activities":[
    {
        "name": "CopyToADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Parquet output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "ParquetSink",
                "storeSettings":{
                    "type": "AzureDataLakeStoreWriteSettings",
                    "copyBehavior": "PreserveHierarchy"
                }
            }
        }
    }
]
```

### <a name="folder-and-file-filter-examples"></a>Примеры фильтров папок и файлов

В этом разделе описываются результаты применения фильтров с подстановочными знаками к пути папки и имени файла.

| folderPath | fileName | рекурсивные | Структура исходной папки и результат фильтрации (извлекаются файлы, выделенные **полужирным** шрифтом)|
|:--- |:--- |:--- |:--- |
| `Folder*` | (Пусто, используйте значение по умолчанию) | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | (Пусто, используйте значение по умолчанию) | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл4.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |

### <a name="examples-of-behavior-of-the-copy-operation"></a>Примеры поведения операции копирования

В данном разделе описываются результаты выполнения операции копирования при использовании различных сочетаний значений `recursive` и `copyBehavior`.

| рекурсивные | copyBehavior | Структура папок источника | Результаты цели |
|:--- |:--- |:--- |:--- |
| Да |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая "Папка1" создается с такой же структурой, как и исходная папка:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 |
| Да |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл3"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл4"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл5" |
| Да |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;file1 + file2 + Файл3 + "Файл4" + "Файл5" содержимое объединяется в один файл с автоматически сформированным именем файла. |
| false |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |
| false |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |
| false |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;файлы file1 + file2 объединяются в один файл с автоматически созданным именем файла. автоматически созданное имя для "Файл1"<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |

## <a name="preserve-acls-to-data-lake-storage-gen2"></a>Сохранение списков управления доступом в Data Lake Storage 2-го поколения

>[!TIP]
>Инструкции по копированию данных из Azure Data Lake Storage 1-го поколения в Gen2 см. в статье [копирование данных из Azure Data Lake Storage 1-го поколения в Gen2 с помощью фабрики данных Azure](load-azure-data-lake-storage-gen2-from-gen1.md) .

Если требуется реплицировать списки управления доступом (ACL) вместе с файлами данных при обновлении с Data Lake Storage 1-го поколения до Data Lake Storage 2-го поколения, см. раздел [сохранение списков ACL из Data Lake Storage 1-го поколения](copy-activity-preserve-metadata.md#preserve-acls).

## <a name="mapping-data-flow-properties"></a>Сопоставление свойств потока данных

При преобразовании данных в потоке сопоставления данных можно считывать и записывать файлы из Azure Data Lake Storage 1-го поколения в формате JSON, Avro, разделенном тексте или Parquet. Дополнительные сведения см. в разделе Преобразование [источника](data-flow-source.md) и [Преобразование приемника](data-flow-sink.md) в функции потока данных сопоставления.

### <a name="source-transformation"></a>Преобразование источника

В преобразовании «источник» можно выполнять чтение из контейнера, папки или отдельного файла в Azure Data Lake Storage 1-го поколения. Вкладка **Параметры источника** позволяет управлять чтением файлов. 

![Параметры источника](media/data-flow/sourceOptions1.png "Параметры источника")

**Путь с подстановочными знаками:** Использование шаблона с подстановочными знаками даст указание потоку ADF перебрать каждую соответствующую папку и файл в одном преобразовании источника. Это эффективный способ обработки нескольких файлов в одном потоке. Добавьте несколько шаблонов сопоставления с подстановочными знаками с символом +, который появляется при наведении указателя мыши на существующий шаблон шаблона.

В исходном контейнере выберите ряд файлов, соответствующих шаблону. В наборе данных можно указать только контейнер. Путь к шаблону должен также включать путь к папке из корневой папки.

Примеры подстановочных знаков:

* ```*``` представляет любой набор символов
* ```**``` представляет рекурсивную вложенность каталога
* ```?``` заменяет один символ
* ```[]``` соответствует одному из символов в квадратных скобках

* ```/data/sales/**/*.csv``` получает все CSV-файлы в/Дата/Салес
* ```/data/sales/20??/**``` получает все файлы в 20 века
* ```/data/sales/2004/*/12/[XY]1?.csv``` получает все CSV-файлы в 2004 в декабре, начиная с префикса X или Y и заканчивая двузначным числом

**Корневой путь к разделу:** Если в источнике файлов имеются секционированные папки с форматом ```key=value``` (например, Year = 2019), то верхний уровень этого дерева папок секционирования можно назначить имени столбца в потоке данных потока.

Во-первых, задайте подстановочный знак, чтобы включить все пути, которые являются секционированными папками, а также конечные файлы, которые вы хотите прочитать.

![Параметры исходного файла секции](media/data-flow/partfile2.png "Параметр файла секционирования")

Для определения верхнего уровня структуры папок используйте параметр путь к корневому каталогу секции. При просмотре содержимого данных с помощью предварительного просмотра данных вы увидите, что ADF добавит разрешенные секции, найденные на каждом уровне папок.

![Корневой путь к разделу](media/data-flow/partfile1.png "Предварительный просмотр корневого пути к разделу")

**Список файлов:** Это набор файлов. Создайте текстовый файл, содержащий список файлов относительных путей для обработки. Наведите указатель на этот текстовый файл.

**Столбец для хранения имени файла:** Сохраните имя исходного файла в столбце данных. Введите имя нового столбца, чтобы сохранить строку имени файла.

**После завершения:** Выберите не выполнять никаких действий с исходным файлом после выполнения потока данных, удалите исходный файл или переместите исходный файл. Пути для перемещения являются относительными.

Чтобы переместить исходные файлы в другое расположение после обработки, сначала выберите "Переместить" для операции с файлом. Затем задайте каталог "from". Если вы не используете подстановочные знаки для своего пути, параметр "от" будет иметь ту же папку, что и исходная папка.

Если у вас есть исходный путь с подстановочным знаком, синтаксис будет выглядеть следующим образом:

```/data/sales/20??/**/*.csv```

Можно указать "от" в качестве

```/data/sales```

И "to" как

```/backup/priorSales```

В этом случае все файлы, источником которых является/дата/Салес, перемещаются в/Баккуп/приорсалес.

> [!NOTE]
> Операции с файлами выполняются только при запуске потока данных из запуска конвейера (Отладка или выполнение конвейера), в котором используется действие «выполнение потока данных» в конвейере. Операции с файлами *не* выполняются в режиме отладки потока данных.

**Фильтровать по дате последнего изменения:** Вы можете отфильтровать обрабатываемые файлы, указав диапазон дат последнего изменения. Все значения даты и времени указаны в формате UTC. 

### <a name="sink-properties"></a>Свойства приемника

В преобразовании приемника можно выполнять запись в контейнер или папку в Azure Data Lake Storage 1-го поколения. Вкладка **Параметры** позволяет управлять записью файлов.

![параметры приемника](media/data-flow/file-sink-settings.png "параметры приемника")

**Очистите папку:** Определяет, удаляется ли конечная папка перед записью данных.

**Параметр имени файла:** Определяет, как имена целевых файлов именуются в конечной папке. Параметры имени файла:
   * **По умолчанию**: разрешить Spark использовать имена файлов на основе параметров по умолчанию.
   * **Шаблон**: введите шаблон, который перечисляет выходные файлы для каждой секции. Например, **займы [n]. csv** будут создавать loans1. csv, loans2. csv и т. д.
   * **Для каждой секции**: введите одно имя файла для каждой секции.
   * **Как данные в столбце**: задайте для выходного файла значение столбца. Путь задается относительно контейнера набора данных, а не конечной папки.
   * **Вывод в один файл**: Объединение секционированных выходных файлов в один именованный файл. Путь задается относительно папки набора данных. Имейте в виду, что операция слияния с TE может завершиться сбоем в зависимости от размера узла. Этот параметр не рекомендуется для больших наборов данных.

**Цитата:** Определяет, следует ли заключать все значения в кавычки

## <a name="lookup-activity-properties"></a>Свойства действия поиска

Чтобы получить сведения о свойствах, проверьте [действие поиска](control-flow-lookup-activity.md).

## <a name="getmetadata-activity-properties"></a>Свойства действия с метаданными

Дополнительные сведения о свойствах см. в статье [действие с операциями](control-flow-get-metadata-activity.md) с помощью метаданных. 

## <a name="delete-activity-properties"></a>Свойства действия удаления

Чтобы получить сведения о свойствах, проверьте [действие Удалить](delete-activity.md) .

## <a name="legacy-models"></a>Устаревшие модели

>[!NOTE]
>Следующие модели по-прежнему поддерживаются "как есть" для обеспечения обратной совместимости. Рекомендуется использовать новую модель, упомянутую в разделах выше, и пользовательский интерфейс создания ADF переключился на создание новой модели.

### <a name="legacy-dataset-model"></a>Устаревшая модель набора данных

| Свойство | Description | Обязательно |
|:--- |:--- |:--- |
| type | Свойство Type набора данных должно иметь значение **AzureDataLakeStoreFile**. |Да |
| folderPath | Путь к папке в Data Lake Store. Если это свойство не указано, будет использоваться корневая папка. <br/><br/>Поддерживается фильтр с подстановочными знаками. Разрешенные подстановочные знаки `*` (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или escape-символ внутри. <br/><br/>Например: RootFolder/вложенная папка/. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). |нет |
| fileName | Имя или фильтр по шаблону для файлов с указанной "folderPath". Если этому свойству не присвоить значение, набор данных будет указывать на все файлы в папке. <br/><br/>Для фильтра разрешены подстановочные знаки `*` (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу).<br/>Пример 1. `"fileName": "*.csv"`<br/>Пример 2. `"fileName": "???20180427.txt"`<br/>Используйте `^` для экранирования, если фактическое имя файла имеет подстановочный знак или escape-символ внутри.<br/><br/>Если параметр fileName не указан для выходного набора данных, а **preserveHierarchy** не указан в приемнике действия, действие копирования автоматически создает имя файла со следующим форматом: "*Data. [ Идентификатор запуска действия GUID]. [GUID if FlattenHierarchy]. [Format, если настроено]. [compression, если он настроен]* ", например" Data. 0a405f8a-93ff-4c6f-b3be-f69616f1df7a. txt. gz ". При копировании из табличного источника с использованием имени таблицы вместо запроса используется шаблон имени " *[имя таблицы]. [ format]. [compression, если он настроен]* ", например" MyTable. csv ". |нет |
| modifiedDatetimeStart | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах диапазона времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра влияет на общую производительность перемещения данных, если требуется использовать фильтр файлов с огромным объемом файлов. <br/><br/> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime.| нет |
| modifiedDatetimeEnd | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах диапазона времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра влияет на общую производительность перемещения данных, если требуется использовать фильтр файлов с огромным объемом файлов. <br/><br/> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime.| нет |
| format | Если требуется копировать файлы между хранилищами на основе файлов (двоичное копирование), пропустите раздел Format в определениях входного и выходного наборов данных.<br/><br/>Если нужно проанализировать или создать файлы определенного формата, поддерживаются следующие типы форматов файлов: **TextFormat**, **JsonFormat**, **AvroFormat**, **OrcFormat** и **ParquetFormat**. Свойству **type** в разделе **format** необходимо присвоить одно из этих значений. Дополнительные сведения см. в разделах о [текстовом формате](supported-file-formats-and-compression-codecs-legacy.md#text-format), [формате JSON](supported-file-formats-and-compression-codecs-legacy.md#json-format), [формате Avro](supported-file-formats-and-compression-codecs-legacy.md#avro-format), [формате Orc](supported-file-formats-and-compression-codecs-legacy.md#orc-format) и [формате Parquet](supported-file-formats-and-compression-codecs-legacy.md#parquet-format). |Нет (только для сценария двоичного копирования) |
| compression | Укажите тип и уровень сжатия данных. Дополнительные сведения см. в разделе [Поддержка сжатия](supported-file-formats-and-compression-codecs-legacy.md#compression-support).<br/>Поддерживаемые типы: **GZip**, **Deflate**, **BZip2** и **ZipDeflate**.<br/>Поддерживаемые уровни: **Optimal** и **Fastest**. |нет |

>[!TIP]
>Чтобы скопировать все файлы в папке, укажите только **folderPath**.<br>Чтобы скопировать отдельный файл с определенным именем, укажите параметр **FolderPath** с именем файла **, который является** частью папки.<br>Чтобы скопировать подмножество файлов в папке, укажите параметр **FolderPath** с частью папки и **именем файла** с фильтром с подстановочными знаками. 

**Пример**.

```json
{
    "name": "ADLSDataset",
    "properties": {
        "type": "AzureDataLakeStoreFile",
        "linkedServiceName":{
            "referenceName": "<ADLS linked service name>",
            "type": "LinkedServiceReference"
        },
        "typeProperties": {
            "folderPath": "datalake/myfolder/",
            "fileName": "*",
            "modifiedDatetimeStart": "2018-12-01T05:00:00Z",
            "modifiedDatetimeEnd": "2018-12-01T06:00:00Z",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ",",
                "rowDelimiter": "\n"
            },
            "compression": {
                "type": "GZip",
                "level": "Optimal"
            }
        }
    }
}
```

### <a name="legacy-copy-activity-source-model"></a>Исходная модель действия копирования прежних версий

| Свойство | Description | Обязательно |
|:--- |:--- |:--- |
| type | Свойство `type` источника действия копирования должно иметь значение **AzureDataLakeStoreSource**. |Да |
| рекурсивные | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если для `recursive` задано значение true и приемник является хранилищем на основе файлов, пустая папка или подпапка не копируется и не создается в приемнике. Допустимые значения: **true** (по умолчанию) и **false**. | нет |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | нет |

**Пример**.

```json
"activities":[
    {
        "name": "CopyFromADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<ADLS Gen1 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "AzureDataLakeStoreSource",
                "recursive": true
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="legacy-copy-activity-sink-model"></a>Модель приемника действия копирования прежних версий

| Свойство | Description | Обязательно |
|:--- |:--- |:--- |
| type | Свойство `type` приемника действия копирования должно иметь значение **AzureDataLakeStoreSink**. |Да |
| copyBehavior | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае имя файла создается автоматически. | нет |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | нет |

**Пример**.

```json
"activities":[
    {
        "name": "CopyToADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<ADLS Gen1 output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "AzureDataLakeStoreSink",
                "copyBehavior": "PreserveHierarchy"
            }
        }
    }
]
```

## <a name="next-steps"></a>Дальнейшие действия

В таблице [Поддерживаемые хранилища данных](copy-activity-overview.md#supported-data-stores-and-formats) приведен список хранилищ данных, которые поддерживаются в качестве источников и приемников для действия копирования в фабрике данных Azure.
