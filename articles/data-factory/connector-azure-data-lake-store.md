---
title: Копирование данных и из него Gen1 хранилища Озера данных Azure с помощью фабрики данных | Документация Майкрософт
description: Узнайте, как копировать данные из поддерживаемых исходных хранилищ данных в Azure Data Lake Store или из Data Lake Store в поддерживаемые приемники хранилищ с помощью фабрики данных.
services: data-factory
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: ''
ms.devlang: ''
ms.topic: conceptual
ms.date: 07/02/2019
ms.author: jingwang
ms.openlocfilehash: df88c3e2e07165182c917eaf30a5f37451fbd073
ms.sourcegitcommit: 79496a96e8bd064e951004d474f05e26bada6fa0
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2019
ms.locfileid: "67509581"
---
# <a name="copy-data-to-or-from-azure-data-lake-storage-gen1-using-azure-data-factory"></a>Копирование данных и из него Gen1 хранилища Озера данных Azure с помощью фабрики данных Azure
> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-azure-datalake-connector.md)
> * [Текущая версия](connector-azure-data-lake-store.md)

В этой статье описывается, как копировать данные из Gen1 хранилища Озера данных Azure. Дополнительные сведения о Фабрике данных Azure см. во [вводной статье](introduction.md).

## <a name="supported-capabilities"></a>Поддерживаемые возможности

Этот соединитель Gen1 хранилища Озера данных Azure поддерживается для следующих действий:

- [Действие копирования](copy-activity-overview.md) с [поддерживается источника или приемника матрицы](copy-activity-overview.md)
- [Процесс сопоставления данных](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)

В частности, с помощью этого соединителя можно:

- Скопируйте файлы с помощью одного из следующих методов проверки подлинности: участника или управляемых удостоверений для ресурсов Azure службы.
- Скопируйте файлы как есть или проанализировать или создать файлы [поддерживаемых форматов файлов и кодеков сжатия](supported-file-formats-and-compression-codecs.md).

> [!IMPORTANT]
> При копировании данных с использованием среды выполнения интеграции, настройте корпоративный брандмауэр, чтобы разрешить исходящий трафик `<ADLS account name>.azuredatalakestore.net` и `login.microsoftonline.com/<tenant>/oauth2/token` через порт 443. Последняя – это служба токенов безопасности Azure, с которой должна взаимодействовать среда выполнения интеграции для получения маркера доступа.

## <a name="get-started"></a>Начало работы

> [!TIP]
> Пошаговые инструкции по того, как использовать соединитель Azure Data Lake Store, см. в разделе [загрузка данных в Azure Data Lake Store](load-azure-data-lake-store.md).

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

Следующие разделы содержат сведения о свойствах, которые используются для определения сущностей фабрики данных, относящихся к Azure Data Lake Store.

## <a name="linked-service-properties"></a>Свойства связанной службы

Для связанной службы Azure Data Lake Store поддерживаются следующие свойства:

| Свойство | ОПИСАНИЕ | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Для свойства `type` следует задать значение **AzureDataLakeStore**. | Yes |
| dataLakeStoreUri | Сведения об учетной записи Azure Data Lake Store. Эти данные принимают один из следующих форматов: `https://[accountname].azuredatalakestore.net/webhdfs/v1` или `adl://[accountname].azuredatalakestore.net/`. | Yes |
| subscriptionId | Идентификатор подписки Azure, к которой принадлежит учетная запись Data Lake Store. | Необходимо для приемника |
| resourceGroupName | Имя группы ресурсов Azure, к которой принадлежит учетная запись Data Lake Store. | Необходимо для приемника |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Если хранилище данных находится в частной сети можно использовать среду выполнения интеграции Azure или локальную среду выполнения интеграции. Если это свойство не задано, используется среда выполнения интеграции Azure по умолчанию. |Нет |

### <a name="use-service-principal-authentication"></a>Использование аутентификации субъекта-службы

При использовании проверки подлинности на основе субъекта-службы необходимо зарегистрировать сущность приложения в Azure Active Directory и предоставить ей доступ к Data Lake Store. Подробные инструкции см. в статье [Аутентификация между службами в Data Lake Store с помощью Azure Active Directory](../data-lake-store/data-lake-store-authenticate-using-active-directory.md). Запишите следующие значения, которые используются для определения связанной службы:

- Идентификатор приложения
- Ключ приложения
- Tenant ID

>[!IMPORTANT]
> Предоставьте разрешение субъекта-службы правильной в Data Lake Store:
>- **В качестве источника**. Выбрав **Обозреватель данных** > **Доступ**, назначьте как минимум разрешение **Чтение и выполнение** для просмотра и копирования файлов в папках и подпапках. Можно также предоставить разрешение **Чтения** для копирования одного файла. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Нет необходимости в элементе управления доступом на уровне учетной записи (IAM).
>- **В качестве приемника**. Выбрав **Обозреватель данных** > **Доступ**, предоставьте по крайней мере разрешение **Запись и выполнение** для создания дочерних элементов в папке. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. При использовании среды выполнения интеграции Azure для копирования (источник и приемник находятся в облаке), в IAM, предоставлять по крайней мере **чтения** роли, чтобы фабрика данных смогла определить регион Data Lake Store. Если вы хотите избежать этой роли IAM, явным образом [создайте среду выполнения интеграции Azure](create-azure-integration-runtime.md#create-azure-ir) с расположением Data Lake Store. Например если ваш Data Lake Store в Западной Европе, создание среды выполнения интеграции Azure с расположением, равным «Западная Европа». Свяжите их в Data Lake Store связанной службы, как показано в следующем примере.

>[!NOTE]
>Для отображения папок, начиная с корня, необходимо задать разрешения для субъекта-службы, которое предоставляется **на корневом уровне с разрешением "Выполнение"** . Это работает, если вы используете:
>- **Средство копирования данных** конвейер копирования автора.
>- **пользовательский интерфейс фабрики данных** для проверки подключения и перемещения по папкам во время разработки.
>Если у вас возникли вопросы о предоставлении разрешения на корневом уровне, во время разработки, пропустите тестирования подключения и ввод данных paraent пути с предоставлено разрешение, затем выберите для просмотра из указанного пути. Скопируйте works действия до тех пор, пока участнику службы предоставляется с предоставлено правильное разрешение в файлы для копирования.

Поддерживаются следующие свойства:

| Свойство | ОПИСАНИЕ | Обязательно для заполнения |
|:--- |:--- |:--- |
| servicePrincipalId | Укажите идентификатора клиента приложения. | Да |
| servicePrincipalKey | Укажите ключ приложения. Пометьте это поле как `SecureString`, чтобы безопасно хранить его в фабрике данных, или [добавьте ссылку на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). | Yes |
| tenant | Укажите информацию о клиенте, такие как доменное имя или идентификатор, на котором размещается приложение клиента. Эти сведения можно получить, наведя указатель мыши на правый верхний угол страницы портала Azure. | Yes |

**Пример.**

```json
{
    "name": "AzureDataLakeStoreLinkedService",
    "properties": {
        "type": "AzureDataLakeStore",
        "typeProperties": {
            "dataLakeStoreUri": "https://<accountname>.azuredatalakestore.net/webhdfs/v1",
            "servicePrincipalId": "<service principal id>",
            "servicePrincipalKey": {
                "type": "SecureString",
                "value": "<service principal key>"
            },
            "tenant": "<tenant info, e.g. microsoft.onmicrosoft.com>",
            "subscriptionId": "<subscription of ADLS>",
            "resourceGroupName": "<resource group of ADLS>"
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="managed-identity"></a> Использование аутентификации управляемых удостоверений для ресурсов Azure

Фабрика данных может быть связана с [управляемым удостоверением для ресурсов Azure](data-factory-service-identity.md), которое представляет эту фабрику данных. Можно напрямую использовать это управляемое удостоверение для проверки подлинности Data Lake Store, аналогичны использованию субъекта-службы. Оно разрешает назначенной фабрике обращаться к данным и копировать их из службы Data Lake Store и в нее.

Использование аутентификации управляемых удостоверений для ресурсов Azure.

1. [Получить сведения об удостоверениях управляемых фабрики данных](data-factory-service-identity.md#retrieve-managed-identity) путем копирования значения «идентификатор приложения удостоверения службы» созданного вместе с фабрикой.
2. Предоставьте доступ управляемое удостоверение для Data Lake Store, так же, как и для субъекта-службы, выполнив эти заметки.

>[!IMPORTANT]
> Убедитесь, что данные фабрики управляемых удостоверений предоставлено правильное разрешение в Data Lake Store:
>- **В качестве источника**. Выбрав **Обозреватель данных** > **Доступ**, назначьте как минимум разрешение **Чтение и выполнение** для просмотра и копирования файлов в папках и подпапках. Можно также предоставить разрешение **Чтения** для копирования одного файла. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. Нет необходимости в элементе управления доступом на уровне учетной записи (IAM).
>- **В качестве приемника**. Выбрав **Обозреватель данных** > **Доступ**, предоставьте по крайней мере разрешение **Запись и выполнение** для создания дочерних элементов в папке. Вы можете выбрать добавление в **эту папку и все дочерние элементы** для свойства recursive и добавить в качестве **записи разрешения доступа и записи разрешения по умолчанию**. При использовании среды выполнения интеграции Azure для копирования (источник и приемник находятся в облаке), в IAM, предоставлять по крайней мере **чтения** роли, чтобы фабрика данных смогла определить регион Data Lake Store. Если вы хотите избежать этой роли IAM, явным образом [создайте среду выполнения интеграции Azure](create-azure-integration-runtime.md#create-azure-ir) с расположением Data Lake Store. Свяжите их в Data Lake Store связанной службы, как показано в следующем примере.

>[!NOTE]
>Список папок, начиная от корня, необходимо задать разрешения управляемое удостоверение, которое предоставляется **на корневом уровне с разрешением «Execute»** . Это работает, если вы используете:
>- **Средство копирования данных** конвейер копирования автора.
>- **пользовательский интерфейс фабрики данных** для проверки подключения и перемещения по папкам во время разработки.
>Если у вас возникли вопросы о предоставлении разрешения на корневом уровне, во время разработки, пропустите тестирования подключения и ввод данных выберите родительский путь с предоставлено разрешение для просмотра из указанного пути. Скопируйте works действия до тех пор, пока участнику службы предоставляется с предоставлено правильное разрешение в файлы для копирования.

В фабрике данных Azure не нужно указывать ничего, кроме общих сведений о Data Lake Store в связанной службе.

**Пример.**

```json
{
    "name": "AzureDataLakeStoreLinkedService",
    "properties": {
        "type": "AzureDataLakeStore",
        "typeProperties": {
            "dataLakeStoreUri": "https://<accountname>.azuredatalakestore.net/webhdfs/v1",
            "subscriptionId": "<subscription of ADLS>",
            "resourceGroupName": "<resource group of ADLS>"
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в статье о [наборах данных](concepts-datasets-linked-services.md). 

- Parquet и текстовый формат с разделителями, см. в разделе [Parquet и текстовый файл с разделителями, формат набора данных](#parquet-and-delimited-text-format-dataset) раздел.
- Для других форматов, например ORC, Avro, JSON или двоичном формате, см. в разделе [другой набор данных в формате](#other-format-dataset) раздел.

### <a name="parquet-and-delimited-text-format-dataset"></a>Parquet и набор данных формат с разделителями

Чтобы скопировать данные в и из Azure Data Lake Store Gen1 в parquet или формат текста с разделителями, см. в разделе [формат Parquet](format-parquet.md) и [текстовый формат с разделителями](format-delimited-text.md) статьи на основе формат набора данных и поддерживаемых параметров. Следующие свойства поддерживаются для Azure Data Lake Store поколение 1 в разделе `location` параметры в наборе данных на основе формата:

| Свойство   | ОПИСАНИЕ                                                  | Обязательно для заполнения |
| ---------- | ------------------------------------------------------------ | -------- |
| type       | Свойство типа в списке `location` в наборе данных должно быть присвоено **AzureDataLakeStoreLocation**. | Да      |
| folderPath | Путь к папке. Если вы хотите использовать подстановочные знаки для фильтрации папок, пропустите этот параметр и укажите его в параметрах исходного действия. | Нет       |
| fileName   | Имя файла, в разделе данной folderPath. Если вы хотите использовать подстановочные знаки для фильтрации файлов, пропустите этот параметр и указать его в параметрах исходного действия. | Нет       |

> [!NOTE]
>
> **AzureDataLakeStoreFile** типа набора данных в формате parquet или текст, описанные в следующем разделе по-прежнему поддерживается, так как для копирования, поиска и действие GetMetadata для обеспечения обратной совместимости. Но он не работает с функцией сопоставления данных потока. Мы рекомендуем использовать эту новую модель, в дальнейшем. Создание пользовательского интерфейса фабрики данных создает эти новые типы.

**Пример.**

```json
{
    "name": "DelimitedTextDataset",
    "properties": {
        "type": "DelimitedText",
        "linkedServiceName": {
            "referenceName": "<ADLS Gen1 linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, auto retrieved during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureDataLakeStoreLocation",
                "folderPath": "root/folder/subfolder"
            },
            "columnDelimiter": ",",
            "quoteChar": "\"",
            "firstRowAsHeader": true,
            "compressionCodec": "gzip"
        }
    }
}
```

### <a name="other-format-dataset"></a>Другой набор данных в формате

Чтобы копировать данные из Azure Data Lake Store Gen1 в ORC, Avro, JSON или двоичном формате, поддерживаются следующие свойства:

| Свойство | ОПИСАНИЕ | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Свойство type набора данных должно быть присвоено **AzureDataLakeStoreFile**. |Да |
| folderPath | Путь к папке в Data Lake Store. Если это свойство не указано, будет использоваться корневая папка. <br/><br/>Фильтр с подстановочными знаками поддерживается. Допустимые подстановочные знаки `*` (совпадает с нуля или более символов) и `?` (выделяет ноль или один символ). Используйте `^` для экранирования, если имя фактические папки содержит подстановочный знак или этот символ внутри. <br/><br/>Например: rootfolder/subfolder /. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). |Нет |
| fileName | Имя или подстановочный знак, фильтр для файлов в указанной folderPath. Если этому свойству не присвоить значение, набор данных будет указывать на все файлы в папке. <br/><br/>Для фильтра, будут разрешены подстановочные знаки `*` (совпадает с нуля или более символов) и `?` (выделяет ноль или один символ).<br/>Пример 1. `"fileName": "*.csv"`<br/>Пример 2. `"fileName": "???20180427.txt"`<br/>Используйте `^` для экранирования, если имя фактического файла содержит подстановочные знаки или этот символ внутри.<br/><br/>Если fileName для выходного набора данных не указан, а **preserveHierarchy** не указан в приемнике действия, действие копирования автоматически создаст имя файла по следующему шаблону: "*Данных. [действие выполняется, идентификатор GUID]. [Идентификатор GUID Если FlattenHierarchy]. [формат, если настроен]. [сжатие, если настроен]* «, например «Data.0a405f8a-93ff-4c6f-b3be-f69616f1df7a.txt.gz». При копировании из табличного источника с помощью имени таблицы вместо запроса, шаблон имени — " *[Имя_таблицы]. [ Format]. [сжатие, если настроен]* «, например «MyTable.csv». |Нет |
| modifiedDatetimeStart | Фильтр файлов, на основе атрибута последнее изменение. Файлы выбираются, если их время последнего изменения в течение интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется часовой пояс UTC в формате «2018-12-01T05:00:00Z». <br/><br/> При включении этого параметра, если хотите сохранить фильтр с огромные объемы файлы снижается общая производительность перемещения данных. <br/><br/> Свойства могут иметь значение NULL, это означает, что фильтр атрибутов не файл применяется к набору данных. Когда `modifiedDatetimeStart` имеет значение даты и времени, но `modifiedDatetimeEnd` имеет значение NULL, значит, последний измененный атрибут больше, чем файлы или значение даты и времени, равным выбраны. Когда `modifiedDatetimeEnd` имеет значение даты и времени, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, последний измененный, атрибут которого меньше, чем значение даты и времени.| Нет |
| modifiedDatetimeEnd | Фильтр файлов, на основе атрибута последнее изменение. Файлы выбираются, если их время последнего изменения в течение интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется часовой пояс UTC в формате «2018-12-01T05:00:00Z». <br/><br/> При включении этого параметра, если хотите сохранить фильтр с огромные объемы файлы снижается общая производительность перемещения данных. <br/><br/> Свойства могут иметь значение NULL, это означает, что фильтр атрибутов не файл применяется к набору данных. Когда `modifiedDatetimeStart` имеет значение даты и времени, но `modifiedDatetimeEnd` имеет значение NULL, значит, последний измененный атрибут больше, чем файлы или значение даты и времени, равным выбраны. Когда `modifiedDatetimeEnd` имеет значение даты и времени, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, последний измененный, атрибут которого меньше, чем значение даты и времени.| Нет |
| format | Если вы хотите скопировать файлы между файловыми хранилищами (двоичное копирование), можно пропустите раздел форматирования в определениях входного и выходного наборов данных.<br/><br/>Если необходимо проанализировать или создать файлы определенного формата, поддерживаются следующие форматы файлов: **TextFormat**, **JsonFormat**, **AvroFormat**, **OrcFormat** и **ParquetFormat**. Свойству **type** в разделе **format** необходимо присвоить одно из этих значений. Дополнительные сведения см. в разделах о [текстовом формате](supported-file-formats-and-compression-codecs.md#text-format), [формате JSON](supported-file-formats-and-compression-codecs.md#json-format), [формате Avro](supported-file-formats-and-compression-codecs.md#avro-format), [формате Orc](supported-file-formats-and-compression-codecs.md#orc-format) и [формате Parquet](supported-file-formats-and-compression-codecs.md#parquet-format). |Нет (только для сценария двоичного копирования) |
| compression | Укажите тип и уровень сжатия данных. Дополнительные сведения см. в разделе [Поддержка сжатия](supported-file-formats-and-compression-codecs.md#compression-support).<br/>Поддерживаемые типы: **GZip**, **Deflate**, **BZip2** и **ZipDeflate**.<br/>Поддерживаемые уровни: **Optimal** и **Fastest**. |Нет |


>[!TIP]
>Чтобы скопировать все файлы в папке, укажите только **folderPath**.<br>Чтобы скопировать один файл с определенным именем, укажите **folderPath** с частью папки и **fileName** с именем файла.<br>Чтобы скопировать подмножество файлов в папке, укажите **folderPath** с частью папки и **fileName** с фильтр с подстановочными знаками. 

**Пример.**

```json
{
    "name": "ADLSDataset",
    "properties": {
        "type": "AzureDataLakeStoreFile",
        "linkedServiceName":{
            "referenceName": "<ADLS linked service name>",
            "type": "LinkedServiceReference"
        },
        "typeProperties": {
            "folderPath": "datalake/myfolder/",
            "fileName": "*",
            "modifiedDatetimeStart": "2018-12-01T05:00:00Z",
            "modifiedDatetimeEnd": "2018-12-01T06:00:00Z",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ",",
                "rowDelimiter": "\n"
            },
            "compression": {
                "type": "GZip",
                "level": "Optimal"
            }
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, доступных для определения действий, см. в разделе [Конвейеры и действия в фабрике данных Azure](concepts-pipelines-activities.md). Этот раздел содержит список свойств, поддерживаемых источником и приемником Azure Data Lake Store.

### <a name="azure-data-lake-store-as-source"></a>Azure Data Lake Store в качестве источника

- Чтобы копировать из parquet или формат текста с разделителями, см. в разделе [Parquet и исходный формат с разделителями](#parquet-and-delimited-text-format-source) раздел.
- Чтобы копировать из других форматов, например ORC, Avro, JSON или двоичном формате, см. в разделе [другого формата источника](#other-format-source) раздел.

#### <a name="parquet-and-delimited-text-format-source"></a>Parquet и исходный формат с разделителями

Чтобы скопировать данные из Azure Data Lake Store Gen1 в parquet или формат текста с разделителями, см. в разделе [формат Parquet](format-parquet.md) и [текстовый формат с разделителями](format-delimited-text.md) статьи о источника действия копирования на основе формата и поддерживаемых параметров. Следующие свойства поддерживаются для Azure Data Lake Store поколение 1 в разделе `storeSettings` параметры источника копирования на основе формата:

| Свойство                 | ОПИСАНИЕ                                                  | Обязательно для заполнения                                      |
| ------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| type                     | Свойство типа в списке `storeSettings` должно быть присвоено **AzureDataLakeStoreReadSetting**. | Yes                                           |
| recursive                | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если recursive задано значение true и приемником является файловое хранилище, пустые папки и подпапки не копируется или создаются в приемнике. Допустимые значения: **true** (по умолчанию) и **false**. | Нет                                            |
| wildcardFolderPath       | Путь к папке с использованием подстановочных знаков для фильтрации исходных папках. <br>Допустимые подстановочные знаки `*` (совпадает с нуля или более символов) и `?` (выделяет ноль или один символ). Используйте `^` для экранирования, если имя фактические папки содержит подстановочный знак или этот символ внутри. <br>Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Нет                                            |
| wildcardFileName         | Имя файла с использованием подстановочных знаков в заданной folderPath/wildcardFolderPath к исходным файлам фильтра. <br>Допустимые подстановочные знаки `*` (совпадает с нуля или более символов) и `?` (выделяет ноль или один символ). Используйте `^` для экранирования, если имя фактические папки содержит подстановочный знак или этот символ внутри. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Да, в том случае, если `fileName` не указан в наборе данных |
| modifiedDatetimeStart    | Фильтр файлов, на основе атрибута последнее изменение. Файлы выбираются, если их время последнего изменения в течение интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется часовой пояс UTC в формате «2018-12-01T05:00:00Z». <br> Свойства могут иметь значение NULL, это означает, что фильтр атрибутов не файл применяется к набору данных. Когда `modifiedDatetimeStart` имеет значение даты и времени, но `modifiedDatetimeEnd` имеет значение NULL, значит, последний измененный атрибут больше, чем файлы или значение даты и времени, равным выбраны. Когда `modifiedDatetimeEnd` имеет значение даты и времени, но `modifiedDatetimeStart` имеет значение NULL, это означает, что выбраны файлы, последний измененный, атрибут которого меньше, чем значение даты и времени. | Нет                                            |
| modifiedDatetimeEnd      | То же, что и выше.                                               | Нет                                            |
| maxConcurrentConnections | Число подключений для подключения к хранилищу хранилища, одновременно. Укажите только в том случае, если вы хотите ограничить максимальное количество одновременных подключений к хранилищу данных. | Нет                                            |

> [!NOTE]
> Parquet или текстовый формат с разделителями **AzureDataLakeStoreSource** источника действия копирования типа, описанные в следующем разделе по-прежнему поддерживается, так как для обеспечения обратной совместимости. Мы рекомендуем использовать эту новую модель, в дальнейшем. Создание пользовательского интерфейса фабрики данных создает эти новые типы.

**Пример.**

```json
"activities":[
    {
        "name": "CopyFromADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<Delimited text input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "DelimitedTextSource",
                "formatSettings":{
                    "type": "DelimitedTextReadSetting",
                    "skipLineCount": 10
                },
                "storeSettings":{
                    "type": "AzureDataLakeStoreReadSetting",
                    "recursive": true,
                    "wildcardFolderPath": "myfolder*A",
                    "wildcardFileName": "*.csv"
                }
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

#### <a name="other-format-source"></a>Другой источник формат

Чтобы скопировать данные из Azure Data Lake Store Gen1 в ORC, Avro, JSON или двоичном формате, поддерживаются следующие свойства в действии копирования **источника** раздел:

| Свойство | ОПИСАНИЕ | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | `type` Свойство источника действия копирования должно быть присвоено **AzureDataLakeStoreSource**. |Да |
| recursive | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Когда `recursive` имеет значение true, а приемником является файловое хранилище, пустую папку или вложенную папку не копируется или создаются в приемнике. Допустимые значения: **true** (по умолчанию) и **false**. | Нет |
| maxConcurrentConnections | Число подключений для подключения к хранилищу данных, одновременно. Укажите только в том случае, если вы хотите ограничить максимальное количество одновременных подключений к хранилищу данных. | Нет |

**Пример.**

```json
"activities":[
    {
        "name": "CopyFromADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<ADLS Gen1 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "AzureDataLakeStoreSource",
                "recursive": true
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="azure-data-lake-store-as-sink"></a>Azure Data Lake Store в качестве приемника

- Чтобы скопировать parquet и текстовый формат с разделителями, см. в разделе [Parquet и приемником формат с разделителями](#parquet-and-delimited-text-format-sink) раздел.
- Чтобы скопировать в другие форматы, такие как ORC, Avro, JSON или двоичном формате, см. в разделе [других приемника формат](#other-format-sink) раздел.

#### <a name="parquet-and-delimited-text-format-sink"></a>Parquet и приемником формат с разделителями

Чтобы скопировать данные в Azure Data Lake Store Gen1 в parquet или формат текста с разделителями, см. в разделе [формат Parquet](format-parquet.md) и [текстовый формат с разделителями](format-delimited-text.md) статьи о приемника действия копирования на основе формата и поддерживаемых параметров. Следующие свойства поддерживаются для Azure Data Lake Store поколение 1 в разделе `storeSettings` параметры приемника копирования на основе формата:

| Свойство                 | ОПИСАНИЕ                                                  | Обязательно для заполнения |
| ------------------------ | ------------------------------------------------------------ | -------- |
| type                     | Свойство типа в списке `storeSettings` должно быть присвоено **AzureDataLakeStoreWriteSetting**. | Yes      |
| copyBehavior             | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | Нет       |
| maxConcurrentConnections | Число подключений для подключения к хранилищу данных, одновременно. Укажите только в том случае, если вы хотите ограничить максимальное количество одновременных подключений к хранилищу данных. | Нет       |

> [!NOTE]
> Parquet или текстовый формат с разделителями **AzureDataLakeStoreSink** приемника действия копирования типа, описанные в следующем разделе по-прежнему поддерживается, так как для обеспечения обратной совместимости. Мы рекомендуем использовать эту новую модель, в дальнейшем. Создание пользовательского интерфейса фабрики данных создает эти новые типы.

**Пример.**

```json
"activities":[
    {
        "name": "CopyToADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Parquet output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "ParquetSink",
                "storeSettings":{
                    "type": "AzureDataLakeStoreWriteSetting",
                    "copyBehavior": "PreserveHierarchy"
                }
            }
        }
    }
]
```

#### <a name="other-format-sink"></a>Другие формат приемника

Чтобы скопировать данные в Azure Data Lake Store Gen1 в ORC, Avro, JSON или двоичном формате, поддерживаются следующие свойства в **приемника** раздел:

| Свойство | ОПИСАНИЕ | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | `type` Свойства приемника действия копирования должно быть присвоено **AzureDataLakeStoreSink**. |Да |
| copyBehavior | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае имя файла создается автоматически. | Нет |
| maxConcurrentConnections | Число подключений для подключения к хранилищу данных, одновременно. Укажите только в том случае, если вы хотите ограничить максимальное количество одновременных подключений к хранилищу данных. | Нет |

**Пример.**

```json
"activities":[
    {
        "name": "CopyToADLSGen1",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<ADLS Gen1 output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "AzureDataLakeStoreSink",
                "copyBehavior": "PreserveHierarchy"
            }
        }
    }
]
```

### <a name="folder-and-file-filter-examples"></a>Примеры фильтров папок и файлов

В этом разделе описываются результаты применения фильтров с подстановочными знаками к пути папки и имени файла.

| folderPath | fileName | recursive | Структура исходной папки и результат фильтрации (извлекаются файлы, выделенные **полужирным** шрифтом)|
|:--- |:--- |:--- |:--- |
| `Folder*` | (Пустое, используется по умолчанию) | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | (Пустое, используется по умолчанию) | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл4.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |

### <a name="examples-of-behavior-of-the-copy-operation"></a>Примеры поведения операции копирования

В данном разделе описываются результаты выполнения операции копирования при использовании различных сочетаний значений `recursive` и `copyBehavior`.

| recursive | copyBehavior | Структура папок источника | Результаты цели |
|:--- |:--- |:--- |:--- |
| Да |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая "Папка1" создается с такой же структурой, как и исходная папка:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 |
| Да |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл3"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл4"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл5" |
| Да |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Файл1" и "файл2" + "файл3" + "файл4" и "файл5" объединяется содержимое в один файл с автоматически созданным именем. |
| false |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/><br/>С файлами "файл3", "файл4" и "файл5" не вложенная_папка1. |
| false |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/><br/>С файлами "файл3", "файл4" и "файл5" не вложенная_папка1. |
| false |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;"Файл1" и "файл2" содержимое объединяются в один файл с автоматически созданным именем. автоматически созданное имя для "Файл1"<br/><br/>С файлами "файл3", "файл4" и "файл5" не вложенная_папка1. |

## <a name="preserve-acls-to-data-lake-storage-gen2"></a>Сохраняет списки управления доступом на уровень Gen2 хранилища Озера данных

Если вы хотите реплицировать списки управления доступом (ACL) вместе с файлами данных при обновлении с Gen1 хранилища Озера данных на уровень Gen2 хранилища Озера данных, см. в разделе [сохранить списки управления доступом из Gen1 хранилища Озера данных](connector-azure-data-lake-storage.md#preserve-acls-from-data-lake-storage-gen1).

## <a name="mapping-data-flow-properties"></a>Сопоставление свойств потока данных

Дополнительные сведения о [преобразование исходного](data-flow-source.md) и [приемника преобразования](data-flow-sink.md) в разделе «сопоставление» потока данных.

## <a name="next-steps"></a>Дальнейшие действия

В таблице [Поддерживаемые хранилища данных](copy-activity-overview.md##supported-data-stores-and-formats) приведен список хранилищ данных, которые поддерживаются в качестве источников и приемников для действия копирования в фабрике данных Azure.
