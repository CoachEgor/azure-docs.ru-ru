---
title: Инструкции по повышению производительности и масштабируемости действия копирования
description: Сведения о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure при использовании действия копирования.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/11/2020
ms.openlocfilehash: aedb3df69821d1436b03b2eb1f12873b624d426e
ms.sourcegitcommit: 877491bd46921c11dd478bd25fc718ceee2dcc08
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 07/02/2020
ms.locfileid: "81414178"
---
# <a name="copy-activity-performance-and-scalability-guide"></a>Инструкции по повышению производительности и масштабируемости действия копирования

> [!div class="op_single_selector" title1="Выберите версию Фабрики данных, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Если вы хотите выполнить крупномасштабную миграцию данных из Data Lake или корпоративного хранилища данных (EDW) в Azure или хотите принимать данные в масштабе из разных источников в Azure для аналитики больших данных, крайне важно обеспечить оптимальную производительность и масштабируемость.  Фабрика данных Azure предоставляет мощный, устойчивый и экономичный механизм для приема данных в масштабе, что делает их отличными для специалистов по разработке данных, которые ищут высокопроизводительные и масштабируемые конвейеры приема данных.

После прочтения этой статьи вы сможете ответить на следующие вопросы:

- Какой уровень производительности и масштабируемости можно достичь с помощью действия копирования ADF для переноса данных и сценариев приема данных?

- Какие действия следует предпринять для настройки производительности действия копирования ADF?
- Какие счетчики производительности ADF можно использовать для оптимизации производительности при выполнении одного действия копирования?
- Какие другие факторы выходят за пределы ADF, которые следует учитывать при оптимизации производительности копирования?

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, ознакомьтесь с [обзором действия копирования](copy-activity-overview.md) , прежде чем приступить к ознакомлению с этой статьей.

## <a name="copy-performance-and-scalability-achievable-using-adf"></a>Производительность и масштабируемость копирования, которые додостижимы с помощью ADF

Фабрика данных Azure имеет бессерверную архитектуру, которая обеспечивает параллелизм на разных уровнях. Это позволяет разработчикам создавать конвейеры для полного использования пропускной способности сети и хранилища с целью передачи данных в среде с максимальной скоростью.  Это означает, что можно оценить пропускную способность, которая может быть достигнута путем измерения минимальной пропускной способности, предоставляемой исходным хранилищем данных, конечным хранилищем данных и пропускной способностью сети между источником и назначением.  В следующей таблице вычисляется длительность копирования на основе размера данных и ограничения пропускной способности для вашей среды. 

| Размер данных/ <br/> bandwidth | 50 Мбит/с    | 100 Мбит/с  | 500 Мбит/с  | 1 Гбит/с   | 5 Гбит/с   | 10 Гбит/с  | 50 Гбит/с   |
| --------------------------- | ---------- | --------- | --------- | -------- | -------- | -------- | --------- |
| **1 ГБ**                    | 2,7 мин    | 1,4 мин   | 0,3 мин   | 0,1 мин  | 0,03 мин | 0,01 мин | 0,0 мин   |
| **10 ГБ**                   | 27,3 мин   | 13,7 мин  | 2,7 мин   | 1,3 мин  | 0,3 мин  | 0,1 мин  | 0,03 мин  |
| **100 ГБ**                  | 4,6 часов    | 2,3 часов   | 0,5 часов   | 0,2 часов  | 0,05 часов | 0,02 часов | 0,0 часов   |
| **1 TБ**                    | 46,6 часов   | 23,3 часов  | 4,7 часов   | 2,3 часов  | 0,5 часов  | 0,2 часов  | 0,05 часов  |
| **10 ТБ**                   | 19,4 дней  | 9,7 дней  | 1,9 дней  | 0,9 дней | 0,2 дней | 0,1 дней | 0,02 дней |
| **100 ТБ**                  | 194,2 дней | 97,1 дней | 19,4 дней | 9,7 дней | 1,9 дней | 1 день    | 0,2 дней  |
| **1 ПБ**                    | 64,7 Mo    | 32,4 Mo   | 6,5 mo    | 3,2 mo   | 0,6 Mo   | 0,3 Mo   | 0,06 Mo   |
| **10 ПБ**                   | 647,3 Mo   | 323,6 Mo  | 64,7 Mo   | 31,6 Mo  | 6,5 mo   | 3,2 mo   | 0,6 Mo    |

Копия ADF масштабируется на разных уровнях:

![как в ADF копируется масштабирование](media/copy-activity-performance/adf-copy-scalability.png)

- Поток управления Фабрики данных Azure может запускать несколько операций копирования параллельно, например с помощью [цикла For Each](control-flow-for-each-activity.md).
- Для одного действия копирования можно использовать масштабируемые вычислительные ресурсы: при использовании Azure Integration Runtime можно указать [до 256 единиц интеграции данных](#data-integration-units) для каждого бессерверного действия копирования. При использовании локальной среды выполнения интеграции можно вручную масштабировать компьютер по вертикали или выполнить масштабирование по горизонтали до нескольких компьютеров ([до 4 узлов](create-self-hosted-integration-runtime.md#high-availability-and-scalability)), и действие копирования разделит набор файлов по всем узлам.
- Одно действие копирования считывает и выполняет запись в хранилище данных, используя несколько потоков [параллельно](#parallel-copy).

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с помощью действия копирования.

1. **Выберите тестовый набор данных и создайте базовый план.** На этапе разработки протестируйте конвейер с помощью действия копирования в образце репрезентативных данных. Выбранный набор данных должен представлять стандартные шаблоны данных (структуру папок, шаблон файла, схему данных и т. д.) и достаточно велика для оценки производительности копирования, например для завершения операции копирования занимает 10 минут или больше. Собирайте сведения о выполнении и характеристики производительности после [мониторинга действий копирования](copy-activity-monitoring.md).

2. **Как повысить производительность одного действия копирования**:

   Для начала рекомендуется сначала повысить производительность с помощью одного действия копирования.

   - **Если действие копирования выполняется в Azure Integration Runtime:** Start со значениями по умолчанию для [единиц интеграции данных (Диу)](#data-integration-units) и [параллельных параметров копирования](#parallel-copy) . 

   - **Если действие копирования выполняется на автономной Integration Runtime:** рекомендуется использовать выделенный компьютер отдельно от сервера, на котором размещено хранилище данных, для размещения среды выполнения интеграции. Начните со значений по умолчанию для параметра [параллельной копии](#parallel-copy) и с помощью одного узла для автономной среды IR.  

   Выполните тест производительности и запишите показатели производительности, а также фактические значения, используемые как диус и параллельные копии. Сведения о том, как выполнять поиск результатов выполнения и используемых параметров производительности, см. в статье [мониторинг действий копирования](copy-activity-monitoring.md) и [Устранение проблем с производительностью действий копирования](copy-activity-performance-troubleshooting.md) для выявления и устранения узкого места. 

   Выполните итерации для выполнения дополнительных тестов производительности, следуя указаниям по устранению неполадок и настройке. Как только выполнение одной операции копирования может повысить пропускную способность, рассмотрите возможность максимально увеличить общую пропускную способность, запустив несколько копий одновременно с шагом 3.


3. **Как максимально увеличить общую пропускную способность, одновременно выполнив несколько копий:**

   Теперь, когда вы установили максимальную производительность одного действия копирования, если вы еще не настроили верхние пределы пропускной способности вашей среды — сети, исходного хранилища данных и целевого хранилища данных, можно выполнять несколько действий копирования параллельно с помощью конструкций потока управления ADF, таких как [цикл for each](control-flow-for-each-activity.md). См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md), [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md)или [полное копирование с помощью шаблонов решений для управления таблицами](solution-template-bulk-copy-with-control-table.md) в качестве общего примера.

5. **Разверните конфигурацию для всего набора данных.** Когда вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="troubleshoot-copy-activity-performance"></a>Устранение неполадок с производительностью действия копирования

Выполните [шаги по настройке производительности](#performance-tuning-steps) , чтобы спланировать и провести тест производительности для вашего сценария. И Узнайте, как устранять проблемы производительности выполнения действий копирования в фабрике данных Azure от [устранения неполадок, связанных с действиями копирования](copy-activity-performance-troubleshooting.md).

## <a name="copy-performance-optimization-features"></a>Копирование функций оптимизации производительности

Фабрика данных Azure предоставляет следующие возможности оптимизации производительности.

- [Единицы интеграции данных](#data-integration-units)
- [Масштабируемость локальной среды выполнения интеграции](#self-hosted-integration-runtime-scalability)
- [Параллельное копирование](#parallel-copy)
- [промежуточное копирование](#staged-copy)

### <a name="data-integration-units"></a>Единицы интеграции данных

Единица интеграции данных — это мера, представляющая мощность (сочетание ЦП, памяти и выделения ресурсов сети) одного блока в фабрике данных Azure. Единица интеграции данных применяется только к [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime), но не к локальной [среде выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime). [Подробнее.](copy-activity-performance-features.md#data-integration-units)

### <a name="self-hosted-integration-runtime-scalability"></a>Масштабируемость локальной среды выполнения интеграции

Для увеличения параллельной рабочей нагрузки или для достижения более высокой производительности можно увеличить или уменьшить масштаб размещения Integration Runtime. [Подробнее.](copy-activity-performance-features.md#self-hosted-integration-runtime-scalability)

### <a name="parallel-copy"></a>Параллельное копирование

Можно задать Параллельное копирование, чтобы указать параллелизм, который будет использоваться действием копирования. Это свойство можно считать максимальным числом потоков в действии копирования, считываемых из источника или записываемых в хранилище данных приемника параллельно. [Подробнее.](copy-activity-performance-features.md#parallel-copy)

### <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. [Подробнее.](copy-activity-performance-features.md#staged-copy)

## <a name="next-steps"></a>Дальнейшие действия
См. другие статьи о действии копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Устранение неполадок с производительностью действия копирования](copy-activity-performance-troubleshooting.md)
- [Функции оптимизации производительности действий копирования](copy-activity-performance-features.md)
- [Перенос данных из хранилища данных в Azure с помощью фабрики данных Azure](data-migration-guidance-overview.md)
- [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
