---
title: Инструкции по повышению производительности и масштабируемости действия копирования
description: Сведения о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure при использовании действия копирования.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/11/2020
ms.openlocfilehash: 231b0d77dc441e70dc0ec8de313291bb6b4f9292
ms.sourcegitcommit: 7b25c9981b52c385af77feb022825c1be6ff55bf
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/13/2020
ms.locfileid: "79261402"
---
# <a name="copy-activity-performance-and-scalability-guide"></a>Инструкции по повышению производительности и масштабируемости действия копирования

> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)

Если вы хотите выполнить крупномасштабную миграцию данных из Data Lake или корпоративного хранилища данных (EDW) в Azure или хотите принимать данные в масштабе из разных источников в Azure для анализа больших данных, крайне важно добиться оптимальной производительности и масштабируемости.  Фабрика данных Azure предоставляет мощный, устойчивый и экономичный механизм для приема данных в масштабе, что делает их отличными для специалистов по разработке данных, которые ищут высокопроизводительные и масштабируемые конвейеры приема данных.

После прочтения этой статьи вы сможете ответить на следующие вопросы:

- Какой уровень производительности и масштабируемости можно достичь с помощью действия копирования ADF для переноса данных и сценариев приема данных?

- Какие действия следует предпринять для настройки производительности действия копирования ADF?
- Какие счетчики производительности ADF можно использовать для оптимизации производительности при выполнении одного действия копирования?
- Какие другие факторы выходят за пределы ADF, которые следует учитывать при оптимизации производительности копирования?

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, ознакомьтесь с [обзором действия копирования](copy-activity-overview.md) , прежде чем приступить к ознакомлению с этой статьей.

## <a name="copy-performance-and-scalability-achievable-using-adf"></a>Производительность и масштабируемость копирования, которые додостижимы с помощью ADF

ADF предлагает бессерверную архитектуру, которая обеспечивает параллелизм на разных уровнях, что позволяет разработчикам создавать конвейеры для полного использования пропускной способности сети, а также операций ввода-вывода и пропускной способности хранилища для максимального увеличения пропускной способности перемещения данных для вашей среды.  Это означает, что можно оценить пропускную способность, которая может быть достигнута путем измерения минимальной пропускной способности, предоставляемой исходным хранилищем данных, конечным хранилищем данных и пропускной способностью сети между источником и назначением.  В следующей таблице вычисляется длительность копирования на основе размера данных и ограничения пропускной способности для вашей среды. 

| Размер данных/ <br/> bandwidth | 50 Мбит/с    | 100 Мбит/с  | 500 Мбит/с  | 1 Гбит/с   | 5 Гбит/с   | 10 Гбит/с  | 50 Гбит/с   |
| --------------------------- | ---------- | --------- | --------- | -------- | -------- | -------- | --------- |
| **1 ГБ**                    | 2,7 мин    | 1,4 мин   | 0,3 мин   | 0,1 мин  | 0,03 мин | 0,01 мин | 0,0 мин   |
| **10 ГБ**                   | 27,3 мин   | 13,7 мин  | 2,7 мин   | 1,3 мин  | 0,3 мин  | 0,1 мин  | 0,03 мин  |
| **100 ГБ**                  | 4,6 часов    | 2,3 часов   | 0,5 часов   | 0,2 часов  | 0,05 часов | 0,02 часов | 0,0 часов   |
| **1 ТБ**                    | 46,6 часов   | 23,3 часов  | 4,7 часов   | 2,3 часов  | 0,5 часов  | 0,2 часов  | 0,05 часов  |
| **10 ТБ**                   | 19,4 дней  | 9,7 дней  | 1,9 дней  | 0,9 дней | 0,2 дней | 0,1 дней | 0,02 дней |
| **100 ТБ**                  | 194,2 дней | 97,1 дней | 19,4 дней | 9,7 дней | 1,9 дней | 1 день    | 0,2 дней  |
| **1 ПБ**                    | 64,7 Mo    | 32,4 Mo   | 6,5 mo    | 3,2 mo   | 0,6 Mo   | 0,3 Mo   | 0,06 Mo   |
| **10 ПБ**                   | 647,3 Mo   | 323,6 Mo  | 64,7 Mo   | 31,6 Mo  | 6,5 mo   | 3,2 mo   | 0,6 Mo    |

Копия ADF масштабируется на разных уровнях:

![как в ADF копируется масштабирование](media/copy-activity-performance/adf-copy-scalability.png)

- Поток управления ADF может запускать несколько операций копирования параллельно, например, с использованием [циклов for each](control-flow-for-each-activity.md).
- Одно действие копирования может воспользоваться преимуществами масштабируемых вычислений: при использовании Azure Integration Runtime можно указать [до 256 диус](#data-integration-units) для каждого действия копирования на бессерверном сервере. При использовании автономного Integration Runtime можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до 4 узлов](create-self-hosted-integration-runtime.md#high-availability-and-scalability)), и одно действие копирования будет секционировать набор файлов на всех узлах.
- Одно действие копирования считывает и выполняет запись в хранилище данных, используя несколько потоков [параллельно](#parallel-copy).

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с помощью действия копирования.

1. **Выберите тестовый набор данных и создайте базовый план.** На этапе разработки протестируйте конвейер с помощью действия копирования в образце репрезентативных данных. Выбранный набор данных должен представлять стандартные шаблоны данных (структуру папок, шаблон файла, схему данных и т. д.) и достаточно велика для оценки производительности копирования, например для завершения операции копирования занимает 10 минут или больше. Собирайте сведения о выполнении и характеристики производительности после [мониторинга действий копирования](copy-activity-monitoring.md).

2. **Как повысить производительность одного действия копирования**:

   Для начала рекомендуется сначала повысить производительность с помощью одного действия копирования.

   - **Если действие копирования выполняется в Azure Integration Runtime:** Start со значениями по умолчанию для [единиц интеграции данных (Диу)](#data-integration-units) и [параллельных параметров копирования](#parallel-copy) . 

   - **Если действие копирования выполняется на автономной Integration Runtime:** рекомендуется использовать выделенный компьютер отдельно от сервера, на котором размещено хранилище данных, для размещения среды выполнения интеграции. Начните со значений по умолчанию для параметра [параллельной копии](#parallel-copy) и с помощью одного узла для автономной среды IR.  

   Выполните тест производительности и запишите показатели производительности, а также фактические значения, используемые как диус и параллельные копии. Сведения о том, как выполнять поиск результатов выполнения и используемых параметров производительности, см. в статье [мониторинг действий копирования](copy-activity-monitoring.md) и [Устранение проблем с производительностью действий копирования](copy-activity-performance-troubleshooting.md) для выявления и устранения узкого места. 

   Выполните итерации для выполнения дополнительных тестов производительности, следуя указаниям по устранению неполадок и настройке. Как только выполнение одной операции копирования может повысить пропускную способность, рассмотрите возможность максимально увеличить общую пропускную способность, запустив несколько копий одновременно с шагом 3.


3. **Как максимально увеличить общую пропускную способность, одновременно выполнив несколько копий:**

   Теперь, когда вы установили максимальную производительность одного действия копирования, если вы еще не настроили верхние пределы пропускной способности вашей среды — сети, исходного хранилища данных и целевого хранилища данных, можно выполнять несколько действий копирования параллельно с помощью конструкций потока управления ADF, таких как [цикл for each](control-flow-for-each-activity.md). См. статью [копирование файлов из нескольких контейнеров](solution-template-copy-files-multiple-containers.md), [Перенос данных из Amazon S3 в ADLS 2-го поколения](solution-template-migration-s3-azure.md)или [полное копирование с помощью шаблонов решений для управления таблицами](solution-template-bulk-copy-with-control-table.md) в качестве общего примера.

5. **Разверните конфигурацию для всего набора данных.** Когда вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="troubleshoot-copy-activity-performance"></a>Устранение неполадок с производительностью действия копирования

Выполните [шаги по настройке производительности](#performance-tuning-steps) , чтобы спланировать и провести тест производительности для вашего сценария. И Узнайте, как устранять проблемы производительности выполнения действий копирования в фабрике данных Azure от [устранения неполадок, связанных с действиями копирования](copy-activity-performance-troubleshooting.md).

## <a name="copy-performance-optimization-features"></a>Копирование функций оптимизации производительности

Фабрика данных Azure предоставляет следующие возможности оптимизации производительности.

- [Единицы интеграции данных](#data-integration-units)
- [Масштабируемость локальной среды выполнения интеграции](#self-hosted-integration-runtime-scalability)
- [Параллельное копирование](#parallel-copy)
- [Промежуточное копирование](#staged-copy)

### <a name="data-integration-units"></a>Единицы интеграции данных

Единица интеграции данных — это мера, представляющая мощность (сочетание ЦП, памяти и выделения ресурсов сети) одного блока в фабрике данных Azure. Единица интеграции данных применяется только к [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime), но не к локальной [среде выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime). [Дополнительные сведения](copy-activity-performance-features.md#data-integration-units)

### <a name="self-hosted-integration-runtime-scalability"></a>Масштабируемость локальной среды выполнения интеграции

Для увеличения параллельной рабочей нагрузки или для достижения более высокой производительности можно увеличить или уменьшить масштаб размещения Integration Runtime. [Дополнительные сведения](copy-activity-performance-features.md#self-hosted-integration-runtime-scalability)

### <a name="parallel-copy"></a>Параллельное копирование

Можно задать Параллельное копирование, чтобы указать параллелизм, который будет использоваться действием копирования. Это свойство можно считать максимальным числом потоков в действии копирования, считываемых из источника или записываемых в хранилище данных приемника параллельно. [Дополнительные сведения](copy-activity-performance-features.md#parallel-copy)

### <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. [Дополнительные сведения](copy-activity-performance-features.md#staged-copy)

## <a name="next-steps"></a>Дальнейшие действия
См. Другие статьи о действиях копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Устранение неполадок с производительностью действия копирования](copy-activity-performance-troubleshooting.md)
- [Функции оптимизации производительности действий копирования](copy-activity-performance-features.md)
- [Перенос данных из хранилища данных в Azure с помощью фабрики данных Azure](data-migration-guidance-overview.md)
- [Перенос данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
