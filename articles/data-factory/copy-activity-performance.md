---
title: Копирование руководства по производительности и масштабируемости
description: Узнайте о ключевых факторах, влияющих на производительность движения данных на фабрике данных Azure, при использовании действия копирования.
services: data-factory
documentationcenter: ''
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/11/2020
ms.openlocfilehash: 231b0d77dc441e70dc0ec8de313291bb6b4f9292
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "79261402"
---
# <a name="copy-activity-performance-and-scalability-guide"></a>Копирование руководства по производительности и масштабируемости

> [!div class="op_single_selector" title1="Выберите используемую версию фабрики данных Azure:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)

Независимо от того, хотите ли вы осуществить масштабную миграцию данных из хранилища данных или корпоративного хранилища данных (EDW) в Azure, или хотите глотать данные в масштабе из разных источников в Azure для анализа больших данных, крайне важно достичь оптимальной производительности и Масштабируемость.  Azure Data Factory предоставляет эффективный, устойчивый и экономичный механизм для вхотворения данных в масштабе, что делает его отличным подходом для инженеров по обработке данных, стремящихся построить высокоэффективные и масштабируемые конвейеры приема данных.

После прочтения этой статьи вы сможете ответить на следующие вопросы:

- Какого уровня производительности и масштабируемости можно достичь с помощью активности копирования ADF для миграции данных и сценариев приема данных?

- Какие шаги следует предпринять для настройки производительности копирования ADF?
- Какие ручки оптимизации ADF perf можно использовать для оптимизации производительности для выполнения одной копирования?
- Какие еще факторы за пределами ADF следует учитывать при оптимизации производительности копий?

> [!NOTE]
> Если вы не знакомы с активностью копирования в целом, смотрите [обзор активности копирования](copy-activity-overview.md) перед прочтением этой статьи.

## <a name="copy-performance-and-scalability-achievable-using-adf"></a>Копирование производительности и масштабируемости, достижимой с помощью ADF

ADF предлагает бессерверную архитектуру, которая позволяет параллелизм на различных уровнях, что позволяет разработчикам создавать конвейеры, чтобы в полной мере использовать пропускную способность сети, а также память IOPS и пропускную способность для максимизации пропускной способности движения данных для вашей среды.  Это означает, что пропускная способность, которую вы можете достичь, может быть оценена путем измерения минимальной пропускной способности, предлагаемой хранилищем исходных данных, хранилищем данных назначения и пропускной способностью сети между источником и пунктом назначения.  В приведенной ниже таблице вычисляется продолжительность копии на основе размера данных и предела пропускной способности для среды. 

| Размер данных / <br/> bandwidth | 50 Мбит/с    | 100 Мбит/с  | 500 Мбит/с  | 1 Гбит/с   | 5 Гбит/с   | 10 Гбит/с  | 50 Гбит/с   |
| --------------------------- | ---------- | --------- | --------- | -------- | -------- | -------- | --------- |
| **1 ГБ**                    | 2,7 мин.    | 1,4 мин.   | 0,3 мин.   | 0,1 мин.  | 0,03 мин. | 0,01 мин. | 0,0 мин.   |
| **10 ГБ**                   | 27,3 мин.   | 13,7 мин.  | 2,7 мин.   | 1,3 мин.  | 0,3 мин.  | 0,1 мин.  | 0,03 мин.  |
| **100 ГБ**                  | 4,6 часа    | 2,3 часа   | 0,5 часа   | 0,2 часа  | 0,05 часа | 0,02 часа | 0,0 часа   |
| **1 ТБ**                    | 46,6 ч.   | 23,3 часа  | 4,7 часа   | 2,3 часа  | 0,5 часа  | 0,2 часа  | 0,05 часа  |
| **10 ТБ**                   | 19,4 дня  | 9,7 дней  | 1,9 дня  | 0,9 дней | 0,2 дня | 0,1 дня | 0,02 дня |
| **100 ТБ**                  | 194,2 дня | 97,1 дня | 19,4 дня | 9,7 дней | 1,9 дня | 1 день    | 0,2 дня  |
| **1 ПБ**                    | 64,7 м    | 32,4 м   | 6,5 м    | 3,2 м   | 0,6 м   | 0,3 м   | 0,06 м   |
| **10 ПБ**                   | 647,3 м   | 323,6 м  | 64,7 м   | 31,6 м  | 6,5 м   | 3,2 м   | 0,6 м    |

Копия ADF масштабируется на разных уровнях:

![как aDF копирует весы](media/copy-activity-performance/adf-copy-scalability.png)

- Поток управления ADF может запускать несколько действий копирования параллельно, например, используя [для каждого цикла.](control-flow-for-each-activity.md)
- Одноразовая копия может использовать масштабируемые вычислительные ресурсы: при использовании Azure Integration Runtime можно указать [до 256 DI-образных емких](#data-integration-units) данных для каждой деятельности копирования без сервера; при использовании автономной интеграции Runtime, вы можете вручную масштабировать машину или масштабировать до нескольких машин[(до 4 узлов),](create-self-hosted-integration-runtime.md#high-availability-and-scalability)и одна копия деятельности будет разделить его файл, установленный на всех узлов.
- Одноразовая копия действия читается и записывается в хранилище данных, используя несколько потоков [параллельно.](#parallel-copy)

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Примите эти меры, чтобы настроить производительность службы Azure Data Factory с помощью действия копирования.

1. **Возьмите набор тестовых данных и установите базовый уклад.** На этапе разработки проверьте конвейер, используя активность копирования в отношении репрезентативной выборки данных. Выбираемый набор данных должен представлять типичные шаблоны данных (структура папок, шаблон файла, схема данных и т.д.) и достаточно велик, чтобы оценить производительность копирования, например, для завершения копирования— это займет 10 минут или более. Сбор деталей исполнения и характеристик производительности после [мониторинга активности копирования.](copy-activity-monitoring.md)

2. **Как максимизировать производительность деятельности одной копии:**

   Для начала мы рекомендуем вам сначала максимизировать производительность с помощью одной копирования деятельности.

   - **Если действие копирования выполняется в runtime интеграции Azure:** начните с значений по умолчанию для [единиц интеграции данных (DIU)](#data-integration-units) и [параллельных](#parallel-copy) настроек копирования. 

   - **Если действие копирования выполняется на самостоятельно модном часовом запуске интеграции:** мы рекомендуем использовать специальную машину отдельно от сервера, на котором размещается хранилище данных, для размещения времени выполнения интеграции. Начните с значений по умолчанию для параллельной настройки [копии](#parallel-copy) и с помощью одного узла для самостоятельно гостовых ИК.  

   Выполните тестовый запуск производительности и обратите внимание на достигнутую производительности, а также фактические значения, используемые как DIUs и параллельные копии. Обратитесь к [копированию мониторинга активности](copy-activity-monitoring.md) о том, как собирать результаты выполнения и используемые параметры производительности, и узнать, как [производительность копирования копирования Troubleshoot](copy-activity-performance-troubleshooting.md) для выявления и устранения узких мест. 

   Итерировать для проведения дополнительных тестов производительности после устранения неполадок и настройки руководства. После того, как один экземпляр деятельности запустить не может достичь лучшей пропускной суммы, рассмотреть вопрос о максимальной агрегированной пропускной путе, запустив несколько копий одновременно со ссылкой на шаг 3.


3. **Как максимизировать совокупную пропускную стоимость, одновременно запуская несколько копий:**

   Теперь, когда вы максимизировали производительность одной активности копирования, если вы еще не достигли верхних пределов пропускной способности среды - сети, хранилища исходных данных и хранилища данных назначения - вы можете выполнить несколько действий копирования параллельно с помощью конструкций потока управления ADF, таких как [Для каждого цикла.](control-flow-for-each-activity.md) Обратитесь к [файлам копирования из нескольких контейнеров,](solution-template-copy-files-multiple-containers.md) [переносу данных из Amazon S3 в ADLS Gen2](solution-template-migration-s3-azure.md)или [массовой копии с](solution-template-bulk-copy-with-control-table.md) шаблонами решений диспетчерских таблиц в качестве общего примера.

5. **Расширьте конфигурацию до всего набора данных.** Если вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="troubleshoot-copy-activity-performance"></a>Производительность действия копирования troubleshoot

Следуйте [шагам настройки производительности,](#performance-tuning-steps) чтобы спланировать и провести тест производительности для вашего сценария. И узнайте, как устранить неполадки в выполнении каждого выполнения действия копирования в Azure Data Factory из [производительности копирования Troubleshoot.](copy-activity-performance-troubleshooting.md)

## <a name="copy-performance-optimization-features"></a>Функции оптимизации производительности

Azure Data Factory предоставляет следующие функции оптимизации производительности:

- [Единицы интеграции данных](#data-integration-units)
- [Масштабируемость автономной интеграции](#self-hosted-integration-runtime-scalability)
- [Параллельное копирование](#parallel-copy)
- [промежуточное копирование](#staged-copy)

### <a name="data-integration-units"></a>Единицы интеграции данных

Группа интеграции данных — это мера, представляющая мощность (комбинация процессора, памяти и распределения сетевых ресурсов) одного блока в Azure Data Factory. Группа интеграции данных применяется только к [времени выполнения интеграции Azure,](concepts-integration-runtime.md#azure-integration-runtime)но не [к самостоятельной интеграции.](concepts-integration-runtime.md#self-hosted-integration-runtime) Ознакомьтесь с [дополнительными сведениями](copy-activity-performance-features.md#data-integration-units).

### <a name="self-hosted-integration-runtime-scalability"></a>Масштабируемость автономной интеграции

Чтобы уhost увеличивающейся одновременной рабочей нагрузки или для достижения более высокой производительности, можно масштабировать или масштабировать самоходной интеграции Runtime. Ознакомьтесь с [дополнительными сведениями](copy-activity-performance-features.md#self-hosted-integration-runtime-scalability).

### <a name="parallel-copy"></a>Параллельное копирование

Можно установить параллельную копию, чтобы указать параллелизм, который вы хотите использовать для использования копирования. Это свойство можно считать максимальным количеством потоков в потоке копирования, которые считываются из вашего источника или пишут в хранилища данных раковины параллельно. Ознакомьтесь с [дополнительными сведениями](copy-activity-performance-features.md#parallel-copy).

### <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Ознакомьтесь с [дополнительными сведениями](copy-activity-performance-features.md#staged-copy).

## <a name="next-steps"></a>Дальнейшие действия
Смотрите другие статьи деятельности копирования:

- [Общие сведения о действии копирования](copy-activity-overview.md)
- [Производительность действия копирования troubleshoot](copy-activity-performance-troubleshooting.md)
- [Копирование функций оптимизации производительности](copy-activity-performance-features.md)
- [Используйте фабрику данных Azure для переноса данных из озера данных или хранилища данных в Azure](data-migration-guidance-overview.md)
- [Миграция данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
