---
title: Обзор производительности и настройки действий копирования в фабрике данных Azure | Документация Майкрософт
description: Сведения о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure при использовании действия копирования.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 07/02/2019
ms.author: jingwang
ms.openlocfilehash: d8ce0a4f6bacdd1c8c858d474e6f3957a23c6357
ms.sourcegitcommit: 5d6c8231eba03b78277328619b027d6852d57520
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/13/2019
ms.locfileid: "68967359"
---
# <a name="copy-activity-performance-and-tuning-guide"></a>Инструкции по настройке производительности действия копирования
> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)


Действие копирования в фабрике данных Azure предоставляет безопасное, надежное и высокопроизводительное решение для загрузки данных в первую очередь. Его можно использовать для копирования десятков терабайт данных каждый день в разнообразных облачных и локальных хранилищах данных. Высокая производительность загрузки данных — это ключ, позволяющий сосредоточиться на решении основных проблем с большими данными: создание решений для расширенной аналитики и получение подробных сведений обо всех этих данных.

Azure предоставляет набор решений для хранения данных корпоративного класса и хранилища данных. Действие копирования предлагает очень оптимизированный интерфейс загрузки данных, который легко настроить и настроить. С помощью одного действия копирования можно загрузить данные в:

* Хранилище данных SQL Azure с частотой 1,2 Гбит/с.
* Хранилище BLOB-объектов Azure с частотой 1,0 Гбит/с.
* Azure Data Lake Store с частотой 1,0 Гбит/с.

Содержание статьи

* [Справочные номера производительности](#performance-reference) для поддерживаемых хранилищ данных источника и приемника, которые помогут вам спланировать проект.
* Функции, которые могут повысить пропускную способность копирования в различных сценариях, включая [единицы интеграции данных](#data-integration-units) (диус), [параллельную копию](#parallel-copy)и [промежуточное копирование](#staged-copy).
* [Рекомендации по настройке производительности](#performance-tuning-steps) для настройки производительности и ключевых факторов, которые могут повлиять на производительность копирования.

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, ознакомьтесь с [обзором действия копирования](copy-activity-overview.md) , прежде чем приступить к ознакомлению с этой статьей.
>

## <a name="performance-reference"></a>Базовые показатели производительности

В следующей таблице показан номер пропускной способности копирования в Мбит/с для заданных пар источника и приемника в рамках одного действия копирования, выполняемого на основе внутреннего тестирования. Для сравнения также показано, как различные параметры [единиц интеграции данных](#data-integration-units) или масштабируемости локальной [среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime) (несколько узлов) могут помочь при копировании производительности.

![Матрица производительности](./media/copy-activity-performance/CopyPerfRef.png)

> [!IMPORTANT]
> Если действие копирования выполняется в среде выполнения интеграции Azure, минимально допустимые единицы интеграции данных (ранее назывались единицами перемещения данных) — два. Если этот параметр не указан, см. раздел единицы интеграции данных по умолчанию, используемые в [единицах интеграции данных](#data-integration-units).

**Примечания:**

* Пропускная способность вычисляется с помощью следующей формулы: [размер данных, считанных из источника]/[длительность выполнения действия копирования].
* Справочные показатели производительности в таблице измеряются с помощью набора данных [TPC-H](http://www.tpc.org/tpch/) в ходе одного действия копирования. Файлы тестов для файловых хранилищ — это несколько файлов с размером 10 ГБ.
* При использовании хранилищ данных Azure источник и приемник находились в одном регионе Azure.
* Для гибридного копирования между локальными и облачными хранилищами данных каждый узел локальной среды выполнения интеграции был запущен на компьютере, который был отделен от хранилища данных со следующей спецификацией. При выполнении одного действия операция копирования потребляла только небольшую часть ресурсов ЦП, памяти и пропускной способности сети на тестовом компьютере.
    <table>
    <tr>
        <td>ЦП</td>
        <td>Intel Xeon E5-2660 v2, 32 ядра с частотой 2,20 ГГц</td>
    </tr>
    <tr>
        <td>Память</td>
        <td>128 ГБ</td>
    </tr>
    <tr>
        <td>Сеть</td>
        <td>Веб-интерфейс: 10 Гбит/с; интерфейс интрасети: 40 Гбит/с</td>
    </tr>
    </table>


> [!TIP]
> Повысить пропускную способность можно с помощью более диус. Например, с 100 диус можно скопировать данные из хранилища BLOB-объектов Azure в Azure Data Lake Store с 1,0 Гбит/с. Дополнительные сведения об этой функции и поддерживаемом сценарии см. в разделе " [единицы интеграции данных](#data-integration-units) ". 

## <a name="data-integration-units"></a>Единицы интеграции данных

Единица интеграции данных — это мера, представляющая мощность (сочетание ЦП, памяти и выделения ресурсов сети) одного блока в фабрике данных Azure. Единица интеграции данных применяется только к [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime), но не к локальной [среде выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime).

Минимальное диус для запуска действия копирования — два. В следующей таблице перечислены количества единиц интеграции данных, используемые по умолчанию в различных сценариях копирования, если другое значение не указано:

| Сценарий копирования | Число единиц интеграции данных, устанавливаемое по умолчанию службой |
|:--- |:--- |
| Копирование данных между файловыми хранилищами | От 4 до 32 в зависимости от числа и размера файлов |
| Копирование данных в базу данных SQL Azure или Azure Cosmos DB |От 4 до 16 в зависимости от уровня приемника базы данных SQL Azure или Cosmos DB (число DTU/RUs) |
| Все остальные сценарии копирования | 4 |

Чтобы переопределить это значение по умолчанию, укажите значение для свойства **dataIntegrationUnits**, как показано ниже. *Допустимые значения* для свойства **датаинтегратионунитс** : до 256. *Фактическое число единиц интеграции данных*, используемых при копировании, не превышает заданного значения, в зависимости от формата данных. Сведения о том, как можно повысить уровень производительности, настроив дополнительные единицы для определенного источника и приемника, см. в [справочнике по производительности](#performance-reference).

При наблюдении за выполнением действия диус, используемые для каждой копии, можно просмотреть в выходных данных действия копирования. Дополнительные сведения см. в разделе [мониторинг действий копирования](copy-activity-overview.md#monitoring).

> [!NOTE]
> Параметр диус больше 4 применяется только при копировании нескольких файлов из службы хранилища Azure, Azure Data Lake Storage, Amazon S3, облачного хранилища Google, облачного FTP или облака SFTP в любые другие облачные хранилища данных.
>

**Пример**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "dataIntegrationUnits": 32
        }
    }
]
```

### <a name="data-integration-units-billing-impact"></a>Влияние единиц интеграции данных на выставление счетов

Помните, что плата наследуется на основе общего времени операции копирования. Общая длительность перемещения данных — это сумма длительности по диус. Если задание копирования обычно занимало один час и две облачные единицы, а теперь на это требуется 15 минут и восемь облачных единиц, то стоимость практически не изменится.

## <a name="parallel-copy"></a>Параллельное копирование

Свойство **parallelCopies** можно использовать для указания параллелизма, который будет использоваться действием копирования. Это свойство можно считать максимальным числом потоков в действии копирования, которые могут считывать данные из источника или записывать в хранилище данных приемника параллельно.

Для каждого запуска действия копирования фабрика данных Azure определяет количество параллельных копий, используемых для копирования данных из исходного хранилища данных и в целевое хранилище данных. Используемое по умолчанию количество параллельных копий зависит от типа источника и приемника, который используется.

| Сценарий копирования | Число параллельных копий по умолчанию, определенное службой |
| --- | --- |
| Копирование данных между файловыми хранилищами |Зависит от размера файлов и числа диус, используемых для копирования данных между двумя облачными хранилищами данных, или физической конфигурацией компьютера, на котором размещена локальная среда выполнения интеграции. |
| Копирование данных из любого исходного хранилища в хранилище таблиц Azure |4 |
| Все остальные сценарии копирования |1 |

> [!TIP]
> При копировании данных между файловыми хранилищами поведение по умолчанию обычно дает лучшую пропускную способность. Поведение по умолчанию определяется автоопределением на основе шаблона исходного файла.

Для управления нагрузкой на компьютеры, на которых размещены хранилища данных, или для настройки производительности копирования можно переопределить значение по умолчанию и указать значение для свойства **parallelCopies** . Значение должно быть целым числом больше или равно 1. Во время выполнения для наилучшей производительности действие копирования использует значение, меньшее или равное заданному значению.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

**Примечания:**

* При копировании данных между файловыми хранилищами **parallelCopies** определяет параллелизм на уровне файлов. Фрагментация в одном файле происходит автоматически и прозрачно. Он предназначен для использования наилучшего подходящего размера фрагмента для заданного типа исходного хранилища данных для параллельной загрузки данных и ортогональной обработки в **parallelCopies**. Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов. Если поведение копирования — **mergeFile**, действие копирования не сможет воспользоваться параллелизмом на уровне файлов.
* При копировании данных из хранилищ, которые не основаны на файлах (за исключением [Oracle](connector-oracle.md#oracle-as-source), [Teradata](connector-teradata.md#teradata-as-source), [таблицы SAP](connector-sap-table.md#sap-table-as-source)и соединителя [SAP Open Hub](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source) в качестве источника с включенным секционированием данных), в хранилища, основанные на файлах, служба перемещения данных игнорирует свойство **parallelCopies** . В этом случае параллелизм не применяется, даже если задан соответствующий параметр.
* Свойство **parallelCopies** является ортогональным для **датаинтегратионунитс**. Первое из них учитывается для всех единиц интеграции данных.
* При указании значения для свойства **parallelCopies** учитывайте увеличение нагрузки для хранилищ данных источника и приемника. Также учтите увеличение нагрузки на локальную среду выполнения интеграции, если это предоставляет действие копирования, например для гибридного копирования. Это увеличение нагрузки происходит в особенности при наличии нескольких действий или параллельных запусков тех же действий, которые выполняются с одним и тем же хранилищем данных. Если вы заметили, что хранилище данных или локальная среда выполнения интеграции перегружена, уменьшите значение **parallelCopies** , чтобы освободить нагрузку.

## <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

- **Вы хотите принимать данные из различных хранилищ данных в хранилище данных SQL через Polybase.** Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Исходные данные должны находиться в хранилище BLOB-объектов или Azure Data Lake Store, и они должны удовлетворять дополнительным критериям. При загрузке данных не из хранилища BLOB-объектов или Azure Data Lake Store можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае фабрика данных Azure выполняет необходимые преобразования данных, чтобы обеспечить соответствие требованиям Polybase. Затем она эффективно загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
- **Иногда для выполнения гибридного перемещения данных (т. е. копирования из локального хранилища данных в облачное хранилище данных) через низкое сетевое подключение требуется некоторое время.** Для повышения производительности можно использовать промежуточное копирование для сжатия данных в локальной среде, чтобы уменьшить время на перемещение данных в промежуточное хранилище данных в облаке. Затем можно распаковать данные в промежуточном хранилище перед загрузкой в целевое хранилище данных.
- **Вы не хотите открывать порты, отличные от порта 80 и порта 443, в брандмауэре из-за корпоративных ИТ-политик.** Например, при копировании данных из локального хранилища в приемник Базы данных SQL Azure или приемник Хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом сценарии поэтапное копирование может использовать локальную среду выполнения интеграции, чтобы сначала скопировать данные в промежуточный экземпляр хранилища BLOB-объектов по протоколу HTTP или HTTPS через порт 443. Затем он может загрузить данные в базу данных SQL или хранилище данных SQL из промежуточного хранилища BLOB-объектов. В таком сценарии не нужно включать порт 1433.

### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования

Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное хранилище BLOB-объектов (собственное). Оттуда данные копируются в приемник данных. Фабрика данных Azure автоматически управляет процессом с двумя этапами. Фабрика данных Azure также очищает временные данные из промежуточного хранилища после завершения перемещения данных.

![промежуточное копирование](media/copy-activity-performance/staged-copy.png)

При активации перемещения данных с помощью промежуточного хранилища можно указать, следует ли сжимать данные перед перемещением данных из исходного хранилища данных в промежуточное или промежуточное хранилище, а затем распаковать перед перемещением данных из промежуточного или промежуточного хранилища данных dat. хранилище в хранилище данных-приемник.

В настоящее время нельзя копировать данные между двумя хранилищами данных, которые подключены через разные собственные данные IRs, ни с промежуточным копированием, так и без него. Для такого сценария можно настроить два явно связанных действия копирования для копирования из источника в промежуточную среду, а затем из промежуточного хранения в приемник.

### <a name="configuration"></a>Конфигурация

Настройте параметр **enableStaging** в действии копирования, чтобы указать, должны ли данные быть помещены в хранилище BLOB-объектов перед их загрузкой в целевое хранилище данных. При установке **enableStaging** в `TRUE`укажите дополнительные свойства, перечисленные в следующей таблице. Кроме того, для промежуточного хранения необходимо создать связанную службу хранилища Azure или подписи общего доступа, если у вас ее нет.

| Свойство | Описание | Значение по умолчанию | Обязательное значение |
| --- | --- | --- | --- |
| enableStaging |Укажите, следует ли копировать данные в промежуточное хранилище. |Ложь |Нет |
| linkedServiceName |Укажите имя связанной службы [AzureStorage](connector-azure-blob-storage.md#linked-service-properties), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Хранилище с подписью общего доступа нельзя использовать для загрузки данных в хранилище данных SQL через Polybase. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| path |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. Если не указать путь, служба создает контейнер для хранения временных данных. <br/><br/> Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |Нет |
| enableCompression |Указывает, следует ли сжимать данные перед их копированием в место назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |Ложь |Нет |

>[!NOTE]
> Если используется промежуточное копирование с включенным сжатием, проверка подлинности субъекта-службы или MSI для связанной службы BLOB-объектов не поддерживается.

Ниже приведен пример определения действия копирования со свойствами, описанными в предыдущей таблице.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

### <a name="staged-copy-billing-impact"></a>Принцип выставления счетов за промежуточное копирование

Плата наследуется на основе двух шагов: копирование длительности и типа копирования.

* При использовании промежуточного хранения во время копирования в облако, которое копирует данные из облачного хранилища данных в другое облачное хранилище данных, для обоих этапов, которые доставляются службой интеграции Azure, задается [сумма длительности копирования для шага 1 и шаг 2] x [Цена за единицу облачного копирования].
* При использовании промежуточного хранения во время гибридной копии, которая копирует данные из локального хранилища данных в облачное хранилище данных, на один этап, предоставляемый локальной средой выполнения интеграции, выставляются счета за [Длительность гибридной копии] x [Цена за единицу гибридного копирования] + [Длительность облачного копирования] x [Цена за единицу облачного копирования].

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с помощью действия копирования.

1. **Создание базовых показателей.** На этапе разработки протестируйте конвейер с помощью действия копирования в образце репрезентативных данных. Собирайте сведения о выполнении и характеристики производительности после [мониторинга действий копирования](copy-activity-overview.md#monitoring).

2. **Диагностика и оптимизация производительности.** Если наблюдаемая производительность не соответствует ожиданиям, выявление узких мест производительности. В этой статье не приведено полное описание диагностики производительности.

    В некоторых случаях при выполнении действия копирования в фабрике данных Azure отображается сообщение "советы по настройке производительности" в верхней части [страницы "Мониторинг действия копирования](copy-activity-overview.md#monitor-visually)", как показано в следующем примере. Сообщение указывает на узкое место, обнаруженное для данного запуска копирования. Кроме того, здесь рассказывается о том, что нужно изменить, чтобы повысить пропускную способность копирования. В настоящее время советы по настройке производительности предоставляют такие рекомендации:

    - Используйте Polybase при копировании данных в хранилище данных SQL Azure.
    - Увеличение числа единиц запроса Azure Cosmos DB или DTU базы данных SQL Azure (единицы пропускной способности базы данных), когда ресурс на стороне хранилища данных является узким местом.
    - Удалите ненужные промежуточные копии.

    Правила настройки производительности будут постепенно улучшаться.

    **Пример. Копирование в базу данных SQL Azure с помощью советов по настройке производительности**

    В этом примере при выполнении копирования фабрика данных Azure заметит, что база данных SQL Azure приступает к использованию уровня DTU, что замедляет операции записи. Предложение заключается в увеличении уровня базы данных SQL Azure с большим количеством DTU. 

    ![Мониторинг копирования с помощью советов по настройке производительности](./media/copy-activity-overview/copy-monitoring-with-performance-tuning-tips.png)

    Кроме того, следующие советы можно отнести к некоторым общим рекомендациям. Полное описание процесса диагностики производительности выходит за рамки данной статьи.

   * Функции для повышения производительности:
     * [Параллельное копирование](#parallel-copy)
     * [Единицы интеграции данных](#data-integration-units)
     * [Промежуточное копирование](#staged-copy)
     * [Масштабируемость локальной среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime)
   * [Локальная среда выполнения интеграции](#considerations-for-self-hosted-integration-runtime)
   * [Source](#considerations-for-the-source)
   * [Приемник](#considerations-for-the-sink)
   * [Сериализация или десериализация](#considerations-for-serialization-and-deserialization)
   * [Сжатие](#considerations-for-compression)
   * [Сопоставление столбцов](#considerations-for-column-mapping)
   * [Дополнительные рекомендации](#other-considerations)

3. **Разверните конфигурацию для всего набора данных.** Когда вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="considerations-for-self-hosted-integration-runtime"></a>Рекомендации для локальной среды выполнения интеграции

Если действие копирования выполняется в локальной среде выполнения интеграции, обратите внимание на следующее:

**Настройка**. Для размещения среды выполнения интеграции рекомендуется использовать выделенный компьютер. См. [рекомендации по использованию локальной среды выполнения интеграции](concepts-integration-runtime.md).

**Развертывание**. Одна логическая локальная среда выполнения интеграции с одним или несколькими узлами может обслуживать несколько одновременных операций копирования одновременно. Если вы испытываете потребность в гибридном перемещении данных с большим количеством выполняемых операций копирования или при копировании большого объема данных, рассмотрите возможность [масштабирования локальной среды выполнения интеграции](create-self-hosted-integration-runtime.md#high-availability-and-scalability) для предоставления дополнительных ресурсов, чтобы расширить возможности копирования.

## <a name="considerations-for-the-source"></a>Рекомендации для источника

### <a name="general"></a>Общее

Убедитесь, что базовое хранилище данных не перегружено другими рабочими нагрузками, которые выполняются на сервере или.

Сведения о хранилищах данных Майкрософт см. в разделе [мониторинг и Настройка разделов](#performance-reference) , относящихся к хранилищам данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* При копировании данных из хранилища BLOB-объектов в хранилище данных SQL рассмотрите возможность использования Polybase для повышения производительности. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store рекомендуется использовать DistCp для повышения производительности. Дополнительные сведения см. [в статье Использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных из RedShift в хранилище данных SQL Azure, хранилище BLob-объектов Azure или Azure Data Lake Store рекомендуется использовать выгрузку для повышения производительности. Дополнительные сведения см. [в статье Использование ВЫгрузки для копирования данных из Amazon RedShift](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Средний размер файла и число файлов**. Действие копирования передает данные по одному файлу за раз. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. По возможности объедините небольшие файлы в файлы большего размера, чтобы получить более высокую пропускную способность.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Шаблон данных**. Схема таблицы влияет на пропускную способность копирования. Большой размер строки обеспечивает лучшую производительность по сравнению с небольшим размером строки для копирования того же объема данных. Причина состоит в том, что база данных может более эффективно извлекать меньшее число пакетов данных, которые содержат меньше строк.
* **Запрос или хранимая процедура.** Оптимизируйте логику запроса или хранимой процедуры, указанной в источнике действия копирования, для более эффективного получения данных.

## <a name="considerations-for-the-sink"></a>Рекомендации для приемника

### <a name="general"></a>Общее

Убедитесь, что базовое хранилище данных не перегружено другими рабочими нагрузками, которые выполняются на сервере или.

Сведения о хранилищах данных Майкрософт см. в разделе [мониторинг и Настройка разделов](#performance-reference) , относящихся к хранилищам данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* При копировании данных из любого хранилища данных в хранилище данных SQL Azure рассмотрите возможность использования Polybase для повышения производительности. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store рекомендуется использовать DistCp для повышения производительности. Дополнительные сведения см. [в статье Использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных из RedShift в хранилище данных SQL Azure, хранилище BLOB-объектов Azure или Azure Data Lake Store рекомендуется использовать выгрузку для повышения производительности. Дополнительные сведения см. [в статье Использование ВЫгрузки для копирования данных из Amazon RedShift](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Режим копирования.** Если скопировать данные из другого файлового хранилища данных, действие копирования имеет три параметра через свойство **copyBehavior** . сохранение иерархии, преобразование в плоскую структуру или объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Поведение копирования и результат анализа производительности**: Существует несколько способов записи данных в приемник SQL. Ознакомьтесь с [рекомендациями по загрузке данных в базу данных SQL Azure](connector-azure-sql-database.md#best-practice-for-loading-data-into-azure-sql-database).

* **Шаблон данных и размер пакета**.
  * Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
  * Действие копирования вставляет данные в серии пакетов. Количество строк в пакете можно задать с помощью свойства **writeBatchSize** . Если данные содержатся в строках небольшого размера, можно задать для свойства **writeBatchSize** более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Если данные содержатся в строках большого размера, будьте внимательны при увеличении **writeBatchSize**. Высокое значение может привести к сбою копирования из-за перегрузки базы данных.

### <a name="nosql-stores"></a>Хранилища NoSQL

* Для **хранилища таблиц**:
  * **Секционирование.** Запись данных в секции с чередованием значительно снижает производительность. Отсортируйте исходные данные по ключу секции, чтобы эти данные можно было эффективно вставлять в одну секцию после другой. Также можно настроить логику для записи данных в одну секцию.

## <a name="considerations-for-serialization-and-deserialization"></a>Рекомендации по сериализации и десериализации

Сериализация и десериализация могут возникать, если входной набор данных или выходной набор данных являются файлами. Дополнительные сведения о поддерживаемых форматах файлов с помощью действия копирования см. в разделе [Поддерживаемые форматы файлов и сжатия](supported-file-formats-and-compression-codecs.md).

**Режим копирования.**

* При копировании файлов между файловыми хранилищами данных:
  * Если входные и выходные наборы данных имеют одинаковый формат или не имеют параметров формата файла, служба перемещения будет выполнять *двоичную копию* без сериализации или десериализации. В этом случае пропускная способность будет более высокой, чем в сценарии, когда параметры формата файла источника и приемника отличаются друг от друга.
  * Если входные и выходные наборы данных находятся в текстовом формате, а только тип кодировки отличается, служба перемещения данных выполняет только преобразование кодирования. При этом сериализация и десериализация применяться не будут. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
  * Если входные и выходные наборы данных имеют разные форматы файлов или различные конфигурации, например разделители, служба перемещения может десериализовать исходные данные в поток, преобразовать, а затем сериализовать их в указанный формат вывода. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
* При копировании файлов в хранилище данных или из него, не основанном на файлах, например из файлового хранилища в реляционное хранилище, необходимо выполнить шаг сериализации или десериализации. Этот шаг существенно снижает производительность.

**Формат файлов**. Используемый формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Avro является более затратным для сериализации и десериализации, что приводит к снижению пропускной способности копирования по сравнению с текстовым форматом. 

Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — Начните с:

- Сведения о форме, в которой хранятся данные, исходные хранилища данных или для извлечения из внешних систем.
- Наилучший формат для хранения, аналитической обработки и выполнения запросов.
- В каком формате данные должны экспортироваться в киоски данных для средств создания отчетов и визуализации.

Иногда формат файла, который не является достаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## <a name="considerations-for-compression"></a>Рекомендации по сжатию

Если входной или выходной набор данных является файлом, можно задать действие копирования для выполнения сжатия или распаковки при записи данных в назначение. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы. Однако взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных вы можете столкнуться с увеличением общей пропускной способности копирования.

**Кодек**. Каждый кодек сжатия имеет свои преимущества. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, так как ее можно разделить для обработки. GZIP является наиболее сбалансированным вариантом, который используется чаще всего. Следует выбрать кодек, который лучше всего подходит для комплексного сценария.

**Уровень**. Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Параметр самый быстрый сжатый сжимает данные как можно быстрее, даже если итоговый файл не был оптимально сжат. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация.** При копировании данных большого объема между локальным хранилищем и облаком для сжатия можно воспользоваться [промежуточным копированием](#staged-copy) с включенным сжатием данных. Использование промежуточного хранилища полезно, когда пропускная способность корпоративной сети и служб Azure является ограничивающим фактором, и требуется, чтобы входной набор данных и выходной набор данных находящегося в несжатом виде.

## <a name="considerations-for-column-mapping"></a>Рекомендации по сопоставлению столбцов

Можно задать свойство **columnMappings** в действии копирования, чтобы связать все или подмножество входных столбцов с выходными столбцами. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если данные в источнике доступны для запросов, например при использовании реляционного хранилища (база данных SQL или SQL Server) или хранилища NoSQL (хранилище таблиц или Azure Cosmos DB), вместо использования сопоставления столбцов для свойства **query** можно передать фильтрацию столбцов и логику переупорядочивания. Таким образом, проекция происходит, когда служба перемещения данных считывает данные из исходного хранилища данных, где они гораздо более эффективны.

Дополнительные сведения см. в статье [сопоставление схем действий копирования](copy-activity-schema-and-type-mapping.md).

## <a name="other-considerations"></a>Дополнительные рекомендации

Если размер копируемых данных большой, можно настроить бизнес-логику для дальнейшей секционирования данных. Вы можете запланировать более частое выполнение действия копирования, чтобы уменьшить размер данных для каждого выполняемого действия копирования.

Соблюдайте осторожность в отношении количества наборов данных и действий копирования, требующих одновременного подключения к одному и тому же хранилищу данных Azure. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к снижению производительности, внутренним повторным попыткам выполнения действия копирования, а в некоторых случаях — к сбоям выполнения.

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a>Пример сценария. Копирование из локального сервера SQL Server в хранилище BLOB-объектов

**Сценарий**. Конвейер построен для копирования данных из локального сервера SQL Server в хранилище BLOB-объектов в формате CSV. Для ускорения выполнения задания копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ**. Пропускная способность действия копирования меньше 2 Мбит/с, что значительно медленнее, чем тест производительности.

**Анализ и оптимизация производительности.** Чтобы устранить проблемы производительности, сначала необходимо рассмотреть процесс обработки и перемещения данных.

- **Чтение данных.** Среда выполнения интеграции открывает соединение с SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в среду выполнения интеграции через интрасеть.
- **Сериализация и сжатие данных**. Среда выполнения интеграции сериализует поток данных в формат CSV и сжимает данные в поток bzip2.
- **Запись данных.** Среда выполнения интеграции передает поток bzip2 в хранилище BLOB-объектов через Интернет.

Как видите, данные обрабатываются и перемещаются последовательно в потоковой передаче: SQL Server > локальная сеть > среда выполнения интеграции > глобальная сеть > хранилище BLOB-объектов. Общая производительность распределяется по минимальной пропускной способности в конвейере.

![Поток данных](./media/copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут вызвать узкое место производительности.

* **Источник.** SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
* Локальная **Среда выполнения интеграции**:
  * **Локальная сеть.** Среда выполнения интеграции находится далеко от компьютера SQL Server и характеризуется низкой пропускной способностью.
  * **Среда выполнения интеграции.** Выполнение следующих операций привело к достижению ограничений нагрузки для среды выполнения интеграции.
    * **Сериализация**. Сериализация потока данных в формат CSV характеризуется низкой пропускной способностью.
    * **Сжатие.** Вы выбрали кодек для сжатия, например bzip2, который находится в 2,8 Мбит/с с ядром i7.
  * **Глобальная сеть.** Низкая пропускная способность между корпоративной сетью и службами Azure мала, например T1 = 1 544 кбит/с; T2 = 6 312 кбит/с.
* **Приемник.** Хранилище BLOB-объектов имеет низкую пропускную способность. Этот сценарий маловероятно, поскольку его соглашение об уровне обслуживания (SLA) гарантировано не менее 60 Мбит/с.

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.

## <a name="references"></a>Ссылки

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Служба хранилища Azure, которая включает хранилище BLOB-объектов и хранилище таблиц: [Целевые показатели масштабируемости службы хранилища Azure](../storage/common/storage-scalability-targets.md) и [производительность службы хранилища Azure и контрольный список масштабируемости](../storage/common/storage-performance-checklist.md).
* Подключение к базе данных SQL Azure и Можно [отслеживать производительность](../sql-database/sql-database-single-database-monitor.md) и проверять процент единиц транзакций базы данных (DTU).
* Хранилище данных SQL Azure. Его возможности измеряются в единицах использования хранилища данных (Dwu). См. статью [Управление возможностями вычислений в хранилище данных SQL Azure (обзор)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB — [Уровни производительности в Azure Cosmos DB](../cosmos-db/performance-levels.md).
* Локальный сервер SQL Server. [Мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx).
* Локальный файловый сервер. [Настройка производительности файловых серверов](https://msdn.microsoft.com/library/dn567661.aspx).

## <a name="next-steps"></a>Следующие шаги
См. Другие статьи о действиях копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Сопоставление схемы действия копирования](copy-activity-schema-and-type-mapping.md)
- [Отказоустойчивость действия копирования в фабрике данных Azure](copy-activity-fault-tolerance.md)
