---
title: Производительности действия копирования руководство по настройке в фабрике данных Azure | Документация Майкрософт
description: Узнайте о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure, при использовании действия копирования.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 06/10/2019
ms.author: jingwang
ms.openlocfilehash: 3ea89e9f6a6bb8a4c377c70bbe1b5540d3b74d44
ms.sourcegitcommit: a12b2c2599134e32a910921861d4805e21320159
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/24/2019
ms.locfileid: "67341246"
---
# <a name="copy-activity-performance-and-tuning-guide"></a>Производительности действия копирования руководство по настройке
> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)


Действие копирования фабрики данных Azure обеспечивает первоклассную безопасных, надежных и высокопроизводительных решение для загрузки данных. Его можно использовать для Копировать десятки терабайтов данных каждый день на широкие возможности различных облачных и локальных хранилищ данных. Производительность быстро загрузки данных является ключ, чтобы убедиться, что можно сосредоточиться на Основная проблема больших данных: создании решений расширенной аналитики и получении ценной информации из данных.

Azure предоставляет набор корпоративного решения хранилища данных хранилища и данных. Действие копирования предлагает высокой степенью оптимизации загрузки интерфейс, который прост в установке и настройке данных. С помощью отдельного действия копирования можно загрузить данные в:

* Хранилище данных Azure SQL в 1,2 Гбит/с.
* Хранилище BLOB-объектов в 1,0 Гбит/с.
* Azure Data Lake Store в 1,0 Гбит/с.

Содержание статьи

* [Контрольные показатели производительности](#performance-reference) для поддерживаемых хранилищ данных источника и приемника для планирования проекта.
* Функции, которые могут значительно повысить пропускную способность копирования в различных сценариях, включая [единицы интеграции данных](#data-integration-units) (DIUs), [параллельное копирование](#parallel-copy), и [промежуточное копирование](#staged-copy).
* [Рекомендации по настройке производительности](#performance-tuning-steps) о том, как настройка производительности и ключевые факторы, которые могут повлиять на производительность копирования.

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, см. в разделе [об обзоре действия копирования](copy-activity-overview.md) перед чтением этой статьи.
>

## <a name="performance-reference"></a>Базовые показатели производительности

Как ссылка в следующей таблице показаны показатели пропускной способности в Мбит/с для заданного источника и на основе пар приемника в выполнения отдельного действия копирования в ходе внутреннего тестирования. Для сравнения также демонстрируется, как разные параметры [единицы интеграции данных](#data-integration-units) или [масштабируемость среды выполнения интеграции с самостоятельным размещением](concepts-integration-runtime.md#self-hosted-integration-runtime) (несколько узлов) могут помочь определить производительность копирования.

![Матрица производительности](./media/copy-activity-performance/CopyPerfRef.png)

> [!IMPORTANT]
> При выполнении действия копирования в среде выполнения интеграции Azure минимальное разрешенных данных интеграции единицы измерения (ранее известные как единицы перемещения данных) равно двум. Если не указан, см. в разделе данных интеграции единицы измерения по умолчанию, используемых в [единицы интеграции данных](#data-integration-units).

**Примечания:**

* Пропускная способность вычисляется по следующей формуле: [размер данных, считанных из источника] / [длительность выполнения действия копирования].
* Контрольные показатели производительности в таблице были измерены с использованием [TPC-H](http://www.tpc.org/tpch/) набора данных в выполнения отдельного действия копирования. Файлы теста для файлового хранилища находятся несколько файлов с 10 ГБ, размер.
* При использовании хранилищ данных Azure источник и приемник находились в одном регионе Azure.
* Для гибридного копирования между локальным и облачным хранилищами данных, каждый узел среды выполнения интеграции была запущена на компьютере, который был отделен от хранилища данных с помощью следующей спецификации. При выполнении одного действия операция копирования потребляла только небольшую часть ресурсов ЦП, памяти и пропускной способности сети на тестовом компьютере.
    <table>
    <tr>
        <td>ЦП</td>
        <td>Intel Xeon E5-2660 v2, 32 ядра с частотой 2,20 ГГц</td>
    </tr>
    <tr>
        <td>Память</td>
        <td>128 ГБ</td>
    </tr>
    <tr>
        <td>Сеть</td>
        <td>Веб-интерфейс: 10 Гбит/с; интерфейс интрасети: 40 Гбит/с</td>
    </tr>
    </table>


> [!TIP]
> Пропускную способность можно повысить, используя дополнительные DIUs. Например с 100 DIUs можно скопировать данные из хранилища BLOB-объектов Azure в Azure Data Lake Store в 1,0 Гбит/с. Дополнительные сведения об этой функции и поддерживаемый сценарий см. в разделе [единицы интеграции данных](#data-integration-units) раздел. 

## <a name="data-integration-units"></a>Единицы интеграции данных

Подразделение интеграции данных — это мера, представляющая производительность (сочетание ЦП, памяти, выделенных ресурсов и сети) одной единицы в фабрике данных Azure. Единица интеграции данных применяется только к [среды выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime), но не [локальная среда выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime).

Минимальный DIUs для выполнения действия копирования равно двум. В следующей таблице перечислены количества единиц интеграции данных, используемые по умолчанию в различных сценариях копирования, если другое значение не указано:

| Сценарий копирования | Число единиц интеграции данных, устанавливаемое по умолчанию службой |
|:--- |:--- |
| Копирование данных между файловыми хранилищами | От 4 до 32, в зависимости от числа и размера файлов |
| Все остальные сценарии копирования | 4\. |

Чтобы переопределить это значение по умолчанию, укажите значение для свойства **dataIntegrationUnits**, как показано ниже. *Допустимые значения* для **dataIntegrationUnits** задано до 256. *Фактическое число единиц интеграции данных*, используемых при копировании, не превышает заданного значения, в зависимости от формата данных. Сведения о том, как можно повысить уровень производительности, настроив дополнительные единицы для определенного источника и приемника, см. в [справочнике по производительности](#performance-reference).

Вы увидите DIUs, используемый для каждого выполнения в выходных данных действия копирования, при мониторинге выполнение действия копирования. Дополнительные сведения см. в разделе [мониторинг](copy-activity-overview.md#monitoring).

> [!NOTE]
> Параметр DIUs больше четырех в настоящее время применяется только в том случае, при копировании нескольких файлов из хранилища Azure, хранилище Озера данных Azure, Amazon S3, Google Cloud Storage, облака FTP или облака SFTP в другие хранилища данных облачных.
>

**Пример**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "dataIntegrationUnits": 32
        }
    }
]
```

### <a name="data-integration-units-billing-impact"></a>Влияние единиц интеграции данных на выставление счетов

Помните, что плата взимается на общее время операции копирования. Общая длительность, которую вы получите счет для перемещения данных равно сумме длительности между DIUs. Если задание копирования обычно занимало один час и две облачные единицы, а теперь на это требуется 15 минут и восемь облачных единиц, то стоимость практически не изменится.

## <a name="parallel-copy"></a>Параллельное копирование

Можно использовать **parallelCopies** свойство, указывающее параллелизма, которые вы хотите использовать действие копирования. Это свойство можно считать максимальное число потоков в рамках действия копирования, который может считывать данные из источника или записывать в приемник хранилища данных в параллельном режиме.

Для каждого выполнения действия копирования фабрики данных Azure определяет количество параллельных копий для копирования данных из исходного хранилища данных для целевых данных хранения. По умолчанию число параллельных копий, используемых им зависит от типа источника и приемника, который используется.

| Сценарий копирования | Число параллельных копий по умолчанию, определенное службой |
| --- | --- |
| Копирование данных между файловыми хранилищами |Зависит от размера файлов и число DIUs, используемых для копирования данных между двумя облачными хранилищами данных или в пределах физической конфигурации компьютера среды выполнения интеграции. |
| Копирование данных из любого хранилища данных в хранилище таблиц Azure |4\. |
| Все остальные сценарии копирования |1 |

> [!TIP]
> При копировании данных между файловыми хранилищами, поведение по умолчанию обычно предоставляет оптимальную пропускную способность. Поведение по умолчанию определен автоматически.

Чтобы управлять загрузкой компьютеров, на которых размещены ваши данные хранилища, или настроить производительность копирования, можно переопределить значение по умолчанию и указать значение для **parallelCopies** свойство. Значение должно быть целым числом больше или равно 1. Во время выполнения для повышения производительности, действие копирования использует значение, которое меньше или равно значению, заданное.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

**Примечания:**

* При копировании данных между файловыми хранилищами **parallelCopies** определяет параллелизм на уровне файлов. Фрагментирование в пределах одного файла происходит внутри автоматически и незаметно для пользователей. Он предназначен для использования лучше всего подходит фрагмента данных размера для заданного исходного типа хранилища данных для загрузки данных в параллельном режиме и независимая от **parallelCopies**. Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов. Если режим копирования — **mergeFile**, действие копирования не может воспользоваться преимуществами параллелизма на уровне файла.
* Если указать значение для **parallelCopies** свойство, рассмотрите увеличение нагрузки на источника и приемника хранилища данных. Также следует учитывать увеличение нагрузки в среду выполнения интеграции, если действие копирования средой, например, для гибридного копирования. Это увеличение нагрузки происходит, особенно если у вас несколько действий или параллельных выполнений одинаковых действий, которые выполняются в то же хранилище данных. Если вы заметили, что в хранилище данных или локальная среда выполнения интеграции перегружены нагрузки, уменьшить **parallelCopies** значение, чтобы снизить загрузку.
* При копировании данных из хранилищ, которые не являются на основе файлов для хранилищ, которые основаны на файлах, служба перемещения данных игнорирует **parallelCopies** свойство. В этом случае параллелизм не применяется, даже если задан соответствующий параметр.
* **ParallelCopies** свойство не связано с **dataIntegrationUnits**. Первое из них учитывается для всех единиц интеграции данных.

## <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

- **Вы хотите принимать данные из различных хранилищ данных в хранилище данных SQL через PolyBase.** Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Исходные данные должны находиться в хранилище BLOB-объектов или Azure Data Lake Store, и он должен удовлетворять дополнительные критерии. При загрузке данных не из хранилища BLOB-объектов или Azure Data Lake Store можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае фабрика данных Azure выполняет необходимые преобразования данных, чтобы обеспечить соответствие требованиям PolyBase. Затем она эффективно загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
- **Иногда требуется некоторое время для выполнения гибридного перемещения данных (то есть для копирования из локальной среды хранилища данных в Облачное хранилище данных) через медленное сетевое подключение.** Чтобы повысить производительность, можно использовать промежуточное копирование для сжатия данных на предприятии, занимала меньше времени для перемещения данных в промежуточное хранилище в облаке. Затем распакуйте данные в промежуточном хранилище перед их загрузкой в целевое хранилище данных.
- **Вы не хотите открывать порты, отличные от порта 80 и 443 в брандмауэре корпоративными политиками ИТ.** Например, при копировании данных из локального хранилища в приемник Базы данных SQL Azure или приемник Хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом случае промежуточного копирования можно воспользоваться преимуществами локальной среды выполнения интеграции сначала скопировать данные в хранилище BLOB-объектов, в промежуточный экземпляр через HTTP или HTTPS через порт 443. Затем она загружает данные в базу данных SQL или хранилище данных SQL из промежуточного хранилища больших двоичных объектов. В таком сценарии не нужно включать порт 1433.

### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования

Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное хранилище BLOB-объектов (собственное). Оттуда данные копируются в приемник данных. Фабрика данных Azure автоматически управляет двухэтапной процедурой для вас. Фабрика данных Azure также удаляет временные данные из промежуточного хранилища после завершения перемещения данных.

![промежуточное копирование](media/copy-activity-performance/staged-copy.png)

При активации перемещения данных с использованием промежуточного хранилища, можно указать, следует ли в промежуточное хранилище данных будет сжат до перемещения данных из источника данных или данных промежуточного хранения и распаковку перед перемещением данных из промежуточный доступа к данным хранилище в приемник данных.

Сейчас промежуточное хранение при копировании данных между двумя локальными хранилищами не поддерживается.

### <a name="configuration"></a>Параметр Configuration

Настройка **enableStaging** параметра в действии копирования, чтобы указать, следует ли данные в промежуточное хранилище BLOB-объектов перед их загрузкой в целевое хранилище данных. При задании **enableStaging** для `TRUE`, укажите дополнительные свойства, перечисленные в следующей таблице. Также необходимо создать хранилище Azure или хранилища общего доступа подписи связанная служба для промежуточного хранения, если у вас ее нет.

| Свойство | Описание | Значение по умолчанию | Обязательно для заполнения |
| --- | --- | --- | --- |
| enableStaging |Укажите, следует ли копировать данные в промежуточное хранилище. |Ложь |Нет |
| linkedServiceName |Укажите имя связанной службы [AzureStorage](connector-azure-blob-storage.md#linked-service-properties), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Нельзя использовать хранилища с помощью подписи общего доступа для загрузки данных в хранилище данных SQL через PolyBase. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| path |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. Если вы не укажете путь, служба создаст контейнер для хранения временных данных. <br/><br/> Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |Нет |
| EnableCompression |Указывает, должны ли сжиматься данные, перед копированием в место назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |Ложь |Нет |

>[!NOTE]
> При использовании промежуточного копирования с включенным сжатием, субъекта-службы или проверки подлинности MSI для промежуточных связанного BLOB-объектов службы не поддерживается.

Ниже приведен пример определения действия копирования со свойствами, которые описаны в приведенной выше таблице:

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

### <a name="staged-copy-billing-impact"></a>Принцип выставления счетов за промежуточное копирование

Плата взимается на основе двух этапов: копирование длительности и типа копирования.

* При использовании промежуточного копирования облака, который копирует данные из облачного хранилища данных в другое хранилище данных облака, оба этапа средой выполнения интеграции Azure, будет взиматься плата [сумма длительности копирования для этапов 1 и 2] x [Цена за единицу копирования облачного].
* При использовании промежуточного гибридного копирования, который копирует данные из локального хранилища данных в Облачное хранилище данных, один этап средой выполнения интеграции, плата взимается за [длительность гибридного копирования] x [Цена единицы гибридного копирования] + [длительность облачного копирования] x [Цена за единицу копирования облачного].

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с действием копирования.

1. **Определение базовых показателей.** На этапе разработки тестирования конвейера с помощью действия копирования с образцом репрезентативных данных. Собирать сведения о выполнении и характеристики производительности см [мониторинг](copy-activity-overview.md#monitoring).

2. **Диагностика и оптимизировать производительность.** Если вы заметили производительность не соответствует вашим ожиданиям, выявите узкие места производительности. В этой статье не приведено полное описание диагностики производительности.

    В некоторых случаях при выполнении действия копирования в фабрике данных Azure, вы увидите сообщение «Советы по настройке производительности» в верхней части [мониторинга страницы действие копирования](copy-activity-overview.md#monitor-visually), как показано в следующем примере. Сообщения о том, определенный для выполнения копирования данного узкое место. Вы также ознакомитесь на что следует изменить, чтобы повысить пропускную способность копирования. Советы по настройке производительности в настоящее время предоставляют предложения, например:

    - При копировании данных в хранилище данных SQL Azure с помощью PolyBase.
    - Увеличение единиц запросов Azure Cosmos DB или Dtu базы данных SQL Azure (ед. пропускной способности базы данных), когда ресурс на стороне хранилища данных. ее узкое место.
    - Удалите ненужные промежуточного копирования.

    Правила настройки производительности будут постепенно улучшаться.

    **Пример. Скопируйте в базе данных SQL Azure с помощью советы по настройке производительности**

    В этом образце во время выполнения копирования фабрики данных Azure замечает приемник базы данных SQL Azure достигается высокий уровень использования DTU, что замедляет операции записи. Предложение является повышение уровня базы данных SQL Azure с помощью дополнительные единицы Dtu. 

    ![Мониторинг копирования с помощью советов по настройке производительности](./media/copy-activity-overview/copy-monitoring-with-performance-tuning-tips.png)

    Кроме того, следующие советы можно отнести к некоторым общим рекомендациям. Полное описание процесса диагностики производительности выходит за рамки данной статьи.

   * Функции для повышения производительности:
     * [Параллельное копирование](#parallel-copy)
     * [Единицы интеграции данных](#data-integration-units)
     * [Промежуточное копирование](#staged-copy)
     * [Масштабируемость среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime)
   * [Локальная среда выполнения интеграции](#considerations-for-self-hosted-integration-runtime)
   * [Source](#considerations-for-the-source)
   * [Приемник](#considerations-for-the-sink)
   * [Сериализация или десериализация](#considerations-for-serialization-and-deserialization)
   * [Сжатие](#considerations-for-compression)
   * [Сопоставление столбцов](#considerations-for-column-mapping)
   * [Дополнительные рекомендации](#other-considerations)

3. **Разверните конфигурацию для всего набора данных.** Если вас устраивают результаты выполнения и производительности, ее можно развернуть, определение и конвейер для всего набора данных.

## <a name="considerations-for-self-hosted-integration-runtime"></a>Рекомендации для локальной среды выполнения интеграции

Если действие копирования выполняется в локальной среде выполнения интеграции, обратите внимание на следующее:

**Настройка**. Мы рекомендуем использовать выделенный компьютер для узла среды выполнения интеграции. См. в разделе [рекомендации по использованию локальная среда выполнения интеграции](concepts-integration-runtime.md).

**Горизонтальное масштабирование.** Единый логический локальная среда выполнения интеграции с одним или несколькими узлами может обслуживать несколько запусков действия копирования в то же время, одновременно. При наличии большого объема гибридных данных для переноса с большим числом параллельных запусков действия копирования или большого объема данных для копирования рассмотрите [горизонтальное масштабирование среды выполнения интеграции](create-self-hosted-integration-runtime.md#high-availability-and-scalability) подготовить дополнительные ресурсы расширения возможностей копирования.

## <a name="considerations-for-the-source"></a>Рекомендации для источника

### <a name="general"></a>Общие сведения

Убедитесь, что хранилище данных не переполнено другими рабочими нагрузками, которые запущены на или к нему.

Для хранилищ данных корпорации Майкрософт, см. в разделе [контроля и настройки разделов](#performance-reference) , которые относятся к хранилищам данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* При копировании данных из хранилища BLOB-объектов в хранилище данных SQL, рассмотрите возможность использования PolyBase для повышения производительности. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store, рассмотрите возможность использования DistCp для повышения производительности. Дополнительные сведения см. в разделе [использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных из Redshift в хранилище данных SQL Azure, хранилище BLOB-объектов Azure или Azure Data Lake Store, рассмотрите возможность использования UNLOAD для повышения производительности. Дополнительные сведения см. в разделе [копирование данных из Amazon Redshift с помощью UNLOAD](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Средний размер файла и число файлов**. Действие копирования передает один файл данных за раз. При одинаковом объеме данных общая пропускная способность перемещения данных, которые состоят из большого количества небольших файлов, будет ниже, чем в случае перемещения данных, которые состоят из небольшого количества файлов большего размера. Это происходит из-за времени начальной загрузки каждого файла. Если это возможно объединяйте небольшие файлы в файлы большего размера, чтобы получить более высокую пропускную способность.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Шаблон данных**. Схема таблицы влияет на пропускную способность копирования. Большой размер строки обеспечивает лучшую производительность, чем использовании строк небольшого размера, копируемый одинаковый объем данных. Причина состоит в том, что база данных может более эффективно извлекать меньшее число пакетов данных, которые содержат меньше строк.
* **Запрос или хранимая процедура.** Оптимизируйте логику запроса или хранимой процедуры, которые указываются в источнике действия копирования, чтобы более эффективно извлекать данные.

## <a name="considerations-for-the-sink"></a>Рекомендации для приемника

### <a name="general"></a>Общие сведения

Убедитесь, что хранилище данных не переполнено другими рабочими нагрузками, которые запущены на или к нему.

Для хранилищ данных корпорации Майкрософт, см. в разделе [контроля и настройки разделов](#performance-reference) , которые относятся к хранилищам данных. В них подробно рассмотрены базовые показатели производительности хранилища данных, способы сокращения времени отклика и повышения пропускной способности.

* Если скопировать данные из любого хранилища данных в хранилище данных SQL Azure, рекомендуется использовать PolyBase для повышения производительности. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
* При копировании данных из HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Store, рассмотрите возможность использования DistCp для повышения производительности. Дополнительные сведения см. в разделе [использование DistCp для копирования данных из HDFS](connector-hdfs.md#use-distcp-to-copy-data-from-hdfs).
* При копировании данных из Redshift в хранилище данных SQL Azure, хранилище BLOB-объектов Azure или Azure Data Lake Store, рассмотрите возможность использования UNLOAD для повышения производительности. Дополнительные сведения см. в разделе [копирование данных из Amazon Redshift с помощью UNLOAD](connector-amazon-redshift.md#use-unload-to-copy-data-from-amazon-redshift).

### <a name="file-based-data-stores"></a>Файловые хранилища данных

* **Режим копирования.** При копировании данных из хранилища разных файловых данных действие копирования предусмотрено три варианта поведения через **copyBehavior** свойство. сохранение иерархии, преобразование в плоскую структуру или объединение файлов. Сохранение иерархии или преобразование в плоскую структуру практически не оказывает влияния на производительность, в то время как объединение файлов существенно ее ухудшает.
* **Формат файла и сжатие**. Дополнительные сведения о способах повышения производительности см. в разделах [Рекомендации по сериализации и десериализации](#considerations-for-serialization-and-deserialization) и [Рекомендации по сжатию](#considerations-for-compression).

### <a name="relational-data-stores"></a>Реляционные хранилища данных

* **Скопируйте поведение и производительность неявно**: Для записи данных в приемник SQL разными способами. Дополнительные сведения из [рекомендация по загрузке данных в базе данных SQL Azure](connector-azure-sql-database.md#best-practice-for-loading-data-into-azure-sql-database).

* **Шаблон данных и размер пакета**.
  * Схема таблицы влияет на пропускную способность копирования. Во время копирования данных одинакового объема использование строк большого размера позволяет добиться лучшей производительности, чем при использовании строк небольшого размера. Это связано с тем, что база данных более эффективно сохраняет меньшее количество пакетов данных.
  * Действие копирования вставляет данные в виде последовательности пакетов. Количество строк в пакете можно задать с помощью свойства **writeBatchSize** . Если данные содержатся в строках небольшого размера, можно задать для свойства **writeBatchSize** более высокое значение, чтобы использовать меньшее количество пакетов и тем самым увеличить пропускную способность. Если данные содержатся в строках большого размера, будьте внимательны при увеличении **writeBatchSize**. Высокое значение может привести к сбою копирования из-за перегрузки базы данных.

### <a name="nosql-stores"></a>Хранилища NoSQL

* Для **хранилища таблиц**:
  * **Секционирование.** Запись данных в секции с чередованием значительно снижает производительность. Отсортируйте исходные данные по ключу секции, чтобы эффективно вставлять данные в одну секцию за другим. Также можно настроить логику для записи данных в одну секцию.

## <a name="considerations-for-serialization-and-deserialization"></a>Рекомендации по сериализации и десериализации

Сериализация и десериализация может произойти, если входной набор данных или выходной набор данных представляет собой файл. Дополнительные сведения о поддерживаемых форматах файлов действием копирования, см. в разделе [поддерживаемые форматы файлов и сжатия](supported-file-formats-and-compression-codecs.md).

**Режим копирования.**

* При копировании файлов между файловыми хранилищами данных:
  * Если входные и выходные наборы данных обоих одинаковые параметры формата файла, служба перемещения данных выполнит *двоичное копирование* без сериализации или десериализации. В этом случае пропускная способность будет более высокой, чем в сценарии, когда параметры формата файла источника и приемника отличаются друг от друга.
  * Если входные данные и выходных наборов на обоих данных находятся в текстовом формате и только кодирование типа отличается, служба перемещения данных выполнит только преобразование кодирования. При этом сериализация и десериализация применяться не будут. По сравнению с двоичным копированием, это совсем незначительно повлияет на производительность.
  * Если входные и выходные наборы данных оба имеют различных форматах файлов или различные конфигурации, например отличаются разделителями, служба перемещения данных десериализует исходные данные для потоковой передачи, преобразования и затем выполнить его сериализацию в формат выходных данных, указанные вами. В отличие от предыдущих сценариев, это приведет к более значительному снижению производительности.
* При копировании файлов в или из локального хранилища данных, отсутствующий файл, в зависимости, например, из файлового хранилища с реляционным хранилищем сериализации или десериализации шаг является обязательным. Этот шаг существенно снижает производительность.

**Формат файлов**. Используемый формат файла может повлиять на производительность копирования. К примеру, Avro — это компактный двоичный формат, в котором хранятся метаданные с данными. Этот формат поддерживает экосистема Hadoop для обработки и выполнения запросов. Avro стоит дороже, для сериализации и десериализации, что приводит к способность копирования ниже по сравнению с форматом текста. 

Формат файла, который необходимо использовать в процессе обработки, следует выбирать, принимая во внимание все элементы — Начните с:

- От формы данных хранится в исходных хранилищ данных или извлекаемое из внешних систем.
- Лучший формат для хранения, аналитической обработки и запросов.
- В каком формате следует экспортировать данные в киоски данных для средств создания отчетов и визуализации.

Иногда формат файла, который не является достаточно оптимальным для производительности операций чтения и записи, может отлично подойти, учитывая общий аналитический процесс.

## <a name="considerations-for-compression"></a>Рекомендации по сжатию

Если входной или выходной набор данных представляет собой файл, можно задать действие копирования выполнить упаковку или распаковку, так как он записывает данные в место назначения. Использование сжатия — это компромисс между количеством операций ввода-вывода и потреблением ЦП, так как для сжатия данных требуются дополнительные вычислительные ресурсы. Однако взамен уменьшается количество сетевых операций ввода-вывода и используемый объем хранилища. В зависимости от данных может появиться повысить общую пропускную способность копирования.

**Кодек**. Каждый кодек сжатия имеет свои преимущества. Например, кодек BZIP2 обладает минимальной пропускной способностью копирования, но предоставляет лучшую производительность выполнения запросов Hive, так как ее можно разделить для обработки. Кодек gzip — это наиболее оптимальный вариант, и он используются наиболее часто. Следует выбрать кодек, который лучше всего подходит для комплексного сценария.

**Уровень**. Для каждого кодека сжатия можно выбрать один из двух параметров — самое быстрое сжатие или оптимальное сжатие. Параметр самого быстрого сжатия сжимает данные, как можно быстрее, даже если полученный файл не сжат оптимально. Если использовать параметр оптимального сжатия, данные сжимаются дольше, предоставляя минимальный объем данных. Можно испытать оба варианта, чтобы увидеть, который из них обеспечивает лучшую общую производительность в определенном случае.

**Рекомендация.** При копировании данных большого объема между локальным хранилищем и облаком для сжатия можно воспользоваться [промежуточным копированием](#staged-copy) с включенным сжатием данных. Использование промежуточное хранилище полезно в том случае, когда пропускной способности корпоративной сети и служб Azure является ограничивающим фактором и входной набор данных, а выходной набор данных как в несжатом виде.

## <a name="considerations-for-column-mapping"></a>Рекомендации по сопоставлению столбцов

Можно задать **columnMappings** свойство в действии копирования для сопоставления всех или подмножества входных столбцов для выходных столбцов. После считывания данных из источника службе перемещения данных требуется выполнить сопоставление столбцов данных, прежде чем записать их в приемник. Эта дополнительная обработка снижает пропускную способность копирования.

Если данные в источнике доступны для запросов, например при использовании реляционного хранилища (база данных SQL или SQL Server) или хранилища NoSQL (хранилище таблиц или Azure Cosmos DB), вместо использования сопоставления столбцов для свойства **query** можно передать фильтрацию столбцов и логику переупорядочивания. Таким образом, осуществляется проецирование служба перемещения данных считывает данные из исходного хранилища данных, где это гораздо эффективнее.

Дополнительные сведения из [сопоставление схем в действии копирования](copy-activity-schema-and-type-mapping.md).

## <a name="other-considerations"></a>Дополнительные рекомендации

Если размер данных, которые требуется скопировать, можно настроить бизнес-логику для дальнейшего секционирования данных. Вы можете запланировать более частое выполнение для уменьшения размера данных для каждого действия копирования, выполняемый действии копирования.

Необходимо следить за количество наборов данных и скопируйте действия, требующие фабрики данных Azure для подключения к одному хранилищу данных, в то же время. Большое количество одновременно выполняемых заданий копирования может привести к регулированию хранилища данных, что ведет к снижению производительности, внутренним повторным попыткам выполнения действия копирования, а в некоторых случаях — к сбоям выполнения.

## <a name="sample-scenario-copy-from-an-on-premises-sql-server-to-blob-storage"></a>Пример сценария. Копирование из локального SQL server в хранилище BLOB-объектов

**Сценарий**. Конвейер предназначен для копирования данных из локального SQL server в хранилище BLOB-объектов в формате CSV. Для ускорения выполнения задания копирования необходимо сжать CSV-файлы в формат BZIP2.

**Тестирование и анализ**. Пропускная способность действия копирования является менее чем 2 Мбит/с, — гораздо медленнее, чем в тесте производительности.

**Анализ и оптимизация производительности.** Чтобы устранить проблемы производительности, сначала необходимо рассмотреть процесс обработки и перемещения данных.

- **Чтение данных.** Среда выполнения интеграции устанавливает подключение к SQL Server и отправляет запрос. SQL Server отвечает, отправляя поток данных в среду выполнения интеграции через интрасеть.
- **Сериализация и сжатие данных**. Среда выполнения интеграции сериализует поток данных в формате CSV и сжимает данные в поток bzip2.
- **Запись данных.** Среда выполнения интеграции отправляет поток bzip2 в хранилище BLOB-объектов через Интернет.

Как вы видите, их обработки и перемещения в последовательном режиме потоковой передачи: SQL Server > локальная сеть > среда выполнения интеграции > глобальная сеть > хранилище BLOB-объектов. Общая производительность достигается при минимальной пропускной способности в конвейере.

![Поток данных](./media/copy-activity-performance/case-study-pic-1.png)

Один или несколько следующих факторов могут вызвать узкое место производительности.

* **Источник.** SQL Server отличается низкой пропускной способностью из-за высокой нагрузки.
* **Локальная среда выполнения интеграции**:
  * **Локальная сеть.** Среда выполнения интеграции находится далеко от компьютера SQL Server и характеризуется низкой пропускной способностью.
  * **Среда выполнения интеграции.** Выполнение следующих операций привело к достижению ограничений нагрузки для среды выполнения интеграции.
    * **Сериализация**. Сериализация потока данных в формат CSV характеризуется низкой пропускной способностью.
    * **Сжатие.** Вы выбрали кодек медленного сжатия, например, bzip2, который является 2,8 Мбит/с с процессором Core i7.
  * **Глобальная сеть.** Пропускная способность между корпоративной сетью и службами Azure недостаточно, например, T1 = 1544 Кбит/с; T2 = 6312 Кбит/с.
* **Приемник.** Хранилище BLOB-объектов имеет низкую пропускную способность. Это маловероятно, так как его соглашения уровня обслуживания (SLA) гарантирует не менее 60 Мбит/с.

В этом случае сжатие данных в формат BZIP2 может замедлять работу всего конвейера. Этого можно избежать, если перейти на использование кодека сжатия в формат GZIP.

## <a name="references"></a>Справочники

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Хранилище Azure, включая хранилище BLOB-объектов и хранилища таблиц: [Целевые показатели масштабируемости хранилища Azure](../storage/common/storage-scalability-targets.md) и [контрольный список производительности и масштабируемости хранилища Azure](../storage/common/storage-performance-checklist.md).
* База данных SQL Azure. Вы можете [наблюдения за производительностью](../sql-database/sql-database-single-database-monitor.md) и проверять процент единицы транзакций базы данных (DTU).
* Хранилище данных SQL Azure. Его использование измеряется в единицах использования хранилища данных (Dwu). См. в разделе [управление вычислительными ресурсами в хранилище данных SQL Azure (Обзор)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB — [Уровни производительности в Azure Cosmos DB](../cosmos-db/performance-levels.md).
* Локальный сервер SQL Server. [Наблюдение и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx).
* Локальный файловый сервер. [Настройка производительности для файловых серверов](https://msdn.microsoft.com/library/dn567661.aspx).

## <a name="next-steps"></a>Дальнейшие действия
Ознакомьтесь со статьями действия копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Сопоставление схем в действии копирования](copy-activity-schema-and-type-mapping.md)
- [Отказоустойчивость действия копирования в фабрике данных Azure](copy-activity-fault-tolerance.md)
