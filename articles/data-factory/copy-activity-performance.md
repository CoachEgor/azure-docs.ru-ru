---
title: Рекомендации по производительности и масштабируемости действий копирования в фабрике данных Azure
description: Сведения о ключевых факторах, влияющих на производительность перемещения данных в фабрике данных Azure при использовании действия копирования.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 10/24/2019
ms.author: jingwang
ms.openlocfilehash: 701eaad8d36b352e946ae8d74204876b41ecb53d
ms.sourcegitcommit: 609d4bdb0467fd0af40e14a86eb40b9d03669ea1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/06/2019
ms.locfileid: "73678266"
---
# <a name="copy-activity-performance-and-scalability-guide"></a>Инструкции по повышению производительности и масштабируемости действия копирования
> [!div class="op_single_selector" title1="Выберите версию фабрики данных Azure, которую вы используете:"]
> * [Версия 1](v1/data-factory-copy-activity-performance.md)
> * [Текущая версия](copy-activity-performance.md)

Если вы хотите выполнить крупномасштабную миграцию данных из Data Lake или корпоративного хранилища данных (EDW) в Azure или хотите принимать данные в масштабе из разных источников в Azure для анализа больших данных, крайне важно добиться оптимальной производительности и масштабируемости.  Фабрика данных Azure предоставляет мощный, устойчивый и экономичный механизм для приема данных в масштабе, что делает их отличными для специалистов по разработке данных, которые ищут высокопроизводительные и масштабируемые конвейеры приема данных.

После прочтения этой статьи вы сможете ответить на следующие вопросы:

- Какой уровень производительности и масштабируемости можно достичь с помощью действия копирования ADF для переноса данных и сценариев приема данных?

- Какие действия следует предпринять для настройки производительности действия копирования ADF?
- Какие счетчики производительности ADF можно использовать для оптимизации производительности при выполнении одного действия копирования?
- Какие другие факторы выходят за пределы ADF, которые следует учитывать при оптимизации производительности копирования?

> [!NOTE]
> Если вы не знакомы с действием копирования в целом, ознакомьтесь с [обзором действия копирования](copy-activity-overview.md) , прежде чем приступить к ознакомлению с этой статьей.

## <a name="copy-performance-and-scalability-achievable-using-adf"></a>Производительность и масштабируемость копирования, которые додостижимы с помощью ADF

ADF предлагает бессерверную архитектуру, которая обеспечивает параллелизм на разных уровнях, что позволяет разработчикам создавать конвейеры для полного использования пропускной способности сети, а также операций ввода-вывода и пропускной способности хранилища для максимального увеличения пропускной способности перемещения данных для вашей среды.  Это означает, что можно оценить пропускную способность, которая может быть достигнута путем измерения минимальной пропускной способности, предоставляемой исходным хранилищем данных, конечным хранилищем данных и пропускной способностью сети между источником и назначением.  В следующей таблице вычисляется длительность копирования на основе размера данных и ограничения пропускной способности для вашей среды. 

| Размер данных/ <br/> bandwidth | 50 Мбит/с    | 100 Мбит/с  | 500 Мбит/с  | 1 Гбит/с   | 5 Гбит/с   | 10 Гбит/с  | 50 Гбит/с   |
| --------------------------- | ---------- | --------- | --------- | -------- | -------- | -------- | --------- |
| **1 ГБ**                    | 2,7 мин    | 1,4 мин   | 0,3 мин   | 0,1 мин  | 0,03 мин | 0,01 мин | 0,0 мин   |
| **10 ГБ**                   | 27,3 мин   | 13,7 мин  | 2,7 мин   | 1,3 мин  | 0,3 мин  | 0,1 мин  | 0,03 мин  |
| **100 ГБ**                  | 4,6 часов    | 2,3 часов   | 0,5 часов   | 0,2 часов  | 0,05 часов | 0,02 часов | 0,0 часов   |
| **1 ТБ**                    | 46,6 часов   | 23,3 часов  | 4,7 часов   | 2,3 часов  | 0,5 часов  | 0,2 часов  | 0,05 часов  |
| **10 ТБ**                   | 19,4 дней  | 9,7 дней  | 1,9 дней  | 0,9 дней | 0,2 дней | 0,1 дней | 0,02 дней |
| **100 ТБ**                  | 194,2 дней | 97,1 дней | 19,4 дней | 9,7 дней | 1,9 дней | 1 день   | 0,2 дней  |
| **1 ПБ**                    | 64,7 Mo    | 32,4 Mo   | 6,5 mo    | 3,2 mo   | 0,6 Mo   | 0,3 Mo   | 0,06 Mo   |
| **10 ПБ**                   | 647,3 Mo   | 323,6 Mo  | 64,7 Mo   | 31,6 Mo  | 6,5 mo   | 3,2 mo   | 0,6 Mo    |

Копия ADF масштабируется на разных уровнях:

![как в ADF копируется масштабирование](media/copy-activity-performance/adf-copy-scalability.png)

- Поток управления ADF может запускать несколько операций копирования параллельно, например, с использованием [циклов for each](control-flow-for-each-activity.md).
- Одно действие копирования может воспользоваться преимуществами масштабируемых вычислений: при использовании Azure Integration Runtime можно указать [до 256 диус](#data-integration-units) для каждого действия копирования на бессерверном сервере. При использовании автономного Integration Runtime можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до 4 узлов](create-self-hosted-integration-runtime.md#high-availability-and-scalability)), и одно действие копирования будет секционировать набор файлов на всех узлах.
- Одно действие копирования считывает и выполняет запись в хранилище данных, используя несколько потоков [параллельно](#parallel-copy).

## <a name="performance-tuning-steps"></a>Этапы настройки производительности

Выполните следующие действия, чтобы настроить производительность службы фабрики данных Azure с помощью действия копирования.

1. **Выберите тестовый набор данных и создайте базовый план.** На этапе разработки протестируйте конвейер с помощью действия копирования в образце репрезентативных данных. Выбранный набор данных должен представлять стандартные шаблоны данных (структуру папок, шаблон файла, схему данных и т. д.) и достаточно велика для оценки производительности копирования, например для завершения операции копирования занимает 10 минут или больше. Собирайте сведения о выполнении и характеристики производительности после [мониторинга действий копирования](copy-activity-overview.md#monitoring).

2. **Как повысить производительность одного действия копирования**:

   Для начала рекомендуется сначала повысить производительность с помощью одного действия копирования.

   **Если действие копирования выполняется в Azure Integration Runtime:**

   Начните со значений по умолчанию для [единиц интеграции данных (Диу)](#data-integration-units) и параметров [параллельного копирования](#parallel-copy) .  Выполните тест производительности и запишите показатели производительности, а также фактические значения, используемые для диус и параллельных копий.  Сведения о том, как получить результаты выполнения и используемые параметры производительности, см. в статье [мониторинг действий копирования](copy-activity-overview.md#monitoring) .

   Теперь выполните дополнительные тесты производительности, каждый раз построив значение параметра Диу.  Кроме того, если вы считаете, что производительность достигается при использовании параметра по умолчанию, гораздо ниже, чем предполагается, вы можете значительно увеличить значение параметра Диу в последующем тестовом запуске.

   Действие копирования должно масштабироваться почти полностью линейно по мере увеличения значения параметра Диу.  Если при удвоении параметра Диу пропускная способность не видна, то может произойти две вещи:

   - Для конкретного шаблона копирования, который вы используете, не требуется добавлять дополнительные диус.  Даже если было указано большее значение Диу, фактически использованный Диу остается тем же, и поэтому вы получаете ту же пропускную способность, что и раньше.  В этом случае можно максимально увеличить общую пропускную способность, запустив несколько копий одновременно с шагом 3.
   - Добавляя дополнительные диус (более высокий уровень) и тем самым уменьшая скорость извлечения, передачи и загрузки данных, хранилище исходных данных, сеть между или целевое хранилище данных достигла узкого места и, возможно, регулируется.  В этом случае попробуйте обратиться к администратору хранилища данных или администратору сети, чтобы увеличить верхний предел, или же уменьшите значение параметра Диу до тех пор, пока регулирование не будет остановлено.

   **Если действие копирования выполняется на автономной Integration Runtime:**

   Рекомендуется использовать выделенный компьютер отдельно от сервера, на котором размещено хранилище данных, для размещения среды выполнения интеграции.

   Начните со значений по умолчанию для параметра [параллельной копии](#parallel-copy) и с помощью одного узла для автономной среды IR.  Выполните тест производительности и запомните, что производительность достигнута.

   Если вы хотите добиться более высокой пропускной способности, можно увеличить или уменьшить масштаб для локальной среды IR:

   - Если ЦП и доступная память на автономном узле IR не используются полностью, но выполнение параллельных заданий достигает предела, необходимо увеличить масштаб, увеличив число параллельных заданий, которые могут выполняться на узле.  Инструкции см. [здесь](create-self-hosted-integration-runtime.md#scale-up) .
   - С другой стороны, если ЦП высок на свободно размещенном IR-узле или объем доступной памяти низкий, можно добавить новый узел, чтобы расширить нагрузку между несколькими узлами.  Инструкции см. [здесь](create-self-hosted-integration-runtime.md#high-availability-and-scalability) .

   При увеличении или уменьшении емкости локальной среды IR повторите тест производительности, чтобы узнать, не повышается ли пропускная способность.  Если пропускная способность больше не работает, скорее всего, хранилище исходных данных, сеть между или целевое хранилище данных достигло узкого места и начинает регулироваться. В этом случае попробуйте обратиться к администратору хранилища данных или администратору сети, чтобы увеличить верхний предел, или же вернитесь к предыдущему параметру масштабирования для локальной среды IR. 

3. **Как максимально увеличить общую пропускную способность, одновременно выполнив несколько копий:**

   Теперь, когда вы установили максимальную производительность одного действия копирования, если вы еще не настроили верхние пределы пропускной способности вашей среды — сети, исходного хранилища данных и целевого хранилища данных, вы можете параллельно запускать несколько действий копирования с помощью ADF. конструкции потока управления, такие как [цикл for each](control-flow-for-each-activity.md).

4. **Советы по настройке производительности и функции оптимизации.** В некоторых случаях при выполнении действия копирования в фабрике данных Azure отображается сообщение "советы по настройке производительности" на основе [наблюдения за действиями копирования](copy-activity-overview.md#monitor-visually), как показано в следующем примере. Сообщение указывает на узкое место, обнаруженное для данного запуска копирования. Кроме того, здесь рассказывается о том, что нужно изменить, чтобы повысить пропускную способность копирования. В настоящее время советы по настройке производительности предоставляют такие рекомендации:

   - Используйте Polybase при копировании данных в хранилище данных SQL Azure.
   - Увеличение числа единиц запроса Azure Cosmos DB или DTU базы данных SQL Azure (единицы пропускной способности базы данных), когда ресурс на стороне хранилища данных является узким местом.
   - Удалите ненужные промежуточные копии.

   Правила настройки производительности будут постепенно улучшаться.

   **Пример. копирование в базу данных SQL Azure с помощью советов по настройке производительности**

   В этом примере при выполнении копирования фабрика данных Azure заметит, что база данных SQL Azure приступает к использованию уровня DTU, что замедляет операции записи. Предложение заключается в увеличении уровня базы данных SQL Azure с большим количеством DTU. 

   ![Мониторинг копирования с помощью советов по настройке производительности](media/copy-activity-overview/copy-monitoring-with-performance-tuning-tips.png)

   Кроме того, ниже приведены некоторые функции оптимизации производительности, о которых следует помнить.

   - [Параллельное копирование](#parallel-copy)
   - [Единицы интеграции данных](#data-integration-units)
   - [Промежуточное копирование](#staged-copy)
   - [Масштабируемость локальной среды выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime)

5. **Разверните конфигурацию для всего набора данных.** Когда вы удовлетворены результатами выполнения и производительностью, вы можете расширить определение и конвейер, чтобы охватить весь набор данных.

## <a name="copy-performance-optimization-features"></a>Копирование функций оптимизации производительности

Фабрика данных Azure предоставляет следующие возможности оптимизации производительности.

- [Параллельное копирование](#parallel-copy)
- [Единицы интеграции данных](#data-integration-units)
- [Промежуточное копирование](#staged-copy)

### <a name="data-integration-units"></a>Единицы интеграции данных

Единица интеграции данных — это мера, представляющая мощность (сочетание ЦП, памяти и выделения ресурсов сети) одного блока в фабрике данных Azure. Единица интеграции данных применяется только к [среде выполнения интеграции Azure](concepts-integration-runtime.md#azure-integration-runtime), но не к локальной [среде выполнения интеграции](concepts-integration-runtime.md#self-hosted-integration-runtime).

Вам будет выставляться плата за **Использование диус \* длительность копирования \* Цена за единицу/Диу-час**. Текущие цены см. [здесь](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/). Местная валюта и отдельные скидки могут применяться для каждого типа подписки.

Допустимый диус для повышения производительности действия копирования составляет **от 2 до 256**. Если вы не указали или выбираете "Auto" в пользовательском интерфейсе, фабрика данных динамически применит оптимальный параметр Диу на основе пары "источник-приемник" и шаблона данных. В следующей таблице перечислены диус по умолчанию, используемые в различных сценариях копирования.

| Сценарий копирования | Число единиц интеграции данных, устанавливаемое по умолчанию службой |
|:--- |:--- |
| Копирование данных между файловыми хранилищами | От 4 до 32 в зависимости от числа и размера файлов |
| Копирование данных в базу данных SQL Azure или Azure Cosmos DB |От 4 до 16 в зависимости от уровня приемника базы данных SQL Azure или Cosmos DB (число DTU/RUs) |
| Все остальные сценарии копирования | 4\. |

Чтобы переопределить это значение по умолчанию, укажите значение для свойства **dataIntegrationUnits**, как показано ниже. *Фактическое число единиц интеграции данных*, используемых при копировании, не превышает заданного значения, в зависимости от формата данных.

При наблюдении за выполнением действия диус, используемые для каждой копии, можно просмотреть в выходных данных действия копирования. Дополнительные сведения см. в разделе [мониторинг действий копирования](copy-activity-overview.md#monitoring).

> [!NOTE]
> Параметр диус больше 4 применяется только при копировании нескольких файлов из Azure BLOB/ADLS 1-го поколения/ADLS 2-го поколения/Amazon S3/облачное хранилище данных в облаке или облачном хранилище (включая [Oracle](connector-oracle.md#oracle-as-source)/[Netezza](connector-netezza.md#netezza-as-source)/[Teradata](connector-teradata.md#teradata-as-source)) в другие облачные хранилища данных.

**Пример**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "dataIntegrationUnits": 32
        }
    }
]
```

### <a name="parallel-copy"></a>Параллельное копирование

Свойство **parallelCopies** можно использовать для указания параллелизма, который будет использоваться действием копирования. Это свойство можно считать максимальным числом потоков в действии копирования, которые могут считывать данные из источника или записывать в хранилище данных приемника параллельно.

Для каждого запуска действия копирования фабрика данных Azure определяет количество параллельных копий, используемых для копирования данных из исходного хранилища данных и в целевое хранилище данных. Используемое по умолчанию количество параллельных копий зависит от типа источника и приемника, который используется.

| Сценарий копирования | Число параллельных копий по умолчанию, определенное службой |
| --- | --- |
| Копирование данных между файловыми хранилищами |Зависит от размера файлов и числа диус, используемых для копирования данных между двумя облачными хранилищами данных, или физической конфигурацией компьютера, на котором размещена локальная среда выполнения интеграции. |
| Копирование из реляционного хранилища данных с включенным параметром секционирования (включая [Oracle](connector-oracle.md#oracle-as-source), [Netezza](connector-netezza.md#netezza-as-source), [Teradata](connector-teradata.md#teradata-as-source), [таблицу SAP](connector-sap-table.md#sap-table-as-source)и [открытый центр SAP](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source))|4\. |
| Копирование данных из любого исходного хранилища в хранилище таблиц Azure |4\. |
| Все остальные сценарии копирования |1 |

> [!TIP]
> При копировании данных между файловыми хранилищами поведение по умолчанию обычно дает лучшую пропускную способность. Поведение по умолчанию определяется автоопределением на основе шаблона исходного файла.

Для управления нагрузкой на компьютеры, на которых размещены хранилища данных, или для настройки производительности копирования можно переопределить значение по умолчанию и указать значение для свойства **parallelCopies** . Значение должно быть целым числом больше или равно 1. Во время выполнения для наилучшей производительности действие копирования использует значение, меньшее или равное заданному значению.

**Примечания:**

- При копировании данных между файловыми хранилищами **parallelCopies** определяет параллелизм на уровне файлов. Фрагментация в одном файле происходит автоматически и прозрачно. Он предназначен для использования наилучшего подходящего размера фрагмента для заданного типа исходного хранилища данных для параллельной загрузки данных и ортогональной обработки в **parallelCopies**. Фактическое число параллельных копий, используемых службой перемещения данных для копирования во время выполнения, не превышает количество файлов. Если поведение копирования — **mergeFile**, действие копирования не сможет воспользоваться параллелизмом на уровне файлов.
- При копировании данных из хранилищ, которые не основаны на файлах (за исключением [Oracle](connector-oracle.md#oracle-as-source), [Netezza](connector-netezza.md#netezza-as-source), [Teradata](connector-teradata.md#teradata-as-source), [таблицы SAP](connector-sap-table.md#sap-table-as-source)и соединителя [SAP Open Hub](connector-sap-business-warehouse-open-hub.md#sap-bw-open-hub-as-source) в качестве источника с включенным секционированием данных) в хранилища, основанные на файлах, данные Служба перемещения игнорирует свойство **parallelCopies** . В этом случае параллелизм не применяется, даже если задан соответствующий параметр.
- Свойство **parallelCopies** является ортогональным для **датаинтегратионунитс**. Первое из них учитывается для всех единиц интеграции данных.
- При указании значения для свойства **parallelCopies** учитывайте увеличение нагрузки для хранилищ данных источника и приемника. Также учтите увеличение нагрузки на локальную среду выполнения интеграции, если это предоставляет действие копирования, например для гибридного копирования. Это увеличение нагрузки происходит в особенности при наличии нескольких действий или параллельных запусков тех же действий, которые выполняются с одним и тем же хранилищем данных. Если вы заметили, что хранилище данных или локальная среда выполнения интеграции перегружена, уменьшите значение **parallelCopies** , чтобы освободить нагрузку.

**Пример**

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "BlobSource",
            },
            "sink": {
                "type": "AzureDataLakeStoreSink"
            },
            "parallelCopies": 32
        }
    }
]
```

### <a name="staged-copy"></a>промежуточное копирование

При копировании данных из источника в приемник можно использовать хранилище BLOB-объектов в качестве промежуточного пространства для хранения. Промежуточное хранилище очень удобно в следующих ситуациях.

- **Вы хотите принимать данные из различных хранилищ данных в хранилище данных SQL через Polybase.** Хранилище данных SQL использует функцию PolyBase, которая обеспечивает высокую пропускную способность при загрузке больших объемов данных в хранилище SQL. Исходные данные должны находиться в хранилище BLOB-объектов или Azure Data Lake Store, и они должны удовлетворять дополнительным критериям. При загрузке данных не из хранилища BLOB-объектов или Azure Data Lake Store можно активировать копирование через промежуточное хранилище BLOB-объектов. В этом случае фабрика данных Azure выполняет необходимые преобразования данных, чтобы обеспечить соответствие требованиям Polybase. Затем она эффективно загружает данные в хранилище данных SQL с помощью PolyBase. Дополнительные сведения см. в разделе [Загрузка данных в хранилище данных SQL Azure с помощью PolyBase](connector-azure-sql-data-warehouse.md#use-polybase-to-load-data-into-azure-sql-data-warehouse).
- **Иногда для выполнения гибридного перемещения данных (т. е. копирования из локального хранилища данных в облачное хранилище данных) через низкое сетевое подключение требуется некоторое время.** Для повышения производительности можно использовать промежуточное копирование для сжатия данных в локальной среде, чтобы уменьшить время на перемещение данных в промежуточное хранилище данных в облаке. Затем можно распаковать данные в промежуточном хранилище перед загрузкой в целевое хранилище данных.
- **Вы не хотите открывать порты, отличные от порта 80 и порта 443, в брандмауэре из-за корпоративных ИТ-политик.** Например, при копировании данных из локального хранилища в приемник Базы данных SQL Azure или приемник Хранилища данных SQL Azure необходимо активировать исходящие TCP-подключения через порт 1433 для брандмауэра Windows и корпоративного брандмауэра. В этом сценарии поэтапное копирование может использовать локальную среду выполнения интеграции, чтобы сначала скопировать данные в промежуточный экземпляр хранилища BLOB-объектов по протоколу HTTP или HTTPS через порт 443. Затем он может загрузить данные в базу данных SQL или хранилище данных SQL из промежуточного хранилища BLOB-объектов. В таком сценарии не нужно включать порт 1433.

#### <a name="how-staged-copy-works"></a>Принцип промежуточного копирования

Если активировать функцию промежуточного копирования, сначала данные копируются из исходного хранилища в промежуточное хранилище BLOB-объектов (собственное). Оттуда данные копируются в приемник данных. Фабрика данных Azure автоматически управляет процессом с двумя этапами. Фабрика данных Azure также очищает временные данные из промежуточного хранилища после завершения перемещения данных.

![промежуточное копирование](media/copy-activity-performance/staged-copy.png)

При активации перемещения данных с помощью промежуточного хранилища можно указать, следует ли сжимать данные перед перемещением данных из исходного хранилища данных в промежуточное или промежуточное хранилище, а затем распаковать перед перемещением данных из промежуточного или промежуточного хранилища данных dat. хранилище в хранилище данных-приемник.

В настоящее время нельзя копировать данные между двумя хранилищами данных, которые подключены через разные собственные данные IRs, ни с промежуточным копированием, так и без него. Для такого сценария можно настроить два явно связанных действия копирования для копирования из источника в промежуточную среду, а затем из промежуточного хранения в приемник.

#### <a name="configuration"></a>Параметр Configuration

Настройте параметр **enableStaging** в действии копирования, чтобы указать, должны ли данные быть помещены в хранилище BLOB-объектов перед их загрузкой в целевое хранилище данных. Если для **enableStaging** задано значение `TRUE`, укажите дополнительные свойства, перечисленные в следующей таблице. Кроме того, для промежуточного хранения необходимо создать связанную службу хранилища Azure или подписи общего доступа, если у вас ее нет.

| Свойство | ОПИСАНИЕ | Значение по умолчанию | обязательные |
| --- | --- | --- | --- |
| enableStaging |Укажите, следует ли копировать данные в промежуточное хранилище. |Ложь |Нет |
| linkedServiceName (имя связанной службы) |Укажите имя связанной службы [AzureStorage](connector-azure-blob-storage.md#linked-service-properties), которая будет ссылаться на используемый в качестве промежуточного экземпляр хранилища. <br/><br/> Хранилище с подписью общего доступа нельзя использовать для загрузки данных в хранилище данных SQL через Polybase. Его можно использовать в других случаях. |Недоступно |Да, если для параметра **enableStaging** задано значение true |
| path |Укажите путь к хранилищу BLOB-объектов, в котором будут храниться промежуточные данные. Если не указать путь, служба создает контейнер для хранения временных данных. <br/><br/> Укажите путь, только если используется хранилище с подписанным URL-адресом или требуется, чтобы временные данные хранились в определенном месте. |Недоступно |Нет |
| enableCompression |Указывает, следует ли сжимать данные перед их копированием в место назначения. Этот параметр позволяет уменьшить объем передаваемых данных. |Ложь |Нет |

>[!NOTE]
> Если используется промежуточное копирование с включенным сжатием, проверка подлинности субъекта-службы или MSI для связанной службы BLOB-объектов не поддерживается.

Ниже приведен пример определения действия копирования со свойствами, описанными в предыдущей таблице.

```json
"activities":[
    {
        "name": "Sample copy activity",
        "type": "Copy",
        "inputs": [...],
        "outputs": [...],
        "typeProperties": {
            "source": {
                "type": "SqlSource",
            },
            "sink": {
                "type": "SqlSink"
            },
            "enableStaging": true,
            "stagingSettings": {
                "linkedServiceName": {
                    "referenceName": "MyStagingBlob",
                    "type": "LinkedServiceReference"
                },
                "path": "stagingcontainer/path",
                "enableCompression": true
            }
        }
    }
]
```

#### <a name="staged-copy-billing-impact"></a>Принцип выставления счетов за промежуточное копирование

Плата наследуется на основе двух шагов: копирование длительности и типа копирования.

* При использовании промежуточного хранения во время копирования в облако, которое копирует данные из облачного хранилища данных в другое облачное хранилище данных, для обоих этапов, которые доставляются службой интеграции Azure, задается [сумма длительности копирования для шага 1 и шаг 2] x [Цена за единицу облачного копирования].
* При использовании промежуточного хранения во время гибридной копии, которая копирует данные из локального хранилища данных в облачное хранилище данных, на один этап, предоставляемый локальной средой выполнения интеграции, выставляются счета за [Длительность гибридной копии] x [Цена за единицу гибридного копирования] + [Длительность облачного копирования] x [Цена за единицу облачного копирования].

## <a name="references"></a>Ссылки

Ниже приведены справочные материалы по мониторингу и настройке производительности для некоторых поддерживаемых хранилищ данных.

* Служба хранилища Azure, которая включает хранилище BLOB-объектов и хранилище таблиц: [целевые показатели масштабируемости службы хранилища Azure](../storage/common/storage-scalability-targets.md) и [производительность службы хранилища Azure и контрольный список масштабируемости](../storage/common/storage-performance-checklist.md).
* База данных SQL Azure. Вы можете [отслеживать производительность](../sql-database/sql-database-single-database-monitor.md) и проверять процент использования единиц транзакций базы данных (DTU).
* Хранилище данных SQL Azure. его возможности измеряются в единицах использования хранилища данных (Dwu). См. статью [Управление возможностями вычислений в хранилище данных SQL Azure (обзор)](../sql-data-warehouse/sql-data-warehouse-manage-compute-overview.md).
* Azure Cosmos DB: [уровни производительности в Azure Cosmos DB](../cosmos-db/performance-levels.md).
* Локальные SQL Server: [мониторинг и настройка производительности](https://msdn.microsoft.com/library/ms189081.aspx).
* Локальный файловый сервер: [Настройка производительности файловых серверов](https://msdn.microsoft.com/library/dn567661.aspx).

## <a name="next-steps"></a>Дополнительная информация
См. Другие статьи о действиях копирования:

- [Действие копирования в фабрике данных Azure](copy-activity-overview.md)
- [Перенос данных из хранилища данных в Azure с помощью фабрики данных Azure](data-migration-guidance-overview.md)
- [Перенос данных из Amazon S3 в службу хранилища Azure](data-migration-guidance-s3-azure-storage.md)
