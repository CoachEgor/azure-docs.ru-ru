---
title: Перенос данных из локального кластера Hadoop в службу хранилища Azure с помощью фабрики данных Azure
description: Узнайте, как использовать фабрику данных Azure для переноса данных из локального кластера Hadoop в службу хранилища Azure.
services: data-factory
documentationcenter: ''
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 8/30/2019
ms.openlocfilehash: b952be49bf5bc00b338aa04ed51e9dc451b5c4f9
ms.sourcegitcommit: 609d4bdb0467fd0af40e14a86eb40b9d03669ea1
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/06/2019
ms.locfileid: "73675819"
---
# <a name="use-azure-data-factory-to-migrate-data-from-an-on-premises-hadoop-cluster-to-azure-storage"></a>Перенос данных из локального кластера Hadoop в службу хранилища Azure с помощью фабрики данных Azure 

Фабрика данных Azure предоставляет производительный, надежный и экономичный механизм переноса данных из локальной системы HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Storage 2-го поколения. 

Фабрика данных предлагает два основных подхода к переносу данных из локальной сети HDFS в Azure. Вы можете выбрать подход на основе вашего сценария. 

- **Режим DistCp фабрики данных** (рекомендуется). в фабрике данных можно использовать [DistCp](https://hadoop.apache.org/docs/current3/hadoop-distcp/DistCp.html) (распределенное копирование) для копирования файлов "как есть" в хранилище BLOB-объектов Azure (включая [промежуточное копирование](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#staged-copy)) или Azure Data Lake Store Gen2. Используйте фабрику данных, интегрированную с DistCp, чтобы воспользоваться преимуществами существующего мощного кластера для достижения наилучшей пропускной способности копирования. Кроме того, вы получаете преимущества гибкого планирования и единого мониторинга в фабрике данных. В зависимости от конфигурации фабрики данных действие копирования автоматически формирует команду DistCp, отправляет данные в кластер Hadoop, а затем отслеживает состояние копирования. Мы рекомендуем использовать режим DistCp фабрики данных для переноса данных из локального кластера Hadoop в Azure.
- **Собственный режим среды выполнения интеграции фабрики данных**: DistCp не является параметром во всех сценариях. Например, в среде виртуальных сетей Azure средство DistCp не поддерживает частный пиринг Azure ExpressRoute с конечной точкой виртуальной сети службы хранилища Azure. Кроме того, в некоторых случаях вы не хотите использовать существующий кластер Hadoop в качестве подсистемы для переноса данных, чтобы вы не поместили большие нагрузки в кластер, что может повлиять на производительность существующих заданий ETL. Вместо этого можно использовать собственную возможность среды выполнения интеграции фабрики данных в качестве механизма, который копирует данные из локальной системы HDFS в Azure.

В этой статье содержатся следующие сведения о обоих подходах.
> [!div class="checklist"]
> * Производительность 
> * Устойчивость к копированию
> * Безопасность сети
> * Архитектура высокого уровня решения 
> * Рекомендации по реализации  

## <a name="performance"></a>Производительность

В режиме DistCp фабрики данных пропускная способность будет такой же, как при использовании средства DistCp независимо. Режим DistCp фабрики данных позволяет максимально увеличить емкость существующего кластера Hadoop. DistCp можно использовать для крупномасштабного копирования между кластерами или внутри кластера. 

DistCp использует MapReduce для воздействия на свое распределение, обработку ошибок и восстановление, а также создание отчетов. Он расширяет список файлов и каталогов на входные данные для сопоставления задач. Каждая задача копирует файловую секцию, указанную в списке Источник. Фабрику данных, интегрированную с DistCp, можно использовать для создания конвейеров, чтобы полностью использовать пропускную способность сети, операций ввода-вывода в хранилище и пропускную способность для увеличения пропускной способности перемещения данных для вашей среды  

Собственный режим интеграции фабрики данных также обеспечивает параллелизм на разных уровнях. С помощью параллелизма можно полностью использовать пропускную способность сети, операции ввода-вывода в хранилище и пропускную способность, чтобы максимально увеличить пропускную способность перемещения данных:

- Одно действие копирования может воспользоваться преимуществами масштабируемых ресурсов вычислений. С помощью локальной среды выполнения интеграции можно вручную масштабировать компьютер или масштабировать его на нескольких компьютерах ([до четырех узлов](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)). Одно действие копирования разделяет набор файлов на все узлы. 
- Одно действие копирования считывает и выполняет запись в хранилище данных с помощью нескольких потоков. 
- Поток управления фабрикой данных может параллельно запускать несколько операций копирования. Например, можно использовать [цикл for each](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity). 

Дополнительные сведения см. в разделе [Обзор производительности действия копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance).

## <a name="resilience"></a>Устойчивость

В режиме DistCp фабрики данных можно использовать различные параметры командной строки DistCp (например `-i`, пропускать сбои или `-update`, записывать данные, когда исходный файл и файл назначения различаются по размеру) для различных уровней устойчивости.

В собственном режиме среды выполнения интеграции фабрики данных при выполнении одного действия копирования фабрика данных имеет встроенный механизм повторных попыток. Он может управлять определенным уровнем временных сбоев в хранилищах данных или в базовой сети. 

При выполнении двоичного копирования из локальной системы HDFS в хранилище BLOB-объектов и из локального HDFS в Data Lake Store Gen2 фабрика данных автоматически выполняет контрольные точки в большом экстенте. Если выполнение действия копирования завершается ошибкой или истекает время ожидания, при последующей повторной попытке (убедитесь, что число повторных попыток равно > 1), после чего копирование будет возобновлено с последней точки сбоя, а не с начала.

## <a name="network-security"></a>Безопасность сети 

По умолчанию фабрика данных передает данные из локальной системы HDFS в хранилище BLOB-объектов или Azure Data Lake Storage 2-го поколения с помощью зашифрованного соединения по протоколу HTTPS. HTTPS обеспечивает шифрование данных при передаче и предотвращает атаки перехвата и атак типа "злоумышленник в середине". 

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, для повышения безопасности можно передать данные через канал ExpressRoute через частный пиринг. 

## <a name="solution-architecture"></a>Архитектура решения

На этом рисунке показано, как перенести данные через общедоступный Интернет:

![Схема, показывающая архитектуру решения для переноса данных через общедоступную сеть](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-public-network.png)

- В этой архитектуре данные безопасно передаются с помощью протокола HTTPS через общедоступный Интернет. 
- Мы рекомендуем использовать режим DistCp фабрики данных в общедоступной сетевой среде. Для достижения наилучшей пропускной способности копирования можно воспользоваться мощным имеющимся кластером. Кроме того, вы получаете преимущества гибкого планирования и единого мониторинга из фабрики данных.
- Для этой архитектуры необходимо установить локальную среду выполнения интеграции фабрики данных на компьютере Windows, расположенном за корпоративным брандмауэром, чтобы отправить команду DistCp в кластер Hadoop и отслеживать состояние копирования. Так как компьютер не является подсистемой, которая будет перемещать данные (только для целей управления), емкость компьютера не влияет на пропускную способность перемещения данных.
- Поддерживаются существующие параметры команды DistCp.

На этом рисунке показано, как перенести данные по частной ссылке: 

![Схема, показывающая архитектуру решения для переноса данных через частную сеть](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-private-network.png)

- В этой архитектуре данные переносятся через ссылку частного пиринга через Azure ExpressRoute. Данные никогда не проходят через общедоступный Интернет.
- Средство DistCp не поддерживает частный пиринг ExpressRoute с конечной точкой виртуальной сети службы хранилища Azure. Для переноса данных рекомендуется использовать собственные возможности фабрики данных через среду выполнения интеграции.
- Для этой архитектуры необходимо установить локальную среду выполнения интеграции фабрики данных на виртуальной машине Windows в виртуальной сети Azure. Вы можете вручную масштабировать виртуальную машину или масштабировать ее до нескольких виртуальных машин, чтобы полностью использовать операции ввода-вывода в сети и хранилища.
- Рекомендуемая конфигурация для начала для каждой виртуальной машины Azure (с установленной локальной средой выполнения интеграции фабрики данных) — Standard_D32s_v3 с 32 виртуальных ЦП и 128 ГБ памяти. Вы можете отслеживать использование ЦП и памяти виртуальной машины во время переноса данных, чтобы узнать, нужно ли масштабировать виртуальную машину для повышения производительности или масштабирования виртуальной машины, чтобы снизить затраты.
- Кроме того, можно выполнить горизонтальное масштабирование, связав до четырех узлов виртуальных машин с одной локальной средой выполнения интеграции. Одно задание копирования, выполняемое для локальной среды выполнения интеграции, автоматически разделяет набор файлов и использует все узлы виртуальной машины для параллельного копирования файлов. Для обеспечения высокой доступности рекомендуется начать с двух узлов виртуальных машин, чтобы избежать ситуации одной точки отказа при переносе данных.
- При использовании этой архитектуры для вас доступны исходные данные миграции моментальных снимков и перенос разностных данных.

## <a name="implementation-best-practices"></a>Рекомендации по реализации

Рекомендуется следовать этим рекомендациям при реализации переноса данных.

### <a name="authentication-and-credential-management"></a>Проверка подлинности и управление учетными данными 

- Для проверки подлинности в HDFS можно использовать [либо Windows (Kerberos), либо анонимный](https://docs.microsoft.com/azure/data-factory/connector-hdfs#linked-service-properties). 
- Для подключения к хранилищу BLOB-объектов Azure поддерживаются несколько типов проверки подлинности.  Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity). Управляемые удостоверения, созданные на основе автоматически управляемого удостоверения фабрики данных в Azure Active Directory (Azure AD), позволяют настраивать конвейеры без предоставления учетных данных в определении связанной службы. Кроме того, можно выполнить проверку подлинности в хранилище BLOB-объектов с помощью [субъекта службы](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication), [подписанного](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication)URL-доступа или [ключа учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication). 
- Для подключения к Data Lake Storage 2-го поколения также поддерживаются несколько типов проверки подлинности.  Мы настоятельно рекомендуем использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity), но вы также можете воспользоваться [субъектом-службой](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключом учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication). 
- Если управляемые удостоверения для ресурсов Azure не используются, настоятельно рекомендуется [хранить учетные данные в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) , чтобы упростить централизованное управление и вращение ключей без изменения связанных служб фабрики данных. Это также [рекомендовано для CI/CD](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="initial-snapshot-data-migration"></a>Исходный моментальный снимок — перенос данных 

В режиме DistCp фабрики данных можно создать одно действие копирования для отправки команды DistCp и использовать другие параметры для управления первоначальным поведением при миграции данных. 

В режиме встроенной среды выполнения интеграции фабрики данных рекомендуется использовать раздел данных, особенно при переносе более 10 ТБ данных. Чтобы секционировать данные, используйте имена папок в HDFS. Затем каждое задание копирования фабрики данных может копировать один раздел папки за раз. Для повышения пропускной способности можно одновременно запустить несколько заданий копирования фабрики данных.

Если какие-либо из заданий копирования завершаются неудачей вследствие временных проблем с сетью или хранилищем данных, можно повторно выполнить задание копирования, завершившееся сбоем, чтобы перезагрузить эту конкретную секцию из HDFS. Другие задания копирования, которые загружают другие секции, не затрагиваются.

### <a name="delta-data-migration"></a>Перенос разностных данных 

В режиме DistCp фабрики данных можно использовать параметр командной строки DistCp `-update`, записывать данные, если размер исходного файла и целевого файла различается для переноса разностных данных.

В собственном режиме интеграции фабрики данных наиболее производительный способ обнаружения новых или измененных файлов из HDFS — использование соглашения об именовании с временным секционированием. Когда данные в HDFS были секционированы по времени с данными временных срезов в имени файла или папки (например, */ИИИИ/мм/дд/филе.КСВ*), конвейер может легко найти файлы и папки, которые нужно скопировать в инкрементном виде.

Кроме того, если данные в HDFS не секционированы по времени, фабрика данных может обнаруживать новые или измененные файлы с помощью их значения **LastModifiedDate** . Фабрика данных сканирует все файлы из HDFS и копирует только новые и обновленные файлы с отметкой времени последнего изменения, которая больше, чем заданное значение. 

Если в HDFS имеется большое количество файлов, сканирование исходного файла может занять много времени, независимо от того, сколько файлов соответствует условию фильтра. В этом сценарии рекомендуется сначала секционировать данные с помощью той же секции, которая использовалась для первоначальной миграции моментальных снимков. Затем сканирование файлов может выполняться параллельно.

### <a name="estimate-price"></a>Оценка цены 

Рассмотрим следующий конвейер для переноса данных из HDFS в хранилище BLOB-объектов Azure: 

![Схема, на которой показан конвейер ценообразования](media/data-migration-guidance-hdfs-to-azure-storage/pricing-pipeline.png)

Предположим, что у вас есть следующие сведения: 

- Общий объем данных составляет 1 ПБ.
- Данные переносятся с помощью собственного режима среды выполнения интеграции фабрики данных.
- 1 PB делится на 1 000 секций и каждая копия перемещается в одну секцию.
- Для каждого действия копирования настраивается одна локальная среда выполнения интеграции, которая связана с четырьмя компьютерами и обеспечивает пропускную способность 500 Мбит/с.
- Параметр параллелизма ForEach имеет значение **4** , а суммарная пропускная способность — 2 Гбит/с.
- В итоге выполнение миграции займет 146 часа.

Вот примерная цена, основанная на наших допущениях: 

![Таблица, в которой показаны вычисления цен](media/data-migration-guidance-hdfs-to-azure-storage/pricing-table.png)

> [!NOTE]
> Это гипотетический пример цены. Реальная цена зависит от фактической пропускной способности в вашей среде.
> Цена для виртуальной машины Azure Windows (с установленной локальной средой выполнения интеграции) не включена.

### <a name="additional-references"></a>Дополнительные ссылки

- [Соединитель HDFS](https://docs.microsoft.com/azure/data-factory/connector-hdfs)
- [Соединитель хранилища BLOB-объектов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Краткое руководств по настройке производительности действий копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и настройка локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Высокая доступность и масштабируемость в среде выполнения интеграции с локальным размещением](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности перемещения данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Хранение учетных данных в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Добавочное копирование файла на основе имени временного секционированного файла](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-partitioned-file-name-copy-data-tool)
- [Копировать новые и измененные файлы на основе LastModifiedDate](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-lastmodified-copy-data-tool)
- [Страница цен на фабрику данных](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Дальнейшие действия

- [Копирование файлов из нескольких контейнеров с помощью фабрики данных Azure](solution-template-copy-files-multiple-containers.md)