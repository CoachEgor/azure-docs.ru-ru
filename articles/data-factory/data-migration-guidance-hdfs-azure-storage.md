---
title: Перенос данных из кластера «Хадуп» в Azure Storage
description: Узнайте, как использовать фабрику данных Azure для переноса данных из кластера Hadoop в Azure Storage.
services: data-factory
ms.author: yexu
author: dearandyxu
ms.reviewer: ''
manager: shwang
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 8/30/2019
ms.openlocfilehash: afccbdbbfd5b8ddeefa621448d6170d937b518f0
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "74931452"
---
# <a name="use-azure-data-factory-to-migrate-data-from-an-on-premises-hadoop-cluster-to-azure-storage"></a>Используйте фабрику данных Azure для переноса данных из кластера Hadoop в хранилище Azure 

Azure Data Factory предоставляет эффективный, надежный и экономичный механизм для переноса данных по шкале от находной HDFS к хранению Azure Blob или хранилищам Azure Data Lake Storage Gen2. 

Data Factory предлагает два основных подхода к миграции данных из находной HDFS в Azure. Вы можете выбрать подход на основе сценария. 

- **Режим DistCp Data Factory** (рекомендуется): В Data Factory можно использовать [DistCp](https://hadoop.apache.org/docs/current3/hadoop-distcp/DistCp.html) (распределенную копию) для копирования файлов как для хранения Azure Blob (включая [постановочную копию)](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#staged-copy)или Azure Data Lake Store Gen2. Используйте Data Factory, интегрированный с DistCp, чтобы воспользоваться существующим мощным кластером для достижения наилучшей пропускной четырбы копий. Вы также получаете преимущества гибкого планирования и единого мониторинга от Data Factory. В зависимости от конфигурации Data Factory, активность копирования автоматически строит команду DistCp, отправляет данные в кластер Hadoop, а затем отслеживает состояние копирования. Мы рекомендуем режим Data Factory DistCp для переноса данных из кластера Hadoop в Azure.
- **Режим выполнения интеграции Data Factory:** DistCp не является вариантом во всех сценариях. Например, в среде виртуальных сетей Azure инструмент DistCp не поддерживает приватное пиринг Azure ExpressRoute с помощью конечной точки виртуальной сети Azure Storage. Кроме того, в некоторых случаях не требуется использовать существующий кластер Hadoop в качестве движущегося ресурса для миграции данных, чтобы не ставить большие нагрузки на кластер, что может повлиять на производительность существующих заданий ETL. Вместо этого можно использовать назаемные возможности времени выполнения интеграции Data Factory в качестве движка, копирует данные с предприимчивого HDFS в Azure.

В этой статье приводится следующая информация об обоих подходах:
> [!div class="checklist"]
> * Производительность 
> * Устойчивость копирования
> * Безопасность сети
> * Архитектура решений высокого уровня 
> * Внедрение передовой практики  

## <a name="performance"></a>Производительность

В режиме Data Factory DistCp пропускная часть такая же, как если бы вы использовали инструмент DistCp самостоятельно. Режим Data Factory DistCp максимизирует емкость существующего кластера Hadoop. Можно использовать DistCp для большого межкластерного или внутрикластерного копирования. 

DistCp использует MapReduce для осуществления своего распространения, обработки ошибок и восстановления, а также отчетности. Он расширяет список файлов и каталогов в входиные для отображения задач. Каждая задача копирует раздел файла, указанный в списке исходных источников. Вы можете использовать Data Factory, интегрированную с DistCp, для создания конвейеров, чтобы в полной мере использовать пропускную способность сети, память IOPS и пропускную способность для максимизации пропускной способности передачи данных для вашей среды.  

Режим внедрения интеграции Data Factory также позволяет проводить параллелизм на разных уровнях. Можно использовать параллелизм для полного использования пропускной способности сети, хранения IOPS и пропускной способности для максимизации пропускной способности движения данных:

- Одноразовая копия может использовать масштабируемые вычислительные ресурсы. С автономной интеграцией время выполнения, вы можете вручную масштабировать машину или масштабировать до нескольких машин[(до четырех узлов).](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability) Одиночная часть действия копирования разгородки его файла устанавливается во всех узлах. 
- Одноразовая копия действия считывается из хранилища данных и записывается с помощью нескольких потоков. 
- Поток управления Data Factory может начать несколько действий копирования параллельно. Например, можно использовать [цикл Для каждого цикла](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity). 

Для получения дополнительной информации смотрите [руководство по производительности деятельности копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance).

## <a name="resilience"></a>Устойчивость

В режиме Data Factory DistCp можно использовать различные параметры командной `-i`строки `-update`DistCp (например, игнорировать сбои или записывание данных, когда исходный файл и файл назначения различаются по размеру) для различных уровней устойчивости.

В режиме внедрения наиболее интеграционных моментов Data Factory в запущенном виде действия на одной копии Data Factory имеетвстроенный механизм повторной работы. Он может обрабатывать определенный уровень временных сбоев в хранилищах данных или в базовой сети. 

При выполнении двоичного копирования от находной HDFS до хранения Blob и от натерритории HDFS до Data Lake Store Gen2, Data Factory автоматически выполняет контрольные точки в значительной степени. Если выполняется действие копии, не удается или время выводится, при последующей повторной попытке (убедитесь, что количество повторений > 1), копия возобновляется с последней точки сбоя вместо начала.

## <a name="network-security"></a>Безопасность сети 

По умолчанию Data Factory передает данные из находной HDFS в хранилище Blob или Azure Data Lake Storage Gen2 с помощью зашифрованного соединения по протоколу HTTPS. HTTPS обеспечивает шифрование данных в пути и предотвращает подслушивание и атаки «человек в середине». 

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, для повышения безопасности, вы можете передавать данные по частной вглядывающей ссылке через ExpressRoute. 

## <a name="solution-architecture"></a>Архитектура решения

На этом изображении изображены миграционные данные через общедоступный интернет:

![Диаграмма, отображающая архитектуру решений для миграции данных по общедоступной сети](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-public-network.png)

- В этой архитектуре данные передаются безопасно с помощью HTTPS через общедоступный Интернет. 
- Мы рекомендуем использовать режим Data Factory DistCp в общедоступной сетевой среде. Вы можете воспользоваться мощным существующим кластером для достижения наилучшей пропускной выгоды копировальной копии. Вы также получаете преимущества гибкого планирования и унифицированного опыта мониторинга от Data Factory.
- Для этой архитектуры необходимо установить саморазмещенное время выполнения интеграции Data Factory на компьютере Windows за корпоративным брандмауэром, чтобы отправить команду DistCp в кластер Hadoop и контролировать состояние копирования. Поскольку машина не является двигателем, который будет перемещать данные (только для целей управления), емкость машины не влияет на пропускную способность движения данных.
- Существующие параметры из команды DistCp поддерживаются.

На этом изображении изображены миграционные данные по приватной ссылке: 

![Диаграмма, отображающая архитектуру решений для миграции данных через частную сеть](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-private-network.png)

- В этой архитектуре данные перекладываются через приватную ссылку пиринга через Azure ExpressRoute. Данные никогда не пересекают через общественный интернет.
- Инструмент DistCp не поддерживает приватное пиринг ExpressRoute с помощью конечной точки виртуальной сети Azure Storage. Мы рекомендуем использовать нативные возможности Data Factory через время выполнения интеграции для переноса данных.
- Для этой архитектуры необходимо установить самохотданную интеграцию Data Factory на Windows VM в виртуальной сети Azure. Вы можете вручную масштабировать ваш VM или масштабировать до нескольких ВМ, чтобы в полной мере использовать вашу сеть и ioPS хранения или пропускную способность.
- Рекомендуемая конфигурация для каждого Azure VM (с установленным самохозня интеграционным временем внедрения Data Factory) Standard_D32s_v3 с 32 vCPU и 128 ГБ памяти. Вы можете контролировать использование процессора и памяти VM во время миграции данных, чтобы увидеть, нужно ли масштабировать VM для повышения производительности или уменьшить VM, чтобы уменьшить затраты.
- Вы также можете масштабироваться, связывая до четырех узлов VM с одним автономным временем выполнения интеграции. Одноразовая работа, работающее на основе самостоятельной интеграции, автоматически перерезает набор файлов и использует все vM-узлы для параллельного копирования файлов. При высокой доступности мы рекомендуем начать с двух узлов VM, чтобы избежать сценария с одной точки сбоя во время миграции данных.
- При использовании этой архитектуры вам доступен начальный моментальный моментальный моментальный моментм данных и миграция данных дельты.

## <a name="implementation-best-practices"></a>Внедрение передовой практики

Мы рекомендуем соблюдать эти рекомендации при реализации миграции данных.

### <a name="authentication-and-credential-management"></a>Аутентификация и управление учетных данных 

- Для проверки подлинности в HDFS можно использовать [Windows (Kerberos) или Anonymous.](https://docs.microsoft.com/azure/data-factory/connector-hdfs#linked-service-properties) 
- Несколько типов аутентификации поддерживаются для подключения к хранилищу Azure Blob.  Мы настоятельно рекомендуем использовать [управляемые идентификаторы для ресурсов Azure.](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity) Управляемые идентификаторы, созданные поверх автоматически управляемой идентификатора Data Factory в active Directory Azure (Azure AD), позволяют настраивать конвейеры без предоставления учетных данных в связанном определении службы. Кроме того, вы можете проверить подлинность хранилища Blob с помощью [принципа службы,](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication) [общей подписи доступа](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication)или ключа [учетной записи хранилища.](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication) 
- Несколько типов аутентификации также поддерживаются для подключения к Data Lake Storage Gen2.  Мы настоятельно рекомендуем использовать [управляемые идентификаторы для ресурсов Azure,](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity)но вы также можете использовать [принцип службы](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключ учетной записи хранилища.](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication) 
- При неиспользовании управляемых идентификаторов для ресурсов Azure мы настоятельно рекомендуем [хранить учетные данные в Azure Key Vault,](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) чтобы упростить централизованное управление и изменение ключей без изменения связанных служб Data Factory. Это также [является наилучшей практикой для CI / CD](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="initial-snapshot-data-migration"></a>Первоначальная миграция данных моментального снимка 

В режиме Data Factory DistCp можно создать одно действие копий для отправки команды DistCp и использования различных параметров для управления исходным поведением миграции данных. 

В режиме внедрения наиболее интеграционных данных мы рекомендуем раздел данных, особенно при переносе более 10 ТБ данных. Для раздела данных используйте имена папок на HDFS. Затем каждое задание копирования Data Factory может копировать одну разделпапу папки за один раз. Можно одновременно запускать несколько заданий копий Data Factory для лучшей пропускной всей входной.

Если какая-либо из заданий копирования не сбой из-за сети или хранения временных проблем, вы можете перезапустить неудавшую работу копирования для перезагрузки этого конкретного раздела из HDFS. Другие задания копирования, которые загружают другие разделы, не затрагиваются.

### <a name="delta-data-migration"></a>Миграция данных Delta 

В режиме Data Factory DistCp можно использовать параметр `-update`командной строки DistCp, записывать данные, когда исходный файл и файл назначения различаются по размеру, для миграции данных дельты.

В режиме интеграции Data Factory наиболее эффективный способ идентификации новых или измененных файлов из HDFS — это использование конвенции именования, разделенной по времени. Когда ваши данные в HDFS были разделены по времени с информацией о срезе времени в файле или имени папки (например, */yyyy/mm/dd/file.csv),* ваш конвейер может легко определить, какие файлы и папки копировать постепенно.

Кроме того, если данные в HDFS не разделены по времени, Data Factory может идентифицировать новые или измененные файлы, используя их значение **LastModifiedDate.** Data Factory сканирует все файлы из HDFS и копирует только новые и обновленные файлы, которые имеют последнюю измененную метку времени, которая больше, чем задеваемый значение. 

Если в HDFS есть большое количество файлов, первоначальное сканирование файлов может занять много времени, независимо от того, сколько файлов соответствует состоянию фильтра. В этом случае мы рекомендуем сначала развести данные с помощью того же раздела, который использовался для первоначальной миграции моментального снимка. Затем сканирование файлов может происходить параллельно.

### <a name="estimate-price"></a>Ориентировочная цена 

Рассмотрим следующий конвейер для переноса данных из данных HDFS в хранилище Azure Blob: 

![Диаграмма, отобрадав ценопровод](media/data-migration-guidance-hdfs-to-azure-storage/pricing-pipeline.png)

Давайте предположим следующую информацию: 

- Общий объем данных составляет 1 ПБ.
- Вы переносите данные с помощью нативной интеграции Data Factory.
- 1 PB делится на 1000 разделов, и каждая копия перемещает один раздел.
- Каждая копия настроена с одним самоходной интеграцией, которая связана с четырьмя машинами и которая достигает пропускной связи 500 Мбит/с.
- ForEach параллелизм установлен на **4,** а совокупная пропускная стоимость составляет 2 GBps.
- В общей сложности для завершения миграции требуется 146 часов.

Вот оценочная цена, основанная на наших предположениях: 

![Таблица, поотвенена расчеты ценообразования](media/data-migration-guidance-hdfs-to-azure-storage/pricing-table.png)

> [!NOTE]
> Это гипотетический пример ценообразования. Фактические цены зависят от фактической пропускной выхаживаемостью в вашей среде.
> Цена на Azure Windows VM (с установленным самохлаженным временем выполнения интеграции) не включена.

### <a name="additional-references"></a>Дополнительные ссылки

- [Соединитель HDFS](https://docs.microsoft.com/azure/data-factory/connector-hdfs)
- [Разъем для хранения Azure Blob](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Копирование руководства по настройке производительности](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и настройка локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Самохонугистом интеграции время выполнения высокая доступность и масштабируемость](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности при перемещении данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Храните учетные данные в Хранилище ключей Azure](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Копирование файла постепенно на основе времени разделенного имени файла](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-partitioned-file-name-copy-data-tool)
- [Копирование новых и измененных файлов на основе LastModifiedDate](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-lastmodified-copy-data-tool)
- [Страница ценообразования Data Factory](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Дальнейшие действия

- [Копирование файлов из нескольких контейнеров с помощью Azure Data Factory](solution-template-copy-files-multiple-containers.md)