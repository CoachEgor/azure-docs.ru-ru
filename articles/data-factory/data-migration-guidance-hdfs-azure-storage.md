---
title: Перенос данных из локального кластера Hadoop в службу хранилища Azure с помощью фабрики данных Azure | Документация Майкрософт
description: Используйте фабрику данных Azure для переноса данных из локального кластера Hadoop в службу хранилища Azure.
services: data-factory
documentationcenter: ''
author: dearandyxu
ms.author: yexu
ms.reviewer: ''
manager: ''
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.topic: conceptual
ms.date: 8/30/2019
ms.openlocfilehash: 1b26b22fa9cdf9f6671702ceb9640aa39a6ecf17
ms.sourcegitcommit: 8fea78b4521921af36e240c8a92f16159294e10a
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/02/2019
ms.locfileid: "70211596"
---
# <a name="use-azure-data-factory-to-migrate-data-from-on-premises-hadoop-cluster-to-azure-storage"></a>Перенос данных из локального кластера Hadoop в службу хранилища Azure с помощью фабрики данных Azure 

Фабрика данных Azure предоставляет производительный, надежный и экономичный механизм переноса данных из локальной системы HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Storage 2-го поколения. По сути, фабрика данных Azure содержит два подхода к переносу данных из локальной службы HDFS в Azure. Вы можете выбрать каждый из них в зависимости от вашего сценария. 

- DistCpный режим ADF. Поддержка ADF с помощью [DistCp](https://hadoop.apache.org/docs/current3/hadoop-distcp/DistCp.html) для копирования файлов "как есть" в большой двоичный объект Azure (включая [промежуточное копирование](https://docs.microsoft.com/azure/data-factory/copy-activity-performance#staged-copy)) или Azure Data Lake Store. в этом случае можно полностью использовать мощность кластера, а не работать в автономной среде выполнения интеграции ADF (IR). Она обеспечит лучшую пропускную способность копирования, особенно если кластер является очень мощным. В зависимости от конфигурации в фабрике данных Azure действие копирования автоматически формирует команду DistCp, отправляет в кластер Hadoop и отслеживает состояние копирования. С помощью ADF, интегрированного с DistCp, клиент может не только использовать имеющийся мощный кластер для достижения наилучшей пропускной способности копирования, но также получить преимущества гибкого планирования и единого мониторинга из ADF. По умолчанию режим ADF DistCp является рекомендуемым способом переноса данных из локального кластера Hadoop в Azure.
- Собственный IR-режим ADF. В некоторых сценариях DistCp не может работать в своих случаях (например, в среде виртуальной сети, средство DistCp не поддерживает частный пиринг с помощью Express Route + конечная точка виртуальной сети службы хранилища Azure). Кроме того, иногда нежелательно использовать существующий кластер Hadoop в качестве подсистемы для переноса данных, так как он обеспечит высокую нагрузку на кластер, что может повлиять на производительность существующих заданий ETL. В этом случае можно использовать собственные возможности ADF, где среда выполнения интеграции ADF (IR) может быть подсистемой для копирования данных из локальной системы HDFS в Azure.

В этой статье представлены следующие сведения о обоих подходах для инженеров и разработчиков данных:
> [!div class="checklist"]
> * Производительность 
> * Устойчивость к копированию
> * Безопасность сети
> * Архитектура высокого уровня решения 
> * Рекомендации по реализации  

## <a name="performance"></a>Производительность

В режиме ADF DistCp пропускная способность аналогична использованию средства DistCp независимо, что использует емкость существующего кластера Hadoop. DistCp (распределенная копия) — это средство, используемое для крупного копирования между или внутри кластера. Она использует MapReduce для воздействия на свое распределение, обработку ошибок и восстановление, а также создание отчетов. Он расширяет список файлов и каталогов на входные данные для отображения задач, каждый из которых копирует раздел файлов, указанных в списке Источник. Используя ADF, интегрированный с DistCp, можно создавать конвейеры, чтобы полностью использовать пропускную способность сети, а также операции ввода-вывода в хранилище и пропускную способность, чтобы максимально увеличить пропускную способность перемещения данных для вашей среды.  

В собственном IR-режиме ADF также обеспечивает параллелизм на разных уровнях, что позволяет полностью использовать пропускную способность сети, а также операции ввода-вывода в хранилище и пропускную способность, чтобы максимально увеличить пропускную способность перемещения данных путем ручного масштабирования на локальном компьютере или масштабирования до локально размещенные ИК-соединения на нескольких компьютерах.

- Одно действие копирования может воспользоваться преимуществами масштабируемых ресурсов вычислений. С помощью локальной среды выполнения интеграции можно вручную масштабировать компьютер или масштабировать его на несколько компьютеров ([до 4 узлов](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)), и одно действие копирования будет секционировать набор файлов на всех узлах. 
- Одно действие копирования считывает из хранилища данных и выполняет запись в него с помощью нескольких потоков. 
- Поток управления ADF может запускать несколько операций копирования параллельно, например, с использованием [циклов for each](https://docs.microsoft.com/azure/data-factory/control-flow-for-each-activity). 

Дополнительные сведения можно получить из [руководств по производительности действия копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance) .

## <a name="resilience"></a>Устойчивость

В режиме ADF DistCp можно использовать различные параметры командной строки DistCp (например,-i, игнорировать ошибки,-Update, записывать данные, когда исходный файл и файл назначения различаются по размеру) для достижения различных уровней устойчивости.

В собственном IR-режиме ADF в рамках одного действия копирования ADF-файл имеет встроенный механизм повторных попыток, чтобы он мог управлять определенным уровнем временных сбоев в хранилищах данных или в базовой сети. При выполнении двоичного копирования из локальной HDFS в BLOB-объект и из локальной HDFS в ADLS 2-го поколения, ADF автоматически выполняет контрольные точки в большом экстенте. Если при выполнении действия копирования произошел сбой или истекло время ожидания, при последующей попытке (убедитесь, что число повторных попыток > 1) начинается с последней точки сбоя, а не с начала.

## <a name="network-security"></a>Безопасность сети 

По умолчанию ADF передает данные из локальной системы HDFS в хранилище BLOB-объектов Azure или Azure Data Lake Storage 2-го поколения с помощью зашифрованного соединения по протоколу HTTPS.  HTTPS обеспечивает шифрование данных при передаче и предотвращает атаки перехвата и атак типа "злоумышленник в середине". 

Кроме того, если вы не хотите, чтобы данные передавались через общедоступный Интернет, вы можете повысить уровень безопасности, передавая данные через частный пиринг через маршрут Azure Express. Сведения о том, как это можно сделать, см. в описании архитектуры решения.

## <a name="solution-architecture"></a>Архитектура решения

Перенос данных через общедоступный Интернет:

![решение — архитектура — общедоступная — сеть](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-public-network.png)

- В этой архитектуре данные безопасно передаются по протоколу HTTPS через общедоступный Интернет. 
- Для использования в среде общедоступной сети рекомендуется использовать режим DistCp ADF. Это позволяет не только использовать имеющийся мощный кластер для достижения наилучшей пропускной способности копирования, но также обеспечивает гибкие возможности планирования и единого мониторинга из ADF.
- Необходимо установить локальную среду выполнения интеграции ADF на компьютере под управлением Windows, расположенном за корпоративным брандмауэром, для отправки команды DistCp в кластер Hadoop и мониторинга состояния копирования. Данный компьютер не будет подсистемой для перемещения данных (только для целей управления). емкость компьютера не влияет на пропускную способность перемещения данных.
- Поддерживаются существующие параметры команды DistCp.


Перенос данных по частной ссылке: 

![решение — архитектура — частный — сеть](media/data-migration-guidance-hdfs-to-azure-storage/solution-architecture-private-network.png)

- В этой архитектуре миграция данных выполняется через ссылку частного пиринга через Azure Express Route, так что данные никогда не проходят через общедоступный Интернет.
- Средство DistCp не поддерживает частный пиринг прямого пиринга и конечную точку виртуальной сети службы хранилища Azure, поэтому для переноса данных рекомендуется использовать собственные возможности ADF через среду выполнения интеграции.
- Для достижения этой архитектуры необходимо установить автономную среду выполнения интеграции ADF на виртуальной машине Windows в виртуальной сети Azure. Вы можете вручную масштабировать виртуальную машину или масштабировать ее до нескольких виртуальных машин, чтобы полностью использовать операции ввода-вывода и пропускную способность сети и хранилища.
- Рекомендуемая конфигурация для начала для каждой виртуальной машины Azure (с установленной локальной средой выполнения ADF) — Standard_D32s_v3 с 32 виртуальных ЦП и 128 ГБ памяти. Вы можете отслеживать использование ЦП и памяти виртуальной машины во время переноса данных, чтобы узнать, нужно ли дополнительно масштабировать виртуальную машину для повышения производительности или уменьшения масштаба виртуальной машины, чтобы сэкономить затраты.
- Кроме того, можно выполнить горизонтальное масштабирование, связав до 4 узлов виртуальных машин с одним локальным IR. Одно задание копирования, выполняемое для автономной среды IR, автоматически разсекционует набор файлов и будет использовать все узлы виртуальных машин для параллельного копирования файлов. Для обеспечения высокой доступности рекомендуется начать с двух узлов виртуальных машин, чтобы избежать единой точки отказа во время переноса данных.
- С помощью этой архитектуры можно достичь первоначальной миграции данных моментальных снимков и переноса разностных данных.


## <a name="implementation-best-practices"></a>Рекомендации по реализации 

### <a name="authentication-and-credential-management"></a>Проверка подлинности и управление учетными данными 

- Для проверки подлинности в HDFS можно использовать [либо Windows (Kerberos), либо анонимный](https://docs.microsoft.com/azure/data-factory/connector-hdfs#linked-service-properties). 
- Для подключения к хранилищу BLOB-объектов Azure поддерживаются несколько типов проверки подлинности.  Настоятельно рекомендуется использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#managed-identity) , основанные на автоматически управляемой идентификации ADF в Azure AD. она позволяет настраивать конвейеры без предоставления учетных данных в определении связанной службы.  Кроме того, можно выполнить аутентификацию в хранилище BLOB-объектов Azure с помощью [субъекта-службы](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#service-principal-authentication), [подписанного URL-имени](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#shared-access-signature-authentication) или [ключа учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage#account-key-authentication). 
- Для подключения к Azure Data Lake Storage 2-го поколения также поддерживаются несколько типов проверки подлинности.  Настоятельно рекомендуется использовать [управляемые удостоверения для ресурсов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#managed-identity) , хотя также можно использовать [субъект-службу](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#service-principal-authentication) или [ключ учетной записи хранения](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage#account-key-authentication) . 
- Если вы не используете управляемые удостоверения для ресурсов Azure, настоятельно рекомендуется [хранить учетные данные в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault) , чтобы упростить централизованное управление и вращение ключей без изменения связанных служб ADF.  Это также один из рекомендаций [по интеграции и откомпакт-диску](https://docs.microsoft.com/azure/data-factory/continuous-integration-deployment#best-practices-for-cicd). 

### <a name="initial-snapshot-data-migration"></a>Исходный моментальный снимок — перенос данных 

В режиме ADF DistCp можно создать одно действие копирования для отправки команды DistCp с различными параметрами для управления первоначальным поведением при миграции данных. 

В собственном ИК-режиме ADF рекомендуется использовать раздел данных, особенно при переносе более 10 ТБ данных. Чтобы секционировать данные, используйте имена папок HDFS, а затем каждое задание копирования ADF может скопировать один раздел папки за раз. Для повышения пропускной способности можно одновременно запустить несколько заданий копирования ADF.
Если какое-либо из заданий копирования завершилось сбоем из – за временной проблемы с сетью или хранилищем данных, можно повторно выполнить задание копирования, завершившееся сбоем, чтобы повторно загрузить эту конкретную секцию из HDFS. Все остальные задания копирования, загружают другие секции, не будут затронуты.

### <a name="delta-data-migration"></a>Перенос разностных данных 

В режиме ADF DistCp можно использовать параметры командной строки DistCp "-Update, записывать данные, когда исходный файл и файл назначения различаются по размеру" для достижения разностной миграции данных.

В собственном ИК-режиме ADF наиболее эффективный способ обнаружения новых или измененных файлов из HDFS заключается в использовании соглашения об именовании с секционированием по времени, когда данные в HDFS были секционированы с данными временных срезов в имени файла или папки (например,/ИИИИ/мм/дд/ файл. csv), то конвейер может легко найти файлы и папки для добавочного копирования.
Кроме того, если данные в HDFS не имеют временных секций, ADF может выделять новые или измененные файлы по их LastModifiedDate. В этом случае ADF будет сканировать все файлы из HDFS и копировать только новый и обновленный файл, метка времени последнего изменения которого больше определенного значения. Имейте в виду, что при наличии большого количества файлов в HDFS проверка исходного файла может занять много времени независимо от того, сколько файлов соответствует условию фильтра. В этом случае рекомендуется сначала секционировать данные, используя одну и ту же секцию для первоначальной миграции моментальных снимков, чтобы сканирование файлов можно было выполнять параллельно.

### <a name="estimating-price"></a>Оценка цены 

Рассмотрим следующий конвейер, созданный для переноса данных из HDFS в хранилище BLOB-объектов Azure: 

![цены — конвейер](media/data-migration-guidance-hdfs-to-azure-storage/pricing-pipeline.png)

Предположим, что мы предполагаем следующее: 

- Общий объем данных составляет 1 ПБ
- Перенос данных с помощью второй архитектуры решения (собственный IR-режим ADF)
- 1 PB делится на 1000 секций и каждая копия перемещается в одну секцию
- Для каждого действия копирования настраивается один автономный IR-сервер, связанный с 4 компьютерами, и достигается пропускная способность 500 Мбит/с.
- Параметр параллелизма ForEach имеет значение 4, а суммарная пропускная способность — 2 Гбит/с
- В итоге выполнение миграции займет 146 часа.


Ниже приведена Оценочная цена, основанная на указанных выше допущениях. 

![цены — таблица](media/data-migration-guidance-hdfs-to-azure-storage/pricing-table.png)

> [!NOTE]
> Это гипотетический пример цены.  Реальная цена зависит от фактической пропускной способности в вашей среде.
> Цена для виртуальной машины Azure Windows (с установленной локальной средой выполнения интеграции) не включена.

### <a name="additional-references"></a>Дополнительные ссылки 
- [Соединитель HDFS](https://docs.microsoft.com/azure/data-factory/connector-hdfs)
- [Соединитель хранилища BLOB-объектов Azure](https://docs.microsoft.com/azure/data-factory/connector-azure-blob-storage)
- [Copy data to or from Azure Data Lake Storage Gen2 Preview using Azure Data Factory (Preview)](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-storage) (Копирование данных в Azure Data Lake Storage Gen2 (предварительная версия) или из него с помощью фабрики данных Azure)
- [Краткое руководств по настройке производительности действий копирования](https://docs.microsoft.com/azure/data-factory/copy-activity-performance)
- [Создание и Настройка автономных Integration Runtime](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime)
- [Высокая доступность и масштабируемость локальной среды выполнения интеграции](https://docs.microsoft.com/azure/data-factory/create-self-hosted-integration-runtime#high-availability-and-scalability)
- [Вопросы безопасности перемещения данных](https://docs.microsoft.com/azure/data-factory/data-movement-security-considerations)
- [Хранение учетных данных в Azure Key Vault](https://docs.microsoft.com/azure/data-factory/store-credentials-in-key-vault)
- [Копировать файл добавочно в соответствии с временным секционированным именем файла](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-partitioned-file-name-copy-data-tool)
- [Копировать новые и измененные файлы на основе LastModifiedDate](https://docs.microsoft.com/azure/data-factory/tutorial-incremental-copy-lastmodified-copy-data-tool)
- [Страница с ценами на ADF](https://azure.microsoft.com/pricing/details/data-factory/data-pipeline/)

## <a name="next-steps"></a>Следующие шаги

- [Копирование файлов из нескольких контейнеров с помощью фабрики данных Azure](solution-template-copy-files-multiple-containers.md)