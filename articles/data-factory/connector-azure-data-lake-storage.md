---
title: Копирование данных в Azure Data Lake Storage 2-го поколения с помощью фабрики данных или из нее | Документация Майкрософт
description: Узнайте, как копировать данные в Azure Data Lake Storage 2-го поколения с помощью фабрики данных Azure и обратно.
services: data-factory
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.date: 09/09/2019
ms.author: jingwang
ms.openlocfilehash: 8f190f6b933c61072df9af954c8db01497e35e82
ms.sourcegitcommit: a819209a7c293078ff5377dee266fa76fd20902c
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 09/16/2019
ms.locfileid: "71010233"
---
# <a name="copy-data-to-or-from-azure-data-lake-storage-gen2-using-azure-data-factory"></a>Копирование данных в хранилище Azure Data Lake Storage 2-го поколения и из него с помощью Фабрики данных Azure

Azure Data Lake Storage 2-го поколения (ADLS 2-го поколения) — это набор возможностей, предназначенных для аналитики больших данных, встроенных в [хранилище BLOB-объектов Azure](../storage/blobs/storage-blobs-introduction.md). Его можно использовать для взаимодействия с данными с помощью парадигмы файловой системы и хранилища объектов.

В этой статье описано, как копировать данные в Azure Data Lake Storage 2-го поколения и обратно. Дополнительные сведения о Фабрике данных Azure см. во [вводной статье](introduction.md).

## <a name="supported-capabilities"></a>Поддерживаемые возможности

Этот соединитель Azure Data Lake Storage 2-го поколения поддерживается для следующих действий:

- [Действие копирования](copy-activity-overview.md) с [поддерживаемой матрицей источника и приемника](copy-activity-overview.md)
- [Поток данных сопоставления](concepts-data-flow-overview.md)
- [Действие поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)
- [Удалить действие](delete-activity.md)

В частности, с помощью этого соединителя можно:

- Копирование данных с помощью ключа учетной записи, субъекта-службы или управляемых удостоверений для проверки подлинности ресурсов Azure.
- Скопируйте файлы как есть или Проанализируйте или создайте файлы с [поддерживаемыми форматами файлов и кодеками сжатия](supported-file-formats-and-compression-codecs.md).

>[!TIP]
>При включении иерархического пространства имен в настоящее время не существует взаимодействия между BLOB-объектами и Data Lake Storage 2-го поколения API. Если вы столкнулись с ошибкой "ErrorCode = Филесистемнотфаунд" с сообщением "указанная файловая система не существует", это вызвано указанной файловой системой приемника, созданной с помощью API BLOB-объектов, а не Data Lake Storage 2-го поколения API в других местах. Чтобы устранить эту проблему, укажите новую файловую систему с именем, которое не существует в качестве имени контейнера больших двоичных объектов. Затем фабрика данных автоматически создает эту файловую систему во время копирования данных.

>[!NOTE]
>Если вы включили параметр **разрешить доверенным службам Майкрософт доступ к этой учетной записи хранения** в параметрах брандмауэра службы хранилища Azure, среда выполнения интеграции Azure не подключится к Data Lake Storage 2-го поколения и отобразит ошибку запрета. Выводится сообщение об ошибке, так как фабрика данных не рассматривается как доверенная служба Майкрософт. Вместо этого используйте локальную среду выполнения интеграции.

## <a name="get-started"></a>Начало работы

>[!TIP]
>Пошаговые инструкции по использованию соединителя Data Lake Storage 2-го поколения см. в разделе [Загрузка данных в Azure Data Lake Storage 2-го поколения](load-azure-data-lake-storage-gen2.md).

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

Следующие разделы содержат сведения о свойствах, которые используются для определения сущностей фабрики данных, относящихся к Data Lake Storage 2-го поколения.

## <a name="linked-service-properties"></a>Свойства связанной службы

Соединитель Azure Data Lake Storage 2-го поколения поддерживает следующие типы проверки подлинности. Дополнительные сведения см. в соответствующих разделах:

- [Проверка подлинности на основе ключа учетной записи](#account-key-authentication)
- [Проверка подлинности субъекта-службы](#service-principal-authentication)
- [Проверка подлинности на основе управляемого удостоверения службы](#managed-identity)

>[!NOTE]
>При использовании Polybase для загрузки данных в хранилище данных SQL, если в исходной Data Lake Storage 2-го поколения настроена конечная точка виртуальной сети, необходимо использовать управляемую проверку подлинности с идентификацией в соответствии с требованиями Polybase. Дополнительные предварительные требования см. в разделе [Проверка подлинности управляемого удостоверения](#managed-identity) .

### <a name="account-key-authentication"></a>Проверка подлинности на основе ключа учетной записи

При использовании проверки подлинности на основе ключа учетной записи поддерживаются следующие свойства.

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Data Lake Storage 2-го поколения с шаблоном `https://<accountname>.dfs.core.windows.net`. | true |
| accountKey | Ключ учетной записи для Data Lake Storage 2-го поколения. Пометьте это поле как SecureString, чтобы безопасно хранить его в фабрике данных, или [добавьте ссылку на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). |Да |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду выполнения интеграции, если хранилище данных находится в частной сети. Если это свойство не указано, используется среда выполнения интеграции Azure по умолчанию. |Нет |

>[!NOTE]
>Вторичная конечная точка файловой системы ADLS не поддерживается при использовании проверки подлинности ключа учетной записи. Можно использовать другие типы проверки подлинности.

**Пример.**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "accountkey": { 
                "type": "SecureString", 
                "value": "<accountkey>" 
            }
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="service-principal-authentication"></a>Проверка подлинности субъекта-службы

Чтобы использовать проверку подлинности субъекта-службы, выполните следующие действия.

1. Зарегистрируйте сущность приложения в Azure Active Directory (Azure AD), выполнив действия, описанные в статье [Регистрация приложения в клиенте Azure AD](../storage/common/storage-auth-aad-app.md#register-your-application-with-an-azure-ad-tenant). Запишите следующие значения, которые используются для определения связанной службы:

    - ИД приложения
    - Ключ приложения
    - Идентификатор клиента

2. Предоставьте субъекту-службе соответствующее разрешение. Дополнительные сведения о том, как работает разрешение в Data Lake Storage 2-го поколения из [списков управления доступом к файлам и каталогам](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories)

    - **В качестве источника**. В Обозреватель службы хранилища предоставьте по меньшей мере разрешение **EXECUTE** , начиная с исходной файловой системы, а также разрешение на **Чтение** файлов для копирования. Кроме того, в системе управления доступом (IAM) Предоставьте по крайней мере роль **читателя данных BLOB-объекта хранилища** .
    - **В качестве приемника**. В Обозреватель службы хранилища предоставьте по крайней мере разрешение на **выполнение** из файловой системы приемника, а также разрешение на **запись** для папки приемника. Кроме того, в системе управления доступом (IAM) Предоставьте по крайней мере роль **участника данных BLOB-объекта хранилища** .

>[!NOTE]
>Чтобы получить список папок, начиная с уровня учетной записи или для проверки подключения, необходимо задать разрешение субъекта-службы, предоставленное **учетной записи хранения, с разрешением "модуль чтения BLOB-объектов хранилища" в IAM**. Это работает, если вы используете:
>- **Средство копирования данных** для создания конвейера копирования.
>- **пользовательский интерфейс фабрики данных** для проверки подключения и перемещения по папкам во время разработки. 
>Если у вас есть вопросы, связанные с предоставлением разрешения на уровне учетной записи, при создании, пропуске проверки соединения и вводе родительского пути с предоставленными разрешениями выберите Просмотр по указанному пути. Действие копирования работает при условии, что субъект-служба предоставляет соответствующее разрешение на копируемых файлах.

Для связанной службы поддерживаются следующие свойства:

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Data Lake Storage 2-го поколения с шаблоном `https://<accountname>.dfs.core.windows.net`. | true |
| servicePrincipalId | Укажите идентификатора клиента приложения. | true |
| servicePrincipalKey | Укажите ключ приложения. Пометьте это поле как `SecureString` , чтобы безопасно хранить его в фабрике данных. Или можно [сослаться на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). | true |
| tenant | Укажите сведения о клиенте (доменное имя или идентификатор клиента), в котором находится приложение. Извлеките его, наведя указатель мыши на правый верхний угол портал Azure. | true |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду выполнения интеграции, если хранилище данных находится в частной сети. Если значение не указано, используется среда выполнения интеграции Azure по умолчанию. |Нет |

**Пример.**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "servicePrincipalId": "<service principal id>",
            "servicePrincipalKey": {
                "type": "SecureString",
                "value": "<service principal key>"
            },
            "tenant": "<tenant info, e.g. microsoft.onmicrosoft.com>" 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="managed-identity"></a> Управляемые удостоверения для аутентификации ресурсов Azure

Фабрика данных может быть связана с [управляемым удостоверением для ресурсов Azure](data-factory-service-identity.md), которое представляет эту фабрику данных. Вы можете напрямую использовать это управляемое удостоверение для проверки подлинности Data Lake Storage 2-го поколения, как и при использовании собственного субъекта-службы. Она позволяет этой назначенной фабрике получать доступ к Data Lake Storage 2-го поколения и копировать данные из него.

Чтобы использовать управляемые удостоверения для проверки подлинности ресурсов Azure, выполните следующие действия.

1. [Получите сведения об управляемом удостоверении фабрики данных](data-factory-service-identity.md#retrieve-managed-identity) , СКОПИРОВАВ значение **идентификатора приложения удостоверений службы** , созданного вместе с фабрикой.

2. Предоставьте управляемому удостоверению соответствующее разрешение. Дополнительные сведения о том, как работает разрешение в Data Lake Storage 2-го поколения из [списков управления доступом к файлам и каталогам](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories).

    - **В качестве источника**. В Обозреватель службы хранилища предоставьте по меньшей мере разрешение **EXECUTE** , начиная с исходной файловой системы, а также разрешение на **Чтение** файлов для копирования. Кроме того, в системе управления доступом (IAM) Предоставьте по крайней мере роль **читателя данных BLOB-объекта хранилища** .
    - **В качестве приемника**. В Обозреватель службы хранилища предоставьте по крайней мере разрешение на **выполнение** из файловой системы приемника, а также разрешение на **запись** для папки приемника. Кроме того, в системе управления доступом (IAM) Предоставьте по крайней мере роль **участника данных BLOB-объекта хранилища** .

>[!NOTE]
>Чтобы получить список папок, начинающихся с уровня учетной записи или для проверки подключения, необходимо задать разрешение управляемому удостоверению, предоставленное **учетной записи хранения, с разрешением "модуль чтения BLOB-данных хранилища" в IAM**. Это работает, если вы используете:
>- **Средство копирования данных** для создания конвейера копирования.
>- **пользовательский интерфейс фабрики данных** для проверки подключения и перемещения по папкам во время разработки. 
>Если у вас есть вопросы, связанные с предоставлением разрешения на уровне учетной записи, при создании, пропуске проверки соединения и вводе родительского пути с предоставленными разрешениями выберите Просмотр по указанному пути. Действие копирования работает при условии, что субъект-служба предоставляет соответствующее разрешение на копируемых файлах.

>[!IMPORTANT]
>Если вы используете Polybase для загрузки данных из Data Lake Storage 2-го поколения в хранилище данных SQL, при использовании проверки подлинности управляемого удостоверения для Data Lake Storage 2-го поколения убедитесь, что вы также выполните шаги 1 и 2 в [этом руководстве](../sql-database/sql-database-vnet-service-endpoint-rule-overview.md#impact-of-using-vnet-service-endpoints-with-azure-storage) , чтобы 1) зарегистрировать сервер базы данных SQL с помощью. Azure Active Directory (Azure AD) и 2) Назначьте роль участника данных BLOB-объекта хранилища серверу базы данных SQL. остальные обрабатываются фабрикой данных. Если ваша Data Lake Storage 2-го поколения настроена с конечной точкой виртуальной сети Azure, чтобы использовать Polybase для загрузки данных из нее, необходимо использовать управляемую проверку подлинности с использованием идентификации, которая необходима Polybase.

Для связанной службы поддерживаются следующие свойства:

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для Data Lake Storage 2-го поколения с шаблоном `https://<accountname>.dfs.core.windows.net`. | true |
| connectVia | [Среда выполнения интеграции](concepts-integration-runtime.md), используемая для подключения к хранилищу данных. Вы можете использовать среду выполнения интеграции Azure или локальную среду выполнения интеграции, если хранилище данных находится в частной сети. Если значение не указано, используется среда выполнения интеграции Azure по умолчанию. |Нет |

**Пример.**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, см. в разделе [наборы данных](concepts-datasets-linked-services.md).

- Для **Parquet, текстовых форматов, JSON, Avro и двоичного**формата, см. раздел [Parquet, текстовый, JSON, Avro и двоичный формат набора данных](#format-based-dataset) .
- Другие форматы, например **Формат ORC**, см. в разделе [другой формат набора данных](#other-format-dataset) .

### <a name="format-based-dataset"></a>Parquet, текстовый набор данных с разделителями, JSON, Avro и двоичный формат

Чтобы скопировать данные в **Parquet, разделенный текст, Avro или двоичный формат**, см. статью [Формат Parquet](format-parquet.md), [текстовый формат с разделителями](format-delimited-text.md), [Формат Avro](format-avro.md) и [двоичный формат](format-binary.md) в наборе данных на основе формата и поддерживаемых параметрах. Следующие свойства поддерживаются для Data Lake Storage 2-го поколения в разделе `location` "Параметры" в наборе данных на основе формата:

| Свойство   | Описание                                                  | Обязательно для заполнения |
| ---------- | ------------------------------------------------------------ | -------- |
| type       | Свойство `location` Type в наборе данных должно иметь значение **азуреблобфслокатион**. | true      |
| fileSystem | Data Lake Storage 2-го поколения имя файловой системы.                              | Нет       |
| folderPath | Путь к папке в данной файловой системе. Если вы хотите использовать подстановочный знак для фильтрации папок, пропустите этот параметр и укажите его в параметрах источника действия. | Нет       |
| fileName   | Имя файла в заданной файловой системе и folderPath. Если вы хотите использовать подстановочный знак для фильтрации файлов, пропустите этот параметр и укажите его в параметрах источника действия. | Нет       |

> [!NOTE]
> Набор данных типа **азуреблобфсфиле** с Parquet или текстовым форматом, упомянутым в следующем разделе, по-прежнему поддерживается как "для операций копирования, поиска или работы с метаданными для обеспечения обратной совместимости. Но он не работает с функцией потока данных сопоставления. Мы рекомендуем использовать эту новую модель в дальнейшем. Пользовательский интерфейс создания фабрики данных создает эти новые типы.

**Пример.**

```json
{
    "name": "DelimitedTextDataset",
    "properties": {
        "type": "DelimitedText",
        "linkedServiceName": {
            "referenceName": "<Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, auto retrieved during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureBlobFSLocation",
                "fileSystem": "filesystemname",
                "folderPath": "folder/subfolder"
            },
            "columnDelimiter": ",",
            "quoteChar": "\"",
            "firstRowAsHeader": true,
            "compressionCodec": "gzip"
        }
    }
}
```

### <a name="other-format-dataset"></a>Другой формат набора данных

Чтобы скопировать данные в Data Lake Storage 2-го поколения в **формате ORC**и обратно, поддерживаются следующие свойства:

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Свойство type для набора данных должно иметь значение **AzureBlobFSFile**. |Да |
| folderPath | Путь к папке в Data Lake Storage 2-го поколения. Если это свойство не указано, будет использоваться корневая папка. <br/><br/>Поддерживается фильтр с подстановочными знаками. Разрешенные подстановочные `*` знаки (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или этот escape-символ находится внутри. <br/><br/>Примеры: FileSystem/Folder/. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). |Нет |
| fileName | Имя или фильтр по шаблону для файлов с указанной "folderPath". Если этому свойству не присвоить значение, набор данных будет указывать на все файлы в папке. <br/><br/>Для фильтра разрешены `*` подстановочные знаки (соответствует нулю или больше символов) и `?` (соответствует нулю или одиночному символу).<br/>Пример 1. `"fileName": "*.csv"`<br/>Пример 2. `"fileName": "???20180427.txt"`<br/>Используйте `^` для экранирования, если фактическое имя файла имеет подстановочный знак или этот escape-символ находится внутри.<br/><br/>Если fileName для выходного набора данных не указан, а **preserveHierarchy** не указан в приемнике действия, действие копирования автоматически создаст имя файла по следующему шаблону: "*Данные. [ИД выполнения действия идентификатор GUID]. [GUID if FlattenHierarchy]. [Format, если настроено]. [compression, если он настроен]* ", например" Data. 0a405f8a-93ff-4c6f-b3be-f69616f1df7a. txt. gz ". При копировании из табличного источника с использованием имени таблицы вместо запроса используется шаблон имени " *[имя таблицы]. [ format]. [compression, если он настроен]* ", например" MyTable. csv ". |Нет |
| modifiedDatetimeStart | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра влияет на общую производительность перемещения данных, если требуется использовать фильтр файлов с огромным объемом файлов. <br/><br/> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime.| Нет |
| modifiedDatetimeEnd | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br/><br/> Включение этого параметра влияет на общую производительность перемещения данных, если требуется использовать фильтр файлов с огромным объемом файлов. <br/><br/> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime.| Нет |
| format | Если требуется скопировать файлы между файловыми хранилищами "как есть" (двоичное копирование), можно пропустить раздел форматирования в определениях входного и выходного наборов данных.<br/><br/>Вам может понадобиться анализировать или создавать файлы, имеющие определенный формат. Поддерживаются следующие форматы файлов: **TextFormat**, **JsonFormat**, **AvroFormat**, **OrcFormat** и **ParquetFormat**. Свойству **type** в разделе **format** необходимо присвоить одно из этих значений. Дополнительные сведения см. в разделах формат [текста](supported-file-formats-and-compression-codecs.md#text-format), [Формат JSON](supported-file-formats-and-compression-codecs.md#json-format), [Формат Avro](supported-file-formats-and-compression-codecs.md#avro-format), [Формат ORC](supported-file-formats-and-compression-codecs.md#orc-format)и [Формат Parquet](supported-file-formats-and-compression-codecs.md#parquet-format) . |Нет (только для сценария двоичного копирования) |
| compression | Укажите тип и уровень сжатия данных. Дополнительные сведения см. в разделе [Поддержка сжатия](supported-file-formats-and-compression-codecs.md#compression-support).<br/>Поддерживаемые типы: **GZip**, **Deflate**, **BZip2** и **ZipDeflate**.<br/>Поддерживаемые уровни: **Optimal** и **Fastest**. |Нет |

>[!TIP]
>Чтобы скопировать все файлы в папке, укажите только **folderPath**.<br>Чтобы скопировать один файл с заданным именем, укажите параметр **FolderPath** **с именем файла и файлом** .<br>Чтобы скопировать подмножество файлов в папке, укажите параметр **FolderPath** с частью папки и **именем файла** с фильтром с подстановочными знаками. 

**Пример.**

```json
{
    "name": "ADLSGen2Dataset",
    "properties": {
        "type": "AzureBlobFSFile",
        "linkedServiceName": {
            "referenceName": "<Azure Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "typeProperties": {
            "folderPath": "myfilesystem/myfolder",
            "fileName": "*",
            "modifiedDatetimeStart": "2018-12-01T05:00:00Z",
            "modifiedDatetimeEnd": "2018-12-01T06:00:00Z",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ",",
                "rowDelimiter": "\n"
            },
            "compression": {
                "type": "GZip",
                "level": "Optimal"
            }
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, доступных для определения действий, см. в разделе [конфигурации действий копирования](copy-activity-overview.md#configuration) , [конвейеры и действия](concepts-pipelines-activities.md). Этот раздел содержит список свойств, поддерживаемых источником и приемником Data Lake Storage Gen2.

### <a name="azure-data-lake-storage-gen2-as-a-source-type"></a>Azure Data Lake Storage 2-го поколения в качестве типа источника

- Чтобы скопировать данные из **Parquet, разделенного текста, JSON, Avro и двоичного**формата, обратитесь к разделу [Parquet, тексту с разделителями, JSON, Avro и источнику двоичного формата](#format-based-source) .
- Чтобы выполнить копирование из других форматов, таких как **Формат ORC**, обратитесь к другому разделу [исходного формата](#other-format-source) .

#### <a name="format-based-source"></a>Parquet, текст с разделителями, JSON, Avro и источник двоичного формата

Чтобы скопировать данные из **Parquet, разделенного текста, JSON, Avro и двоичного**формата, см. статью [Формат Parquet](format-parquet.md), [текстовый формат с разделителями](format-delimited-text.md), [Формат Avro](format-avro.md) и [двоичный формат](format-binary.md) для источника действия копирования на основе формата и поддерживается. Параметры. Следующие свойства поддерживаются для Data Lake Storage 2-го поколения в разделе `storeSettings` параметры в источнике копирования на основе формата:

| Свойство                 | Описание                                                  | Обязательно для заполнения                                      |
| ------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| type                     | Свойство Type в разделе `storeSettings` должно иметь значение **азуреблобфсреадсеттинг**. | Да                                           |
| recursive                | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если параметру recursive присвоено значение true и приемник является хранилищем на основе файлов, пустая папка или подпапка не копируется или не создается в приемнике. Допустимые значения: **true** (по умолчанию) и **false**. | Нет                                            |
| вилдкардфолдерпас       | Путь к папке с подстановочными знаками в заданной файловой системе, настроенной в наборе данных для фильтрации исходных папок. <br>Разрешенные подстановочные `*` знаки (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или escape-символ внутри. <br>Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Нет                                            |
| вилдкардфиленаме         | Имя файла с подстановочными знаками в заданной файловой системе + folderPath/Вилдкардфолдерпас для фильтрации исходных файлов. <br>Разрешенные подстановочные `*` знаки (соответствует нулю или большему числу символов) и `?` (соответствует нулю или одиночному символу). Используйте `^` для экранирования, если фактическое имя папки содержит подстановочный знак или escape-символ внутри. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Да, `fileName` если не указано в наборе данных |
| modifiedDatetimeStart    | Фильтр файлов, основанный на последнем измененном атрибуте. Файлы выбираются, если время последнего изменения находится в пределах интервала времени между `modifiedDatetimeStart` и `modifiedDatetimeEnd`. Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00Z". <br> Свойства могут иметь значение NULL, что означает, что фильтр атрибутов файла не применяется к набору данных. Если `modifiedDatetimeStart` имеет значение DateTime, но `modifiedDatetimeEnd` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых больше или равен значению DateTime. Если `modifiedDatetimeEnd` имеет значение DateTime, но `modifiedDatetimeStart` равно null, это означает, что выбраны файлы, атрибут последнего изменения которых меньше значения DateTime. | Нет                                            |
| modifiedDatetimeEnd      | То же, что и выше.                                               | Нет                                            |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу хранилища. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | Нет                                            |

> [!NOTE]
> Для формата текста Parquet или с разделителями в качестве источника действия копирования типа **азуреблобфссаурце** , упомянутого в следующем разделе, по-прежнему поддерживается в целях обратной совместимости. Мы рекомендуем использовать эту новую модель в дальнейшем. Пользовательский интерфейс создания фабрики данных создает эти новые типы.

**Пример.**

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<Delimited text input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "DelimitedTextSource",
                "formatSettings":{
                    "type": "DelimitedTextReadSetting",
                    "skipLineCount": 10
                },
                "storeSettings":{
                    "type": "AzureBlobFSReadSetting",
                    "recursive": true,
                    "wildcardFolderPath": "myfolder*A",
                    "wildcardFileName": "*.csv"
                }
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

#### <a name="other-format-source"></a>Другой источник формата

Чтобы скопировать данные из Data Lake Storage 2-го поколения в **формате ORC**, в разделе **источник** действия копирования поддерживаются следующие свойства.

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Свойство type источника действия копирования должно иметь значение **AzureBlobFSSource**. |Да |
| recursive | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Если параметру recursive присвоено значение true и приемник является хранилищем на основе файлов, пустая папка или подпапка не копируется или не создается в приемнике.<br/>Допустимые значения: **true** (по умолчанию) и **false**. | Нет |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | Нет |

**Пример.**

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<ADLS Gen2 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "AzureBlobFSSource",
                "recursive": true
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="azure-data-lake-storage-gen2-as-a-sink-type"></a>Azure Data Lake Storage Gen2 как тип приемника

- Чтобы скопировать в **Parquet, текст, JSON, Avro и двоичный формат**, см. раздел [Parquet, Text, JSON, Avro и приемник двоичного формата](#format-based-sink) .
- Чтобы скопировать данные в другие форматы, такие как **Формат ORC/JSON**, см. раздел [другой приемник формата](#other-format-sink) .

#### <a name="format-based-sink"></a>Parquet, текстовый приемник с разделителями, JSON, Avro и двоичный формат

Чтобы скопировать данные в **Parquet, текстовые форматы с разделителями, JSON, Avro и двоичный**формат, см. статью [Формат Parquet](format-parquet.md), [текстовый формат с разделителями](format-delimited-text.md), [Формат Avro](format-avro.md) и [двоичный формат](format-binary.md) для приемника действия копирования на основе формата и поддерживается. Параметры. Следующие свойства поддерживаются для Data Lake Storage 2-го поколения в разделе `storeSettings` параметры в приемнике копирования на основе формата:

| Свойство                 | Описание                                                  | Обязательно для заполнения |
| ------------------------ | ------------------------------------------------------------ | -------- |
| type                     | Свойство Type в разделе `storeSettings` должно иметь значение **азуреблобфсвритесеттинг**. | Да      |
| copyBehavior             | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | Нет       |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | Нет       |

> [!NOTE]
> Для формата текста Parquet или с разделителями тип **азуреблобфссинк** (приемник действия копирования), упомянутый в следующем разделе, по-прежнему поддерживается в целях обратной совместимости. Мы рекомендуем использовать эту новую модель в дальнейшем. Пользовательский интерфейс создания фабрики данных создает эти новые типы.

**Пример.**

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Parquet output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "ParquetSink",
                "storeSettings":{
                    "type": "AzureBlobFSWriteSetting",
                    "copyBehavior": "PreserveHierarchy"
                }
            }
        }
    }
]
```

#### <a name="other-format-sink"></a>Другой приемник формата

Чтобы скопировать данные в Data Lake Storage 2-го поколения в **формате ORC**, в разделе **приемника** поддерживаются следующие свойства:

| Свойство | Описание | Обязательно для заполнения |
|:--- |:--- |:--- |
| type | Свойство type приемника действия копирования должно иметь значение **AzureBlobFSSink**. |Да |
| copyBehavior | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | Нет |
| maxConcurrentConnections | Число подключений для одновременного подключения к хранилищу данных. Укажите, только если требуется ограничить одновременный подключение к хранилищу данных. | Нет |

**Пример.**

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<ADLS Gen2 output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "AzureBlobFSSink",
                "copyBehavior": "PreserveHierarchy"
            }
        }
    }
]
```

### <a name="folder-and-file-filter-examples"></a>Примеры фильтров папок и файлов

В этом разделе описываются результаты применения фильтров с подстановочными знаками к пути папки и имени файла.

| folderPath | fileName | recursive | Структура исходной папки и результат фильтрации (извлекаются файлы, выделенные **полужирным** шрифтом)|
|:--- |:--- |:--- |:--- |
| `Folder*` | (Пусто, используйте значение по умолчанию) | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | (Пусто, используйте значение по умолчанию) | true | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл4.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | true | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |

### <a name="some-recursive-and-copybehavior-examples"></a>Некоторые примеры recursive и copyBehavior

В этом разделе описывается результирующее поведение операции копирования для различных сочетаний рекурсивных и copyBehavior значений.

| recursive | copyBehavior | Структура папок источника | Результаты цели |
|:--- |:--- |:--- |:--- |
| true |preserveHierarchy | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая "Папка1" создается с такой же структурой, как и исходная папка:<br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 |
| true |flattenHierarchy | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл3"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл4"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл5" |
| true |mergeFiles | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1", "Файл2", "Файл3", "Файл4" и "Файл5" объединяется в один файл с автоматически созданным именем. |
| false |preserveHierarchy | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |
| false |flattenHierarchy | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |
| false |mergeFiles | Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Folder1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1" и "Файл2" объединяется в один файл с автоматически созданным именем. автоматически созданное имя для "Файл1"<br/><br/>Subfolder1 с Файл3, "Файл4" и "Файл5" не забирается. |

## <a name="preserve-acls-from-data-lake-storage-gen1"></a>Сохранение списков управления доступом из Data Lake Storage 1-го поколения

>[!TIP]
>Инструкции по копированию данных из Azure Data Lake Storage 1-го поколения в Gen2 см. в статье [копирование данных из Azure Data Lake Storage 1-го поколения в Gen2 с помощью фабрики данных Azure](load-azure-data-lake-storage-gen2-from-gen1.md) .

При копировании файлов из Azure Data Lake Storage 1-го поколения в Gen2 можно сохранить список управления доступом POSIX (ACL) вместе с данными. Дополнительные сведения об управлении доступом см. в разделе [Контроль доступа в Azure Data Lake Storage 1-го поколения](../data-lake-store/data-lake-store-access-control.md) и [управление доступом в Azure Data Lake Storage 2-го поколения](../storage/blobs/data-lake-storage-access-control.md).

С помощью действия копирования в фабрике данных Azure можно сохранять следующие типы списков ACL. Можно выбрать один или несколько типов:

- **СПИСОК УПРАВЛЕНИЯ ДОСТУПОМ**: Копирование и сохранение списков управления доступом POSIX для файлов и каталогов. Он копирует все существующие списки ACL из источника в приемник. 
- **Владелец**: Копирование и сохранение пользователя-владельца файлов и каталогов. Требуется доступ суперпользователя к Data Lake Storage 2-го поколения приемника.
- **Группа**: Копирование и сохранение группы владельцев файлов и каталогов. Необходим доступ суперпользователя к Data Lake Storage 2-го поколения приемника или пользователю-владельцу (если владелец также является членом Целевой группы).

Если вы указываете копировать из папки, фабрика данных реплицирует списки управления доступом для указанной папки, а также файлы и каталоги, если `recursive` для параметра задано значение true. Если указать копирование из одного файла, то списки ACL для этого файла будут скопированы.

>[!IMPORTANT]
>Если вы решили сохранить списки управления доступом, убедитесь, что вы предоставляли достаточно высокий уровень разрешений для работы фабрики данных с учетной записью Data Lake Storage 2-го поколения приемника. Например, используйте проверку подлинности с помощью ключа учетной записи или назначьте роль владельца данных BLOB-объекта хранилища субъекту-службе или управляемому удостоверению.

При настройке исходного кода как Data Lake Storage 1-го поколения с параметром двоичного копирования или двоичного формата и приемника, как Data Lake Storage 2-го поколения с параметром двоичного копирования или двоичного формата, параметр **сохранить** можно найти на странице **копирование данных параметры средства** или на Вкладка**Параметры** **действия** > копирования для создания действий.

![Data Lake Storage 1-го поколения Gen2 сохранить список ACL](./media/connector-azure-data-lake-storage/adls-gen2-preserve-acl.png)

Ниже приведен пример конфигурации JSON (см. раздел `preserve`): 

```json
"activities":[
    {
        "name": "CopyFromGen1ToGen2",
        "type": "Copy",
        "typeProperties": {
            "source": {
                "type": "AzureDataLakeStoreSource",
                "recursive": true
            },
            "sink": {
                "type": "AzureBlobFSSink",
                "copyBehavior": "PreserveHierarchy"
            },
            "preserve": [
                "ACL",
                "Owner",
                "Group"
            ]
        },
        "inputs": [
            {
                "referenceName": "<Azure Data Lake Storage Gen1 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Azure Data Lake Storage Gen2 output dataset name>",
                "type": "DatasetReference"
            }
        ]
    }
]
```

## <a name="mapping-data-flow-properties"></a>Сопоставление свойств потока данных

Дополнительные сведения о преобразовании [источника](data-flow-source.md) и [преобразования приемников](data-flow-sink.md) в функции потока данных сопоставления.

## <a name="lookup-activity-properties"></a>Свойства действия поиска

Чтобы получить сведения о свойствах, проверьте [действие поиска](control-flow-lookup-activity.md).

## <a name="getmetadata-activity-properties"></a>Свойства действия с метаданными

Дополнительные сведения о свойствах см. в статье [действие с операциями](control-flow-get-metadata-activity.md) с помощью метаданных. 

## <a name="delete-activity-properties"></a>Свойства действия удаления

Чтобы получить сведения о свойствах, проверьте [действие Удалить](delete-activity.md) .
## <a name="next-steps"></a>Следующие шаги

В таблице [Поддерживаемые хранилища данных и форматы](copy-activity-overview.md##supported-data-stores-and-formats) приведен список хранилищ данных, которые поддерживаются в качестве источников и приемников для действия копирования в фабрике данных.
