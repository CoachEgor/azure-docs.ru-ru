---
title: Копирование и преобразование данных в Azure Data Lake Storage Gen2
description: Узнайте, как копировать данные в azure Data Lake Storage Gen2 и преобразовывать данные в Azure Data Lake Storage Gen2 с помощью Azure Data Factory.
services: data-factory
ms.author: jingwang
author: linda33wj
manager: shwang
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.topic: conceptual
ms.custom: seo-lt-2019
ms.date: 03/24/2020
ms.openlocfilehash: 3c7ff0061a57d1a1a7525ec03b4f77c117415ca5
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/28/2020
ms.locfileid: "80155856"
---
# <a name="copy-and-transform-data-in-azure-data-lake-storage-gen2-using-azure-data-factory"></a>Копирование и преобразование данных в Хранилище озер данных Azure Gen2 с помощью Azure Data Factory

Azure Data Lake Storage Gen2 (ADLS Gen2) — это набор возможностей, предназначенных для анализа больших данных, встроенных в [хранилище Azure Blob.](../storage/blobs/storage-blobs-introduction.md) Вы можете использовать его для взаимодействия с данными, используя как файловую систему, так и парадигмы хранения объектов.

В этой статье излагается, как использовать активность копирования в фабрике данных Azure для копирования данных из и в Azure Data Lake Storage Gen2 и использовать поток данных для преобразования данных в Azure Data Lake Storage Gen2. Дополнительные сведения о Фабрике данных Azure см. во [вводной статье](introduction.md).

## <a name="supported-capabilities"></a>Поддерживаемые возможности

Этот разъем хранения данных Azure Data Lake Gen2 поддерживается для следующих действий:

- [Копирование активности](copy-activity-overview.md) с [помощью поддерживаемой матрицы источника/раковины](copy-activity-overview.md)
- [Картирование потока данных](concepts-data-flow-overview.md)
- [Активность поиска](control-flow-lookup-activity.md)
- [Действие получения метаданных в Фабрике данных Azure](control-flow-get-metadata-activity.md)
- [Удаление действия](delete-activity.md)

Для копирования деятельности, с этим разъемом вы можете:

- Копирование данных из/в Azure Data Lake Storage 2 с помощью ключа учетной записи, основной службы или управляемых идентификаторов для проверки подлинности ресурсов Azure.
- Копировать файлы как есть или разбирать или генерировать файлы с [поддерживаемыми форматами файлов и кодеков сжатия.](supported-file-formats-and-compression-codecs.md)
- [Сохранить метаданные файлов во время копирования](#preserve-metadata-during-copy).
- [Сохранить AcLs](#preserve-acls) при копировании из Azure Data Lake Storage Gen1/Gen2.

>[!IMPORTANT]
>Если вы позволяете **доверенным службам Microsoft разрешить доступ к этой** опции учетной записи хранилища в настройках брандмауэра Azure Storage и хотите использовать время выполнения интеграции Azure для подключения к Data Lake Storage Gen2, необходимо использовать [управляемую проверку подлинности идентификации](#managed-identity) для ADLS Gen2.

>[!TIP]
>Если включить иерархическое пространство имен, то в настоящее время нет совместимости операций между ApIs Blob и Data Lake Storage Gen2. Если вы нажмете на ошибку "ErrorCode-FilesystemNotFound" с сообщением "Указанная файловая система не существует", это вызвано указанной файловой системой раковины, которая была создана через Blob API вместо API data Lake Storage Gen2 в другом месте. Чтобы устранить проблему, укажите новую файловую систему с именем, которое не существует как имя контейнера Blob. Затем Data Factory автоматически создает эту файловую систему во время копирования данных.

## <a name="get-started"></a>Начало работы

>[!TIP]
>Для просмотра возможностей использования разъема Data Lake Storage Gen2 можно ознакомиться с [данными ОПорон-Диас в Azure Data Lake Storage Gen2.](load-azure-data-lake-storage-gen2.md)

[!INCLUDE [data-factory-v2-connector-get-started](../../includes/data-factory-v2-connector-get-started.md)]

В следующих разделах приводится информация о свойствах, используемых для определения сущностей Фабрики данных, специфичных для data Lake Storage Gen2.

## <a name="linked-service-properties"></a>Свойства связанной службы

Разъем Azure Data Lake Storage Gen2 поддерживает следующие типы аутентификации. Подробнее о следующих разделах смотрите:

- [Проверка подлинности на основе ключа учетной записи](#account-key-authentication)
- [Главная аутентификация службы](#service-principal-authentication)
- [Управляемые удостоверения для проверки подлинности ресурсов Azure](#managed-identity)

>[!NOTE]
>При использовании PolyBase для загрузки данных в хранилище данных S'L, если ваш источник Data Lake Storage Gen2 настроен с помощью конечной точки виртуальной сети, необходимо использовать управляемую аутентификацию идентификации, как того требует PolyBase. Просмотрите [раздел управляемой проверки подлинности с](#managed-identity) большим количеством предпосылок конфигурации.

### <a name="account-key-authentication"></a>Проверка подлинности на основе ключа учетной записи

При использовании проверки подлинности на основе ключа учетной записи поддерживаются следующие свойства.

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для хранения данных `https://<accountname>.dfs.core.windows.net`озера Gen2 с шаблоном . | Да |
| accountKey | Ключ к учетной записи для хранения данных озера Gen2. Пометьте это поле как SecureString, чтобы безопасно хранить его в фабрике данных, или [добавьте ссылку на секрет, хранящийся в Azure Key Vault](store-credentials-in-key-vault.md). |Да |
| connectVia | [Время выполнения интеграции,](concepts-integration-runtime.md) используемое для подключения к хранилику данных. Вы можете использовать время выполнения интеграции Azure или самохозня, если ваш хранилище данных находится в частной сети. Если это свойство не указано, используется время выполнения интеграции Azure по умолчанию. |нет |

>[!NOTE]
>Второстепенная конечная точка файловой системы ADLS не поддерживается при использовании аутентификации ключа учетной записи. Вы можете использовать другие типы аутентификации.

**Примере:**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "accountkey": { 
                "type": "SecureString", 
                "value": "<accountkey>" 
            }
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="service-principal-authentication"></a>Проверка подлинности субъекта-службы

Чтобы использовать основную аутентификацию службы, выполните следующие действия.

1. Зарегистрируйте сущность приложения в каталоге Azure Active Directory (Azure AD), выяснив шаги в [регистрации приложения с арендатором Azure AD.](../storage/common/storage-auth-aad-app.md#register-your-application-with-an-azure-ad-tenant) Запишите следующие значения, которые используются для определения связанной службы:

    - Идентификатор приложения
    - Ключ приложения
    - Tenant ID

2. Предоставите главному сервису соответствующее разрешение. Смотрите примеры того, как работает разрешение в [списках управления data](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories) Lake В.

    - **Как источник**: В Хранилище Explorer, предоставить по крайней мере **выполнить** разрешение для всех папок вверх по течению и файловой системы, а также **Читать** разрешение на файлы для копирования. Кроме того, в области контроля доступа (IAM) предоставим по крайней мере роль **читателя данных Storage Blob.**
    - **Как раковина**: В исследователе хранения, дарить по крайней мере **выполнить** позволение для ВСЕХ папок upstream и файловой системы, вместе с **позволением записывать** для скоросшивателя раковины. Кроме того, в области контроля доступа (IAM) предоставим, по крайней мере, роль **вкладчика хранилища данных Blob.**

>[!NOTE]
>Если вы используете uI Data Factory для автора, а директор службы не устанавливается с ролью «Хранение Blob Data Reader/Contributor» в IAM, при выполнении тестового соединения или просмотре/навигационных папках, выберите «Тестподключение к пути файла» или «Просмотр с указанного пути» и укажите путь с разрешением **Read и Execute** для продолжения.

Эти свойства поддерживаются для связанной службы:

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для хранения данных `https://<accountname>.dfs.core.windows.net`озера Gen2 с шаблоном . | Да |
| servicePrincipalId | Укажите идентификатора клиента приложения. | Да |
| servicePrincipalKey | Укажите ключ приложения. Отметьте это `SecureString` поле как безопасное хранение на фабрике данных. Или вы можете [ссылаться на секрет, хранящийся в Хранилище ключей Azure.](store-credentials-in-key-vault.md) | Да |
| tenant | Укажите сведения о клиенте (доменное имя или идентификатор клиента), в котором находится приложение. Извлеките его, зависая мышью в правом верхнем углу портала Azure. | Да |
| connectVia | [Время выполнения интеграции,](concepts-integration-runtime.md) используемое для подключения к хранилику данных. Вы можете использовать время выполнения интеграции Azure или самохозня, если ваш хранилище данных находится в частной сети. Если не указано, используется время выполнения интеграции Azure по умолчанию. |нет |

**Примере:**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
            "servicePrincipalId": "<service principal id>",
            "servicePrincipalKey": {
                "type": "SecureString",
                "value": "<service principal key>"
            },
            "tenant": "<tenant info, e.g. microsoft.onmicrosoft.com>" 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

### <a name="managed-identities-for-azure-resources-authentication"></a><a name="managed-identity"></a>Управляемые идентификаторы для проверки подлинности ресурсов Azure

Фабрика данных может быть связана с [управляемым удостоверением для ресурсов Azure](data-factory-service-identity.md), которое представляет эту фабрику данных. Эту управляемую идентификацию можно использовать непосредственно для проверки подлинности Data Lake Storage Gen2, подобно использованию собственного принципала обслуживания. Это позволяет этой назначенной фабрике получать доступ и копировать данные к вашему Data Lake Storage Gen2 или из него.

Для использования управляемых идентификаторов для проверки подлинности ресурсов Azure выполните следующие действия.

1. [Retrieve the Data Factory managed identity information](data-factory-service-identity.md#retrieve-managed-identity) by copying the value of the managed identity object **ID** generated generated along with your factory.

2. Предоставить управляемое разрешение на идентификацию. Смотрите примеры того, как работает разрешение в списках управления Data Lake ВАшего генсетях в [файлах и каталогах.](../storage/blobs/data-lake-storage-access-control.md#access-control-lists-on-files-and-directories)

    - **Как источник**: В Хранилище Explorer, предоставить по крайней мере **выполнить** разрешение для всех папок вверх по течению и файловой системы, а также **Читать** разрешение на файлы для копирования. Кроме того, в области контроля доступа (IAM) предоставим по крайней мере роль **читателя данных Storage Blob.**
    - **Как раковина**: В исследователе хранения, дарить по крайней мере **выполнить** позволение для ВСЕХ папок upstream и файловой системы, вместе с **позволением записывать** для скоросшивателя раковины. Кроме того, в области контроля доступа (IAM) предоставим, по крайней мере, роль **вкладчика хранилища данных Blob.**

>[!NOTE]
>Если вы используете uI Data Factory для автора, а управляемая идентификация не установлена с ролью «Хранение Blob Data Reader/Contributor» в IAM, при выполнении тестового соединения или просмотре/навигационных папках, выберите «Тестподключение к пути файла» или «Просмотр с указанного пути» и укажите путь с разрешением **Read и Execute** для продолжения.

>[!IMPORTANT]
>Если вы используете PolyBase для загрузки данных из Data Lake Storage Gen2 в хранилище данных, при использовании управляемой проверки подлинности данных Data Lake Storage Gen2, убедитесь, что вы также выполните шаги 1 и 2 в [этом руководстве](../sql-database/sql-database-vnet-service-endpoint-rule-overview.md#impact-of-using-vnet-service-endpoints-with-azure-storage) для 1) зарегистрируйте свой сервер базы данных S'L с Azure Active Directory (Azure AD) и 2) присвоите роль вкладчика данных хранилища данных остальные обрабатываются Data Factory. Если хранилище Data Lake Storage Gen2 настроено с помощью конечной точки Виртуальной сети Azure, чтобы использовать PolyBase для загрузки данных из нее, необходимо использовать управляемую аутентификацию идентификации, как того требует PolyBase.

Эти свойства поддерживаются для связанной службы:

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Для свойства type необходимо задать значение **AzureBlobFS**. |Да |
| url | Конечная точка для хранения данных `https://<accountname>.dfs.core.windows.net`озера Gen2 с шаблоном . | Да |
| connectVia | [Время выполнения интеграции,](concepts-integration-runtime.md) используемое для подключения к хранилику данных. Вы можете использовать время выполнения интеграции Azure или самохозня, если ваш хранилище данных находится в частной сети. Если не указано, используется время выполнения интеграции Azure по умолчанию. |нет |

**Примере:**

```json
{
    "name": "AzureDataLakeStorageGen2LinkedService",
    "properties": {
        "type": "AzureBlobFS",
        "typeProperties": {
            "url": "https://<accountname>.dfs.core.windows.net", 
        },
        "connectVia": {
            "referenceName": "<name of Integration Runtime>",
            "type": "IntegrationRuntimeReference"
        }
    }
}
```

## <a name="dataset-properties"></a>Свойства набора данных

Полный список разделов и свойств, доступных для определения наборов данных, [см.](concepts-datasets-linked-services.md)

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Следующие свойства поддерживаются для Data `location` Lake Storage Gen2 в настройках в наборе данных на основе формата:

| Свойство   | Описание                                                  | Обязательно |
| ---------- | ------------------------------------------------------------ | -------- |
| type       | Свойство типа, под `location` данными, должно быть установлено в **AzureBlobFSLocation.** | Да      |
| fileSystem | Имя файловой системы Data Lake Storage Gen2.                              | нет       |
| folderPath | Путь к папке в данной файловой системе. Если вы хотите использовать подстановочный знак для фильтрации папок, пропустите эту настройку и укажите его в настройках источника активности. | нет       |
| fileName   | Имя файла в данной файловой системе и папкеPath. Если вы хотите использовать подстановочный знак для фильтрации файлов, пропустите эту настройку и укажите ее в настройках источника активности. | нет       |

**Примере:**

```json
{
    "name": "DelimitedTextDataset",
    "properties": {
        "type": "DelimitedText",
        "linkedServiceName": {
            "referenceName": "<Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "schema": [ < physical schema, optional, auto retrieved during authoring > ],
        "typeProperties": {
            "location": {
                "type": "AzureBlobFSLocation",
                "fileSystem": "filesystemname",
                "folderPath": "folder/subfolder"
            },
            "columnDelimiter": ",",
            "quoteChar": "\"",
            "firstRowAsHeader": true,
            "compressionCodec": "gzip"
        }
    }
}
```

## <a name="copy-activity-properties"></a>Свойства действия копирования

Полный список разделов и свойств, доступных для [Pipelines and activities](concepts-pipelines-activities.md)определения действий, [см.](copy-activity-overview.md#configuration) Этот раздел содержит список свойств, поддерживаемых источником и приемником Data Lake Storage Gen2.

### <a name="azure-data-lake-storage-gen2-as-a-source-type"></a>Хранение озер ных данных Azure Gen2 как тип источника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Следующие свойства поддерживаются для Data `storeSettings` Lake Storage Gen2 в настройках в формате на основе источника копий:

| Свойство                 | Описание                                                  | Обязательно                                      |
| ------------------------ | ------------------------------------------------------------ | --------------------------------------------- |
| type                     | Свойство типа `storeSettings` под должны быть установлены на **AzureBlobFSReadSettings.** | Да                                           |
| recursive                | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Когда рекурсивный установлен на истину и раковина файл на основе магазина, пустая папка или subfolder не скопированы или созданы в раковине. Разрешенные значения **верны** (по умолчанию) и **ложные.** | нет                                            |
| подстановочный знакFolderPath       | Путь папки с символами подстановочных знаков в данной файловой системе, настроенной в наборе данных для фильтрации папок источника. <br>Разрешенные подстановочные знаки `*` (соответствует `?` нулю или более символов) и (соответствует нулю или одному символу). Используйте, `^` чтобы избежать, если ваше фактическое имя папки имеет подстановочный знак или этот побег символ внутри. <br>Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | нет                                            |
| подстановочный знакFileName         | Имя файла с символами подстановочных знаков в данной файловой системе - папкаPath/wildcardFolderPath для фильтрации исходных файлов. <br>Разрешенные подстановочные знаки `*` (соответствует `?` нулю или более символов) и (соответствует нулю или одному символу). Используйте, `^` чтобы избежать, если ваше фактическое имя папки имеет подстановочный знак или этот побег символ внутри. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). | Да, `fileName` если не указан в наборе данных |
| modifiedDatetimeStart    | Фильтр файлов на основе атрибута Последнее изменение. Файлы выбираются, если их последнее измененное `modifiedDatetimeStart` `modifiedDatetimeEnd`время находится в пределах временной промена между и . Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00". <br> Свойства могут быть NULL, что означает, что фильтр атрибута файла не применяется к набору данных. Когда `modifiedDatetimeStart` значение датируется `modifiedDatetimeEnd` датой, но является NULL, это означает, что выбраны файлы, последний измененный атрибут которых больше или равен значению времени дат. При `modifiedDatetimeEnd` значении времени `modifiedDatetimeStart` дат, но NULL, это означает, что файлы, последний измененный атрибут которых меньше значения времени даты, выбраны. | нет                                            |
| modifiedDatetimeEnd      | То же, что и выше.                                               | нет                                            |
| maxConcurrentConnections | Одновременное количество подключений для подключения к хранилищу. Указать только при ограничении одновременного подключения к хранилику данных. | нет                                            |

**Примере:**

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<Delimited text input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "DelimitedTextSource",
                "formatSettings":{
                    "type": "DelimitedTextReadSettings",
                    "skipLineCount": 10
                },
                "storeSettings":{
                    "type": "AzureBlobFSReadSettings",
                    "recursive": true,
                    "wildcardFolderPath": "myfolder*A",
                    "wildcardFileName": "*.csv"
                }
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="azure-data-lake-storage-gen2-as-a-sink-type"></a>Azure Data Lake Storage Gen2 как тип приемника

[!INCLUDE [data-factory-v2-file-formats](../../includes/data-factory-v2-file-formats.md)] 

Следующие свойства поддерживаются для Data `storeSettings` Lake Storage Gen2 в настройках в формате на основе копий раковины:

| Свойство                 | Описание                                                  | Обязательно |
| ------------------------ | ------------------------------------------------------------ | -------- |
| type                     | Свойство типа `storeSettings` под должны быть установлены на **AzureBlobFSWriteSettings.** | Да      |
| copyBehavior             | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | нет       |
| blockSizeinMB | Укажите размер блока в Mb, используемый для записи данных в ADLS Gen2. Узнайте больше [о Block Blobs](https://docs.microsoft.com/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs#about-block-blobs). <br/>Разрешенное значение составляет **от 4 до 100 МБ.** <br/>По умолчанию ADF автоматически определяет размер блока на основе типа и данных исходного хранилища. Для небирной копии в ADLS Gen2 размер блока по умолчанию составляет 100 МБ, чтобы вписаться не более чем в 4,95 ТБ данных. Это может быть не оптимальным, когда ваши данные не являются большими, особенно когда вы используете самостоятельно размещенную интеграцию Runtime с плохой сетью, что приводит к тайм-ауту работы или проблеме с производительностью. Можно явно указать размер блока, при этом обеспечить, чтобы блокSizeInMB-50000 был достаточно большим для хранения данных, в противном случае запуск активности копирования не удастся. | нет |
| maxConcurrentConnections | Одновременное количество подключений к хранилику данных. Указать только при ограничении одновременного подключения к хранилику данных. | нет       |

**Примере:**

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<Parquet output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "ParquetSink",
                "storeSettings":{
                    "type": "AzureBlobFSWriteSettings",
                    "copyBehavior": "PreserveHierarchy"
                }
            }
        }
    }
]
```

### <a name="folder-and-file-filter-examples"></a>Примеры фильтров папок и файлов

В этом разделе описываются результаты применения фильтров с подстановочными знаками к пути папки и имени файла.

| folderPath | fileName | recursive | Структура папки исхода и результат фильтра (файлы **жирным шрифтом** извлекаются)|
|:--- |:--- |:--- |:--- |
| `Folder*` | (Пустой, используйте по умолчанию) | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | (Пустой, используйте по умолчанию) | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл2.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл4.json**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | false | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3.csv<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5.csv<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |
| `Folder*` | `*.csv` | Да | ПапкаA<br/>&nbsp;&nbsp;&nbsp;&nbsp;**Файл1.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл3.csv**<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4.json<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Файл5.csv**<br/>Другая_папкаB<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл6.csv |

### <a name="some-recursive-and-copybehavior-examples"></a>Некоторые примеры recursive и copyBehavior

В этом разделе описывается итоговое поведение операции копирования для различных комбинаций рекурсивных и копийПоведенческих значений.

| recursive | copyBehavior | Структура папок источника | Результаты цели |
|:--- |:--- |:--- |:--- |
| Да |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая "Папка1" создается с такой же структурой, как и исходная папка:<br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 |
| Да |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл3"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл4"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл5" |
| Да |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1", "Файл2", "Файл3", "Файл4" и "Файл5" объединяется в один файл с автоматически созданным именем. |
| false |preserveHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/><br/>Subfolder1 с File3, File4 и File5 не подобраны. |
| false |flattenHierarchy | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл1"<br/>&nbsp;&nbsp;&nbsp;&nbsp;автоматически созданное имя для "Файл2"<br/><br/>Subfolder1 с File3, File4 и File5 не подобраны. |
| false |mergeFiles | Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Файл2<br/>&nbsp;&nbsp;&nbsp;&nbsp;Вложенная_папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл3<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл4<br/>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Файл5 | Целевая папка "Папка1" создается со следующей структурой: <br/><br/>Папка1<br/>&nbsp;&nbsp;&nbsp;&nbsp;Содержимое файлов "Файл1" и "Файл2" объединяется в один файл с автоматически созданным именем. автоматически созданное имя для "Файл1"<br/><br/>Subfolder1 с File3, File4 и File5 не подобраны. |

## <a name="preserve-metadata-during-copy"></a>Сохранение метаданных во время копирования

При копировании файлов из Amazon S3/Azure Blob/Azure Data Lake Storage Gen2 в Azure Data Lake Storage Gen2/Azure Blob можно сохранить метаданные файлов вместе с данными. Узнайте больше из [метаданных заповедника](copy-activity-preserve-metadata.md#preserve-metadata).

## <a name="preserve-acls-from-data-lake-storage-gen1gen2"></a><a name="preserve-acls"></a>Сохранение ACLs из хранилища данных озера Gen1/Gen2

При копировании файлов из Azure Data Lake Storage Gen1/Gen2 в Gen2 можно сохранить списки управления доступом POSIX (ACLs) вместе с данными. Узнайте больше из [preserve ACLs от data Lake Storage Gen1/Gen2 до Gen2.](copy-activity-preserve-metadata.md#preserve-acls)

>[!TIP]
>Для копирования данных из Azure Data Lake Storage Gen1 в Gen2 в целом см. [Копии данных из Azure Data Lake Storage Gen1 до Gen2 с помощью фабрики данных Azure](load-azure-data-lake-storage-gen2-from-gen1.md) data Factory для прохождения и передового опыта.

## <a name="mapping-data-flow-properties"></a>Отображение свойств потока данных

При преобразовании данных в картографируем поток данных можно читать и писать файлы из Azure Data Lake Storage Gen2 в формате JSON, Avro, Delimited Text или Parquet. Для получения дополнительной информации см. [преобразование источника](data-flow-source.md) и преобразование [раковины](data-flow-sink.md) в функции потока данных отображения.

### <a name="source-transformation"></a>Преобразование источника

В исходной трансформации можно прочитать из контейнера, папки или отдельного файла в Azure Data Lake Storage 2. Вкладка **параметры «Источник»** позволяет управлять чтением файлов. 

![Варианты исхода](media/data-flow/sourceOptions1.png "Варианты исхода")

**Путь Wildcard:** Использование шаблона подстановочных знаков поручает ADF прослежять каждую соответствующую папку и файл в одном преобразовании Исходного кода. Это эффективный способ обработки нескольких файлов в одном потоке. Добавьте несколько шаблонов подстановочного знака, который появляется при нависшем над существующим шаблоном подстановочных знаков.

Из исходного контейнера выберите серию файлов, которые соответствуют шаблону. Только контейнер может быть указан в наборе данных. Таким образом, ваш путь подстановочного знака должен также включать путь папки из корневой папки.

Примеры Wildcard:

* ```*```Представляет любой набор символов
* ```**```Представляет собой рекурсивное вложение каталога
* ```?```Заменяет одного символа
* ```[]```Соответствует одному из символов в скобках

* ```/data/sales/**/*.csv```Получает все файлы csv под /данными/продажами
* ```/data/sales/20??/**/```Получает все файлы в 20-м веке
* ```/data/sales/*/*/*.csv```Получает csv файлы двух уровней под /данные / продажи
* ```/data/sales/2004/*/12/[XY]1?.csv```Получает все файлы csv в 2004 году в декабре, начиная с X или Y префиксированы двузначным числом

**Раздел Корневой путь:** Если в исходном исходном материале с ```key=value``` форматом (например, год-2019) есть раздельные папки с форматом (например, год 2019), то можно назначить верхний уровень этого дерева папки раздела к имени столбца в потоке данных.

Во-первых, установите подстановочный знак, чтобы включить все пути, которые разделены папки плюс лист файлы, которые вы хотите прочитать.

![Настройки исходного кода раздела](media/data-flow/partfile2.png "Настройка файла раздела")

Используйте настройки раздела Root Path, чтобы определить, что такое верхний уровень структуры папки. При просмотре содержимого данных с помощью предварительного просмотра данных можно увидеть, что ADF добавит разрешенные разделы, найденные в каждом из уровней папки.

![Путь корня раздела](media/data-flow/partfile1.png "Предварительный просмотр корневого пути раздела")

**Список файлов:** Это набор файлов. Создайте текстовый файл, включающий список относительного пути обработки файлов. Укажите на этот текстовый файл.

**Колонка для хранения имени файла:** Храните имя исходного файла в столбце в данных. Введите новое имя столбца здесь для хранения строки имени файла.

**После завершения:** Выберите ничего не делать с исходным файлом после запуска потока данных, удаления исходного файла или перемещения исходного файла. Пути для перемещения являются относительными.

Чтобы переместить исходные файлы в другое место после обработки, сначала выберите "Движение" для операции файлов. Затем установите "из" каталога. Если вы не используете какие-либо подстановочные знаки для вашего пути, то параметр "от" будет той же папкой, что и папка исходного кода.

Если у вас есть исходный путь с подстановочным знаком, ваш синтаксис будет выглядеть следующим образом:

```/data/sales/20??/**/*.csv```

Вы можете указать "от" как

```/data/sales```

И "к", как

```/backup/priorSales```

В этом случае все файлы, полученные в соответствии с /данными/продажами, перемещаются в /backup/priorSales.

> [!NOTE]
> Операции файлов выполняются только при запуске потока данных из запуска конвейера (отладка или выполнение конвейера), используюго действие потока данных в конвейере. Операции файлов *не* работают в режиме отладки потока данных.

**Фильтр по последним модифицированным:** Можно фильтровать файлы, которые вы обрабатываете, указывая диапазон дат, когда они были в последний раз изменены. Все даты-время в UTC. 

### <a name="sink-properties"></a>Свойства раковины

При преобразовании раковины можно написать в контейнер или папку в Azure Data Lake Storage 2. вкладка **«Настройки»** позволяет управлять написанием файлов.

![варианты раковины](media/data-flow/file-sink-settings.png "варианты раковины")

**Очистить папку:** Определяет, очищается ли папка назначения до их написания данных.

**Опция названия файла:** Определяет, как будут названы файлы назначения в папке назначения. Параметры имени файла:
   * **По умолчанию**: Разрешить Spark называть файлы на основе по умолчанию PART.
   * **Шаблон**: Введите шаблон, перечисляет выводные файлы на раздел. Например, **кредиты будут** создавать кредиты1.csv, loans2.csv и так далее.
   * **Для раздела**: Введите одно имя файла на раздел.
   * **Как данные в столбце:** Установите выходный файл на значение столбца. Путь относительно контейнера набора данных, а не папки назначения. Если в наборе данных есть путь папки, он будет перекрыт.
   * **Выход в один файл:** Объедините разделенные выходные файлы в один названный файл. Путь относительно папки набора данных. Пожалуйста, имейте в виду, что операция te merge может быть сбой в зависимости от размера узла. Этот параметр не рекомендуется для больших наборов данных.

**Цитата все:** Определяет, следует ли приложить все значения в кавычки

## <a name="lookup-activity-properties"></a>Свойства активности поиска

Чтобы узнать подробности о свойствах, проверьте [активность поиска.](control-flow-lookup-activity.md)

## <a name="getmetadata-activity-properties"></a>Свойства активности GetMetadata

Чтобы узнать подробности о свойствах, проверьте [активность GetMetadata](control-flow-get-metadata-activity.md) 

## <a name="delete-activity-properties"></a>Удаление свойств активности

Чтобы узнать подробности о свойствах, проверьте [действия Delete](delete-activity.md)

## <a name="legacy-models"></a>Устаревшие модели

>[!NOTE]
>Следующие модели по-прежнему поддерживаются как для обратной совместимости. Вы предложили использовать новую модель, упомянутую в вышеуказанных разделах в будущем, и ADF авторство UI переключился на генерацию новой модели.

### <a name="legacy-dataset-model"></a>Устаревшая модель набора данных

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type для набора данных должно иметь значение **AzureBlobFSFile**. |Да |
| folderPath | Путь к папке в Data Lake Storage Gen2. Если это свойство не указано, будет использоваться корневая папка. <br/><br/>Фильтр Wildcard поддерживается. Разрешенные подстановочные знаки `*` (соответствует `?` нулю или более символов) и (соответствует нулю или одному символу). Используйте, `^` чтобы избежать, если ваше фактическое имя папки имеет подстановочный знак или этот побег символ находится внутри. <br/><br/>Примеры: файловая система/папка/. Дополнительные примеры приведены в разделе [Примеры фильтров папок и файлов](#folder-and-file-filter-examples). |нет |
| fileName | Фильтр имени или подстановочного знака для файлов под указанным "folderPath". Если этому свойству не присвоить значение, набор данных будет указывать на все файлы в папке. <br/><br/>Для фильтра разрешены `*` подстановочные знаки (совпадает с нулем или более символов) и `?` (совпадают с нулем или одним символом).<br/>Пример 1. `"fileName": "*.csv"`<br/>Пример 2. `"fileName": "???20180427.txt"`<br/>Используйте, `^` чтобы избежать, если ваше фактическое имя файла имеет подстановочный знак или этот побег символ находится внутри.<br/><br/>Когда fileName не указан для набора данных вывода и **сохраненияИерархия** не указана в поглотителе активности, активность копирования автоматически генерирует имя файла со следующим шаблоном:*«Данные». действия запустить ID GUID. (ГУИД, если ФлэттенИерархии). «формат, если настроен». «Сжатие при настройке»,* например, «Data.0a405f8a-93ff-4c6f-b3be-f696166f1df7a.txt.gz». Если вы копируете из табликового источника, используя имя таблицы вместо запроса, шаблон имени —*«имя стола». формата. «Сжатие при настройке»,* например, «MyTable.csv». |нет |
| modifiedDatetimeStart | Фильтр файлов на основе атрибута Последнее изменение. Файлы выбираются, если их последнее измененное `modifiedDatetimeStart` `modifiedDatetimeEnd`время находится в пределах временной промена между и . Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00". <br/><br/> На общую производительность движения данных влияет включение этой настройки, когда требуется создать файловый фильтр с огромным количеством файлов. <br/><br/> Свойства могут быть NULL, что означает, что фильтр атрибута файла не применяется к набору данных. Когда `modifiedDatetimeStart` значение датируется `modifiedDatetimeEnd` датой, но является NULL, это означает, что выбраны файлы, последний измененный атрибут которых больше или равен значению времени даты. Когда `modifiedDatetimeEnd` значение времени дат, но `modifiedDatetimeStart` NULL, это означает файлы, чей последний измененный атрибут меньше, чем значение времени даты выбрано.| нет |
| modifiedDatetimeEnd | Фильтр файлов на основе атрибута Последнее изменение. Файлы выбираются, если их последнее измененное `modifiedDatetimeStart` `modifiedDatetimeEnd`время находится в пределах временной промена между и . Время применяется к часовому поясу UTC в формате "2018-12-01T05:00:00". <br/><br/> На общую производительность движения данных влияет включение этой настройки, когда требуется создать файловый фильтр с огромным количеством файлов. <br/><br/> Свойства могут быть NULL, что означает, что фильтр атрибута файла не применяется к набору данных. Когда `modifiedDatetimeStart` значение датируется `modifiedDatetimeEnd` датой, но является NULL, это означает, что выбраны файлы, последний измененный атрибут которых больше или равен значению времени даты. Когда `modifiedDatetimeEnd` значение времени дат, но `modifiedDatetimeStart` NULL, это означает файлы, чей последний измененный атрибут меньше, чем значение времени даты выбрано.| нет |
| format | Если требуется скопировать файлы между файловыми хранилищами "как есть" (двоичное копирование), можно пропустить раздел форматирования в определениях входного и выходного наборов данных.<br/><br/>Если нужно проанализировать или создать файлы определенного формата, поддерживаются следующие типы форматов файлов: **TextFormat**, **JsonFormat**, **AvroFormat**, **OrcFormat** и **ParquetFormat**. Свойству **type** в разделе **format** необходимо присвоить одно из этих значений. Для получения дополнительной информации, см [текст формата](supported-file-formats-and-compression-codecs-legacy.md#text-format), [JSON формат](supported-file-formats-and-compression-codecs-legacy.md#json-format), [формат Avro](supported-file-formats-and-compression-codecs-legacy.md#avro-format), [формат ORC](supported-file-formats-and-compression-codecs-legacy.md#orc-format), и [формат parquet](supported-file-formats-and-compression-codecs-legacy.md#parquet-format) разделы. |Нет (только для сценария двоичного копирования) |
| compression | Укажите тип и уровень сжатия данных. Дополнительные сведения см. в разделе [Поддержка сжатия](supported-file-formats-and-compression-codecs-legacy.md#compression-support).<br/>Поддерживаемые типы: **GZip**, **Deflate**, **BZip2** и **ZipDeflate**.<br/>Поддерживаемые уровни: **Optimal** и **Fastest**. |нет |

>[!TIP]
>Чтобы скопировать все файлы в папке, укажите только **folderPath**.<br>Чтобы скопировать один файл с указанным именем, укажите **папкуPath** с частью папки и **fileName** с именем файла.<br>Чтобы скопировать подмножество файлов под папкой, укажите **папкуPath** с частью папки и **fileName** с фильтром подстановочных знаков. 

**Примере:**

```json
{
    "name": "ADLSGen2Dataset",
    "properties": {
        "type": "AzureBlobFSFile",
        "linkedServiceName": {
            "referenceName": "<Azure Data Lake Storage Gen2 linked service name>",
            "type": "LinkedServiceReference"
        },
        "typeProperties": {
            "folderPath": "myfilesystem/myfolder",
            "fileName": "*",
            "modifiedDatetimeStart": "2018-12-01T05:00:00Z",
            "modifiedDatetimeEnd": "2018-12-01T06:00:00Z",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ",",
                "rowDelimiter": "\n"
            },
            "compression": {
                "type": "GZip",
                "level": "Optimal"
            }
        }
    }
}
```

### <a name="legacy-copy-activity-source-model"></a>Модель источника исходной деятельности устаревшей копирования

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type источника действия копирования должно иметь значение **AzureBlobFSSource**. |Да |
| recursive | Указывает, следует ли читать данные рекурсивно из вложенных папок или только из указанной папки. Когда рекурсивный установлен на истину и раковина файл на основе магазина, пустая папка или subfolder не скопированы или созданы в раковине.<br/>Разрешенные значения **верны** (по умолчанию) и **ложные.** | нет |
| maxConcurrentConnections | Одновременное количество подключений к хранилику данных. Указать только при ограничении одновременного подключения к хранилику данных. | нет |

**Примере:**

```json
"activities":[
    {
        "name": "CopyFromADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<ADLS Gen2 input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "AzureBlobFSSource",
                "recursive": true
            },
            "sink": {
                "type": "<sink type>"
            }
        }
    }
]
```

### <a name="legacy-copy-activity-sink-model"></a>Устаревшая модель погружения активности копирования

| Свойство | Описание | Обязательно |
|:--- |:--- |:--- |
| type | Свойство type приемника действия копирования должно иметь значение **AzureBlobFSSink**. |Да |
| copyBehavior | Определяет поведение копирования, когда источником являются файлы из файлового хранилища данных.<br/><br/>Допустимые значения:<br/><b>— PreserveHierarchy (по умолчанию)</b>. Сохраняет иерархию файлов в целевой папке. Относительный путь исходного файла в исходной папке идентичен относительному пути целевого файла в целевой папке.<br/><b>— FlattenHierarchy</b>. Все файлы из исходной папки размещаются на первом уровне в целевой папке. Целевые файлы имеют автоматически сформированные имена. <br/><b>— MergeFiles</b>. Объединяет все файлы из исходной папки в один файл. Если указано имя файла, то оно присваивается объединенному файлу. В противном случае присваивается автоматически созданное имя файла. | нет |
| maxConcurrentConnections | Одновременное количество подключений к хранилику данных. Указать только при ограничении одновременного подключения к хранилику данных. | нет |

**Примере:**

```json
"activities":[
    {
        "name": "CopyToADLSGen2",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<input dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<ADLS Gen2 output dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>"
            },
            "sink": {
                "type": "AzureBlobFSSink",
                "copyBehavior": "PreserveHierarchy"
            }
        }
    }
]
```

## <a name="next-steps"></a>Дальнейшие действия

В таблице [Поддерживаемые хранилища данных и форматы](copy-activity-overview.md#supported-data-stores-and-formats) приведен список хранилищ данных, которые поддерживаются в качестве источников и приемников для действия копирования в фабрике данных.
