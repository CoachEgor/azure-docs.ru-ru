---
title: Обработка повторяющихся данных в обозревателе данных Azure
description: В этом разделе мы покажем различные методы обработки с повторяющимися данными, при использовании обозревателя данных Azure.
author: orspod
ms.author: orspodek
ms.reviewer: mblythe
ms.service: data-explorer
ms.topic: conceptual
ms.date: 12/19/2018
ms.openlocfilehash: 8f55b6dfb7b5bc9eda675aca4ed80a66b8a25a7f
ms.sourcegitcommit: 41ca82b5f95d2e07b0c7f9025b912daf0ab21909
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/13/2019
ms.locfileid: "60445776"
---
# <a name="handle-duplicate-data-in-azure-data-explorer"></a>Обработка повторяющихся данных в обозревателе данных Azure

Устройства, которые отправляют данные в облако, поддерживают локальный кэш данных. В зависимости от размера этих данных они могут храниться в локальном кэше несколько дней или даже месяцев. Вам следует принять меры для защиты аналитических баз данных от неисправных устройств, которые могут повторно отправить кэшированные данные и создать дубликаты в аналитической базе данных. В этой статье описаны актуальные рекомендации по обработке дублирующихся данных в таких сценариях.

Самым правильным решением будет предотвращение дублирования данных. Насколько это возможно, устраните все проблемы выше по конвейеру данных, что позволит сэкономить средства на перемещение данных по конвейеру и ресурсы на устранение дублирующихся данных, уже поступивших в систему. Но и в тех случаях, когда невозможно изменить исходную систему, есть несколько способов устранения проблем.

## <a name="understand-the-impact-of-duplicate-data"></a>Анализ влияния дублирующихся данных

Отслеживайте долю дублирующихся данных. Выяснив, сколько в вашей системе дублирующихся данных, вы сможете понять масштаб этой проблемы и ее влияние на бизнес, что поможет выбрать правильное решение.

Пример запроса, который позволяет определить долю дублирующихся записей.

```kusto
let _sample = 0.01; // 1% sampling
let _data =
DeviceEventsAll
| where EventDateTime between (datetime('10-01-2018 10:00') .. datetime('10-10-2018 10:00'));
let _totalRecords = toscalar(_data | count);
_data
| where rand()<= _sample
| summarize recordsCount=count() by hash(DeviceId) + hash(EventId) + hash(StationId)  // Use all dimensions that make row unique. Combining hashes can be improved
| summarize duplicateRecords=countif(recordsCount  > 1)
| extend duplicate_percentage = (duplicateRecords / _sample) / _totalRecords  
```

## <a name="solutions-for-handling-duplicate-data"></a>Решения для обработки дублирующихся данных

### <a name="solution-1-dont-remove-duplicate-data"></a>Решение 1. Сохранение дублирующихся данных

Оцените бизнес-требования и допустимый объем дублирующихся данных. Некоторые наборы данных сохраняют работоспособность с определенной долей дублирующихся данных. Если дублирующиеся данные незначительно влияют на работу, их можно просто игнорировать. Отказ от удаления дублирующихся данных позволяет обойтись без дополнительных расходов на процесс приема данных и (или) снижения производительности запросов.

### <a name="solution-2-handle-duplicate-rows-during-query"></a>Решение 2. Обработка дублирующихся строк при выполнении запроса

Другой вариант — фильтровать дублирующиеся строки данных во время выполнения запроса. Агрегатная функция [`arg_max()`](/azure/kusto/query/arg-max-aggfunction) позволяет отфильтровать дублирующиеся записи, возвращая только последнюю из них по данным в столбце метки времени (или в другом столбце). Этот метод позволяет ускорить прием данных, так как дубликаты удаляются во время выполнения запроса. Кроме того, все записи (в том числе дублирующиеся) доступны для аудита и устранения неполадок. Недостатком использования функции `arg_max` является замедление обработки запроса и повышение нагрузки на ЦП при каждом запросе к данным. В зависимости от объема запрашиваемых данных такое решение может стать неэффективным или потреблять много памяти, и тогда стоит рассмотреть другие варианты.

Следующий пример запроса получает последнюю сохраненную запись по набору столбцов, которые определяют уникальность записей:

```kusto
DeviceEventsAll
| where EventDateTime > ago(90d)
| summarize hint.strategy=shuffle arg_max(EventDateTime, *) by DeviceId, EventId, StationId
```

Этот запрос можно разместить внутри функции, а не просто выполнять в таблице:

```kusto
.create function DeviceEventsView
{
DeviceEventsAll
| where EventDateTime > ago(90d)
| summarize arg_max(EventDateTime, *) by DeviceId, EventId, StationId
}
```

### <a name="solution-3-filter-duplicates-during-the-ingestion-process"></a>Решение 3. Фильтрация дубликатов в процессе приема

Еще один вариант решения — фильтровать все дубликаты в процессе приема данных. Такая система игнорирует дублирующиеся данные при записи в таблицы Kusto. Все данные принимаются в промежуточную таблицу и копируются в целевую таблицу только после удаления дублирующихся строк. Преимуществом этого решения является высокая производительность запросов по сравнению с предыдущим вариантом. К недостаткам следует отнести замедление приема данных и повышение затрат на хранение.

Следующий пример демонстрирует этот метод:

1. Создайте дополнительную таблицу на основе той же схемы:

    ```kusto
    .create table DeviceEventsUnique (EventDateTime: datetime, DeviceId: int, EventId: int, StationId: int)
    ```

1. Создайте функцию, которая фильтрует дублирующиеся записи, используя инвертированное объединение новых записей с полученными ранее.

    ```kusto
    .create function RemoveDuplicateDeviceEvents()
    {
    DeviceEventsAll
    | join hint.strategy=broadcast kind = anti
        (
        DeviceEventsUnique
        | where EventDateTime > ago(7d)   // filter the data for certain time frame
        | limit 1000000   //set some limitations (few million records) to avoid choking-up the system during outage recovery

        ) on DeviceId, EventId, StationId
    }
    ```

    > [!NOTE]
    > Операция объединения потребляет много ресурсов ЦП и повышает общую нагрузку на систему.

1. Задайте [политику обновления](/azure/kusto/management/update-policy) для таблицы `DeviceEventsUnique`. Политика обновления активируется при добавлении новых данных в таблицу `DeviceEventsAll`. Ядро Kusto автоматически выполняет указанную функцию при создании [экстентов](/azure/kusto/management/extents-overview). Вся обработка выполняется только для новых данных. Следующая команда создает политику обновления, объединяя исходную таблицу (`DeviceEventsAll`), целевую таблицу (`DeviceEventsUnique`) и функцию `RemoveDuplicatesDeviceEvents`.

    ```kusto
    .alter table DeviceEventsUnique policy update
    @'[{"IsEnabled": true, "Source": "DeviceEventsAll", "Query": "RemoveDuplicateDeviceEvents()", "IsTransactional": true, "PropagateIngestionProperties": true}]'
    ```

    > [!NOTE]
    > Политика обновления продлевает процесс приема, так как он сопровождается фильтрацией данных и двукратным приемом (сначала в таблицу `DeviceEventsAll`, а затем в `DeviceEventsUnique`).

1. Сократите срок хранения данных в таблице `DeviceEventsAll`, чтобы избежать хранения копий данных (необязательно). Выберите количество дней в зависимости от объема данных и продолжительности срока, к течение которого вы хотите хранить данные для устранения неполадок. Вы можете задать срок хранения в `0d` дн., чтобы снизить себестоимость проданных товаров и повысить производительность, ведь в этом случае данные не передаются в хранилище.

    ```kusto
    .alter-merge table DeviceEventsAll policy retention softdelete = 1d
    ```

## <a name="summary"></a>Сводка

Дублирующиеся данные можно обрабатывать несколькими способами. Внимательно оцените доступные варианты с учетом стоимости и производительности учетной записи, чтобы выбрать правильный метод для вашего бизнеса.

## <a name="next-steps"></a>Дальнейшие действия

> [!div class="nextstepaction"]
> [Написание запросов для обозревателя данных Azure](write-queries.md)
