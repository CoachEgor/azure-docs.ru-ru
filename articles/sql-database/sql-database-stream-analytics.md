---
title: Потоковые данные с помощью интеграции Stream Analytics (предварительный просмотр)
description: Используйте аналитику потоков Azure для потоковой передачи данных в базу данных Azure S'L.
services: sql-database
ms.service: sql-database
ms.subservice: development
ms.custom: ''
ms.devlang: ''
ms.topic: conceptual
author: ajetasin
ms.author: ajetasi
ms.reviewer: sstein
ms.date: 11/04/2019
ms.openlocfilehash: d233d3c98cc495e4b9e84142781f5eb9faa7eec8
ms.sourcegitcommit: 2ec4b3d0bad7dc0071400c2a2264399e4fe34897
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/27/2020
ms.locfileid: "73820841"
---
# <a name="stream-data-by-using-azure-sql-database-stream-analytics-integration-preview"></a>Поток данных с помощью интеграции azure S'L Database Stream Analytics (предварительный просмотр)

Теперь пользователи могут глотать, обрабатывать, просматривать и анализировать потоковые данные в режиме реального времени в таблице непосредственно из базы данных S'L на портале Azure с помощью [Azure Stream Analytics.](../stream-analytics/stream-analytics-introduction.md) Этот опыт позволяет широкий спектр сценариев, таких как подключенный автомобиль, удаленный мониторинг, обнаружение мошенничества, и многое другое. На портале Azure можно выбрать источник событий (Концентратор событий/IoT), просматривать входящие события в реальном времени и выбрать таблицу для хранения событий. Вы также можете записывать запросы на языке stream Analytics на портале для преобразования входящих событий и их хранения в выбранной таблице. Эта новая точка входа является дополнением к опыту создания и конфигурации, которые уже существуют в Stream Analytics. Этот опыт начинается с контекста базы данных, что позволяет быстро настроить работу Stream Analytics и беспрепятственно перемещаться между базой данных Azure s-L и опытом Stream Analytics.

![Поток Stream Analytics](media/sql-database-stream-analytics/stream-analytics-flow.png)

## <a name="key-benefits"></a>Основные преимущества

- Минимальное переключение контекста: Вы можете начать с базы данных S'L на портале и начать глотать данные в режиме реального времени в таблицу без перехода на любую другую службу. 
- Снижение количества шагов: контекст базы данных и таблицы используется для предварительной настройки задания Stream Analytics.
- Дополнительная простота использования данных предварительного просмотра: Предварительный просмотр входящих данных из источника событий (Концентратор событий/IoT) в контексте выбранной таблицы 


## <a name="prerequisites"></a>Предварительные требования

Чтобы выполнить действия, описанные в этой статье, необходимы следующие ресурсы.

- Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись](https://azure.microsoft.com/free/). 
- База данных S'L. Для получения подробной информации [см. Создание единой базы данных в базе данных Azure S'L.](sql-database-single-database-get-started.md)
- Правило брандмауэра, позволяющее компьютеру подключаться к серверу Azure S'L. Для получения подробной информации [см.](sql-database-server-level-firewall-rule.md)


## <a name="configure-stream-analytics-integration"></a>Настройка аналитической интеграции Stream

1. Войдите на портал Azure. 
2. Перейдите к базе данных S'L, где вы хотите глотать потоковые данные. Выберите **аналитику потока (предварительный просмотр)**. 

    ![Stream Analytics](media/sql-database-stream-analytics/stream-analytics.png)

3. Чтобы начать поглоток потоковых данных в эту базу данных S'L, выберите **Создать** и дать имя для вашей потоковой работы, а затем выберите **Следующий: Вход**. 

    ![создать работу Stream Analytics](media/sql-database-stream-analytics/create-job.png)

4. Введите сведения об источнике событий, а затем выберите **Следующий: Выход.**

   - **Тип ввода**: Концентратор событий/IoT
   - **Ввод псевдоним**: Введите имя для идентификации источника событий 
   - **Подписка**: То же самое, что и подписка на базу данных S'L 
   - **Пространство имен event Hub**: Имя для пространства имен 
   - **Имя концентратора событий**: Название концентратора событий в выбранной области имен 
   - **Имя политики концентратора событий** (по умолчанию для создания нового): Укажите имя политики 
   - **Группа потребителей Event Hub** (по умолчанию для создания нового): Укажите имя группы потребителей  
     - Мы рекомендуем создать группу потребителей и политику для каждого нового задания Azure Stream Analytics, которое вы создаете здесь. Группы потребителей разрешают только пять одновременных читателей, поэтому предоставление выделенной группы потребителей для каждого задания позволит избежать ошибок, которые могут возникнуть в результате превышения этого предела. Специальная политика позволяет повернуть ключ или отозвать разрешения, не влияя на другие ресурсы.

    ![создать работу Stream Analytics](media/sql-database-stream-analytics/create-job-output.png)

5. Выберите таблицу, в которую вы хотите глотать потоковые данные. После этого выберите **Создать**.
   - **Имя пользователя**, **Пароль**: Введите свои учетные данные для проверки подлинности сервера S'L. Выберите **Проверить**.
   - **Таблица**: Выберите **Создать новый** или **использовать существующие**. В этом потоке давайте выберем **Создать**. Это создаст новую таблицу при запуске задания «Аналитика потока».

    ![создать работу Stream Analytics](media/sql-database-stream-analytics/create.png)

6. Страница запроса открывается следующими сведениями:

   - Ваш **вход** (источник событий ввода), из которого вы будете глотать данные  
   - Выход **Output** (таблица вывода), в которой будет храниться преобразованные данные 
   - Пример [запроса САЗЛ](../stream-analytics/stream-analytics-stream-analytics-query-patterns.md) с выпиской SELECT. 
   - **Предварительный просмотр ввода**: Отображает снимок последних входящих данных из источника событий ввода.  
     - Тип сериализации в данных автоматически обнаруживается (JSON/CSV). Вы можете вручную изменить его на JSON/CSV/AVRO. 
     - Вы можете просмотреть входящие данные в формате таблицы или в формате Raw. 
     - Если отображаемые данные не актуальны, выберите **Обновление,** чтобы просмотреть последние события. 
     - **Выберите временной диапазон для** проверки запроса в определенном временном диапазоне входящих событий. 
     - Выберите **ввод образца загрузки** для тестирования запроса, загрузив образец файла JSON/CSV. Для получения дополнительной информации о тестировании [Test an Azure Stream Analytics job with sample data](../stream-analytics/stream-analytics-test-query.md)запроса SA'L см. 

    ![тестовый запрос](media/sql-database-stream-analytics/test-query.png)


   - **Результаты тестирования**: Выберите **запрос теста,** и вы можете увидеть результаты потокового запроса 

    ![результаты теста](media/sql-database-stream-analytics/test-results.png)

   - **Схема результатов тестирования:** отображается схема результатов потокового запроса после тестирования. Убедитесь, что схема результатов тестирования совпадает с схемой вывода. 

    ![схема результатов испытаний](media/sql-database-stream-analytics/test-results-schema.png)


   - **Схема вывода**: Это содержит схему таблицы, выбранной в шаге 5 (новая или существующая).
     - Создание нового: Если вы выбрали эту опцию в шаге 5, вы не увидите схему, пока не запустите работу потоковой передачи. При создании новой таблицы выберите соответствующий индекс таблицы. Для получения дополнительной информации [Clustered and Nonclustered Indexes Described](/sql/relational-databases/indexes/clustered-and-nonclustered-indexes-described/)об индексации таблиц см.
    - Используйте существующий: Если вы выбрали эту опцию в шаге 5, вы увидите схему выбранной таблицы. 
 
7. После того, как вы закончили авторство & тестирования запроса, выберите **запрос Сохранить.** Выберите **задание Start Stream Analytics,** чтобы начать глотать преобразованные данные в таблицу S'L. Как только вы завершите следующие поля, **начните** работу. 
   - **Время начала вывода**: Это определяет время первого вывода задания.  
     - Теперь: Задание начнется сейчас и обрабатывает новые входящие данные.
     - Пользовательские: задание начнется сейчас, но будет обрабатывать данные из определенного момента времени (что может быть в прошлом или будущем). Для получения дополнительной информации [см. Как начать работу по аналитике потоков Azure.](../stream-analytics/start-job.md)
   - **Потоковые единицы:** Azure Stream Analytics оценивается по количеству потоковых единиц, необходимых для обработки данных в службу. Для получения дополнительной [Azure Stream Analytics pricing](https://azure.microsoft.com/pricing/details/stream-analytics/)информации см. 
   - **Обработка ошибок вывода данных:**  
     - Повторная попытка: При возникновении ошибки Azure Stream Analytics повторно записывает событие на неопределенный срок до тех пор, пока запись не будет успешной. Время ожидания для повторных попыток не задано. В конечном итоге обработку всех последующих событий блокирует событие, которое Azure Stream Analytics безуспешно пытается записать. Это политика обработки ошибок вывода по умолчанию. 
     - Drop: Аналитика потоков Azure отбросит любое событие вывода, что приведет к ошибке преобразования данных. Восстановить удаленные события для повторной обработки позже невозможно. Для всех временных ошибок (например, сбоев сети) выполняется повторная попытка независимо от конфигурации политики обработки ошибок вывода. 
   - **Настройки вывода базы данных S'L**: опция для наследования схемы раздела предыдущего шага запроса, чтобы включить полностью параллельную топологию с несколькими писателями к столу. Дополнительные сведения см. в статье [Вывод данных Azure Stream Analytics в базу данных SQL Azure](../stream-analytics/stream-analytics-sql-output-perf.md).
   - **Max количество пакетов**: Рекомендуемый верхний предел на количество записей, отправленных с каждой транзакцией навалом вставки.  
    Для получения дополнительной информации об обработке ошибок вывода можно просмотреть [политики ошибок вывода в Azure Stream Analytics.](../stream-analytics/stream-analytics-output-error-policy.md)  

    ![начать работу](media/sql-database-stream-analytics/start-job.png)

8. Как только вы начнете задание, вы увидите задание «Запуск» в списке и сможете принять следующие действия: 
   - **Запустите/остановите задание:** Если задание запущено, вы можете остановить работу. Если задание остановлено, вы можете начать работу. 
   - **Отоденать задание**: Вы можете отсеить запрос. Если вы хотите сделать больше изменений в работу ex, добавьте больше входов / выходов, а затем открыть работу в Stream Analytics. Опция «Оторите» отключается при работе. 
   - **Предварительный просмотр таблицы вывода**: Вы можете просмотреть таблицу в редакторе запросов S'L. 
   - **Откройте в Stream Analytics:** Откройте задание в службе Stream Analytics для просмотра мониторинга, отладки деталей задания. 


    ![поток аналитики рабочих мест](media/sql-database-stream-analytics/jobs.png)






## <a name="next-steps"></a>Дальнейшие действия

- [Документация по Azure Stream Analytics](https://docs.microsoft.com/azure/stream-analytics/)
- [Шаблоны решений Azure Stream Analytics](../stream-analytics/stream-analytics-solution-patterns.md)
