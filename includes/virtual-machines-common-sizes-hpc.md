---
title: включить файл
description: включить файл
services: virtual-machines
author: vermagit
ms.service: virtual-machines
ms.topic: include
ms.date: 04/26/2019
ms.author: azcspmt;jonbeck;cynthn;amverma
ms.custom: include file
ms.openlocfilehash: 006a44e42ed209b6f0e614b92f97e43ec30b99ef
ms.sourcegitcommit: f4f626d6e92174086c530ed9bf3ccbe058639081
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/25/2019
ms.locfileid: "75467041"
---
Виртуальные машины, оптимизированные для Azure HPC, предназначены для повышения производительности класса, масштабируемости MPI и экономичности различных реальных приложений.
 
## <a name="infiniband-networking-for-large-scale-hpc"></a>Сеть InfiniBand для высокомасштабируемых HPC
HBv2 VMS 200 ГБ/с — Mellanox HDR InfiniBand, а для виртуальных машин ХБ и HC — 100 ГБ/с Mellanox ЕДР InfiniBand. Каждый из этих типов виртуальных машин подключен в неблокирующем дереве FAT для обеспечения оптимальной и стабильной производительности RDMA.

HBv2 виртуальные машины поддерживают адаптивную маршрутизацию и динамический подключенный транспорт (ДКТ, дополнительно к стандартным транспортам RC и обновления). Эти функции улучшают производительность, масштабируемость и согласованность приложений, а их использование настоятельно рекомендуется.  

Виртуальные машины HBv2, ХБ и HC поддерживают стандартные драйверы Mellanox/ОФЕД. Таким образом, поддерживаются все команды RDMA и типы MPI. Каждый из этих типов виртуальных машин также поддерживает аппаратную разгрузку совокупных объемов MPI для повышения производительности приложения.
 
Исходная виртуальная машина серии H, функция 56 ГБ/с Mellanox FDR InfiniBand. Чтобы использовать интерфейс InfiniBand для серии H, клиенты должны выполнить развертывание с использованием официально поддерживаемых образов, относящихся к этому типу виртуальной машины, из Azure Marketplace. 


## <a name="hbv2-series"></a>Серия HBv2
Виртуальные машины серии HBv2 оптимизированы для приложений, управляемых с помощью пропускной способности памяти, например "жидкие Dynamics", "анализ с конечными элементами" и "моделирование молекулярного". HBv2 VMS 120 ядра процессора AMD ЕПИК 7742, 4 ГБ ОЗУ на ядро ЦП и без одновременной многопоточности. Каждая виртуальная машина HBv2 предоставляет до 340 ГБ/с для пропускной способности памяти и до 4 операций FP64 вычислений. 

Хранилище класса Premium: поддерживается

| Размер | Виртуальных ЦП | Процессор | Память (ГБ) | Пропускная способность памяти ГБ/с | Базовая частота ЦП (ГГц) | Частота ядер (ГГц, пик) | Частота с одним ядром (ГГц, пик) | Производительность RDMA (ГБ/с) | Поддержка MPI | Хранилище Temp (ГБ) | Макс. количество дисков данных | Максимальное число сетевых адаптеров Ethernet |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Standard_HB120rs | 120 | AMD ЕПИК 7742 | 480 | 350 | 2.45 | 2.45 | 3.4 | 200 | Все | 480 + 960 | 8 | 1 |

<br>

## <a name="hb-series"></a>Серия HB
Виртуальные машины серии HB оптимизированы для приложений, которые работают с учетом пропускной способности памяти. Например, такие приложения применяются в отрасли гидродинамики, а также для явного анализа конечных элементов и моделирования погодных условий. ХБ VMS 60 ядра процессора AMD ЕПИК 7551, 4 ГБ ОЗУ на ядро ЦП и без одновременной многопоточности. Виртуальная машина ХБ предоставляет до 260 ГБ/с для пропускной способности памяти.  

ACU: 199-216

Хранилище класса Premium: поддерживается

Кэширование в хранилище класса Premium: поддерживается

| Размер | Виртуальных ЦП | Процессор | Память (ГиБ) | Пропускная способность памяти гиб/с | Базовая частота ЦП (ГГц) | Частота ядер (ГГц, пик) | Частота с одним ядром (ГГц, пик) | Производительность RDMA (гиб/с) | Поддержка MPI | Временное хранилище, Гиб | Макс. количество дисков данных | Максимальное число сетевых адаптеров Ethernet |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Standard_HB60rs | 60 | AMD ЕПИК 7551 | 240 | 263 | 2.0 | 2.55 | 2.55 | 100 | Все | 700 | 4 | 1 |

<br>

## <a name="hc-series"></a>Серия HC
Виртуальные машины серии HC оптимизированы для приложений, управляемых несжатыми вычислениями, например неявным анализом конечных элементов, молекулярное Dynamics и вычислительными химия. Виртуальные машины серии HC оснащены 44 ядрами процессоров Intel Xeon Platinum 8168 с 8 ГБ ОЗУ на ядро ЦП. Технология Hyper-Threading не поддерживается. Платформа Intel Xeon Platinum поддерживает обширную экосистему программных средств Intel, таких как библиотека Intel Math Kernel. 

ACU: 297-315

Хранилище класса Premium: поддерживается

Кэширование в хранилище класса Premium: поддерживается


| Размер | Виртуальных ЦП | Процессор | Память (ГиБ) | Пропускная способность памяти гиб/с | Базовая частота ЦП (ГГц) | Частота ядер (ГГц, пик) | Частота с одним ядром (ГГц, пик) | Производительность RDMA (гиб/с) | Поддержка MPI | Временное хранилище, Гиб | Макс. количество дисков данных | Максимальное число сетевых адаптеров Ethernet |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Standard_HC44rs | 44 | Intel Xeon Platinum 8168 | 352 | 191 | 2.7 | 3.4 | 3,7 | 100 | Все | 700 | 4 | 1 |


<br>

## <a name="h-series"></a>Серия H
Виртуальные машины серии H оптимизированы для приложений, которые управляются высокой частотой ЦП или большими объемами памяти на базовые требования. Виртуальные машины серии H, компоненты 8 или 16 процессоров Intel Xeon 3 2667 v3, до 14 ГБ ОЗУ на ядро ЦП и без технологии Hyper-Threading. Виртуальная машина серии H предоставляет до 80 ГБ/с для пропускной способности памяти.

ACU: 290–300

Хранилище класса Premium: не поддерживается

Кэширование в хранилище класса Premium: не поддерживается

| Размер | Виртуальных ЦП | Процессор | Память (ГиБ) | Пропускная способность памяти гиб/с | Базовая частота ЦП (ГГц) | Частота ядер (ГГц, пик) | Частота с одним ядром (ГГц, пик) | Производительность RDMA (гиб/с) | Поддержка MPI | Временное хранилище, Гиб | Макс. количество дисков данных | Максимальное число сетевых адаптеров Ethernet |
| --- | --- |--- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Standard_H8 | 8 | Intel Xeon, версия 3, 2667 v3 | 56 | 40 | 3.2 | 3.3 | 3.6 | - | Intel 5. x, MS-MPI | 1000 | 32 | 2 |
| Standard_H16 | 16 | Intel Xeon, версия 3, 2667 v3 | 112 | 80 | 3.2 | 3.3 | 3.6 |  - | Intel 5. x, MS-MPI | 2000 | 64 | 4 |
| Standard_H8m | 8 | Intel Xeon, версия 3, 2667 v3 | 112 | 40 | 3.2 | 3.3 | 3.6 | - | Intel 5. x, MS-MPI | 1000 | 32 | 2 |
| Standard_H16m | 16 | Intel Xeon, версия 3, 2667 v3 | 224 | 80 | 3.2 | 3.3 | 3.6 | - | Intel 5. x, MS-MPI | 2000 | 64 | 4 |
| Standard_H16r <sup>1</sup> | 16 | Intel Xeon, версия 3, 2667 v3 | 112 | 80 | 3.2 | 3.3 | 3.6 | 56 | Intel 5. x, MS-MPI | 2000 | 64 | 4 |
| Standard_H16mr <sup>1</sup> | 16 | Intel Xeon, версия 3, 2667 v3 | 224 | 80 | 3.2 | 3.3 | 3.6 | 56 | Intel 5. x, MS-MPI | 2000 | 64 | 4 |

<sup>1</sup> для приложений MPI сеть с выделенной внутренней сетью RDMA включена в сети FDR InfiniBand.

<br>
